{
    "directed": true,
    "multigraph": false,
    "graph": {},
    "nodes": [
        {
            "title": "Deep learning",
            "info_text": "Deep learning is a subset of machine learning that focuses on utilizing neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be either supervised, semi-supervised or unsupervised.\nSome common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\nEarly forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.",
            "categories": [
                "Category:All articles with dead external links",
                "Category:All articles with links needing disambiguation",
                "Category:All articles with unsourced statements",
                "Category:Articles prone to spam from June 2015",
                "Category:Articles with dead external links from June 2024",
                "Category:Articles with links needing disambiguation from November 2024",
                "Category:Articles with permanently dead external links",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from August 2024",
                "Category:Articles with unsourced statements from July 2016"
            ],
            "id": 0
        },
        {
            "title": "Andrew Zisserman",
            "info_text": "Andrew Zisserman  (born 1957) is a British computer scientist and a professor at the University of Oxford, and a researcher in computer vision. As of 2014 he is affiliated with DeepMind.",
            "categories": [
                "Category:1957 births",
                "Category:Alumni of the University of Cambridge",
                "Category:Alumni of the University of Sunderland",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:British computer scientists",
                "Category:Computer vision researchers",
                "Category:EngvarB from July 2017",
                "Category:Fellows of the Royal Society",
                "Category:Living people"
            ],
            "id": 1
        },
        {
            "title": "Huawei",
            "info_text": "Huawei Technologies Co., Ltd. (\"Huawei\" sometimes stylized as \"HUAWEI\") ( HWAH-way,  WAH-way; Chinese: \u534e\u4e3a; pinyin: ) is a Chinese multinational conglomerate technology corporation headquartered in Longgang District, Shenzhen, Guangdong province. It designs, develops, manufactures and sells digital telecommunications equipment, consumer electronics, smart devices, distributed operating systems, electric vehicle autonomous driving systems, and various rooftop solar products. The corporation was founded in 1987 by Ren Zhengfei, a former officer in the People's Liberation Army (PLA).\nInitially focused on manufacturing phone switches, Huawei has expanded to more than 170 countries to include building telecommunications network infrastructures, providing equipment, operational and consulting services, and manufacturing communications devices for the consumer market. It overtook Ericsson in 2012 as the largest telecommunications equipment manufacturer in the world. Huawei surpassed Apple and Samsung, in 2018 and 2020, respectively, to become the largest smartphone manufacturer worldwide. As of 2024, Huawei's biggest area of business is in telecommunications equipment. Its largest customer is the Chinese government.\nAmidst its rise, Huawei has been accused of intellectual property infringement, for which it has settled with Cisco. Questions regarding the extent of state influence on Huawei have revolved around its national champions role in China, subsidies and financing support from state entities, and reactions of the Chinese government in light of opposition in certain countries to Huawei's participation in 5G. Its software and equipment have been linked to the mass surveillance of Uyghurs and Xinjiang internment camps, drawing sanctions from the United States.\nThe company has faced difficulties in some countries arising from concerns that its equipment may enable surveillance by the Chinese government due to perceived connections with the country's military and intelligence agencies. Huawei has argued that critics such as the US government have not shown evidence of espionage. Experts say that China's 2014 Counter-Espionage Law and 2017 National Intelligence Law can compel Huawei and other companies to cooperate with state intelligence. In 2012, Australian and US intelligence agencies concluded that a hack on Australia's telecom networks was conducted by or through Huawei, although the two network operators have disputed that information.\nIn January 2018, the United States alleged that its sanctions against Iran were violated by Huawei, which was subsequently restricted from doing business with American companies. The US government also requested the extradition of Huawei's chief financial officer from Canada. In June 2019, Huawei cut jobs at its Santa Clara research center, and in December, Ren said it was moving the center to Canada. In 2020, Huawei agreed to sell the Honor brand to a state-owned enterprise of the Shenzhen government to \"ensure its survival\" under US sanctions. In November 2022, the Federal Communications Commission (FCC) banned sales or import of equipment made by Huawei out of national security concerns, and other countries such as all members of the Five Eyes, Quad members India and Japan, and ten European Union states have since also banned or restricted Huawei products.",
            "categories": [
                "Category:All articles containing potentially dated statements",
                "Category:All articles with dead external links",
                "Category:All pages needing factual verification",
                "Category:Articles containing Chinese-language text",
                "Category:Articles containing overly long summaries",
                "Category:Articles containing potentially dated statements from 2010",
                "Category:Articles containing potentially dated statements from 2019",
                "Category:Articles containing potentially dated statements from 2023",
                "Category:Articles containing potentially dated statements from 2024",
                "Category:Articles with Chinese-language sources (zh)"
            ],
            "id": 2
        },
        {
            "title": "Stop sign",
            "info_text": "A stop sign is a traffic sign designed to notify drivers that they must come to a complete stop and make sure the intersection (or railroad crossing) is safely clear of vehicles and pedestrians before continuing past the sign. In many countries, the sign is a red octagon with the word STOP, in either English, the national language of that particular country, or both, displayed in white or yellow. The Vienna Convention on Road Signs and Signals also allows an alternative version: a red circle with a red inverted triangle with either a white or yellow background, and a black or dark blue STOP. Some countries may also use other types, such as Japan's inverted red triangle stop sign. Particular regulations regarding appearance, installation, and compliance with the signs vary by some jurisdictions.",
            "categories": [
                "Category:1915 introductions",
                "Category:All articles lacking reliable references",
                "Category:All articles with unsourced statements",
                "Category:American inventions",
                "Category:Articles containing Amharic-language text",
                "Category:Articles containing Arabic-language text",
                "Category:Articles containing Armenian-language text",
                "Category:Articles containing Burmese-language text",
                "Category:Articles containing Chinese-language text",
                "Category:Articles containing French-language text"
            ],
            "id": 3
        },
        {
            "title": "ChatGPT",
            "info_text": "ChatGPT is a generative artificial intelligence chatbot developed by OpenAI and launched in 2022. It is currently based on the GPT-4o large language model (LLM). ChatGPT can generate human-like conversational responses and enables users to refine and steer a conversation towards a desired length, format, style, level of detail, and language. It is credited with accelerating the AI boom, which has led to ongoing rapid investment in and public attention to the field of artificial intelligence (AI). Some observers have raised concern about the potential of ChatGPT and similar programs to displace human intelligence, enable plagiarism, or fuel misinformation.\nBy January 2023, ChatGPT had become what was then the fastest-growing consumer software application in history, gaining over 100 million users in two months and contributing to the growth of OpenAI's current valuation of $86 billion. ChatGPT's release spurred the release of competing products, including Gemini, Claude, Llama, Ernie, and Grok. Microsoft launched Copilot, initially based on OpenAI's GPT-4. In May 2024, a partnership between Apple Inc. and OpenAI was announced, in which ChatGPT was integrated into the Apple Intelligence feature of Apple operating systems. As of July 2024, ChatGPT's website is among the 10 most-visited websites globally.\nChatGPT is built on OpenAI's proprietary series of generative pre-trained transformer (GPT) models and is fine-tuned for conversational applications using a combination of supervised learning and reinforcement learning from human feedback. Successive user prompts and replies are considered at each conversation stage as context. ChatGPT was released as a freely available research preview, but due to its popularity, OpenAI now operates the service on a freemium model. Users on its free tier can access GPT-4o. The ChatGPT subscriptions \"Plus\", \"Team\", and \"Enterprise\" provide additional features such as DALL-E 3 image generation and an increased usage limit.\n\n",
            "categories": [
                "Category:2022 software",
                "Category:All Wikipedia articles written in American English",
                "Category:All articles containing potentially dated statements",
                "Category:Articles containing potentially dated statements from November 2023",
                "Category:Articles containing simplified Chinese-language text",
                "Category:Articles with short description",
                "Category:CS1 Brazilian Portuguese-language sources (pt-br)",
                "Category:CS1 Chinese-language sources (zh)",
                "Category:CS1 European Spanish-language sources (es-es)",
                "Category:CS1 Italian-language sources (it)"
            ],
            "id": 4
        },
        {
            "title": "Gradient descent",
            "info_text": "Gradient descent is a method for unconstrained mathematical optimization. It is a first-order iterative algorithm for minimizing a differentiable multivariate function.\nThe idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a trajectory that maximizes that function; the procedure is then known as gradient ascent.\nIt is particularly useful in machine learning for minimizing the cost or loss function. Gradient descent should not be confused with local search algorithms, although both are iterative methods for optimization.\nGradient descent is generally attributed to Augustin-Louis Cauchy, who first suggested it in 1847. Jacques Hadamard independently proposed a similar method in 1907. Its convergence properties for non-linear optimization problems were first studied by Haskell Curry in 1944, with the method becoming increasingly well-studied and used in the following decades.\nA simple extension of gradient descent, stochastic gradient descent, serves as the most basic algorithm used for training most deep networks today.",
            "categories": [
                "Category:Articles with short description",
                "Category:Commons category link is on Wikidata",
                "Category:First order methods",
                "Category:Gradient methods",
                "Category:Mathematical optimization",
                "Category:Optimization algorithms and methods",
                "Category:Short description matches Wikidata",
                "Category:Webarchive template wayback links"
            ],
            "id": 5
        },
        {
            "title": "Alan Turing",
            "info_text": "Alan Mathison Turing (; 23 June 1912 \u2013 7 June 1954) was an English mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist. He was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general-purpose computer. Turing is widely considered to be the father of theoretical computer science.\nBorn in London, Turing was raised in southern England. He graduated from King's College, Cambridge, and in 1938, earned a doctorate degree from Princeton University. During World War II, Turing worked for the Government Code and Cypher School at Bletchley Park, Britain's codebreaking centre that produced Ultra intelligence. He led Hut 8, the section responsible for German naval cryptanalysis. Turing devised techniques for speeding the breaking of German ciphers, including improvements to the pre-war Polish bomba method, an electromechanical machine that could find settings for the Enigma machine. He played a crucial role in cracking intercepted messages that enabled the Allies to defeat the Axis powers in many engagements, including the Battle of the Atlantic.\nAfter the war, Turing worked at the National Physical Laboratory, where he designed the Automatic Computing Engine, one of the first designs for a stored-program computer. In 1948, Turing joined Max Newman's Computing Machine Laboratory at the Victoria University of Manchester, where he helped develop the Manchester computers and became interested in mathematical biology. Turing wrote on the chemical basis of morphogenesis and predicted oscillating chemical reactions such as the Belousov\u2013Zhabotinsky reaction, first observed in the 1960s. Despite these accomplishments, he was never fully recognised during his lifetime because much of his work was covered by the Official Secrets Act.\nIn 1952, Turing was prosecuted for homosexual acts. He accepted hormone treatment, a procedure commonly referred to as chemical castration, as an alternative to prison. Turing died on 7 June 1954, aged 41, from cyanide poisoning. An inquest determined his death as suicide, but the evidence is also consistent with accidental poisoning. \nFollowing a campaign in 2009, British prime minister Gordon Brown made an official public apology for \"the appalling way [Turing] was treated\". Queen Elizabeth II granted a pardon in 2013. The term \"Alan Turing law\" is used informally to refer to a 2017 law in the UK that retroactively pardoned men cautioned or convicted under historical legislation that outlawed homosexual acts.\nTuring left an extensive legacy in mathematics and computing which has become widely recognised with statues and many things named after him, including an annual award for computing innovation. His portrait appears on the Bank of England \u00a350 note, first released on 23 June 2021 to coincide with his birthday. The audience vote in a 2019 BBC series named Turing the greatest person of the 20th century.",
            "categories": [
                "Category:1912 births",
                "Category:1954 deaths",
                "Category:1954 suicides",
                "Category:20th-century English LGBTQ people",
                "Category:20th-century English mathematicians",
                "Category:20th-century English philosophers",
                "Category:20th-century atheists",
                "Category:Academics of the University of Manchester",
                "Category:Academics of the University of Manchester Institute of Science and Technology",
                "Category:Alan Turing"
            ],
            "id": 6
        },
        {
            "title": "Starfish",
            "info_text": "Starfish or sea stars are star-shaped echinoderms belonging to the class Asteroidea (). Common usage frequently finds these names being also applied to ophiuroids, which are correctly referred to as brittle stars or basket stars. Starfish are also known as asteroids due to being in the class Asteroidea. About 1,900 species of starfish live on the seabed in all the world's oceans, from warm, tropical zones to frigid, polar regions. They are found from the intertidal zone down to abyssal depths, at 6,000 m (20,000 ft) below the surface.\nStarfish are marine invertebrates. They typically have a central disc and usually five arms, though some species have a larger number of arms. The aboral or upper surface may be smooth, granular or spiny, and is covered with overlapping plates. Many species are brightly coloured in various shades of red or orange, while others are blue, grey or brown. Starfish have tube feet operated by a hydraulic system and a mouth at the centre of the oral or lower surface. They are opportunistic feeders and are mostly predators on benthic invertebrates. Several species have specialized feeding behaviours including eversion of their stomachs and suspension feeding. They have complex life cycles and can reproduce both sexually and asexually. Most can regenerate damaged parts or lost arms and they can shed arms as a means of defense. The Asteroidea occupy several significant ecological roles. Starfish, such as the ochre sea star (Pisaster ochraceus) and the reef sea star (Stichaster australis), have become widely known as examples of the keystone species concept in ecology. The tropical crown-of-thorns starfish (Acanthaster planci) is a voracious predator of coral throughout the Indo-Pacific region, and the Northern Pacific seastar is on the list of the World's 100 Worst Invasive Alien Species.\nThe fossil record for starfish is ancient, dating back to the Ordovician around 450 million years ago, but it is rather sparse, as starfish tend to disintegrate after death. Only the ossicles and spines of the animal are likely to be preserved, making remains hard to locate. With their appealing symmetrical shape, starfish have played a part in literature, legend, design and popular culture. They are sometimes collected as curios, used in design or as logos, and in some cultures, despite possible toxicity, they are eaten.\n\n",
            "categories": [
                "Category:Articles containing video clips",
                "Category:Articles with 'species' microformats",
                "Category:Articles with short description",
                "Category:Asteroidea",
                "Category:CS1: unfit URL",
                "Category:CS1 Japanese-language sources (ja)",
                "Category:CS1 maint: multiple names: authors list",
                "Category:Commons link is on Wikidata",
                "Category:Extant Ordovician first appearances",
                "Category:Featured articles"
            ],
            "id": 7
        },
        {
            "title": "AI takeover",
            "info_text": "An AI takeover is an imagined scenario in which artificial intelligence (AI) emerges as the dominant form of intelligence on Earth and computer programs or robots effectively take control of the planet away from the human species, which relies on human intelligence. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising. Stories of AI takeovers have been popular throughout science fiction, but recent advancements have made the threat more real. Some public figures, such as Stephen Hawking and Elon Musk, have advocated research into precautionary measures to ensure future superintelligent machines remain under human control.",
            "categories": [
                "Category:Articles with excerpts",
                "Category:Articles with short description",
                "Category:Doomsday scenarios",
                "Category:Existential risk from artificial general intelligence",
                "Category:Future problems",
                "Category:Science fiction themes",
                "Category:Short description is different from Wikidata",
                "Category:Technophobia",
                "Category:Webarchive template wayback links"
            ],
            "id": 8
        },
        {
            "title": "Black box",
            "info_text": "In science, computing, and engineering, a black box is a system which can be viewed in terms of its inputs and outputs (or transfer characteristics), without any knowledge of its internal workings. Its implementation is \"opaque\" (black). The term can be used to refer to many inner workings, such as those of a transistor, an engine, an algorithm, the human brain, or an institution or government.\nTo analyze an open system with a typical \"black box approach\", only the behavior of the stimulus/response will be accounted for, to infer the (unknown) box. The usual representation of this \"black box system\" is a data flow diagram centered in the box.\nThe opposite of a black box is a system where the inner components or logic are available for inspection, which is most commonly referred to as a white box (sometimes also known as a \"clear box\" or a \"glass box\").\n\n",
            "categories": [
                "Category:All articles to be expanded",
                "Category:Articles to be expanded from June 2019",
                "Category:Articles with short description",
                "Category:Cybernetics",
                "Category:Metaphors referring to objects",
                "Category:Metatheory of science",
                "Category:Programming principles",
                "Category:Short description matches Wikidata",
                "Category:Software design patterns",
                "Category:Systems theory"
            ],
            "id": 9
        },
        {
            "title": "Generative adversarial network",
            "info_text": "A generative adversarial network (GAN) is a class of machine learning frameworks and a prominent framework for approaching generative artificial intelligence. The concept was initially developed by Ian Goodfellow and his colleagues in June 2014. In a GAN, two neural networks contest with each other in the form of a zero-sum game, where one agent's gain is another agent's loss.\nGiven a training set, this technique learns to generate new data with the same statistics as the training set. For example, a GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers, having many realistic characteristics. Though originally proposed as a form of generative model for unsupervised learning, GANs have also proved useful for semi-supervised learning, fully supervised learning, and reinforcement learning.\nThe core idea of a GAN is based on the \"indirect\" training through the discriminator, another neural network that can tell how \"realistic\" the input seems, which itself is also being updated dynamically. This means that the generator is not trained to minimize the distance to a specific image, but rather to fool the discriminator. This enables the model to learn in an unsupervised manner.\nGANs are similar to mimicry in evolutionary biology, with an evolutionary arms race between both networks.",
            "categories": [
                "Category:Articles with short description",
                "Category:CS1 maint: multiple names: authors list",
                "Category:CS1 maint: numeric names: authors list",
                "Category:Cognitive science",
                "Category:Generative artificial intelligence",
                "Category:Neural network architectures",
                "Category:Short description is different from Wikidata",
                "Category:Unsupervised learning",
                "Category:Use mdy dates from April 2021",
                "Category:Webarchive template wayback links"
            ],
            "id": 10
        },
        {
            "title": "Music and artificial intelligence",
            "info_text": "Music and artificial intelligence (music and AI) is the development of music software programs which use AI to generate music. As with applications in other fields, AI in music also simulates mental tasks. A prominent feature is the capability of an AI algorithm to learn based on past data, such as in computer accompaniment technology, wherein the AI is capable of listening to a human performer and performing accompaniment. Artificial intelligence also drives interactive composition technology, wherein a computer composes music in response to a live performance. There are other AI applications in music that cover not only music composition, production, and performance but also how music is marketed and consumed. Several music player programs have also been developed to use voice recognition and natural language processing technology for music voice control. Current research includes the application of AI in music composition, performance, theory and digital sound processing.\nErwin Panofksy proposed that in all art, there existed three levels of meaning: primary meaning, or the natural subject; secondary meaning, or the conventional subject; and tertiary meaning, the intrinsic content of the subject. AI music explores the foremost of these, creating music without the \"intention\" which is usually behind it, leaving composers who listen to machine-generated pieces feeling unsettled by the lack of apparent meaning.\n\n",
            "categories": [
                "Category:Articles with excerpts",
                "Category:Articles with short description",
                "Category:Artificial intelligence art",
                "Category:CS1: long volume value",
                "Category:CS1 German-language sources (de)",
                "Category:CS1 maint: numeric names: authors list",
                "Category:Cognitive musicology",
                "Category:Computer music",
                "Category:Short description is different from Wikidata",
                "Category:Use dmy dates from November 2024"
            ],
            "id": 11
        },
        {
            "title": "Bernard Widrow",
            "info_text": "Bernard Widrow (born December 24, 1929) is a U.S. professor of electrical engineering at Stanford University.  He is the co-inventor of the Widrow\u2013Hoff least mean squares filter (LMS) adaptive algorithm with his then doctoral student Ted Hoff.  The LMS algorithm led to the ADALINE and MADALINE artificial neural networks and to the backpropagation technique. He made other fundamental contributions to the development of  signal processing in the fields of geophysics, adaptive antennas, and adaptive filtering. A summary of his work is.\nHe is the namesake of \"Uncle Bernie's Rule\": the training sample size should be 10 times the number of weights in a network.\n\n",
            "categories": [
                "Category:1929 births",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Artificial intelligence researchers",
                "Category:Benjamin Franklin Medal (Franklin Institute) laureates",
                "Category:CS1: long volume value",
                "Category:IEEE Centennial Medal laureates",
                "Category:Living people",
                "Category:Massachusetts Institute of Technology alumni",
                "Category:Members of the United States National Academy of Engineering"
            ],
            "id": 12
        },
        {
            "title": "Rectifier (neural networks)",
            "info_text": "In the context of artificial neural networks, the rectifier or ReLU (rectified linear unit) activation function is an activation function defined as the non-negative part of its argument, i.e., the ramp function:\n\n  \n    \n      \n        ReLU\n        \u2061\n        (\n        x\n        )\n        =\n        \n          x\n          \n            +\n          \n        \n        =\n        max\n        (\n        0\n        ,\n        x\n        )\n        =\n        \n          \n            \n              x\n              +\n              \n                |\n              \n              x\n              \n                |\n              \n            \n            2\n          \n        \n        =\n        \n          \n            {\n            \n              \n                \n                  x\n                \n                \n                  \n                    if \n                  \n                  x\n                  >\n                  0\n                  ,\n                \n              \n              \n                \n                  0\n                \n                \n                  x\n                  \u2264\n                  0\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle \\operatorname {ReLU} (x)=x^{+}=\\max(0,x)={\\frac {x+|x|}{2}}={\\begin{cases}x&{\\text{if }}x>0,\\\\0&x\\leq 0\\end{cases}}}\n  \n\nwhere \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n is the input to a neuron. This is analogous to half-wave rectification in electrical engineering.\nReLU is one of the most popular activation functions for artificial neural networks, and finds application in computer vision and speech recognition using deep neural nets and computational neuroscience.\nIt was first used by Alston Householder in 1941 as a mathematical abstraction of biological neural networks. It was introduced by Kunihiko Fukushima in 1969 in the context of visual feature extraction in hierarchical neural networks. It was later argued that it has strong biological motivations and mathematical justifications. In 2011, ReLU activation enabled training deep supervised neural networks without unsupervised pre-training, compared to the widely used activation functions prior to 2011, e.g., the logistic sigmoid (which is inspired by probability theory; see logistic regression) and its more practical counterpart, the hyperbolic tangent. \n\n",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from April 2024",
                "Category:Artificial neural networks",
                "Category:CS1 errors: periodical ignored",
                "Category:Short description is different from Wikidata"
            ],
            "id": 13
        },
        {
            "title": "Neural Computation (journal)",
            "info_text": "Neural Computation is a monthly peer-reviewed scientific journal covering all aspects of neural computation, including modeling the brain and the design and construction of neurally-inspired information processing systems. It was established in 1989 and is published by MIT Press. The editor-in-chief is Terrence J. Sejnowski (Salk Institute for Biological Studies).\nAccording to the Journal Citation Reports, the journal has a 2021 impact factor of 3.278.\n\n",
            "categories": [
                "Category:Academic journals established in 1989",
                "Category:All stub articles",
                "Category:Articles with outdated impact factors from 2021",
                "Category:Articles with short description",
                "Category:Cognitive science journals",
                "Category:English-language journals",
                "Category:Hybrid open access journals (infobox)",
                "Category:MIT Press academic journals",
                "Category:Monthly journals",
                "Category:Monthly journals (infobox)"
            ],
            "id": 14
        },
        {
            "title": "Artificial intelligence in healthcare",
            "info_text": "Artificial intelligence in healthcare is the application of artificial intelligence (AI) to analyze and understand complex medical and healthcare data. In some cases, it can exceed or augment human capabilities by providing better or faster ways to diagnose, treat, or prevent disease.\nAs widespread use of AI in healthcare is relatively new, research is ongoing into its application in various subdisciplines of medicine and related industries. AI programs are applied to practices such as diagnostics, treatment protocol development, drug development, personalized medicine, and patient monitoring and care. Because radiographs are the most common imaging tests conducted in radiology departments, the potential for AI to help with triage and interpretation of radiographs is particularly noteworthy.\nUsing AI also presents unprecedented ethical concerns related to issues such as data privacy, automation of jobs, and amplifying already existing biases. Furthermore, new technologies such as AI are often resisted by healthcare leaders, leading to slow and erratic adoption. In contrast, there are also several cases where AI has been put to use in healthcare without proper testing. A systematic review and thematic analysis in 2023 showed that most stakeholders including health professionals, patients, and the general public doubted that care involving AI could be empathetic. Moreover, meta-studies have found that the scientific literature on AI in healthcare often suffers from a lack of reproducibility.",
            "categories": [
                "Category:Applications of artificial intelligence",
                "Category:Articles with excerpts",
                "Category:Articles with short description",
                "Category:CS1 maint: DOI inactive as of December 2024",
                "Category:CS1 maint: multiple names: authors list",
                "Category:Computing in medical imaging",
                "Category:Cybernetics",
                "Category:Health software",
                "Category:Medical devices",
                "Category:Short description is different from Wikidata"
            ],
            "id": 15
        },
        {
            "title": "Reservoir computing",
            "info_text": "Reservoir computing is a framework for computation derived from recurrent neural network theory that maps input signals into higher dimensional computational spaces through the dynamics of a fixed, non-linear system called a reservoir. After the input signal is fed into the reservoir, which is treated as a \"black box,\" a simple readout mechanism is trained to read the state of the reservoir and map it to the desired output. The first key benefit of this framework is that training is performed only at the readout stage, as the reservoir dynamics are fixed. The second is that the computational power of naturally available systems, both classical and quantum mechanical, can be used to reduce the effective computational cost.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:Artificial neural networks",
                "Category:Short description is different from Wikidata"
            ],
            "id": 16
        },
        {
            "title": "CAPTCHA",
            "info_text": "A CAPTCHA ( KAP-ch\u0259) is a type of challenge\u2013response test used in computing to determine whether the user is human in order to deter bot attacks and spam.\nThe term was coined in 2003 by Luis von Ahn, Manuel Blum, Nicholas J. Hopper, and John Langford. It is a contrived acronym for \"Completely Automated Public Turing test to tell Computers and Humans Apart.\" A historically common type of CAPTCHA (displayed as reCAPTCHA v1) was first invented in 1997 by two groups working in parallel. This form of CAPTCHA requires entering a sequence of letters or numbers from a distorted image. Because the test is administered by a computer, in contrast to the standard Turing test that is administered by a human, CAPTCHAs are sometimes described as reverse Turing tests.\nTwo widely used CAPTCHA services are Google's reCAPTCHA and the independent hCaptcha. It takes the average person approximately 10 seconds to solve a typical CAPTCHA.",
            "categories": [
                "Category:2003 neologisms",
                "Category:20th-century inventions",
                "Category:All articles needing examples",
                "Category:All articles needing rewrite",
                "Category:Articles needing examples from October 2022",
                "Category:Articles with short description",
                "Category:Computer vision",
                "Category:Internet forum terminology",
                "Category:Pages using Sister project links with default search",
                "Category:Pages using Sister project links with hidden wikidata"
            ],
            "id": 17
        },
        {
            "title": "Google Voice Search",
            "info_text": "Google Voice Search or Search by Voice is a Google product that allows users to use Google Search by speaking on a mobile phone or computer, i.e. have the device search for data upon entering information on what to search into the device by speaking.\nInitially named as Voice Action which allowed one to give speech commands to an Android phone. Once only available for the U.S. English locale \u2013 commands were later recognizable and replied to in American, British, and Indian English; Filipino, French, Italian, German, and Spanish.\nIn Android 4.1+ (Jelly Bean), it was merged with Google Now.\nIn August 2014, a new feature was added to Google Voice Search, allowing users to choose up to five languages and the app will automatically understand the spoken language.\n\n",
            "categories": [
                "Category:2012 software",
                "Category:All articles with unsourced statements",
                "Category:All pages needing cleanup",
                "Category:Articles needing cleanup from December 2024",
                "Category:Articles with sections that need to be turned into prose from December 2024",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from September 2020",
                "Category:CS1 errors: generic name",
                "Category:Google Search",
                "Category:Internet properties established in 2012"
            ],
            "id": 18
        },
        {
            "title": "Nature (journal)",
            "info_text": "Nature is a British weekly scientific journal founded and based in London, England. As a multidisciplinary publication, Nature features peer-reviewed research from a variety of academic disciplines, mainly in science and technology. It has core editorial offices across the United States, continental Europe, and Asia under the international scientific publishing company Springer Nature. Nature was one of the world's most cited scientific journals by the Science Edition of the 2022 Journal Citation Reports (with an ascribed impact factor of 50.5), making it one of the world's most-read and most prestigious academic journals. As of 2012, it claimed an online readership of about three million unique readers per month.\nFounded in autumn 1869, Nature was first circulated by Norman Lockyer and Alexander MacMillan as a public forum for scientific innovations. The mid-20th century facilitated an editorial expansion for the journal; Nature redoubled its efforts in explanatory and scientific journalism. The late 1980s and early 1990s saw the creation of a network of editorial offices outside of Britain and the establishment of ten new supplementary, speciality publications (e.g. Nature Materials). Since the late 2000s, dedicated editorial and current affairs columns are created weekly, and electoral endorsements are featured. The primary source of the journal remains, as established at its founding, research scientists; editing standards are primarily concerned with technical readability. Each issue also features articles that are of general interest to the scientific community, namely business, funding, scientific ethics, and research breakthroughs. There are also sections on books, arts, and short science fiction stories.\nThe main research published in Nature consists mostly of papers (articles or letters) in lightly edited form. They are highly technical and dense, but, due to imposed text limits, they are typically summaries of larger work. Innovations or breakthroughs in any scientific or technological field are featured in the journal as either letters or news articles. The papers that have been published in this journal are internationally acclaimed for maintaining high research standards. Conversely, due to the journal's exposure, it has at various times been a subject of controversy for its handling of academic dishonesty, the scientific method, and news coverage. Fewer than 8% of submitted papers are accepted for publication. In 2007, Nature (together with Science) received the Prince of Asturias Award for Communications and Humanity.\nNature mostly publishes research articles. Spotlight articles are not research papers but mostly news or magazine style papers and hence do not count towards impact factor nor receive similar recognition as research articles. Some spotlight articles are also paid by partners or sponsors.\n\n",
            "categories": [
                "Category:1869 establishments in England",
                "Category:All articles containing potentially dated statements",
                "Category:All articles with unsourced statements",
                "Category:All pages needing factual verification",
                "Category:Articles containing potentially dated statements from 2012",
                "Category:Articles intentionally citing retracted publications",
                "Category:Articles needing the year an event occurred from September 2023",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from June 2020",
                "Category:Commons category link is on Wikidata"
            ],
            "id": 19
        },
        {
            "title": "Deception",
            "info_text": "Deception is the act of convincing one or many recipients of untrue information. The person creating the deception knows it to be false while the receiver of the message has a tendency to believe it (although it is not always the case). It is often done for personal gain or advantage. Deception can involve dissimulation, propaganda and sleight of hand as well as distraction, camouflage or concealment. There is also self-deception. It can also be called, with varying subjective implications, beguilement, deceit, bluff, mystification, ruse, or subterfuge.\nDeception is a major relational transgression that often leads to feelings of betrayal and distrust. Deception violates relational rules and is considered to be a negative violation of expectations. Most people expect friends, relational partners, and even strangers to be truthful most of the time. If people expected most conversations to be untruthful, talking and communicating with others would require distraction and misdirection to acquire reliable information. A significant amount of deception occurs between some romantic and relational partners.\nDeceit and dishonesty can also form grounds for civil litigation in tort, or contract law (where it is known as misrepresentation or fraudulent misrepresentation if deliberate), or give rise to criminal prosecution for fraud. It also forms a vital part of psychological warfare in denial and deception.",
            "categories": [
                "Category:All articles covered by WikiProject Wikify",
                "Category:All articles needing references cleanup",
                "Category:All articles to be expanded",
                "Category:All articles with empty sections",
                "Category:All articles with style issues",
                "Category:Articles covered by WikiProject Wikify from January 2024",
                "Category:Articles to be expanded from December 2021",
                "Category:Articles with empty sections from December 2021",
                "Category:Articles with multiple maintenance issues",
                "Category:Articles with short description"
            ],
            "id": 20
        },
        {
            "title": "Adobe Firefly",
            "info_text": "Adobe Firefly is a generative machine learning text-to-image model included as part of Adobe Creative Cloud. It is currently being tested in an open beta phase.\nAdobe Firefly is developed using Adobe's Sensei platform. Firefly is trained with images from Creative Commons, Wikimedia and Flickr Commons as well as 300 million images and videos in Adobe Stock and the public domain. It uses image data sets to generate various designs. It learns from user feedback by adjusting its designs.\nFirefly for Enterprise was released on June 22, 2023.\n\n",
            "categories": [
                "Category:2023 software",
                "Category:Adobe software",
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from June 2023",
                "Category:Graphic design",
                "Category:Short description matches Wikidata",
                "Category:Text-to-image generation"
            ],
            "id": 21
        },
        {
            "title": "Sea urchin",
            "info_text": "Sea urchins or urchins () are typically spiny, globular animals, echinoderms in the class Echinoidea. About 950 species live on the seabed, inhabiting all oceans and depth zones from the intertidal to 5,000 metres (16,000 ft; 2,700 fathoms). Their tests (hard shells) are round and spiny, typically from 3 to 10 cm (1 to 4 in) across. Sea urchins move slowly, crawling with their tube feet, and sometimes pushing themselves with their spines. They feed primarily on algae but also eat slow-moving or sessile animals. Their predators include sharks, sea otters, starfish, wolf eels, and triggerfish.\nLike all echinoderms, adult sea urchins have fivefold symmetry with their pluteus larvae featuring bilateral (mirror) symmetry; The latter indicates that they belong to the Bilateria, along with chordates, arthropods, annelids and molluscs.  Sea urchins are found in every ocean and in every climate, from the tropics to the polar regions, and inhabit marine benthic (sea bed) habitats, from rocky shores to hadal zone depths. The fossil record of the Echinoids dates from the Ordovician period, some 450 million years ago. The closest echinoderm relatives of the sea urchin are the sea cucumbers (Holothuroidea), which like them are deuterostomes, a clade that includes the chordates. (Sand dollars are a separate order in the sea urchin class Echinoidea.)\nThe animals have been studied since the 19th century as model organisms in developmental biology, as their embryos were easy to observe. That has continued with studies of their genomes because of their unusual fivefold symmetry and relationship to chordates. Species such as the slate pencil urchin are popular in aquaria, where they are useful for controlling algae. Fossil urchins have been used as protective amulets.",
            "categories": [
                "Category:Animal developmental biology",
                "Category:Animal models",
                "Category:Articles containing Alutiiq-language text",
                "Category:Articles containing Ancient Greek (to 1453)-language text",
                "Category:Articles containing Chinese-language text",
                "Category:Articles containing French-language text",
                "Category:Articles containing Italian-language text",
                "Category:Articles containing Japanese-language text",
                "Category:Articles containing M\u0101ori-language text",
                "Category:Articles containing Standard Malay-language text"
            ],
            "id": 22
        },
        {
            "title": "Prompt engineering",
            "info_text": "Prompt engineering is the process of structuring or crafting an instruction in order to produce the best possible output from a generative artificial intelligence (AI) model.\nA prompt is natural language text describing the task that an AI should perform. A prompt for a text-to-text language model can be a query, a command, or a longer statement including context, instructions, and conversation history. Prompt engineering may involve phrasing a query, specifying a style, choice of words and grammar, providing relevant context, or describing a character for the AI to mimic.\nWhen communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\". Prompting a text-to-image model may involve adding, removing, emphasizing, and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.\n\n",
            "categories": [
                "Category:2022 neologisms",
                "Category:All articles lacking reliable references",
                "Category:Articles lacking reliable references from October 2024",
                "Category:Articles with short description",
                "Category:Deep learning",
                "Category:Generative artificial intelligence",
                "Category:Linguistics",
                "Category:Machine learning",
                "Category:Natural language processing",
                "Category:Pages using multiple image with auto scaled images"
            ],
            "id": 23
        },
        {
            "title": "Domain knowledge",
            "info_text": "Domain knowledge is knowledge of a specific discipline or field  in contrast to general (or domain-independent) knowledge. The term is often used in reference to a more general discipline\u2014for example, in describing a software engineer who has general knowledge of computer programming as well as domain knowledge about developing programs for a particular industry. People with domain knowledge are often regarded as specialists or experts in their field.\n\n",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All articles with unsourced statements",
                "Category:Articles needing additional references from November 2024",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from November 2024",
                "Category:Knowledge engineering",
                "Category:Short description matches Wikidata"
            ],
            "id": 24
        },
        {
            "title": "ISSN",
            "info_text": "An International Standard Serial Number (ISSN) is an eight-digit serial number used to uniquely identify a periodical publication (periodical), such as a magazine. The ISSN is especially helpful in distinguishing between serials with the same title. ISSNs are used in ordering, cataloging, interlibrary loans, and other practices in connection with serial literature.\nThe ISSN system was first drafted as an International Organization for Standardization (ISO) international standard in 1971 and published as ISO 3297 in 1975. ISO subcommittee TC 46/SC 9 is responsible for maintaining the standard.\nWhen a serial with the same content is published in more than one media type, a different ISSN is assigned to each media type. For example, many serials are published both in print and electronic media. The ISSN system refers to these types as print ISSN (p-ISSN) and electronic ISSN (e-ISSN). Consequently, as defined in ISO 3297:2007, every serial in the ISSN system is also assigned a linking ISSN (ISSN-L), typically the same as the ISSN assigned to the serial in its first published medium, which links together all ISSNs assigned to the serial in every medium.\n\n",
            "categories": [
                "Category:All articles containing potentially dated statements",
                "Category:Articles containing potentially dated statements from December 2016",
                "Category:Articles with short description",
                "Category:CS1 French-language sources (fr)",
                "Category:CS1 German-language sources (de)",
                "Category:Checksum algorithms",
                "Category:Computer-related introductions in 1976",
                "Category:ISO standards",
                "Category:Library science",
                "Category:Pages using Sister project links with hidden wikidata"
            ],
            "id": 25
        },
        {
            "title": "Google Neural Machine Translation",
            "info_text": "Google Neural Machine Translation (GNMT) was a neural machine translation (NMT) system developed by Google and introduced in November 2016 that used an artificial neural network to increase fluency and accuracy in Google Translate. The neural network consisted of two main blocks, an encoder and a decoder, both of LSTM architecture with 8 1024-wide layers each and a simple 1-layer 1024-wide feedforward attention mechanism connecting them. The total number of parameters has been variously described as over 160 million, approximately 210 million, 278 million or 380 million. It used WordPiece tokenizer, and beam search decoding strategy. It ran on Tensor Processing Units.\nBy 2020, the system had been replaced by another deep learning system based on a Transformer encoder and an RNN decoder.\nGNMT improved on the quality of translation by applying an example-based (EBMT) machine translation method in which the system learns from millions of examples of language translation. GNMT's proposed architecture of system learning was first tested on over a hundred languages supported by Google Translate. With the large end-to-end framework, the system learns over time to create better, more natural translations. GNMT attempts to translate whole sentences at a time, rather than just piece by piece. The GNMT network can undertake interlingual machine translation by encoding the semantics of the sentence, rather than by memorizing phrase-to-phrase translations.",
            "categories": [
                "Category:Applications of artificial intelligence",
                "Category:Articles with short description",
                "Category:Artificial neural networks",
                "Category:CS1 Dutch-language sources (nl)",
                "Category:CS1 errors: missing periodical",
                "Category:Computational linguistics",
                "Category:Google Translate",
                "Category:Machine translation",
                "Category:Short description matches Wikidata",
                "Category:Tasks of natural language processing"
            ],
            "id": 26
        },
        {
            "title": "Semantic Scholar",
            "info_text": "Semantic Scholar is a research tool for scientific literature powered by artificial intelligence. It is developed at the Allen Institute for AI and was publicly released in November 2015. Semantic Scholar uses modern techniques in natural language processing to support the research process, for example by providing automatically generated summaries of scholarly papers. The Semantic Scholar team is actively researching the use of artificial intelligence in natural language processing, machine learning, human\u2013computer interaction, and information retrieval.\nSemantic Scholar began as a database for the topics of computer science, geoscience, and neuroscience. In 2017, the system began including biomedical literature in its corpus. As of September 2022, it includes over 200 million publications from all fields of science.",
            "categories": [
                "Category:All articles containing potentially dated statements",
                "Category:All articles with unsourced statements",
                "Category:Applications of artificial intelligence",
                "Category:Articles containing potentially dated statements from August 2019",
                "Category:Articles containing potentially dated statements from September 2022",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from March 2023",
                "Category:Bibliographic databases in computer science",
                "Category:Internet properties established in 2015",
                "Category:Scholarly search services"
            ],
            "id": 27
        },
        {
            "title": "Softmax function",
            "info_text": "The softmax function, also known as softargmax:\u200a184\u200a or normalized exponential function,:\u200a198\u200a converts a vector of K real numbers into a probability distribution of K possible outcomes. It is a generalization of the logistic function to multiple dimensions, and is used in multinomial logistic regression. The softmax function is often used as the last activation function of a neural network to normalize the output of a network to a probability distribution over predicted output classes.\n\n",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles with example Julia code",
                "Category:Articles with example Python (programming language) code",
                "Category:Articles with example R code",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from March 2024",
                "Category:Artificial neural networks",
                "Category:Computational neuroscience",
                "Category:Exponentials",
                "Category:Functions and mappings"
            ],
            "id": 28
        },
        {
            "title": "Bhuvana Ramabhadran",
            "info_text": "Bhuvana Ramabhadran is a speech recognition researcher for Google, and a former distinguished researcher at the IBM T. J. Watson Research Center.\nRamabhadran earned a Ph.D. in electrical engineering in 1995 from the University of Houston. Her dissertation, An object-oriented expert system for the identification of foci of epileptiform activity, was supervised by John R. Glover. She joined IBM in the same year.\nIn 2017, Ramabhadran was elected as an IEEE Fellow \"for contributions to speech recognition and language processing\", and a Fellow of the International Speech Communication Association, \"for contributions to the fields of speech recognition research and applications\".\n\n",
            "categories": [
                "Category:American computer scientists",
                "Category:American women computer scientists",
                "Category:Articles with short description",
                "Category:Fellows of the IEEE",
                "Category:IBM Research computer scientists",
                "Category:Living people",
                "Category:Short description matches Wikidata",
                "Category:Speech processing researchers",
                "Category:Use dmy dates from June 2023",
                "Category:Use list-defined references from June 2023"
            ],
            "id": 29
        },
        {
            "title": "Siri",
            "info_text": "Siri (  SEER-ee, backronym Speech Interpretation and Recognition Interface) is a digital assistant purchased, developed, and popularized by Apple Inc., which is included in the iOS, iPadOS, watchOS, macOS, tvOS, audioOS, and visionOS operating systems. It uses voice queries, gesture based control, focus-tracking and a natural-language user interface to answer questions, make recommendations, and perform actions by delegating requests to a set of Internet services. With continued use, it adapts to users' individual language usages, searches, and preferences, returning individualized results.\nSiri is a spin-off from a project developed by the SRI International Artificial Intelligence Center. Its speech recognition engine was provided by Nuance Communications, and it uses advanced machine learning technologies to function. Its original American, British, and Australian voice actors recorded their respective voices around 2005, unaware of the recordings' eventual usage. Siri was released as an app for iOS in February 2010. Two months later, Apple acquired it and integrated it into the iPhone 4s at its release on 4 October 2011, removing the separate app from the iOS App Store. Siri has since been an integral part of Apple's products, having been adapted into other hardware devices including newer iPhone models, iPad, iPod Touch, Mac, AirPods, Apple TV, HomePod, and Apple Vision Pro.\nSiri supports a wide range of user commands, including performing phone actions, checking basic information, scheduling events and reminders, handling device settings, searching the Internet, navigating areas, finding information on entertainment, and being able to engage with iOS-integrated apps. With the release of iOS 10, in 2016, Apple opened up limited third-party access to Siri, including third-party messaging apps, as well as payments, ride-sharing, and Internet calling apps. With the release of iOS 11, Apple updated Siri's voice and added support for follow-up questions, language translation, and additional third-party actions.\niOS 17 and iPadOS 17 enabled users to activate Siri by simply saying \u201cSiri\u201d, while the previous command, \u201cHey Siri\u201d,  is still supported. Siri was upgraded to using Apple Intelligence on iOS 18, iPadOS 18, and macOS Sequoia, replacing the logo.\nSiri's original release on iPhone 4s on Oct 2011 received mixed reviews. It received praise for its voice recognition and contextual knowledge of user information, including calendar appointments, but was criticized for requiring stiff user commands and having a lack of flexibility. It was also criticized for lacking information on certain nearby places and for its inability to understand certain English accents. In 2016 and 2017, a number of media reports said that Siri lacked innovation, particularly against new competing voice assistants. The reports concerned Siri's limited set of features, \"bad\" voice recognition, and undeveloped service integrations as causing trouble for Apple in the field of artificial intelligence and cloud-based services; the basis for the complaints reportedly due to stifled development, as caused by Apple's prioritization of user privacy and executive power struggles within the company. Its launch was also overshadowed by the death of Steve Jobs, which occurred one day after the launch.",
            "categories": [
                "Category:2010 mergers and acquisitions",
                "Category:2011 software",
                "Category:All articles covered by WikiProject Wikify",
                "Category:All pages needing cleanup",
                "Category:Apple Inc. acquisitions",
                "Category:Apple Inc. software",
                "Category:Articles covered by WikiProject Wikify from December 2024",
                "Category:Articles with short description",
                "Category:CS1 errors: generic title",
                "Category:IOS software"
            ],
            "id": 30
        },
        {
            "title": "Parameter",
            "info_text": "A parameter (from Ancient Greek  \u03c0\u03b1\u03c1\u03ac (par\u00e1) 'beside, subsidiary' and  \u03bc\u03ad\u03c4\u03c1\u03bf\u03bd (m\u00e9tron) 'measure'), generally, is any characteristic that can help in defining or classifying a particular system (meaning an event, project, object, situation, etc.). That is, a parameter is an element of a system that is useful, or critical, when identifying the system, or when evaluating its performance, status, condition, etc.\nParameter has more specific meanings within various disciplines, including mathematics, computer programming, engineering, statistics, logic, linguistics, and electronic musical composition.\nIn addition to its technical uses, there are also extended uses, especially in non-scientific contexts, where it is used to mean defining characteristics or boundaries, as in the phrases 'test parameters' or 'game play parameters'.",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All articles with unsourced statements",
                "Category:Articles needing additional references from August 2011",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from January 2024",
                "Category:Articles with unsourced statements from July 2009",
                "Category:Mathematical terminology",
                "Category:Short description is different from Wikidata",
                "Category:Wikipedia articles incorporating the Cite Grove template",
                "Category:Wikipedia articles incorporating the Cite Grove template without a link parameter"
            ],
            "id": 31
        },
        {
            "title": "Neural radiance field",
            "info_text": "A neural radiance field (NeRF) is a method based on deep learning for reconstructing a three-dimensional representation of a scene from two-dimensional images. The NeRF model enables downstream applications of novel view synthesis, scene geometry reconstruction, and obtaining the reflectance properties of the scene. Additional scene properties such as camera poses may also be jointly learned. First introduced in 2020, it has since gained significant attention for its potential applications in computer graphics and content creation.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:Computer vision",
                "Category:Machine learning algorithms",
                "Category:Short description is different from Wikidata"
            ],
            "id": 32
        },
        {
            "title": "Inverse problem",
            "info_text": "An inverse problem in science is the process of calculating from a set of observations the causal factors that produced them: for example, calculating an image in X-ray computed tomography, source reconstruction in acoustics, or calculating the density of the Earth from measurements of its gravity field. It is called an inverse problem because it starts with the effects and then calculates the causes. It is the inverse of a forward problem, which starts with the causes and then calculates the effects.\nInverse problems are some of the most important mathematical problems in science and mathematics because they tell us about parameters that we cannot directly observe. They can be found in system identification, optics, radar, acoustics, communication theory, signal processing, medical imaging, computer vision, geophysics, oceanography, astronomy, remote sensing, natural language processing, machine learning, nondestructive testing, slope stability analysis and many other fields.",
            "categories": [
                "Category:All articles with dead external links",
                "Category:All articles with unsourced statements",
                "Category:Articles with dead external links from March 2024",
                "Category:Articles with permanently dead external links",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from November 2019",
                "Category:Articles with unsourced statements from September 2020",
                "Category:CS1 maint: location",
                "Category:Inverse problems",
                "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link"
            ],
            "id": 33
        },
        {
            "title": "Probability distribution",
            "info_text": "In probability theory and statistics, a probability distribution is the mathematical function that gives the probabilities of occurrence of possible outcomes for an experiment. It is a mathematical description of a random phenomenon in terms of its sample space and the probabilities of events (subsets of the sample space).\nFor instance, if X is used to denote the outcome of a coin toss (\"the experiment\"), then the probability distribution of X would take the value 0.5 (1 in 2 or 1/2) for X = heads, and 0.5 for X = tails (assuming that the coin is fair). More commonly, probability distributions are used to compare the relative occurrence of many different random values.\nProbability distributions can be defined in different ways and for discrete or for continuous variables. Distributions with special properties or for especially important applications are given specific names.\n\n",
            "categories": [
                "Category:Articles with excerpts",
                "Category:Articles with short description",
                "Category:CS1 maint: location missing publisher",
                "Category:CS1 maint: multiple names: authors list",
                "Category:CS1 maint: numeric names: authors list",
                "Category:Commons link from Wikidata",
                "Category:Mathematical and quantitative methods (economics)",
                "Category:Probability distributions",
                "Category:Short description is different from Wikidata"
            ],
            "id": 34
        },
        {
            "title": "Artificial intelligence",
            "info_text": "Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence\u2014the ability to complete any task performed by a human on an at least equal level\u2014is among the field's long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture, and by the early 2020s many billions of dollars were being invested in AI and the field experienced rapid ongoing progress in what has become known as the AI boom. The emergence of advanced generative AI in the midst of the AI boom and its ability to create and modify content exposed several unintended consequences and harms in the present and raised concerns about the risks of AI and its long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.",
            "categories": [
                "Category:All accuracy disputes",
                "Category:All articles with unsourced statements",
                "Category:Articles with Internet Encyclopedia of Philosophy links",
                "Category:Articles with disputed statements from July 2024",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from June 2024",
                "Category:Artificial intelligence",
                "Category:CS1: long volume value",
                "Category:CS1 German-language sources (de)",
                "Category:CS1 Japanese-language sources (ja)"
            ],
            "id": 35
        },
        {
            "title": "Deepfake",
            "info_text": "Deepfakes (a portmanteau of 'deep learning' and 'fake') are images, videos, or audio which are edited or generated using artificial intelligence tools, and which may depict real or non-existent people. They are a type of synthetic media and modern form of a Media prank.\nWhile the act of creating fake content is not new, deepfakes uniquely leverage the technological tools and techniques of machine learning and artificial intelligence, including facial recognition algorithms and artificial neural networks such as variational autoencoders (VAEs) and generative adversarial networks (GANs). In turn the field of image forensics develops techniques to detect manipulated images. Deepfakes have garnered widespread attention for their potential use in creating child sexual abuse material, celebrity pornographic videos, revenge porn, fake news, hoaxes, bullying, and financial fraud.\nAcademics have raised concerns about the potential for deep fakes to be used to promote disinformation and hate speech, and interfere with elections. The information technology industry and governments have responded with recommendations to detect and limit their use.\nFrom traditional entertainment to gaming, deepfake technology has evolved to be increasingly convincing and available to the public, allowing for the disruption of the entertainment and media industries.",
            "categories": [
                "Category:2018 neologisms",
                "Category:AI safety",
                "Category:All articles with unsourced statements",
                "Category:Articles containing Japanese-language text",
                "Category:Articles containing video clips",
                "Category:Articles that may be too long from November 2024",
                "Category:Articles with limited geographic scope from November 2021",
                "Category:Articles with short description",
                "Category:Articles with trivia sections from November 2024",
                "Category:Articles with unsourced statements from June 2024"
            ],
            "id": 36
        },
        {
            "title": "Ovarian cancer",
            "info_text": "Ovarian cancer is a cancerous tumor of an ovary. It may originate from the ovary itself or more commonly from communicating nearby structures such as fallopian tubes or the inner lining of the abdomen. The ovary is made up of three different cell types including epithelial cells, germ cells, and stromal cells. When these cells become abnormal, they have the ability to divide and form tumors. These cells can also invade or spread to other parts of the body. When this process begins, there may be no or only vague symptoms. Symptoms become more noticeable as the cancer progresses. These symptoms may include bloating, vaginal bleeding, pelvic pain, abdominal swelling, constipation, and loss of appetite, among others. Common areas to which the cancer may spread include the lining of the abdomen, lymph nodes, lungs, and liver.\nThe risk of ovarian cancer increases with age. Most cases of ovarian cancer develop after menopause. It is also more common in women who have ovulated more over their lifetime. This includes those who have never had children, those who began ovulation at a younger age and those who reach menopause at an older age. Other risk factors include hormone therapy after menopause, fertility medication, and obesity. Factors that decrease risk include hormonal birth control, tubal ligation, pregnancy, and breast feeding. About 10% of cases are related to inherited genetic risk; women with mutations in the genes BRCA1 or BRCA2 have about a 50% chance of developing the disease. Some family cancer syndromes such as hereditary nonpolyposis colon cancer and Peutz-Jeghers syndrome also increase the risk of developing ovarian cancer. Epithelial ovarian carcinoma is the most common type of ovarian cancer, comprising more than 95% of cases. There are five main subtypes of ovarian carcinoma, of which high-grade serous carcinoma (HGSC) is the most common. Less common types of ovarian cancer include germ cell tumors and sex cord stromal tumors. A diagnosis of ovarian cancer is confirmed through a biopsy of tissue, usually removed during surgery.\nScreening is not recommended in women who are at average risk, as evidence does not support a reduction in death and the high rate of false positive tests may lead to unneeded surgery, which is accompanied by its own risks. Those at very high risk may have their ovaries removed as a preventive measure. If caught and treated in an early stage, ovarian cancer is often curable. Treatment usually includes some combination of surgery, radiation therapy, and chemotherapy. Outcomes depend on the extent of the disease, the subtype of cancer present, and other medical conditions. The overall five-year survival rate in the United States is 49%. Outcomes are worse in the developing world.\nIn 2020, new cases occurred in approximately 313,000 women. In 2019 it resulted in 13,445 deaths in the United States. Death from ovarian cancer increased globally between 1990 and 2017 by 84.2%. Ovarian cancer is the second-most common gynecologic cancer in the United States. It causes more deaths than any other cancer of the female reproductive system. Among women it ranks fifth in cancer-related deaths. The typical age of diagnosis is 63. Death from ovarian cancer is more common in North America and Europe than in Africa and Asia. In the United States, it is more common in White and Hispanic women than Black or American Indian women. \n\n",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles tagged with the inline citation overkill template from September 2021",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from February 2021",
                "Category:Articles with unsourced statements from March 2018",
                "Category:Articles with unsourced statements from November 2017",
                "Category:CS1: long volume value",
                "Category:Citation overkill",
                "Category:Gynaecological cancer",
                "Category:Ovarian cancer"
            ],
            "id": 37
        },
        {
            "title": "Google DeepMind",
            "info_text": "DeepMind Technologies Limited, trading as Google DeepMind or simply DeepMind, is a British-American artificial intelligence research laboratory which serves as a subsidiary of Alphabet Inc.. Founded in the UK in 2010, it was acquired by Google in 2014 and merged with Google AI's Google Brain division to become Google DeepMind in April 2023. The company is based in London, with research centres in Canada, France, Germany, and the United States.\nDeepMind introduced neural Turing machines (neural networks that can access external memory like a conventional Turing machine), resulting in a computer that loosely resembles short-term memory in the human brain.\nDeepMind has created neural network models to play video games and board games. It made headlines in 2016 after its AlphaGo program beat a human professional Go player Lee Sedol, a world champion, in a five-game match, which was the subject of a documentary film. A more general program, AlphaZero, beat the most powerful programs playing go, chess and shogi (Japanese chess) after a few days of play against itself using reinforcement learning.\nIn 2020, DeepMind made significant advances in the problem of protein folding with AlphaFold. In July 2022, it was announced that over 200 million predicted protein structures, representing virtually all known proteins, would be released on the AlphaFold database. AlphaFold's database of predictions achieved state of the art records on benchmark tests for protein folding algorithms, although each individual prediction still requires confirmation by experimental tests. AlphaFold3 was released in May 2024, making structural predictions for the interaction of proteins with various molecules. It achieved new standards on various benchmarks, raising the state of the art accuracies from 28 and 52 percent to 65 and 76 percent.\n\n",
            "categories": [
                "Category:2010 establishments in England",
                "Category:2014 mergers and acquisitions",
                "Category:All articles lacking reliable references",
                "Category:All articles with unsourced statements",
                "Category:Alphabet Inc.",
                "Category:Alphabet Inc. subsidiaries",
                "Category:Applied machine learning",
                "Category:Articles lacking reliable references from December 2017",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from September 2020"
            ],
            "id": 38
        },
        {
            "title": "Quasi-Newton method",
            "info_text": "In numerical analysis, a quasi-Newton method is an iterative numerical method used either to find zeroes or to find local maxima and minima of functions via an iterative recurrence formula much like the one for Newton's method, except using approximations of the derivatives of the functions in place of exact derivatives. Newton's method requires the Jacobian matrix of all partial derivatives of a multivariate function when used to search for zeros or the Hessian matrix when used for finding extrema. Quasi-Newton methods, on the other hand, can be used when the Jacobian matrices or Hessian matrices are unavailable or are impractical to compute at every iteration.\nSome iterative methods that reduce to Newton's method, such as sequential quadratic programming, may also be considered quasi-Newton methods.",
            "categories": [
                "Category:All articles needing additional references",
                "Category:Articles needing additional references from January 2025",
                "Category:Articles with short description",
                "Category:Quasi-Newton methods",
                "Category:Short description matches Wikidata"
            ],
            "id": 39
        },
        {
            "title": "Ideogram (text-to-image model)",
            "info_text": "Ideogram is a freemium text-to-image model developed by Ideogram, Inc. using deep learning methodologies to generate digital images from natural language descriptions known as prompts. The model is capable of generating legible text in the images compared to other text-to-image models.\n\n",
            "categories": [
                "Category:2023 establishments in Canada",
                "Category:All stub articles",
                "Category:Articles with short description",
                "Category:Artificial intelligence art",
                "Category:Artificial intelligence stubs",
                "Category:Official website different in Wikidata and Wikipedia",
                "Category:Short description is different from Wikidata",
                "Category:Text-to-image generation",
                "Category:Use mdy dates from June 2024"
            ],
            "id": 40
        },
        {
            "title": "Handwriting recognition",
            "info_text": "Handwriting recognition (HWR), also known as handwritten text recognition (HTR), is the ability of a computer to receive and interpret intelligible handwritten input from sources such as paper documents, photographs, touch-screens and other devices. The image of the written text may be sensed \"off line\" from a piece of paper by optical scanning (optical character recognition) or intelligent word recognition. Alternatively, the movements of the pen tip may be sensed \"on line\", for example by a pen-based computer screen surface, a generally easier task as there are more clues available. A handwriting recognition system handles formatting, performs correct segmentation into characters, and finds the most possible words.",
            "categories": [
                "Category:All articles containing potentially dated statements",
                "Category:Articles containing potentially dated statements from 2006",
                "Category:Articles with short description",
                "Category:Handwriting recognition",
                "Category:Machine learning task",
                "Category:Pointing-device text input",
                "Category:Short description matches Wikidata",
                "Category:Use dmy dates from January 2023",
                "Category:Webarchive template wayback links"
            ],
            "id": 41
        },
        {
            "title": "Amazon Alexa",
            "info_text": "Amazon Alexa, or, Alexa, is a virtual assistant technology largely based on a Polish speech synthesizer named Ivona, bought by Amazon in 2013. It was first used in the Amazon Echo smart speaker and the Amazon Echo Dot, Echo Studio and Amazon Tap speakers developed by Amazon Lab126. It is capable of natural language processing for tasks such as voice interaction, music playback, creating to-do lists, setting alarms, streaming podcasts, playing audiobooks, providing weather, traffic, sports, other real-time information and news. Alexa can also control several smart devices as a home automation system.  Alexa capabilities may be extended by installing \"skills\" (additional functionality developed by third-party vendors, in other settings more commonly called apps) such as weather programs and audio features. It performs these tasks using automatic speech recognition, natural language processing, and other forms of weak AI.\nMost devices with Alexa allow users to activate the device using a wake-word (such as Alexa or Amazon); other devices (such as the Amazon mobile app on iOS or Android and Amazon Dash Wand) require the user to click a button to activate Alexa's listening mode, although, some phones also allow a user to say a command, such as \"Alexa, or Alexa go to bed\" or \"Alexa wake\".\nAs of November 2018, more than 10,000 Amazon employees worked on Alexa and related products. In January 2019, Amazon's devices team announced that they had sold over 100 million Alexa-enabled devices.\nIn September 2019, Amazon launched many new devices achieving many records while competing with the world's smart home industry. The new Echo Studio became the first smart speaker with 360 sound and Dolby sound. Other new devices included an Echo dot with a clock behind the fabric, a new third-generation Amazon Echo, Echo Show 8, a plug-in Echo device, Echo Flex, Alexa built-in wireless earphones, Echo buds, Alexa built-in spectacles, Echo frames, an Alexa built-in Ring, and Echo Loop as well as the Echo Show generation.",
            "categories": [
                "Category:2014 software",
                "Category:All articles containing potentially dated statements",
                "Category:All articles lacking reliable references",
                "Category:All articles with unsourced statements",
                "Category:Amazon Alexa",
                "Category:Amazon Web Services",
                "Category:Articles containing potentially dated statements from April 2019",
                "Category:Articles containing potentially dated statements from August 2018",
                "Category:Articles containing potentially dated statements from May 2017",
                "Category:Articles containing potentially dated statements from November 2018"
            ],
            "id": 42
        },
        {
            "title": "Facial recognition system",
            "info_text": "A facial recognition system is a technology potentially capable of matching a human face from a digital image or a video frame against a database of faces. Such a system is typically employed to authenticate users through ID verification services, and works by pinpointing and measuring facial features from a given image.\nDevelopment began on similar systems in the 1960s, beginning as a form of computer application. Since their inception, facial recognition systems have seen wider uses in recent times on smartphones and in other forms of technology, such as robotics. Because computerized facial recognition involves the measurement of a human's physiological characteristics, facial recognition systems are categorized as biometrics. Although the accuracy of facial recognition systems as a biometric technology is lower than iris recognition, fingerprint image acquisition, palm recognition or voice recognition, it is widely adopted due to its contactless process. Facial recognition systems have been deployed in advanced human\u2013computer interaction, video surveillance, law enforcement, passenger screening, decisions on employment and housing and automatic indexing of images.\nFacial recognition systems are employed throughout the world today by governments and private companies. Their effectiveness varies, and some systems have previously been scrapped because of their ineffectiveness. The use of facial recognition systems has also raised controversy, with claims that the systems violate citizens' privacy, commonly make incorrect identifications, encourage gender norms and racial profiling, and do not protect important biometric data. The appearance of synthetic media such as deepfakes has also raised concerns about its security. These claims have led to the ban of facial recognition systems in several cities in the United States. Growing societal concerns led social networking company Meta Platforms to shut down its Facebook facial recognition system in 2021, deleting the face scan data of more than one billion users. The change represented one of the largest shifts in facial recognition usage in the technology's history. IBM also stopped offering facial recognition technology due to similar concerns.",
            "categories": [
                "Category:All Wikipedia articles in need of updating",
                "Category:All articles containing potentially dated statements",
                "Category:All articles with unsourced statements",
                "Category:Articles containing potentially dated statements from 2004",
                "Category:Articles containing potentially dated statements from 2016",
                "Category:Articles containing potentially dated statements from 2017",
                "Category:Articles containing potentially dated statements from 2018",
                "Category:Articles containing potentially dated statements from April 2021",
                "Category:Articles containing potentially dated statements from June 2020",
                "Category:Articles containing potentially dated statements from September 2021"
            ],
            "id": 43
        },
        {
            "title": "Allen Newell",
            "info_text": "Allen Newell (March 19, 1927 \u2013 July 19, 1992) was an American researcher in computer science and cognitive psychology at the RAND Corporation and at Carnegie Mellon University's School of Computer Science, Tepper School of Business, and Department of Psychology. He contributed to the Information Processing Language (1956) and two of the earliest AI programs, the Logic Theorist (1956) and the General Problem Solver (1957) (with Herbert A. Simon). He was awarded the ACM's A.M. Turing Award along with Herbert A. Simon in 1975 for their contributions to artificial intelligence and the psychology of human cognition.\n\n",
            "categories": [
                "Category:1927 births",
                "Category:1992 deaths",
                "Category:20th-century American psychologists",
                "Category:APA Distinguished Scientific Award for an Early Career Contribution to Psychology recipients",
                "Category:American cognitive psychologists",
                "Category:American consciousness researchers and theorists",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Carnegie Mellon University faculty",
                "Category:Computational psychologists"
            ],
            "id": 44
        },
        {
            "title": "Andrew Ng",
            "info_text": "Andrew Yan-Tak Ng (Chinese: \u5433\u6069\u9054; born 1976) is a British-American computer scientist and technology entrepreneur focusing on machine learning and artificial intelligence (AI). Ng was a cofounder and head of Google Brain and was the former Chief Scientist at Baidu, building the company's Artificial Intelligence Group into a team of several thousand people.\nNg is an adjunct professor at Stanford University (formerly associate professor and Director of its Stanford AI Lab or SAIL). Ng has also worked in the field of online education, cofounding Coursera and DeepLearning.AI. He has spearheaded many efforts to \"democratize deep learning\" teaching over 8 million students through his online courses. Ng is renowned globally in computer science, recognized in Time magazine's 100 Most Influential People in 2012 and Fast Company's Most Creative People in 2014. His influence extends to being named in the Time100 AI Most Influential People in 2023.\nIn 2018, he launched and currently heads the AI Fund, initially a $175-million investment fund for backing artificial intelligence startups. He has founded Landing AI, which provides AI-powered SaaS products.\nOn April 11, 2024, Amazon announced the appointment of Ng to its board of directors.",
            "categories": [
                "Category:1976 births",
                "Category:All articles with failed verification",
                "Category:All articles with unsourced statements",
                "Category:American artificial intelligence researchers",
                "Category:American computer businesspeople",
                "Category:American computer scientists",
                "Category:American education businesspeople",
                "Category:American people of Chinese descent",
                "Category:American people of Hong Kong descent",
                "Category:American roboticists"
            ],
            "id": 45
        },
        {
            "title": "Attention (machine learning)",
            "info_text": "Attention is a machine learning method that determines the relative importance of each component in a sequence relative to the other components in that sequence. In natural language processing, importance is represented by \"soft\" weights assigned to each word in a sentence. More generally, attention encodes vectors called token embeddings across a fixed-width sequence that can range from tens to millions of tokens in size.\nUnlike \"hard\" weights, which are computed during the backwards training pass, \"soft\" weights exist only in the forward pass and therefore change with every step of the input. Earlier designs implemented the attention mechanism in a serial recurrent neural network (RNN) language translation system, but a more recent design, namely the transformer, removed the slower sequential RNN and relied more heavily on the faster parallel attention scheme.\nInspired by ideas about attention in humans, the attention mechanism was developed to address the weaknesses of leveraging information from the hidden layers of recurrent neural networks. Recurrent neural networks favor more recent information contained in words at the end of a sentence, while information earlier in the sentence tends to be attenuated. Attention allows a token equal access to any part of a sentence directly, rather than only through the previous state.",
            "categories": [
                "Category:Articles with short description",
                "Category:Machine learning",
                "Category:Short description matches Wikidata"
            ],
            "id": 46
        },
        {
            "title": "Claude (language model)",
            "info_text": "Claude is a family of large language models developed by Anthropic. The first model was released in March 2023.\nThe Claude 3 family, released in March 2024, consists of three models: Haiku optimized for speed, Sonnet balancing capabilities and performance, and Opus designed for complex reasoning tasks. These models can process both text and images, with Claude 3 Opus demonstrating enhanced capabilities in areas like mathematics, programming, and logical reasoning compared to previous versions.\n\n",
            "categories": [
                "Category:2023 software",
                "Category:All Wikipedia articles written in American English",
                "Category:Articles with short description",
                "Category:Chatbots",
                "Category:Large language models",
                "Category:Machine learning",
                "Category:Short description matches Wikidata",
                "Category:Use American English from June 2024",
                "Category:Use mdy dates from September 2024",
                "Category:Virtual assistants"
            ],
            "id": 47
        },
        {
            "title": "LaMDA",
            "info_text": "LaMDA (Language Model for Dialogue Applications) is a family of conversational large language models developed by Google. Originally developed and introduced as Meena in 2020, the first-generation LaMDA was announced during the 2021 Google I/O keynote, while the second generation was announced the following year.\nIn June 2022, LaMDA gained widespread attention when Google engineer Blake Lemoine made claims that the chatbot had become sentient. The scientific community has largely rejected Lemoine's claims, though it has led to conversations about the efficacy of the Turing test, which measures whether a computer can pass for a human. In February 2023, Google announced Bard (now Gemini), a conversational artificial intelligence chatbot powered by LaMDA, to counter the rise of OpenAI's ChatGPT.",
            "categories": [
                "Category:2021 software",
                "Category:2022 controversies in the United States",
                "Category:All Wikipedia articles written in American English",
                "Category:Articles with short description",
                "Category:Chatbots",
                "Category:Google software",
                "Category:Large language models",
                "Category:Philosophy of artificial intelligence",
                "Category:Short description is different from Wikidata",
                "Category:Use American English from June 2022"
            ],
            "id": 48
        },
        {
            "title": "Drug discovery",
            "info_text": "In the fields of medicine, biotechnology, and pharmacology, drug discovery is the process by which new candidate medications are discovered.\nHistorically, drugs were discovered by identifying the active ingredient from traditional remedies or by serendipitous discovery, as with penicillin. More recently, chemical libraries of synthetic small molecules, natural products, or extracts were screened in intact cells or whole organisms to identify substances that had a desirable therapeutic effect in a process known as classical pharmacology. After sequencing of the human genome allowed rapid cloning and synthesis of large quantities of purified proteins, it has become common practice to use high throughput screening of large compounds libraries against isolated biological targets which are hypothesized to be disease-modifying in a process known as reverse pharmacology. Hits from these screens are then tested in cells and then in animals for efficacy.\nModern drug discovery involves the identification of screening hits, medicinal chemistry, and optimization of those hits to increase the affinity, selectivity (to reduce the potential of side effects), efficacy/potency, metabolic stability (to increase the half-life), and oral bioavailability. Once a compound that fulfills all of these requirements has been identified, the process of drug development can continue. If successful, clinical trials are developed.\nModern drug discovery is thus usually a capital-intensive process that involves large investments by pharmaceutical industry corporations as well as national governments (who provide grants and loan guarantees). Despite advances in technology and understanding of biological systems, drug discovery is still a lengthy, \"expensive, difficult, and inefficient process\" with low rate of new therapeutic discovery. In 2010, the research and development cost of each new molecular entity was about US$1.8 billion. In the 21st century, basic discovery research is funded primarily by governments and by philanthropic organizations, while late-stage development is funded primarily by pharmaceutical companies or venture capitalists. To be allowed to come to market, drugs must undergo several successful phases of clinical trials, and pass through a new drug approval process, called the New Drug Application in the United States.\nDiscovering drugs that may be a commercial success, or a public health success, involves a complex interaction between investors, industry, academia, patent laws, regulatory exclusivity, marketing, and the need to balance secrecy with communication. Meanwhile, for disorders whose rarity means that no large commercial success or public health effect can be expected, the orphan drug funding process ensures that people who experience those disorders can have some hope of pharmacotherapeutic advances.\n\n",
            "categories": [
                "Category:All accuracy disputes",
                "Category:All articles with unsourced statements",
                "Category:Articles prone to spam from August 2014",
                "Category:Articles with disputed statements from March 2017",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from March 2017",
                "Category:Articles with unsourced statements from November 2024",
                "Category:CS1 errors: periodical ignored",
                "Category:CS1 maint: multiple names: authors list",
                "Category:CS1 maint: numeric names: authors list"
            ],
            "id": 49
        },
        {
            "title": "Flux (text-to-image model)",
            "info_text": "Flux (also known as FLUX.1) is a text-to-image model developed by Black Forest Labs, based in Freiburg im Breisgau, Germany. Black Forest Labs were founded by former employees of Stability AI. As with other text-to-image models, Flux generates images from natural language descriptions, called prompts.\n\n",
            "categories": [
                "Category:2024 establishments in Germany",
                "Category:All articles containing potentially dated statements",
                "Category:Articles containing potentially dated statements from December 2024",
                "Category:Articles with short description",
                "Category:Artificial intelligence art",
                "Category:CS1 German-language sources (de)",
                "Category:CS1 Japanese-language sources (ja)",
                "Category:Commons category link from Wikidata",
                "Category:Deep learning software applications",
                "Category:Open-source artificial intelligence"
            ],
            "id": 50
        },
        {
            "title": "Gemini (language model)",
            "info_text": "Gemini (formerly known as Bard) is a family of multimodal large language models developed by Google DeepMind, serving as the successor to LaMDA and PaLM 2. Comprising Gemini Ultra, Gemini Pro, Gemini Flash, and Gemini Nano, it was announced on December 6, 2023, positioned as a competitor to OpenAI's GPT-4. It powers the chatbot of the same name.\n\n",
            "categories": [
                "Category:2023 software",
                "Category:All Wikipedia articles written in American English",
                "Category:Articles with short description",
                "Category:CS1 maint: multiple names: authors list",
                "Category:Chatbots",
                "Category:Google DeepMind",
                "Category:Google software",
                "Category:Large language models",
                "Category:Multimodal interaction",
                "Category:Pages using multiple image with auto scaled images"
            ],
            "id": 51
        },
        {
            "title": "Deep Learning (South Park)",
            "info_text": "\"Deep Learning\" is the fourth episode of the twenty-sixth season of the American animated television series South Park, and the 323rd episode of the series overall. Written and directed by Trey Parker, it premiered on March 8, 2023. The episode, which parodies the use of the artificial intelligence chatbot ChatGPT (which is credited as a co-writer for the episode) for text messages, centers upon fourth-grader Stan Marsh, who comes to rely on the software for writing both school essays and romantic texts to his girlfriend Wendy Testaburger, bringing him into conflict with her, his classmates, and school officials.",
            "categories": [
                "Category:All Wikipedia articles written in American English",
                "Category:Articles with short description",
                "Category:ChatGPT",
                "Category:Pages using infobox television episode with unnecessary list markup",
                "Category:Short description is different from Wikidata",
                "Category:South Park season 26 episodes",
                "Category:Television episode articles with short description and disambiguated page names",
                "Category:Television episode articles with short description for single episodes",
                "Category:Television episodes about artificial intelligence",
                "Category:Use American English from January 2025"
            ],
            "id": 52
        },
        {
            "title": "Deep image prior",
            "info_text": "Deep image prior is a type of convolutional neural network used to enhance a given image with no prior training data other than the image itself.\nA neural network is randomly initialized and used as prior to solve inverse problems such as noise reduction, super-resolution, and inpainting. Image statistics are captured by the structure of a convolutional image generator rather than by any previously learned capabilities.\n\n",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All articles that are too technical",
                "Category:All articles with bare URLs for citations",
                "Category:All articles with topics of unclear notability",
                "Category:Articles needing additional references from January 2018",
                "Category:Articles with PDF format bare URLs for citations",
                "Category:Articles with bare URLs for citations from August 2024",
                "Category:Articles with multiple maintenance issues",
                "Category:Articles with topics of unclear notability from April 2018",
                "Category:Deep learning"
            ],
            "id": 53
        },
        {
            "title": "Rectifier (neural networks)",
            "info_text": "In the context of artificial neural networks, the rectifier or ReLU (rectified linear unit) activation function is an activation function defined as the non-negative part of its argument, i.e., the ramp function:\n\n  \n    \n      \n        ReLU\n        \u2061\n        (\n        x\n        )\n        =\n        \n          x\n          \n            +\n          \n        \n        =\n        max\n        (\n        0\n        ,\n        x\n        )\n        =\n        \n          \n            \n              x\n              +\n              \n                |\n              \n              x\n              \n                |\n              \n            \n            2\n          \n        \n        =\n        \n          \n            {\n            \n              \n                \n                  x\n                \n                \n                  \n                    if \n                  \n                  x\n                  >\n                  0\n                  ,\n                \n              \n              \n                \n                  0\n                \n                \n                  x\n                  \u2264\n                  0\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle \\operatorname {ReLU} (x)=x^{+}=\\max(0,x)={\\frac {x+|x|}{2}}={\\begin{cases}x&{\\text{if }}x>0,\\\\0&x\\leq 0\\end{cases}}}\n  \n\nwhere \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n is the input to a neuron. This is analogous to half-wave rectification in electrical engineering.\nReLU is one of the most popular activation functions for artificial neural networks, and finds application in computer vision and speech recognition using deep neural nets and computational neuroscience.\nIt was first used by Alston Householder in 1941 as a mathematical abstraction of biological neural networks. It was introduced by Kunihiko Fukushima in 1969 in the context of visual feature extraction in hierarchical neural networks. It was later argued that it has strong biological motivations and mathematical justifications. In 2011, ReLU activation enabled training deep supervised neural networks without unsupervised pre-training, compared to the widely used activation functions prior to 2011, e.g., the logistic sigmoid (which is inspired by probability theory; see logistic regression) and its more practical counterpart, the hyperbolic tangent. \n\n",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from April 2024",
                "Category:Artificial neural networks",
                "Category:CS1 errors: periodical ignored",
                "Category:Short description is different from Wikidata"
            ],
            "id": 54
        },
        {
            "title": "Semiconductor",
            "info_text": "A semiconductor is a material that is between the conductor and insulator in ability to conduct electrical current. In many cases their conducting properties may be altered in useful ways by introducing impurities (\"doping\") into the crystal structure. When two differently doped regions exist in the same crystal, a semiconductor junction is created. The behavior of charge carriers, which include electrons, ions, and electron holes, at these junctions is the basis of diodes, transistors, and most modern electronics. Some examples of semiconductors are silicon, germanium, gallium arsenide, and elements near the so-called \"metalloid staircase\" on the periodic table. After silicon, gallium arsenide is the second-most common semiconductor and is used in laser diodes, solar cells, microwave-frequency integrated circuits, and others. Silicon is a critical element for fabricating most electronic circuits.\nSemiconductor devices can display a range of different useful properties, such as passing current more easily in one direction than the other, showing variable resistance, and having sensitivity to light or heat. Because the electrical properties of a semiconductor material can be modified by doping and by the application of electrical fields or light, devices made from semiconductors can be used for amplification, switching, and energy conversion. The term semiconductor is also used to describe materials used in high capacity, medium- to high-voltage cables as part of their insulation, and these materials are often plastic XLPE (Cross-linked polyethylene) with carbon black.\nThe conductivity of silicon is increased by adding a small amount (of the order of 1 in 108) of pentavalent (antimony, phosphorus, or arsenic) or trivalent (boron, gallium, indium) atoms. This process is known as doping, and the resulting semiconductors are known as doped or extrinsic semiconductors. Apart from doping, the conductivity of a semiconductor can be improved by increasing its temperature. This is contrary to the behavior of a metal, in which conductivity decreases with an increase in temperature.\nThe modern understanding of the properties of a semiconductor relies on quantum physics to explain the movement of charge carriers in a crystal lattice. Doping greatly increases the number of charge carriers within the crystal. When a semiconductor is doped by Group V elements, they will behave like donors creating free electrons, known as \"n-type\" doping. When a semiconductor is doped by Group III elements, they will behave like acceptors creating free holes, known as \"p-type\" doping. The semiconductor materials used in electronic devices are doped under precise conditions to control the concentration and regions of p- and n-type dopants. A single semiconductor device crystal can have many p- and n-type regions; the p\u2013n junctions between these regions are responsible for the useful electronic behavior. Using a hot-point probe, one can determine quickly whether a semiconductor sample is p- or n-type.\nA few of the properties of semiconductor materials were observed throughout the mid-19th and first decades of the 20th century. The first practical application of semiconductors in electronics was the 1904 development of the cat's-whisker detector, a primitive semiconductor diode used in early radio receivers. Developments in quantum physics led in turn to the invention of the transistor in 1947 and the integrated circuit in 1958.",
            "categories": [
                "Category:Articles with short description",
                "Category:Commons category link is on Wikidata",
                "Category:Semiconductors",
                "Category:Short description matches Wikidata"
            ],
            "id": 55
        },
        {
            "title": "CpG site",
            "info_text": "The CpG sites or CG sites are regions of DNA where a cytosine nucleotide is followed by a guanine nucleotide in the linear sequence of bases along its 5' \u2192 3' direction. CpG sites occur with high frequency in genomic regions called CpG islands. \nCytosines in CpG dinucleotides can be methylated to form 5-methylcytosines. Enzymes that add a methyl group are called DNA methyltransferases. In mammals, 70% to 80% of CpG cytosines are methylated. Methylating the cytosine within a gene can change its expression, a mechanism that is part of a larger field of science studying gene regulation that is called epigenetics. Methylated cytosines often mutate to thymines.\nIn humans, about 70% of promoters located near the transcription start site of a gene (proximal promoters) contain a CpG island.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:CS1 errors: periodical ignored",
                "Category:CS1 maint: date and year",
                "Category:CS1 maint: location missing publisher",
                "Category:DNA",
                "Category:Molecular genetics",
                "Category:Short description is different from Wikidata"
            ],
            "id": 56
        },
        {
            "title": "Nathaniel Rochester (computer scientist)",
            "info_text": "Nathaniel Rochester (January 14, 1919 \u2013 June 8, 2001) was the chief architect of the IBM 701, the first mass produced scientific computer, and of the prototype of its first commercial version, the IBM 702. He wrote the first assembler and participated in the founding of the field of artificial intelligence.\n\n",
            "categories": [
                "Category:1919 births",
                "Category:2001 deaths",
                "Category:American computer scientists",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:IBM Fellows",
                "Category:MIT School of Engineering alumni",
                "Category:Short description is different from Wikidata"
            ],
            "id": 57
        },
        {
            "title": "Biological system",
            "info_text": "A biological system is a complex network which connects several biologically relevant entities. Biological organization spans several scales and are determined based different structures depending on what the system is. Examples of biological systems at the macro scale are populations of organisms. On the organ and tissue scale in mammals and other animals, examples include the circulatory system, the respiratory system, and the nervous system. On the micro to the nanoscopic scale, examples of biological systems are cells, organelles, macromolecular complexes and regulatory pathways. A biological system is not to be confused with a living system, such as a living organism.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:Biological systems",
                "Category:CS1 errors: periodical ignored",
                "Category:Short description is different from Wikidata",
                "Category:Webarchive template wayback links"
            ],
            "id": 58
        },
        {
            "title": "Robot control",
            "info_text": "Robotic control is the system that contributes to the movement of robots. This involves the mechanical aspects and programmable systems that makes it possible to control robots. Robotics can be controlled by various means including manual, wireless, semi-autonomous (a mix of fully automatic and wireless control), and fully autonomous (using artificial intelligence).",
            "categories": [
                "Category:All articles needing additional references",
                "Category:Articles needing additional references from October 2024",
                "Category:Articles with short description",
                "Category:Robot control",
                "Category:Short description is different from Wikidata",
                "Category:Technology"
            ],
            "id": 59
        },
        {
            "title": "Rectifier (neural networks)",
            "info_text": "In the context of artificial neural networks, the rectifier or ReLU (rectified linear unit) activation function is an activation function defined as the non-negative part of its argument, i.e., the ramp function:\n\n  \n    \n      \n        ReLU\n        \u2061\n        (\n        x\n        )\n        =\n        \n          x\n          \n            +\n          \n        \n        =\n        max\n        (\n        0\n        ,\n        x\n        )\n        =\n        \n          \n            \n              x\n              +\n              \n                |\n              \n              x\n              \n                |\n              \n            \n            2\n          \n        \n        =\n        \n          \n            {\n            \n              \n                \n                  x\n                \n                \n                  \n                    if \n                  \n                  x\n                  >\n                  0\n                  ,\n                \n              \n              \n                \n                  0\n                \n                \n                  x\n                  \u2264\n                  0\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle \\operatorname {ReLU} (x)=x^{+}=\\max(0,x)={\\frac {x+|x|}{2}}={\\begin{cases}x&{\\text{if }}x>0,\\\\0&x\\leq 0\\end{cases}}}\n  \n\nwhere \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n is the input to a neuron. This is analogous to half-wave rectification in electrical engineering.\nReLU is one of the most popular activation functions for artificial neural networks, and finds application in computer vision and speech recognition using deep neural nets and computational neuroscience.\nIt was first used by Alston Householder in 1941 as a mathematical abstraction of biological neural networks. It was introduced by Kunihiko Fukushima in 1969 in the context of visual feature extraction in hierarchical neural networks. It was later argued that it has strong biological motivations and mathematical justifications. In 2011, ReLU activation enabled training deep supervised neural networks without unsupervised pre-training, compared to the widely used activation functions prior to 2011, e.g., the logistic sigmoid (which is inspired by probability theory; see logistic regression) and its more practical counterpart, the hyperbolic tangent. \n\n",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from April 2024",
                "Category:Artificial neural networks",
                "Category:CS1 errors: periodical ignored",
                "Category:Short description is different from Wikidata"
            ],
            "id": 60
        },
        {
            "title": "Obesity",
            "info_text": "Obesity is a medical condition, sometimes considered a disease, in which excess body fat has accumulated to such an extent that it can potentially have negative effects on health. People are classified as obese when their body mass index (BMI)\u2014a person's weight divided by the square of the person's height\u2014is over 30 kg/m2; the range 25\u201330 kg/m2 is defined as overweight. Some East Asian countries use lower values to calculate obesity. Obesity is a major cause of disability and is correlated with various diseases and conditions, particularly cardiovascular diseases, type 2 diabetes, obstructive sleep apnea, certain types of cancer, and osteoarthritis.\nObesity has individual, socioeconomic, and environmental causes. Some known causes are diet, low physical activity, automation, urbanization, genetic susceptibility, medications, mental disorders, economic policies, endocrine disorders, and exposure to endocrine-disrupting chemicals.\nWhile many people living with obesity attempt to lose weight and are often successful, maintaining weight loss long-term is rare. Obesity prevention requires a complex approach, including interventions at medical, societal, community, family, and individual levels. Changes to diet as well as exercising are the main treatments recommended by health professionals. Diet quality can be improved by reducing the consumption of energy-dense foods, such as those high in fat or sugars, and by increasing the intake of dietary fiber, although the World Health Organization stresses that these improvements are a societal responsibility and that these dietary choices should be made the most available, affordable, and accessible options. Medications can be used, along with a suitable diet, to reduce appetite or decrease fat absorption. If diet, exercise, and medication are not effective, a gastric balloon or surgery may be performed to reduce stomach volume or length of the intestines, leading to feeling full earlier, or a reduced ability to absorb nutrients from food. Many do not realize that metabolic surgery is not only about reducing intake, it has also been shown to alter gut hormones for a period of time. \nObesity is a leading preventable cause of death worldwide, with increasing rates in adults and children. In 2022, over 1 billion people lived with obesity worldwide (879 million adults and 159 million children), representing more than a double of adult cases (and four times higher than cases among children) registered in 1990. Obesity is more common in women than in men. Today, obesity is stigmatized in most of the world. Conversely, some cultures, past and present, have a favorable view of obesity, seeing it as a symbol of wealth and fertility. The World Health Organization, the US, Canada, Japan, Portugal, Germany, the European Parliament and medical societies, e.g. the American Medical Association, classify obesity as a disease. Others, such as the UK, do not.",
            "categories": [
                "Category:All Wikipedia articles in need of updating",
                "Category:All articles lacking reliable references",
                "Category:All articles with unsourced statements",
                "Category:Articles lacking reliable references from July 2021",
                "Category:Articles with medical app sidebar",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from July 2021",
                "Category:Bariatrics",
                "Category:Body shape",
                "Category:CS1 Dutch-language sources (nl)"
            ],
            "id": 61
        },
        {
            "title": "Hybrid intelligent system",
            "info_text": "Hybrid intelligent system denotes a software system which employs, in parallel, a combination of methods and techniques from artificial intelligence subfields, such as:\n\nNeuro-symbolic systems\nNeuro-fuzzy systems\nHybrid connectionist-symbolic models\nFuzzy expert systems\nConnectionist expert systems\nEvolutionary neural networks\nGenetic fuzzy systems\nRough fuzzy hybridization\nReinforcement learning with fuzzy, neural, or evolutionary methods as well as symbolic reasoning methods.\nFrom the cognitive science perspective, every natural intelligent system is hybrid because it performs mental operations on both the symbolic and subsymbolic levels. For the past few years, there has been an increasing discussion of the importance of A.I. Systems Integration. Based on notions that there have already been created simple and specific AI systems (such as systems for computer vision, speech synthesis, etc., or software that employs some of the models mentioned above) and now is the time for integration to create broad AI systems. Proponents of this approach are researchers such as Marvin Minsky, Ron Sun, Aaron Sloman,  and Michael A. Arbib.\nAn example hybrid is a hierarchical control system in which the lowest, reactive layers are sub-symbolic. The higher layers, having relaxed time constraints, are capable of reasoning from an abstract world model and performing planning.\nIntelligent systems usually rely on hybrid reasoning processes, which include induction, deduction, abduction and reasoning by analogy.\n\n",
            "categories": [
                "Category:Artificial intelligence",
                "Category:Use mdy dates from October 2023",
                "Category:Webarchive template wayback links"
            ],
            "id": 62
        },
        {
            "title": "Cortana (virtual assistant)",
            "info_text": "Cortana was a virtual assistant developed by Microsoft that used the Bing search engine to perform tasks such as setting reminders and answering questions for users.\nCortana was available in English, Portuguese, French, German, Italian, Spanish, Chinese, and Japanese language editions, depending on the software platform and region in which it was used.\nIn 2019, Microsoft began reducing the prevalence of Cortana and converting it from an assistant into different software integrations. It was split from the Windows 10 search bar in April 2019. In January 2020, the Cortana mobile app was removed from certain markets, and on March 31, 2021, the Cortana mobile app was shut down globally. On June 2, 2023, Microsoft announced that support for the Cortana standalone app on Microsoft Windows would end in late 2023 and would be replaced by Microsoft Copilot, an AI chatbot. Support for Cortana in the Microsoft Outlook and Microsoft 365 mobile apps was discontinued in fall of 2023.\n\n",
            "categories": [
                "Category:2014 software",
                "Category:All articles containing potentially dated statements",
                "Category:Android (operating system) software",
                "Category:Articles containing potentially dated statements from 2016",
                "Category:Articles containing potentially dated statements from 2020",
                "Category:Articles containing potentially dated statements from April 2014",
                "Category:Articles with short description",
                "Category:IOS software",
                "Category:Natural language processing software",
                "Category:Official website different in Wikidata and Wikipedia"
            ],
            "id": 63
        },
        {
            "title": "Climatology",
            "info_text": "Climatology (from Greek \u03ba\u03bb\u03af\u03bc\u03b1, klima, \"slope\"; and -\u03bb\u03bf\u03b3\u03af\u03b1, -logia) or climate science is the scientific study of Earth's climate, typically defined as weather conditions averaged over a period of at least 30 years. Climate concerns the atmospheric condition during an extended to indefinite period of time; weather is the condition of the atmosphere during a relative brief period of time. The main topics of research are the study of climate variability, mechanisms of climate changes and modern climate change. This topic of study is regarded as part of the atmospheric sciences and a subdivision of physical geography, which is one of the Earth sciences. Climatology includes some aspects of oceanography and biogeochemistry.\nThe main methods employed by climatologists are the analysis of observations and modelling of the physical processes that determine climate. Short term weather forecasting can be interpreted in terms of knowledge of longer-term phenomena of climate, for instance climatic cycles such as the El Ni\u00f1o\u2013Southern Oscillation (ENSO), the Madden\u2013Julian oscillation (MJO), the North Atlantic oscillation (NAO), the Arctic oscillation (AO), the Pacific decadal oscillation (PDO), and the Interdecadal Pacific Oscillation (IPO). Climate models are used for a variety of purposes from studying the dynamics of the weather and climate system to predictions of future climate.",
            "categories": [
                "Category:Articles containing Ancient Greek (to 1453)-language text",
                "Category:Articles with short description",
                "Category:Atmospheric sciences",
                "Category:CS1 maint: bot: original URL status unknown",
                "Category:Climate and weather statistics",
                "Category:Climatology",
                "Category:Natural environment",
                "Category:Short description is different from Wikidata",
                "Category:Webarchive template wayback links"
            ],
            "id": 64
        },
        {
            "title": "Llama (language model)",
            "info_text": "Llama (Large Language Model Meta AI, formerly stylized as LLaMA) is a family of autoregressive large language models (LLMs) released by Meta AI starting in February 2023. The latest version is Llama 3.3, released in December 2024.\nLlama models are trained at different parameter sizes, ranging between 1B and 405B. Originally, Llama was only available as a foundation model. Starting with Llama 2, Meta AI started releasing instruction fine-tuned versions alongside foundation models.\nModel weights for the first version of Llama were made available to the research community under a non-commercial license, and access was granted on a case-by-case basis. Unauthorized copies of the first model were shared via BitTorrent. Subsequent versions of Llama were made accessible outside academia and released under licenses that permitted some commercial use.\nAlongside the release of Llama 3, Meta added virtual assistant features to Facebook and WhatsApp in select regions, and a standalone website. Both services use a Llama 3 model.",
            "categories": [
                "Category:2023 software",
                "Category:Articles with short description",
                "Category:CS1 maint: archived copy as title",
                "Category:Internet leaks",
                "Category:Large language models",
                "Category:Meta Platforms",
                "Category:Official website different in Wikidata and Wikipedia",
                "Category:Short description matches Wikidata"
            ],
            "id": 65
        },
        {
            "title": "Multiple sclerosis",
            "info_text": "Multiple sclerosis (MS) is an autoimmune disease resulting in damage to the insulating covers of nerve cells in the brain and spinal cord. As a demyelinating disease, MS disrupts the nervous system's ability to transmit signals, resulting in a range of signs and symptoms, including physical, mental, and sometimes psychiatric problems. Symptoms include double vision, vision loss, eye pain, muscle weakness, and loss of sensation or coordination. MS takes several forms, with new symptoms either occurring in isolated attacks (relapsing forms) or building up over time (progressive forms). In relapsing forms of MS symptoms may disappear completely between attacks, although some permanent neurological problems often remain, especially as the disease advances. In progressive forms of MS, bodily function slowly deteriorates once symptoms manifest and will steadily worsen if left untreated.\nWhile its cause is unclear, the underlying mechanism is thought to be due to either destruction by the immune system or inactivation of myelin-producing cells. Proposed causes for this include immune dysregulation, genetics, and environmental factors, such as viral infections. The McDonald criteria are a frequently updated set of guidelines used to establish an MS diagnosis.\nThere is no cure for MS. Current treatments aim to mitigate inflammation and resulting symptoms from acute flares and prevent further attacks with disease-modifying medications. Physical therapy and occupational therapy, along with patient-centered symptom management, can help with people's ability to function. The long-term outcome is difficult to predict; better outcomes are more often seen in women, those who develop the disease early in life, those with a relapsing course, and those who initially experienced few attacks.\nMS is the most common immune-mediated disorder affecting the central nervous system (CNS). In 2020, about 2.8 million people were affected by MS globally, with rates varying widely in different regions and among different populations. The disease usually begins between the ages of 20 and 50 and is twice as common in women as in men. MS was first described in 1868 by French neurologist Jean-Martin Charcot.\nThe name \"multiple sclerosis\" is short for multiple cerebro-spinal sclerosis, which refers to the numerous glial scars (or sclerae \u2013 essentially plaques or lesions) that develop on the white matter of the brain and spinal cord.\n\n",
            "categories": [
                "Category:Ailments of unknown cause",
                "Category:All Wikipedia articles in need of updating",
                "Category:All articles containing potentially dated statements",
                "Category:All articles lacking reliable references",
                "Category:All articles needing additional references",
                "Category:All articles with unsourced statements",
                "Category:Articles containing potentially dated statements from 2017",
                "Category:Articles lacking reliable references from December 2022",
                "Category:Articles lacking reliable references from November 2023",
                "Category:Articles needing additional medical references from July 2022"
            ],
            "id": 66
        },
        {
            "title": "Machine learning in bioinformatics",
            "info_text": "Machine learning in bioinformatics is the application of machine learning algorithms to bioinformatics, including genomics, proteomics, microarrays, systems biology, evolution, and text mining.\nPrior to the emergence of machine learning, bioinformatics algorithms had to be programmed by hand; for problems such as protein structure prediction, this proved difficult. Machine learning techniques such as deep learning can learn features of data sets rather than requiring the programmer to define them individually. The algorithm can further learn how to combine low-level features into more abstract features, and so on. This multi-layered approach allows such systems to make sophisticated predictions when appropriately trained. These methods contrast with other computational biology approaches which, while exploiting existing datasets, do not allow the data to be interpreted and analyzed in unanticipated ways. \n\n",
            "categories": [
                "Category:All Wikipedia articles in need of updating",
                "Category:All articles containing potentially dated statements",
                "Category:All articles lacking reliable references",
                "Category:All articles needing additional references",
                "Category:All articles with specifically marked weasel-worded phrases",
                "Category:Articles containing potentially dated statements from 2002",
                "Category:Articles lacking reliable references from November 2023",
                "Category:Articles needing additional references from June 2021",
                "Category:Articles with specifically marked weasel-worded phrases from June 2021",
                "Category:Bioinformatics"
            ],
            "id": 67
        },
        {
            "title": "Residual neural network",
            "info_text": "A residual neural network (also referred to as a residual network or ResNet) is a deep learning architecture in which the layers learn residual functions with reference to the layer inputs. It was developed in 2015 for image recognition, and won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) of that year.\nAs a point of terminology, \"residual connection\" refers to the specific architectural motif of \n  \n    \n      \n        x\n        \u21a6\n        f\n        (\n        x\n        )\n        +\n        x\n      \n    \n    {\\displaystyle x\\mapsto f(x)+x}\n  \n, where \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n is an arbitrary neural network module. The motif had been used previously (see \u00a7History for details). However, the publication of ResNet made it widely popular for feedforward networks, appearing in neural networks that are seemingly unrelated to ResNet.\nThe residual connection stabilizes the training and convergence of deep neural networks with hundreds of layers, and is a common motif in deep neural networks, such as transformer models (e.g., BERT, and GPT models such as ChatGPT), the AlphaGo Zero system, the AlphaStar system, and the AlphaFold system.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:Deep learning",
                "Category:Neural network architectures",
                "Category:Short description matches Wikidata"
            ],
            "id": 68
        },
        {
            "title": "GPT-1",
            "info_text": "Generative Pre-trained Transformer 1 (GPT-1) was the first of OpenAI's large language models following Google's invention of the transformer architecture in 2017. In June 2018, OpenAI released a paper entitled \"Improving Language Understanding by Generative Pre-Training\", in which they introduced that initial model along with the general concept of a generative pre-trained transformer.\nUp to that point, the best-performing neural NLP models primarily employed supervised learning from large amounts of manually labeled data. This reliance on supervised learning limited their use of datasets that were not well-annotated, in addition to making it prohibitively expensive and time-consuming to train extremely large models; many languages (such as Swahili or Haitian Creole) are difficult to translate and interpret using such models due to a lack of available text for corpus-building. In contrast, a GPT's \"semi-supervised\" approach involved two stages: an unsupervised generative \"pre-training\" stage in which a language modeling objective was used to set initial parameters, and a supervised discriminative \"fine-tuning\" stage in which these parameters were adapted to a target task.\nThe use of a transformer architecture, as opposed to previous techniques involving attention-augmented RNNs, provided GPT models with a more structured memory than could be achieved through recurrent mechanisms; this resulted in \"robust transfer performance across diverse tasks\".\n\n",
            "categories": [
                "Category:All articles lacking reliable references",
                "Category:Articles lacking reliable references from August 2023",
                "Category:Articles with short description",
                "Category:Generative pre-trained transformers",
                "Category:Large language models",
                "Category:OpenAI",
                "Category:Short description is different from Wikidata",
                "Category:Software using the MIT license"
            ],
            "id": 69
        },
        {
            "title": "Seashell",
            "info_text": "A seashell or sea shell, also known simply as a shell, is a hard, protective outer layer usually created by an animal or organism that lives in the sea. Most seashells are made by mollusks, such as snails, clams, and oysters to protect their soft insides. Empty seashells are often found washed up on beaches by beachcombers. The shells are empty because the animal has died and the soft parts have decomposed or been eaten by another organism.\nA seashell is usually the exoskeleton of an invertebrate (an animal without a backbone), and is typically composed of calcium carbonate or chitin. Most shells that are found on beaches are the shells of marine mollusks, partly because these shells are usually made of calcium carbonate, and endure better than shells made of chitin.\nApart from mollusk shells, other shells that can be found on beaches are those of barnacles, horseshoe crabs and brachiopods. Marine annelid worms in the family Serpulidae create shells which are tubes made of calcium carbonate cemented onto other surfaces. The shells of sea urchins are called \"tests\", and the moulted shells of crabs and lobsters are exuviae. While most seashells are external, some cephalopods have internal shells.\nSeashells have been used by humans for many different purposes throughout history and prehistory. However, seashells are not the only kind of shells; in various habitats, there are shells from freshwater animals such as freshwater mussels and freshwater snails, and shells of land snails.\n\n",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All articles with unsourced statements",
                "Category:Articles containing video clips",
                "Category:Articles needing additional references from December 2017",
                "Category:Articles needing additional references from January 2009",
                "Category:Articles needing additional references from July 2016",
                "Category:Articles needing additional references from September 2011",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from February 2011",
                "Category:CS1: long volume value"
            ],
            "id": 70
        },
        {
            "title": "Automated planning and scheduling",
            "info_text": "Automated planning and scheduling, sometimes denoted as simply AI planning, is a branch of artificial intelligence that concerns the realization of strategies or action sequences, typically for execution by intelligent agents, autonomous robots and unmanned vehicles. Unlike classical control and classification problems, the solutions are complex and must be discovered and optimized in multidimensional space. Planning is also related to decision theory.\nIn known environments with available models, planning can be done offline. Solutions can be found and evaluated prior to execution. In dynamically unknown environments, the strategy often needs to be revised online. Models and policies must be adapted. Solutions usually resort to iterative trial and error processes commonly seen in artificial intelligence. These include dynamic programming, reinforcement learning and combinatorial optimization. Languages used to describe planning and scheduling are often called action languages.\n\n",
            "categories": [
                "Category:All articles lacking in-text citations",
                "Category:All articles needing additional references",
                "Category:All articles with unsourced statements",
                "Category:Articles lacking in-text citations from January 2012",
                "Category:Articles needing additional references from February 2021",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from February 2021",
                "Category:Automated planning and scheduling",
                "Category:CS1 maint: multiple names: authors list",
                "Category:Short description is different from Wikidata"
            ],
            "id": 71
        },
        {
            "title": "Dilek Hakkani-T\u00fcr",
            "info_text": "Dilek Z. Hakkani-T\u00fcr is a Turkish-American computer scientist focusing on speech processing, speech recognition, and dialogue systems. She is a professor of computer science at the University of Illinois Urbana-Champaign.\n\n",
            "categories": [
                "Category:AT&T people",
                "Category:Amazon (company) people",
                "Category:American computer scientists",
                "Category:American women computer scientists",
                "Category:Articles with short description",
                "Category:Bilkent University alumni",
                "Category:Fellows of the IEEE",
                "Category:Living people",
                "Category:Microsoft Research people",
                "Category:Middle East Technical University alumni"
            ],
            "id": 72
        },
        {
            "title": "Ben Goertzel",
            "info_text": "Ben Goertzel is a computer scientist, artificial intelligence researcher, and businessman. He helped popularize the term artificial general intelligence.",
            "categories": [
                "Category:1966 births",
                "Category:20th-century American mathematicians",
                "Category:21st-century American mathematicians",
                "Category:Academic staff of Xiamen University",
                "Category:Academic staff of the University of Waikato",
                "Category:Academic staff of the University of Western Australia",
                "Category:All articles with dead external links",
                "Category:All articles with unsourced statements",
                "Category:All pages needing factual verification",
                "Category:American agnostics"
            ],
            "id": 73
        },
        {
            "title": "Zaire ebolavirus",
            "info_text": "Orthoebolavirus zairense or Zaire ebolavirus, more commonly known as Ebola virus (; EBOV), is one of six known species within the genus Ebolavirus. Four of the six known ebolaviruses, including EBOV, cause a severe and often fatal hemorrhagic fever in humans and other mammals, known as Ebola virus disease (EVD). Ebola virus has caused the majority of human deaths from EVD, and was the cause of the 2013\u20132016 epidemic in western Africa, which resulted in at least 28,646 suspected cases and 11,323 confirmed deaths.\nEbola virus and its genus were both originally named for Zaire (now the Democratic Republic of the Congo), the country where it was first described, and was at first suspected to be a new \"strain\" of the closely related Marburg virus. The virus was renamed \"Ebola virus\" in 2010 to avoid confusion. Ebola virus is the single member of the species Zaire ebolavirus, which is assigned to the genus Ebolavirus, family Filoviridae, order Mononegavirales. The members of the species are called Zaire ebolaviruses. The natural reservoir of Ebola virus is believed to be bats, particularly fruit bats, and it is primarily transmitted between humans and from animals to humans through body fluids.\nThe EBOV genome is a single-stranded RNA, approximately 19,000 nucleotides long. It encodes seven structural proteins: nucleoprotein (NP), polymerase cofactor (VP35), (VP40), GP, transcription activator (VP30), VP24, and RNA-dependent RNA polymerase (L).\nBecause of its high fatality rate (up to 83 to 90 percent), EBOV is also listed as a select agent, World Health Organization Risk Group 4 Pathogen (requiring Biosafety Level 4-equivalent containment), a US National Institutes of Health/National Institute of Allergy and Infectious Diseases Category A Priority Pathogen, US CDC Centers for Disease Control and Prevention Category A Bioterrorism Agent, and a Biological Agent for Export Control by the Australia Group.\n\n",
            "categories": [
                "Category:1976 in biology",
                "Category:All articles with unsourced statements",
                "Category:Animal viral diseases",
                "Category:Arthropod-borne viral fevers and viral haemorrhagic fevers",
                "Category:Articles with 'species' microformats",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from April 2019",
                "Category:Articles with unsourced statements from April 2020",
                "Category:Articles with unsourced statements from August 2014",
                "Category:Articles with unsourced statements from December 2016"
            ],
            "id": 74
        },
        {
            "title": "Artificial intelligence in mental health",
            "info_text": "Artificial intelligence in mental health is the application of artificial intelligence (AI), computational technologies and algorithms to supplement the understanding, diagnosis, and treatment of mental health disorders. AI is becoming a ubiquitous force in everyday life which can be seen through frequent operation of models like ChatGPT. Utilizing AI in the realm of mental health signifies a form of digital healthcare, in which, the goal is to increase accessibility in a world where mental health is becoming a growing concern. Prospective ideas involving AI in mental health include identification and diagnosis of mental disorders, explication of electronic health records, creation of personalized treatment plans, and predictive analytics for suicide prevention.  Learning how to apply AI in healthcare proves to be a difficult task with many challenges, thus it remains rarely used as efforts to bridge gaps are deliberated. \n\n",
            "categories": [
                "Category:All articles with style issues",
                "Category:Applications of artificial intelligence",
                "Category:Articles with multiple maintenance issues",
                "Category:Articles with short description",
                "Category:CS1 Norwegian Bokm\u00e5l-language sources (nb)",
                "Category:Mental health",
                "Category:Short description is different from Wikidata",
                "Category:Wikipedia articles with style issues from November 2023"
            ],
            "id": 75
        },
        {
            "title": "Loss functions for classification",
            "info_text": "In machine learning and mathematical optimization, loss functions for classification are computationally feasible loss functions representing the price paid for inaccuracy of predictions in classification problems (problems of identifying which category a particular observation belongs to).  Given \n  \n    \n      \n        \n          \n            X\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {X}}}\n  \n as the space of all possible inputs (usually \n  \n    \n      \n        \n          \n            X\n          \n        \n        \u2282\n        \n          \n            R\n          \n          \n            d\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {X}}\\subset \\mathbb {R} ^{d}}\n  \n), and \n  \n    \n      \n        \n          \n            Y\n          \n        \n        =\n        {\n        \u2212\n        1\n        ,\n        1\n        }\n      \n    \n    {\\displaystyle {\\mathcal {Y}}=\\{-1,1\\}}\n  \n as the set of labels (possible outputs), a typical goal of classification algorithms is to find a function \n  \n    \n      \n        f\n        :\n        \n          \n            X\n          \n        \n        \u2192\n        \n          \n            Y\n          \n        \n      \n    \n    {\\displaystyle f:{\\mathcal {X}}\\to {\\mathcal {Y}}}\n  \n which best predicts a label \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n for a given input \n  \n    \n      \n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {x}}}\n  \n.  However, because of incomplete information, noise in the measurement, or probabilistic components in the underlying process, it is possible for the same \n  \n    \n      \n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {x}}}\n  \n to generate different \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n.  As a result, the goal of the learning problem is to minimize expected loss (also known as the risk), defined as\n\n  \n    \n      \n        I\n        [\n        f\n        ]\n        =\n        \n          \n            \u222b\n            \n              \n                \n                  X\n                \n              \n              \u00d7\n              \n                \n                  Y\n                \n              \n            \n          \n          V\n          (\n          f\n          (\n          \n            \n              \n                x\n                \u2192\n              \n            \n          \n          )\n          ,\n          y\n          )\n          \n          p\n          (\n          \n            \n              \n                x\n                \u2192\n              \n            \n          \n          ,\n          y\n          )\n          \n          d\n          \n            \n              \n                x\n                \u2192\n              \n            \n          \n          \n          d\n          y\n        \n      \n    \n    {\\displaystyle I[f]=\\displaystyle \\int _{{\\mathcal {X}}\\times {\\mathcal {Y}}}V(f({\\vec {x}}),y)\\,p({\\vec {x}},y)\\,d{\\vec {x}}\\,dy}\n  \n\nwhere \n  \n    \n      \n        V\n        (\n        f\n        (\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        )\n        ,\n        y\n        )\n      \n    \n    {\\displaystyle V(f({\\vec {x}}),y)}\n  \n is a given loss function, and  \n  \n    \n      \n        p\n        (\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        ,\n        y\n        )\n      \n    \n    {\\displaystyle p({\\vec {x}},y)}\n  \n is the probability density function of the process that generated the data, which can equivalently be written as\n\n  \n    \n      \n        p\n        (\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        ,\n        y\n        )\n        =\n        p\n        (\n        y\n        \u2223\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        )\n        p\n        (\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        )\n        .\n      \n    \n    {\\displaystyle p({\\vec {x}},y)=p(y\\mid {\\vec {x}})p({\\vec {x}}).}\n  \n\nWithin classification, several commonly used loss functions are written solely in terms of the product of the true label \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n and the predicted label \n  \n    \n      \n        f\n        (\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle f({\\vec {x}})}\n  \n. Therefore, they can be defined as functions of only one variable \n  \n    \n      \n        \u03c5\n        =\n        y\n        f\n        (\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle \\upsilon =yf({\\vec {x}})}\n  \n, so that \n  \n    \n      \n        V\n        (\n        f\n        (\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        )\n        ,\n        y\n        )\n        =\n        \u03d5\n        (\n        y\n        f\n        (\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        )\n        )\n        =\n        \u03d5\n        (\n        \u03c5\n        )\n      \n    \n    {\\displaystyle V(f({\\vec {x}}),y)=\\phi (yf({\\vec {x}}))=\\phi (\\upsilon )}\n  \n with a suitably chosen function \n  \n    \n      \n        \u03d5\n        :\n        \n          R\n        \n        \u2192\n        \n          R\n        \n      \n    \n    {\\displaystyle \\phi :\\mathbb {R} \\to \\mathbb {R} }\n  \n. These are called margin-based loss functions. Choosing a margin-based loss function amounts to choosing \n  \n    \n      \n        \u03d5\n      \n    \n    {\\displaystyle \\phi }\n  \n. Selection of a loss function within this framework impacts the optimal \n  \n    \n      \n        \n          f\n          \n            \u03d5\n          \n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle f_{\\phi }^{*}}\n  \n which minimizes the expected risk, see empirical risk minimization. \nIn the case of binary classification, it is possible to simplify the calculation of expected risk from the integral specified above.  Specifically,\n\n  \n    \n      \n        \n          \n            \n              \n                I\n                [\n                f\n                ]\n              \n              \n                \n                =\n                \n                  \u222b\n                  \n                    \n                      \n                        X\n                      \n                    \n                    \u00d7\n                    \n                      \n                        Y\n                      \n                    \n                  \n                \n                V\n                (\n                f\n                (\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n                )\n                ,\n                y\n                )\n                \n                p\n                (\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n                ,\n                y\n                )\n                \n                d\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n                \n                d\n                y\n              \n            \n            \n              \n              \n                \n                =\n                \n                  \u222b\n                  \n                    \n                      X\n                    \n                  \n                \n                \n                  \u222b\n                  \n                    \n                      Y\n                    \n                  \n                \n                \u03d5\n                (\n                y\n                f\n                (\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n                )\n                )\n                \n                p\n                (\n                y\n                \u2223\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n                )\n                \n                p\n                (\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n                )\n                \n                d\n                y\n                \n                d\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  \u222b\n                  \n                    \n                      X\n                    \n                  \n                \n                [\n                \u03d5\n                (\n                f\n                (\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n                )\n                )\n                \n                p\n                (\n                1\n                \u2223\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n                )\n                +\n                \u03d5\n                (\n                \u2212\n                f\n                (\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n                )\n                )\n                \n                p\n                (\n                \u2212\n                1\n                \u2223\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n                )\n                ]\n                \n                p\n                (\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n                )\n                \n                d\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  \u222b\n                  \n                    \n                      X\n                    \n                  \n                \n                [\n                \u03d5\n                (\n                f\n                (\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n                )\n                )\n                \n                p\n                (\n                1\n                \u2223\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n                )\n                +\n                \u03d5\n                (\n                \u2212\n                f\n                (\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n                )\n                )\n                \n                (\n                1\n                \u2212\n                p\n                (\n                1\n                \u2223\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n                )\n                )\n                ]\n                \n                p\n                (\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n                )\n                \n                d\n                \n                  \n                    \n                      x\n                      \u2192\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}I[f]&=\\int _{{\\mathcal {X}}\\times {\\mathcal {Y}}}V(f({\\vec {x}}),y)\\,p({\\vec {x}},y)\\,d{\\vec {x}}\\,dy\\\\[6pt]&=\\int _{\\mathcal {X}}\\int _{\\mathcal {Y}}\\phi (yf({\\vec {x}}))\\,p(y\\mid {\\vec {x}})\\,p({\\vec {x}})\\,dy\\,d{\\vec {x}}\\\\[6pt]&=\\int _{\\mathcal {X}}[\\phi (f({\\vec {x}}))\\,p(1\\mid {\\vec {x}})+\\phi (-f({\\vec {x}}))\\,p(-1\\mid {\\vec {x}})]\\,p({\\vec {x}})\\,d{\\vec {x}}\\\\[6pt]&=\\int _{\\mathcal {X}}[\\phi (f({\\vec {x}}))\\,p(1\\mid {\\vec {x}})+\\phi (-f({\\vec {x}}))\\,(1-p(1\\mid {\\vec {x}}))]\\,p({\\vec {x}})\\,d{\\vec {x}}\\end{aligned}}}\n  \n\nThe second equality follows from the properties described above.  The third equality follows from the fact that 1 and \u22121 are the only possible values for \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n, and the fourth because \n  \n    \n      \n        p\n        (\n        \u2212\n        1\n        \u2223\n        x\n        )\n        =\n        1\n        \u2212\n        p\n        (\n        1\n        \u2223\n        x\n        )\n      \n    \n    {\\displaystyle p(-1\\mid x)=1-p(1\\mid x)}\n  \n. The term within brackets \n  \n    \n      \n        [\n        \u03d5\n        (\n        f\n        (\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        )\n        )\n        p\n        (\n        1\n        \u2223\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        )\n        +\n        \u03d5\n        (\n        \u2212\n        f\n        (\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        )\n        )\n        (\n        1\n        \u2212\n        p\n        (\n        1\n        \u2223\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        )\n        )\n        ]\n      \n    \n    {\\displaystyle [\\phi (f({\\vec {x}}))p(1\\mid {\\vec {x}})+\\phi (-f({\\vec {x}}))(1-p(1\\mid {\\vec {x}}))]}\n  \n is known as the conditional risk.\nOne can solve for the minimizer of \n  \n    \n      \n        I\n        [\n        f\n        ]\n      \n    \n    {\\displaystyle I[f]}\n  \n by taking the functional derivative of the last equality with respect to \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n and setting the derivative equal to 0.  This will result in the following equation\n\n  \n    \n      \n        \n          \n            \n              \u2202\n              \u03d5\n              (\n              f\n              )\n            \n            \n              \u2202\n              f\n            \n          \n        \n        \u03b7\n        +\n        \n          \n            \n              \u2202\n              \u03d5\n              (\n              \u2212\n              f\n              )\n            \n            \n              \u2202\n              f\n            \n          \n        \n        (\n        1\n        \u2212\n        \u03b7\n        )\n        =\n        0\n        ,\n        \n        \n        \n        \n        \n        (\n        1\n        )\n      \n    \n    {\\displaystyle {\\frac {\\partial \\phi (f)}{\\partial f}}\\eta +{\\frac {\\partial \\phi (-f)}{\\partial f}}(1-\\eta )=0,\\;\\;\\;\\;\\;(1)}\n  \n\nwhere \n  \n    \n      \n        \u03b7\n        =\n        p\n        (\n        y\n        =\n        1\n        \n          |\n        \n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle \\eta =p(y=1|{\\vec {x}})}\n  \n, which is also equivalent to setting the derivative of the conditional risk equal to zero.\nGiven the binary nature of classification, a natural selection for a loss function (assuming equal cost for false positives and false negatives) would be the 0-1 loss function (0\u20131 indicator function), which takes the value of 0 if the predicted classification equals that of the true class or a 1 if the predicted classification does not match the true class. This selection is modeled by\n\n  \n    \n      \n        V\n        (\n        f\n        (\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        )\n        ,\n        y\n        )\n        =\n        H\n        (\n        \u2212\n        y\n        f\n        (\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        )\n        )\n      \n    \n    {\\displaystyle V(f({\\vec {x}}),y)=H(-yf({\\vec {x}}))}\n  \n\nwhere \n  \n    \n      \n        H\n      \n    \n    {\\displaystyle H}\n  \n indicates the Heaviside step function.\nHowever, this loss function is non-convex and non-smooth, and solving for the optimal solution is an NP-hard combinatorial optimization problem.  As a result, it is better to substitute loss function surrogates which are tractable for commonly used learning algorithms, as they have convenient properties such as being convex and smooth.  In addition to  their computational tractability,  one can show that the solutions to the learning problem using these loss surrogates allow for the recovery of the actual solution to the original classification problem.  Some of these surrogates are described below.\nIn practice, the probability distribution \n  \n    \n      \n        p\n        (\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        ,\n        y\n        )\n      \n    \n    {\\displaystyle p({\\vec {x}},y)}\n  \n is unknown.  Consequently, utilizing a training set of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n independently and identically distributed sample points\n\n  \n    \n      \n        S\n        =\n        {\n        (\n        \n          \n            \n              \n                x\n                \u2192\n              \n            \n          \n          \n            1\n          \n        \n        ,\n        \n          y\n          \n            1\n          \n        \n        )\n        ,\n        \u2026\n        ,\n        (\n        \n          \n            \n              \n                x\n                \u2192\n              \n            \n          \n          \n            n\n          \n        \n        ,\n        \n          y\n          \n            n\n          \n        \n        )\n        }\n      \n    \n    {\\displaystyle S=\\{({\\vec {x}}_{1},y_{1}),\\dots ,({\\vec {x}}_{n},y_{n})\\}}\n  \n\ndrawn from the data sample space, one seeks to minimize empirical risk\n\n  \n    \n      \n        \n          I\n          \n            S\n          \n        \n        [\n        f\n        ]\n        =\n        \n          \n            1\n            n\n          \n        \n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        V\n        (\n        f\n        (\n        \n          \n            \n              \n                x\n                \u2192\n              \n            \n          \n          \n            i\n          \n        \n        )\n        ,\n        \n          y\n          \n            i\n          \n        \n        )\n      \n    \n    {\\displaystyle I_{S}[f]={\\frac {1}{n}}\\sum _{i=1}^{n}V(f({\\vec {x}}_{i}),y_{i})}\n  \n\nas a proxy for expected risk. (See statistical learning theory for a more detailed description.)\n\n",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:All pages needing cleanup",
                "Category:Articles needing cleanup from January 2024",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from February 2023",
                "Category:CS1: long volume value",
                "Category:Cleanup tagged articles with a reason field from January 2024",
                "Category:Machine learning algorithms",
                "Category:Short description matches Wikidata",
                "Category:Wikipedia articles needing clarification from February 2023"
            ],
            "id": 76
        },
        {
            "title": "Machine learning in physics",
            "info_text": "Applying machine learning (ML) (including deep learning) methods to the study of quantum systems is an emergent area of physics research. A basic example of this is quantum state tomography, where a quantum state is learned from measurement. Other examples include learning Hamiltonians, learning quantum phase transitions, and automatically generating new quantum experiments. ML is effective at processing large amounts of experimental or calculated data in order to characterize an unknown quantum system, making its application useful in contexts including quantum information theory, quantum technology development, and computational materials design. In this context, for example, it can be used as a tool to interpolate pre-calculated interatomic potentials, or directly solving the Schr\u00f6dinger equation with a variational method.\n\n",
            "categories": [
                "Category:All articles needing additional references",
                "Category:Articles needing additional references from August 2022",
                "Category:Articles with excerpts",
                "Category:Articles with short description",
                "Category:Machine learning",
                "Category:Quantum information science",
                "Category:Quantum programming",
                "Category:Short description matches Wikidata",
                "Category:Theoretical computer science"
            ],
            "id": 77
        },
        {
            "title": "Alex Krizhevsky",
            "info_text": "Alex Krizhevsky is a Ukrainian-born Canadian computer scientist most noted for his work on artificial neural networks and deep learning. In 2012, Krizhevsky, Ilya Sutskever and their PhD advisor Geoffrey Hinton, at the University of Toronto, developed a powerful visual-recognition network AlexNet using only two GeForce NVIDIA GPU cards. This revolutionized research in neural networks. Previously neural networks were trained on CPUs. The transition to GPUs opened the way to the development of advanced AI models. AlexNet won the ImageNet challenge in 2012. Krizhevsky and Sutskever sold their startup, DNN Research Inc., to Google, shortly after winning the contest. Krizhevsky left Google in September 2017 after losing interest in the work, to work at the company Dessa in support of new deep-learning techniques. Many of his numerous papers on machine learning and computer vision are frequently cited by other researchers. He is also the main author of the CIFAR-10 and CIFAR-100 datasets.\n\n",
            "categories": [
                "Category:All Wikipedia articles written in Canadian English",
                "Category:All stub articles",
                "Category:Articles with short description",
                "Category:Canadian artificial intelligence researchers",
                "Category:Canadian computer scientists",
                "Category:Canadian scientist stubs",
                "Category:Computer vision researchers",
                "Category:Living people",
                "Category:Short description is different from Wikidata",
                "Category:Ukrainian computer scientists"
            ],
            "id": 78
        },
        {
            "title": "Double descent",
            "info_text": "Double descent in statistics and machine learning is the phenomenon where a model with a small number of parameters and a model with an extremely large number of parameters have a small test error, but a model whose number of parameters is about the same as the number of data points used to train the model will have a large error. This phenomenon has been considered surprising, as it contradicts assumptions about overfitting in classical machine learning.",
            "categories": [
                "Category:All stub articles",
                "Category:Articles with short description",
                "Category:Machine learning",
                "Category:Model selection",
                "Category:Short description matches Wikidata",
                "Category:Statistical classification",
                "Category:Statistics stubs"
            ],
            "id": 79
        },
        {
            "title": "GPT-4",
            "info_text": "Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model trained and created by OpenAI and the fourth in its series of GPT foundation models. It was launched on March 14, 2023, and made publicly available via the paid chatbot product ChatGPT Plus, via OpenAI's API, and via the free chatbot Microsoft Copilot.  As a transformer-based model, GPT-4 uses a paradigm where pre-training using both public data and \"data licensed from third-party providers\" is used to predict the next token. After this step, the model was then fine-tuned with reinforcement learning feedback from humans and AI for human alignment and policy compliance.:\u200a2\u200a\nObservers reported that the iteration of ChatGPT using GPT-4 was an improvement on the previous iteration based on GPT-3.5, with the caveat that GPT-4 retains some of the problems with earlier revisions. GPT-4, equipped with vision capabilities (GPT-4V), is capable of taking images as input on ChatGPT. OpenAI has not revealed technical details and statistics about GPT-4, such as the precise size of the model.",
            "categories": [
                "Category:2023 software",
                "Category:All Wikipedia articles written in American English",
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from May 2024",
                "Category:ChatGPT",
                "Category:Generative pre-trained transformers",
                "Category:Large language models",
                "Category:OpenAI",
                "Category:Short description is different from Wikidata"
            ],
            "id": 80
        },
        {
            "title": "Mobile advertising",
            "info_text": "Mobile advertising is a form of advertising via mobile (wireless) phones or other mobile devices. It is a subset of mobile marketing, mobile advertising can take place as text ads via SMS, or banner advertisements that appear embedded in a mobile web site.\nIt is estimated that U.S. mobile app-installed ads accounted for 30% of all mobile advertising revenue in 2014, and will top $4.6 billion in 2016, and over $6.8 billion by the end of 2019. Other ways mobile advertising can be purchased include working with a Mobile Demand Side Platform, in which ad impressions are bought in real-time on an ad exchange. Another report has indicated that worldwide mobile digital advertising spend would reach $185 billion in 2018, $217 billion in 2019 and $247 billion in 2020.\n\n",
            "categories": [
                "Category:Advertising",
                "Category:Advertising by medium",
                "Category:All articles needing additional references",
                "Category:All articles with unsourced statements",
                "Category:Articles needing additional references from April 2017",
                "Category:Articles needing additional references from January 2012",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from December 2010",
                "Category:Articles with unsourced statements from December 2021",
                "Category:Articles with unsourced statements from November 2008"
            ],
            "id": 81
        },
        {
            "title": "Hardware acceleration",
            "info_text": "Hardware acceleration is the use of computer hardware designed to perform specific functions more efficiently when compared to software running on a general-purpose central processing unit (CPU). Any transformation of data that can be calculated in software running on a generic CPU can also be calculated in custom-made hardware, or in some mix of both.\nTo perform computing tasks more efficiently, generally one can invest time and money in improving the software, improving the hardware, or both. There are various approaches with advantages and disadvantages in terms of decreased latency, increased throughput, and reduced energy consumption. Typical advantages of focusing on software may include greater versatility, more rapid development, lower non-recurring engineering costs, heightened portability, and ease of updating features or patching bugs, at the cost of overhead to compute general operations. Advantages of focusing on hardware may include speedup, reduced power consumption, lower latency, increased parallelism and bandwidth, and better utilization of area and functional components available on an integrated circuit; at the cost of lower ability to update designs once etched onto silicon and higher costs of functional verification, times to market, and the need for more parts. In the hierarchy of digital computing systems ranging from general-purpose processors to fully customized hardware, there is a tradeoff between flexibility and efficiency, with efficiency increasing by orders of magnitude when any given application is implemented higher up that hierarchy. This hierarchy includes general-purpose processors such as CPUs, more specialized processors such as programmable shaders in a GPU, fixed-function implemented on field-programmable gate arrays (FPGAs), and fixed-function implemented on application-specific integrated circuits (ASICs).\nHardware acceleration is advantageous for performance, and practical when the functions are fixed, so updates are not as needed as in software solutions. With the advent of reprogrammable logic devices such as FPGAs, the restriction of hardware acceleration to fully fixed algorithms has eased since 2010, allowing hardware acceleration to be applied to problem domains requiring modification to algorithms and processing control flow. The disadvantage, however, is that in many open source projects, it requires proprietary libraries that not all vendors are keen to distribute or expose, making it difficult to integrate in such projects.",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All articles with dead external links",
                "Category:Application-specific integrated circuits",
                "Category:Articles needing additional references from September 2014",
                "Category:Articles with dead external links from July 2022",
                "Category:Articles with example C code",
                "Category:Articles with short description",
                "Category:Central processing unit",
                "Category:Commons category link from Wikidata",
                "Category:Computer optimization"
            ],
            "id": 82
        },
        {
            "title": "Sepp Hochreiter",
            "info_text": "Josef \"Sepp\" Hochreiter (born 14 February 1967) is a German computer scientist. Since 2018 he has led the Institute for Machine Learning at the Johannes Kepler University of Linz after having led the Institute of Bioinformatics from 2006 to 2018. In 2017 he became the head of the Linz Institute of Technology (LIT) AI Lab. Hochreiter is also a founding director of the Institute of Advanced Research in Artificial Intelligence (IARAI). Previously, he was at Technische Universit\u00e4t Berlin, at University of Colorado Boulder, and at the Technical University of Munich. He is a chair of the Critical Assessment of Massive Data Analysis (CAMDA) conference.\nHochreiter has made contributions in the fields of machine learning, deep learning and bioinformatics, most notably the development of the long short-term memory (LSTM) neural network architecture, but also in meta-learning, reinforcement learning and biclustering with application to bioinformatics data.\n\n",
            "categories": [
                "Category:1967 births",
                "Category:Academic staff of Johannes Kepler University Linz",
                "Category:Academic staff of the Technical University of Munich",
                "Category:All articles lacking reliable references",
                "Category:Allianz people",
                "Category:Articles lacking reliable references from October 2021",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Biostatisticians",
                "Category:Computational biology"
            ],
            "id": 83
        },
        {
            "title": "Artificial neuron",
            "info_text": "An artificial neuron is a mathematical function conceived as a model of a biological neuron in a neural network. The artificial neuron is the elementary unit of an artificial neural network.\nThe design of the artificial neuron was inspired by biological neural circuitry. Its inputs are analogous to excitatory postsynaptic potentials and inhibitory postsynaptic potentials at neural dendrites, or activation. Its weights are analogous to synaptic weights, and its output is analogous to a neuron's action potential which is transmitted along its axon.\nUsually, each input is separately weighted, and the sum is often added to a term known as a bias (loosely corresponding to the threshold potential), before being passed through a nonlinear function known as an activation function. Depending on the task, these functions could have a sigmoid shape (e.g. for binary classification), but they may also take the form of other nonlinear functions, piecewise linear functions, or step functions. They are also often monotonically increasing, continuous, differentiable, and bounded. Non-monotonic, unbounded, and oscillating activation functions with multiple zeros that outperform sigmoidal and ReLU-like activation functions on many tasks have also been recently explored. The threshold function has inspired building logic gates referred to as threshold logic; applicable to building logic circuits resembling brain processing. For example, new devices such as memristors have been extensively used to develop such logic.\nThe artificial neuron activation function should not be confused with a linear system's transfer function.\nAn artificial neuron may be referred to as a semi-linear unit, Nv neuron, binary neuron, linear threshold function, or McCulloch\u2013Pitts (MCP) neuron, depending on the structure used.\nSimple artificial neurons, such as the McCulloch\u2013Pitts model, are sometimes described as \"caricature models\", since they are intended to reflect one or more neurophysiological observations, but without regard to realism. Artificial neurons can also refer to artificial cells in neuromorphic engineering that are similar to natural physical neurons.\n\n",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:American inventions",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from May 2018",
                "Category:Articles with unsourced statements from September 2024",
                "Category:Artificial neural networks",
                "Category:Bioinspiration",
                "Category:Short description matches Wikidata"
            ],
            "id": 84
        },
        {
            "title": "Psychedelic art",
            "info_text": "Psychedelic art (also known as psychedelia) is art, graphics or visual displays related to or inspired by psychedelic experiences and hallucinations known to follow the ingestion of psychedelic drugs such as LSD, psilocybin, and DMT. Coined by British psychologist Humphry Osmond, the term \"psychedelic\" means \"mind manifesting\".  By that definition, all artistic efforts to depict the inner world of the psyche may be considered \"psychedelic\".\nIn common parlance \"psychedelic art\" refers above all to the art movement of the late 1960s counterculture, featuring highly distorted or surreal visuals, bright colors and full spectrums and animation (including cartoons) to evoke, convey, or enhance psychedelic experiences. Psychedelic visual arts were a counterpart to psychedelic rock music.  Concert posters, album covers, liquid light shows, liquid light art, murals, comic books, underground newspapers and more reflected not only the kaleidoscopically swirling colour patterns typical of psychedelic hallucinations,  but also revolutionary political, social and spiritual sentiments inspired by insights derived from these psychedelic states of consciousness.\n\n",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All articles that may contain original research",
                "Category:Art movements",
                "Category:Articles needing additional references from November 2012",
                "Category:Articles needing additional references from September 2024",
                "Category:Articles prone to spam from August 2016",
                "Category:Articles that may contain original research from February 2014",
                "Category:Articles with short description",
                "Category:Commons category link from Wikidata",
                "Category:Counterculture of the 1960s"
            ],
            "id": 85
        },
        {
            "title": "Comparison of deep learning software",
            "info_text": "The following tables compare notable software frameworks, libraries, and computer programs for deep learning applications.",
            "categories": [
                "Category:Articles with short description",
                "Category:CS1 maint: numeric names: authors list",
                "Category:Comparisons of mathematical software",
                "Category:Deep learning software",
                "Category:Short description is different from Wikidata",
                "Category:Wikipedia articles needing clarification from August 2022"
            ],
            "id": 86
        },
        {
            "title": "American English",
            "info_text": "American English, sometimes called United States English or U.S. English, is the set of varieties of the English language native to the United States. English is the most widely spoken language in the United States. It is an official language in 32 of the 50 U.S. states and the de facto common language used in government, education, and commerce in all 50 states, the District of Columbia, and in all territories except Puerto Rico. Since the late 20th century, American English has become the most influential form of English worldwide.\nVarieties of American English include many patterns of pronunciation, vocabulary, grammar and particularly spelling that are unified nationwide but distinct from other forms of  English around the world. Any American or Canadian accent perceived as lacking noticeably local, ethnic, or cultural markers is known in linguistics as General American; it covers a fairly uniform accent continuum native to certain regions of the U.S. but especially associated with broadcast mass media and highly educated speech. However, historical and present linguistic evidence does not support the notion of there being one single mainstream American accent. The sound of American English continues to evolve, with some local accents disappearing, but several larger regional accents having emerged in the 20th century.",
            "categories": [
                "Category:17th-century establishments in North America",
                "Category:All Wikipedia articles written in American English",
                "Category:All articles lacking reliable references",
                "Category:All articles with unsourced statements",
                "Category:American English",
                "Category:Articles lacking reliable references from August 2020",
                "Category:Articles with hAudio microformats",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from April 2010",
                "Category:Articles with unsourced statements from April 2019"
            ],
            "id": 87
        },
        {
            "title": "Cognitive psychology",
            "info_text": "Cognitive psychology is the scientific study of human mental processes such as attention, language use, memory, perception, problem solving, creativity, and reasoning.\nCognitive psychology originated in the 1960s in a break from behaviorism, which held from the 1920s to 1950s that unobservable mental processes were outside the realm of empirical science. This break came as researchers in linguistics and cybernetics, as well as applied psychology, used models of mental processing to explain human behavior.\nWork derived from cognitive psychology was integrated into other branches of psychology and various other modern disciplines like cognitive science, linguistics, and economics.",
            "categories": [
                "Category:1967 introductions",
                "Category:All articles with unsourced statements",
                "Category:Articles with excerpts",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from July 2024",
                "Category:Behavioural sciences",
                "Category:Cognition",
                "Category:Cognitive psychology",
                "Category:Commons category link from Wikidata",
                "Category:Short description matches Wikidata"
            ],
            "id": 88
        },
        {
            "title": "Gabor filter",
            "info_text": "In image processing, a Gabor filter, named after Dennis Gabor, who first proposed it as a 1D filter. \nThe Gabor filter was first generalized to 2D by G\u00f6sta Granlund, by adding a reference direction.\nThe Gabor filter is a linear filter used for texture analysis, which essentially means that it analyzes whether there is any specific frequency content in the image in specific directions in a localized region around the point or region of analysis. Frequency and orientation representations of Gabor filters are claimed by many contemporary vision scientists to be similar to those of the human visual system. They have been found to be particularly appropriate for texture representation and discrimination. In the spatial domain, a 2D Gabor filter is a Gaussian kernel function modulated by a sinusoidal plane wave (see Gabor transform).\nSome authors claim that simple cells in the visual cortex of mammalian brains can be modeled by Gabor functions. Thus, image analysis with Gabor filters is thought by some to be similar to perception in the human visual system.\n\n",
            "categories": [
                "Category:Accuracy disputes from February 2013",
                "Category:All accuracy disputes",
                "Category:All articles that are too technical",
                "Category:Articles with example Haskell code",
                "Category:Articles with example MATLAB/Octave code",
                "Category:Articles with example Python (programming language) code",
                "Category:Articles with short description",
                "Category:CS1 maint: multiple names: authors list",
                "Category:Image processing",
                "Category:Linear filters"
            ],
            "id": 89
        },
        {
            "title": "Nuance Communications",
            "info_text": "Nuance Communications, Inc. is an American multinational computer software technology corporation, headquartered in Burlington, Massachusetts, that markets speech recognition and artificial intelligence software.\nNuance merged with its competitor in the commercial large-scale speech application business, ScanSoft, in October 2005. ScanSoft was a Xerox spin-off that was bought in 1999 by Visioneer, a hardware and software scanner company, which adopted ScanSoft as the new merged company name. The original ScanSoft had its roots in Kurzweil Computer Products.\nIn April 2021, Microsoft announced it would buy Nuance Communications. The deal is an all-cash transaction of $19.7 billion, including company debt, or $56 per share. The acquisition was completed in March 2022.",
            "categories": [
                "Category:1992 establishments in Massachusetts",
                "Category:2000 initial public offerings",
                "Category:2022 mergers and acquisitions",
                "Category:All Wikipedia articles written in American English",
                "Category:All articles lacking reliable references",
                "Category:All articles needing additional references",
                "Category:All articles with unsourced statements",
                "Category:American companies established in 1992",
                "Category:Articles lacking reliable references from July 2021",
                "Category:Articles needing additional references from July 2021"
            ],
            "id": 90
        },
        {
            "title": "Acoustic model",
            "info_text": "An acoustic model is used in automatic speech recognition to represent the relationship between an audio signal and the phonemes or other linguistic units that make up speech. The model is learned from a set of audio recordings and their corresponding transcripts. It is created by taking audio recordings of speech, and their text transcriptions, and using software to create statistical representations of the sounds that make up each word.\n\n",
            "categories": [
                "Category:All articles needing additional references",
                "Category:Articles needing additional references from February 2011",
                "Category:Computational linguistics",
                "Category:Speech recognition"
            ],
            "id": 91
        },
        {
            "title": "Aja Huang",
            "info_text": "Aja Huang (Chinese: \u9ec3\u58eb\u5091; pinyin: Hu\u00e1ng Sh\u00ecji\u00e9; Wade\u2013Giles: Huang Shih-chieh; born 1978) is a Taiwanese computer scientist and expert on artificial intelligence. He works for DeepMind and was a member of the AlphaGo project.\nBorn in 1978, Huang received a bachelor's degree from National Chiao Tung University in 2001, a master's degree from National Taiwan Normal University in 2003, and a Ph.D degree from National Taiwan Normal University in 2011. One of his doctoral supervisors was R\u00e9mi Coulom. He began to develop computer Go program Erica in 2004, which became the champion in the 2010 Computer Olympiad.\nHuang joined DeepMind in 2012 and became a member of AlphaGo project in 2014. He is one of the first authors of DeepMind's paper on AlphaGo Fan in 2016 and a major author of the paper on AlphaGo Zero in 2017. During the 2016 match AlphaGo v. Lee Sedol and the 2017 Future of Go Summit, Huang placed stones on the Go board for AlphaGo.",
            "categories": [
                "Category:1978 births",
                "Category:All articles with unsourced statements",
                "Category:AlphaGo",
                "Category:Articles containing traditional Chinese-language text",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from October 2020",
                "Category:CS1 Chinese-language sources (zh)",
                "Category:Go (game) researchers",
                "Category:Living people",
                "Category:National Chiao Tung University alumni"
            ],
            "id": 92
        },
        {
            "title": "Herbert Robbins",
            "info_text": "Herbert Ellis Robbins (January 12, 1915 \u2013 February 12, 2001) was an American  mathematician and statistician. He did research in topology, measure theory, statistics, and a variety of other fields.  \nHe was the co-author, with Richard Courant, of What is Mathematics?.  The Robbins lemma, used in empirical Bayes methods, is named after him.  Robbins algebras are named after him because of a conjecture (since proved) that he posed concerning Boolean algebras. The Robbins theorem, in graph theory, is also named after him, as is the Whitney\u2013Robbins synthesis, a tool he introduced to prove this theorem. The well-known unsolved problem of minimizing in sequential selection the expected rank of the selected item under full information, sometimes referred to as the fourth secretary problem, also bears his name: Robbins' problem (of optimal stopping).\n\n",
            "categories": [
                "Category:1915 births",
                "Category:2001 deaths",
                "Category:20th-century American mathematicians",
                "Category:21st-century American mathematicians",
                "Category:All articles lacking in-text citations",
                "Category:American mathematical statisticians",
                "Category:Articles lacking in-text citations from May 2022",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Columbia University faculty"
            ],
            "id": 93
        },
        {
            "title": "Gated recurrent unit",
            "info_text": "Gated recurrent units (GRUs) are a gating mechanism in recurrent neural networks, introduced in 2014 by Kyunghyun Cho et al. The GRU is like a long short-term memory (LSTM) with a gating mechanism to input or forget certain features, but lacks a context vector or output gate, resulting in fewer parameters than LSTM. \nGRU's performance on certain tasks of polyphonic music modeling, speech signal modeling and natural language processing was found to be similar to that of LSTM. GRUs showed that gating is indeed helpful in general, and Bengio's team came to no concrete conclusion on which of the two gating units was better.",
            "categories": [
                "Category:Articles with short description",
                "Category:Artificial neural networks",
                "Category:Neural network architectures",
                "Category:Short description is different from Wikidata"
            ],
            "id": 94
        },
        {
            "title": "Physics-informed neural networks",
            "info_text": "Physics-informed neural networks (PINNs), also referred to as Theory-Trained Neural Networks (TTNs), are a type of universal function approximators that can embed the knowledge of any physical laws that govern a given data-set in the learning process, and can be described by partial differential equations (PDEs). Low data availability for some biological and engineering problems limit the robustness of conventional machine learning models used for these applications. The prior knowledge of general physical laws acts in the training of neural networks (NNs) as a regularization agent that limits the space of admissible solutions, increasing the generalizability of the function approximation. This way, embedding this prior information into a neural network results in enhancing the information content of the available data, facilitating the learning algorithm to capture the right solution and to generalize well even with a low amount of training examples.",
            "categories": [
                "Category:Articles with short description",
                "Category:Deep learning",
                "Category:Differential equations",
                "Category:Short description is different from Wikidata"
            ],
            "id": 95
        },
        {
            "title": "Andrej Karpathy",
            "info_text": "Andrej Karpathy (born 23 October 1986) is a Slovak-Canadian computer scientist who served as the director of artificial intelligence and Autopilot Vision at Tesla. He co-founded and formerly worked at OpenAI, where he specialized in deep learning and computer vision.\n\n",
            "categories": [
                "Category:1986 births",
                "Category:All articles with dead external links",
                "Category:Articles with dead external links from October 2022",
                "Category:Articles with hCards",
                "Category:Articles with permanently dead external links",
                "Category:Articles with short description",
                "Category:CS1 Slovak-language sources (sk)",
                "Category:Canadian computer scientists",
                "Category:Canadian people of Slovak descent",
                "Category:Living people"
            ],
            "id": 96
        },
        {
            "title": "Henry J. Kelley",
            "info_text": "Henry J. Kelley (1926-1988) was Christopher C. Kraft Professor of Aerospace and Ocean Engineering at the Virginia Polytechnic Institute. He produced major contributions to control theory, especially in aeronautical engineering and flight optimization.\nIn 1948, he received a Bachelor of Science from NYU in aeronautical engineering, and began to work for Grumman Aircraft in the same year. His studies continued as a part-time student leading\nto a Master of Science in mathematics (1951) and to the Sc.D. in aeronautical\nengineering (1958). In 1963, he left Grumman (as Assistant Chief of the\nResearch Department)  and founded Analytical Mechanics Associates with two partners. In 1978, he became a professor in the Aerospace and Ocean Engineering Department at the Virginia Polytechnic Institute.\nHis paper on \"Gradient Theory of Optimal Flight Paths\" (1960) is considered a major contribution to the field. In the context of control theory, Kelley derived basics of backpropagation, now widely used for machine learning and artificial neural networks.\nKelley received NYU's Founder's Day Award in 1959, the IAS New York Section Award in 1961, the AIAA Guidance and Control of Flight Award in 1973, and the AIAA Pendray Award in 1979. He was a Fellow of the AIAA, and member of the AAS, the IEEE and SIAM, and founder and first chairman of IFAC's Mathematics of Control Committee.\n\n",
            "categories": [
                "Category:1926 births",
                "Category:1988 deaths",
                "Category:20th-century American mathematicians",
                "Category:All stub articles",
                "Category:American control theorists",
                "Category:American mathematician stubs",
                "Category:Articles with short description",
                "Category:Fellows of the American Institute of Aeronautics and Astronautics",
                "Category:Fellows of the Society for Industrial and Applied Mathematics",
                "Category:New York University alumni"
            ],
            "id": 97
        },
        {
            "title": "John Hopfield",
            "info_text": "John Joseph Hopfield (born July 15, 1933) is an American physicist and emeritus professor of Princeton University, most widely known for his study of associative neural networks in 1982. He is known for the development of the Hopfield network. Previous to its invention, research in artificial intelligence (AI) was in a decay period or AI winter, Hopfield's work revitalized large scale interest in this field.\nIn 2024 Hopfield, along with Geoffrey Hinton, was awarded the Nobel Prize in Physics for their foundational contributions to machine learning, particularly through their work on artificial neural networks. He has been awarded various major physics awards for his work in multidisciplinary fields including condensed matter physics, statistical physics and biophysics.\n\n",
            "categories": [
                "Category:1933 births",
                "Category:20th-century American biologists",
                "Category:20th-century American physicists",
                "Category:21st-century American biologists",
                "Category:21st-century American physicists",
                "Category:Albert Einstein World Award of Science Laureates",
                "Category:American Nobel laureates",
                "Category:American artificial intelligence researchers",
                "Category:American biophysicists",
                "Category:American people of Polish descent"
            ],
            "id": 98
        },
        {
            "title": "Cluster analysis",
            "info_text": "Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some specific sense defined by the analyst) to each other than to those in other groups (clusters). It is a main task of exploratory data analysis, and a common technique for statistical data analysis, used in many fields, including pattern recognition, image analysis, information retrieval, bioinformatics, data compression, computer graphics and machine learning.\nCluster analysis refers to a family of algorithms and tasks rather than one specific algorithm. It can be achieved by various algorithms that differ significantly in their understanding of what constitutes a cluster and how to efficiently find them. Popular notions of clusters include groups with small distances between cluster members, dense areas of the data space, intervals or particular statistical distributions. Clustering can therefore be formulated as a multi-objective optimization problem. The appropriate clustering algorithm and parameter settings (including parameters such as the distance function to use, a density threshold or the number of expected clusters) depend on the individual data set and intended use of the results. Cluster analysis as such is not an automatic task, but an iterative process of knowledge discovery or interactive multi-objective optimization that involves trial and failure. It is often necessary to modify data preprocessing and model parameters until the result achieves the desired properties.\nBesides the term clustering, there is a number of terms with similar meanings, including automatic classification, numerical taxonomy, botryology (from Greek: \u03b2\u03cc\u03c4\u03c1\u03c5\u03c2 'grape'), typological analysis, and community detection. The subtle differences are often in the use of the results: while in data mining, the resulting groups are the matter of interest, in automatic classification the resulting discriminative power is of interest.\nCluster analysis originated in anthropology by Driver and Kroeber in 1932 and introduced to psychology by Joseph Zubin in 1938 and Robert Tryon in 1939 and famously used by Cattell beginning in 1943 for trait theory classification in personality psychology.\n\n",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All articles with unsourced statements",
                "Category:Articles containing Greek-language text",
                "Category:Articles needing additional references from November 2016",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from July 2018",
                "Category:Articles with unsourced statements from May 2018",
                "Category:Articles with unsourced statements from May 2023",
                "Category:CS1: long volume value",
                "Category:CS1 errors: missing periodical"
            ],
            "id": 99
        },
        {
            "title": "Drug design",
            "info_text": "Drug design, often referred to as rational drug design or simply rational design, is the inventive process of finding new medications based on the knowledge of a biological target. The drug is most commonly an organic small molecule that activates or inhibits the function of a biomolecule such as a protein, which in turn results in a therapeutic benefit to the patient. In the most basic sense, drug design involves the design of molecules that are complementary in shape and charge to the biomolecular target with which they interact and therefore will bind to it. Drug design frequently but not necessarily relies on computer modeling techniques. This type of modeling is sometimes referred to as computer-aided drug design. Finally, drug design that relies on the knowledge of the three-dimensional structure of the biomolecular target is known as structure-based drug design. In addition to small molecules, biopharmaceuticals including peptides and especially therapeutic antibodies are an increasingly important class of drugs and computational methods for improving the affinity, selectivity, and stability of these protein-based therapeutics have also been developed.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:CS1 maint: multiple names: authors list",
                "Category:Design of experiments",
                "Category:Drug discovery",
                "Category:Medicinal chemistry",
                "Category:Short description is different from Wikidata"
            ],
            "id": 100
        },
        {
            "title": "Goniasteridae",
            "info_text": "Goniasteridae (the biscuit stars) constitute the largest family of sea stars, included in the order Valvatida. They are mostly deep-dwelling species, but the family also include several colorful shallow tropical species.",
            "categories": [
                "Category:Articles with 'species' microformats",
                "Category:Articles with short description",
                "Category:Commons category link is on Wikidata",
                "Category:Echinoderm families",
                "Category:Extant Jurassic first appearances",
                "Category:Goniasteridae",
                "Category:Short description is different from Wikidata"
            ],
            "id": 101
        },
        {
            "title": "Yann LeCun",
            "info_text": "Yann Andr\u00e9 LeCun ( l\u0259-KUN, French: [l\u0259k\u0153\u0303]; originally spelled Le Cun; born 8 July 1960) is a French-American computer scientist working primarily in the fields of machine learning, computer vision, mobile robotics and computational neuroscience. He is the Silver Professor of the Courant Institute of Mathematical Sciences at New York University and Vice President, Chief AI Scientist at Meta.\nHe is well known for his work on optical character recognition and computer vision using convolutional neural networks (CNNs). He is also one of the main creators of the DjVu image compression technology (together with L\u00e9on Bottou and Patrick Haffner). He co-developed the Lush programming language with L\u00e9on Bottou.\nIn 2018, LeCun, Yoshua Bengio, and Geoffrey Hinton, received the Turing Award for their work on deep learning. The three are sometimes referred to as the \"Godfathers of AI\" and \"Godfathers of Deep Learning\".",
            "categories": [
                "Category:1960 births",
                "Category:2023 fellows of the Association for Computing Machinery",
                "Category:Academic staff of the Coll\u00e8ge de France",
                "Category:All articles with unsourced statements",
                "Category:All pages needing factual verification",
                "Category:American atheists",
                "Category:American computer scientists",
                "Category:American people of Breton descent",
                "Category:American roboticists",
                "Category:Articles with hCards"
            ],
            "id": 102
        },
        {
            "title": "Stanford University",
            "info_text": "Stanford University (officially Leland Stanford Junior University) is a private research university in Stanford, California, United States. It was founded in 1885 by railroad magnate Leland Stanford, the eighth governor of and then-incumbent senator from California, and his wife, Jane, in memory of their only child, Leland Jr. \nThe university admitted its first students in 1891, opening as a coeducational and non-denominational institution. It struggled financially after Leland died in 1893 and again after much of the campus was damaged by the 1906 San Francisco earthquake. Following World War II, university provost Frederick Terman inspired an entrepreneurial culture to build a self-sufficient local industry (later Silicon Valley). In 1951, the Stanford Research Park was established in Palo Alto and is the world's first university research park. By 2021, the university had 2,288 tenure-line faculty, senior fellows, center fellows, and medical faculty on staff.\nThe university is organized around seven schools of study on an 8,180-acre (3,310-hectare) campus, one of the largest in the nation. It houses the Hoover Institution, a public policy think tank, and is classified among \"R1: Doctoral Universities \u2013 Very high research activity\". Students compete in 36 varsity sports, and the university is one of eight private institutions in the Atlantic Coast Conference (ACC). Stanford has won 131 NCAA team championships, and was awarded the NACDA Directors' Cup for 25 consecutive years, beginning in 1994. Students and alumni have won 302 Olympic medals (including 153 gold).\nThe university is associated with 74 living billionaires, 58 Nobel laureates, 33 MacArthur Fellows, 29 Turing Award winners, as well as 7 Wolf Foundation Prize recipients, 2 Supreme Court Justices of the United States, and 4 Pulitzer Prize winners. Additionally, its alumni include many Fulbright Scholars, Marshall Scholars, Gates Cambridge Scholars, Rhodes Scholars, and members of the United States Congress.",
            "categories": [
                "Category:1891 establishments in California",
                "Category:All Wikipedia articles written in American English",
                "Category:All articles with dead external links",
                "Category:Articles containing German-language text",
                "Category:Articles using infobox university",
                "Category:Articles with dead external links from July 2024",
                "Category:Articles with dead external links from June 2022",
                "Category:Articles with permanently dead external links",
                "Category:Articles with short description",
                "Category:CS1 maint: numeric names: authors list"
            ],
            "id": 103
        },
        {
            "title": "Google",
            "info_text": "Google LLC ( , GOO-g\u0259l) is an American multinational corporation and technology company focusing on online advertising, search engine technology, cloud computing, computer software, quantum computing, e-commerce, consumer electronics, and artificial intelligence (AI). It has been referred to as \"the most powerful company in the world\" by the BBC and is one of the world's most valuable brands due to its market dominance, data collection, and technological advantages in the field of AI. Alongside Amazon, Apple, Meta, Microsoft, Google's parent company, Alphabet Inc. is one of the five Big Tech companies.\nGoogle was founded on September 4, 1998, by American computer scientists Larry Page and Sergey Brin while they were PhD students at Stanford University in California. Together, they own about 14% of its publicly listed shares and control 56% of its stockholder voting power through super-voting stock. The company went public via an initial public offering (IPO) in 2004. In 2015, Google was reorganized as a wholly owned subsidiary of Alphabet Inc. Google is Alphabet's largest subsidiary and is a holding company for Alphabet's internet properties and interests. Sundar Pichai was appointed CEO of Google on October 24, 2015, replacing Larry Page, who became the CEO of Alphabet. On December 3, 2019, Pichai also became the CEO of Alphabet.\nThe company has since rapidly grown to offer a multitude of products and services beyond Google Search, many of which hold dominant market positions. These products address a wide range of use cases, including email (Gmail), navigation and mapping (Waze, Maps and Earth), cloud computing (Cloud), web navigation (Chrome), video sharing (YouTube), productivity (Workspace), operating systems (Android), cloud storage (Drive), language translation (Translate), photo storage (Photos), videotelephony (Meet), smart home (Nest), smartphones (Pixel), wearable technology (Pixel Watch and Fitbit), music streaming (YouTube Music), video on demand (YouTube TV), AI (Google Assistant and Gemini), machine learning APIs (TensorFlow), AI chips (TPU), and more. Discontinued Google products include gaming (Stadia), Glass, Google+, Reader, Play Music, Nexus, Hangouts, and Inbox by Gmail. Google's other ventures outside of internet services and consumer electronics include quantum computing (Sycamore), self-driving cars (Waymo, formerly the Google Self-Driving Car Project), smart cities (Sidewalk Labs), and transformer models (Google DeepMind).\nGoogle Search and YouTube are the two most-visited websites worldwide followed by Facebook and Twitter (now known as X). Google is also the largest search engine, mapping and navigation application, email provider, office suite, online video platform, photo and cloud storage provider, mobile operating system, web browser, machine learning framework, and AI virtual assistant provider in the world as measured by market share. On the list of most valuable brands, Google is ranked second by Forbes as of January 2022 and fourth by Interbrand as of February 2022. \nThe company has received significant criticism involving issues such as privacy concerns, tax avoidance, censorship, search neutrality, antitrust and abuse of its monopoly position. On August 5, 2024, D.C. Circuit Court Judge Amit P. Mehta ruled that Google held an illegal monopoly over Internet search.",
            "categories": [
                "Category:1998 establishments in California",
                "Category:2004 initial public offerings",
                "Category:All Wikipedia articles written in American English",
                "Category:All articles containing potentially dated statements",
                "Category:Alphabet Inc.",
                "Category:American corporate subsidiaries",
                "Category:Articles containing potentially dated statements from 1998",
                "Category:Articles containing potentially dated statements from 2007",
                "Category:Articles containing potentially dated statements from 2020",
                "Category:Articles containing potentially dated statements from August 2015"
            ],
            "id": 104
        },
        {
            "title": "Pearson correlation coefficient",
            "info_text": "In statistics, the Pearson correlation coefficient (PCC) is a correlation coefficient that measures linear correlation between two sets of data. It is the ratio between the covariance of two variables and the product of their standard deviations; thus, it is essentially a normalized measurement of the covariance, such that the result always has a value between \u22121 and 1. As with covariance itself, the measure can only reflect a linear correlation of variables, and ignores many other types of relationships or correlations. As a simple example, one would expect the age and height of a sample of children from a primary school to have a Pearson correlation coefficient significantly greater than 0, but less than 1 (as 1 would represent an unrealistically perfect correlation).",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:All pages needing factual verification",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from April 2012",
                "Category:Articles with unsourced statements from February 2015",
                "Category:Articles with unsourced statements from January 2011",
                "Category:CS1: long volume value",
                "Category:CS1 French-language sources (fr)",
                "Category:CS1 errors: missing periodical",
                "Category:Correlation indicators"
            ],
            "id": 105
        },
        {
            "title": "German language",
            "info_text": "German (Deutsch, pronounced [d\u0254\u028ft\u0283] ) is a West Germanic language in the Indo-European language family, mainly spoken in Western and Central Europe. It is the most spoken native language within the European Union. It is the most widely spoken and official (or co-official) language in Germany, Austria, Switzerland, Liechtenstein, and the Italian autonomous province of South Tyrol. It is also an official language of Luxembourg, Belgium and the Italian autonomous region of Friuli-Venezia Giulia, as well as a recognized national language in Namibia. There are also notable German-speaking communities in France (Alsace), the Czech Republic (North Bohemia), Poland (Upper Silesia), Slovakia (Ko\u0161ice Region, Spi\u0161, and Hauerland), Denmark (North Schleswig), Romania and Hungary (Sopron). Overseas, sizeable communities of German-speakers are found in Brazil (Blumenau and Pomerode), South Africa (Kroondal), Namibia, among others, some communities have decidedly Austrian German or Swiss German characters (e.g. Pozuzo, Peru).\nGerman is one of the major languages of the world. German is the second-most widely spoken Germanic language, after English, both as a first and as a second language. German is also widely taught as a foreign language, especially in continental Europe (where it is the third most taught foreign language after English and French), and in the United States. Overall, German is the fourth most commonly learned second language, and the third most commonly learned second language in the United States in K-12 education. The language has been influential in the fields of philosophy, theology, science, and technology. It is the second most commonly used language in science and the third most widely used language on websites. The German-speaking countries are ranked fifth in terms of annual publication of new books, with one-tenth of all books (including e-books) in the world being published in German.\nGerman is most closely related to other West Germanic languages, namely Afrikaans, Dutch, English, the Frisian languages, and Scots. It also contains close similarities in vocabulary to some languages in the North Germanic group, such as Danish, Norwegian, and Swedish. Modern German gradually developed from Old High German, which in turn developed from Proto-Germanic during the Early Middle Ages.\nGerman is an inflected language, with four cases for nouns, pronouns, and adjectives (nominative, accusative, genitive, dative); three genders (masculine, feminine, neuter) and two numbers (singular, plural). It has strong and weak verbs. The majority of its vocabulary derives from the ancient Germanic branch of the Indo-European language family, while a smaller share is partly derived from Latin and Greek, along with fewer words borrowed from French and Modern English. English, however, is the main source of more recent loanwords.\nGerman is a pluricentric language; the three standardized variants are German, Austrian, and Swiss Standard German. Standard German is sometimes called High German, which refers to its regional origin. German is also notable for its broad spectrum of dialects, with many varieties existing in Europe and other parts of the world. Some of these non-standard varieties have become recognized and protected by regional or national governments.\nSince 2004, heads of state of the German-speaking countries have met every year, and the Council for German Orthography has been the main international body regulating German orthography.",
            "categories": [
                "Category:All articles containing potentially dated statements",
                "Category:All articles lacking reliable references",
                "Category:All articles with specifically marked weasel-worded phrases",
                "Category:Articles containing German-language text",
                "Category:Articles containing Hindi-language text",
                "Category:Articles containing Latin-language text",
                "Category:Articles containing Middle High German (ca. 1050-1500)-language text",
                "Category:Articles containing Old High German (ca. 750-1050)-language text",
                "Category:Articles containing potentially dated statements from 2012",
                "Category:Articles lacking reliable references from January 2024"
            ],
            "id": 106
        },
        {
            "title": "Feces",
            "info_text": "Feces (or faeces; sg.: faex) are the solid or semi-solid remains of food that was not digested in the small intestine, and has been broken down by bacteria in the large intestine. Feces contain a relatively small amount of metabolic waste products such as bacterially altered bilirubin, and dead epithelial cells from the lining of the gut.\nFeces are discharged through the anus or cloaca during defecation.\nFeces can be used as fertilizer or soil conditioner in agriculture. They can also be burned as fuel or dried and used for construction. Some medicinal uses have been found. In the case of human feces, fecal transplants or fecal bacteriotherapy are in use. Urine and feces together are called excreta.",
            "categories": [
                "Category:All articles with dead external links",
                "Category:Animal physiology",
                "Category:Articles with dead external links from April 2024",
                "Category:Articles with dead external links from March 2018",
                "Category:Articles with permanently dead external links",
                "Category:Articles with short description",
                "Category:Commons link from Wikidata",
                "Category:Feces",
                "Category:Short description is different from Wikidata",
                "Category:Use dmy dates from March 2021"
            ],
            "id": 107
        },
        {
            "title": "Spain",
            "info_text": "Spain, officially the Kingdom of Spain, is a country in Southwestern Europe with territories in North Africa. Featuring the southernmost point of continental Europe, it is the largest country in Southern Europe and the fourth-most populous European Union member state. Spanning across the majority of the Iberian Peninsula, its territory also includes the Canary Islands, in the Eastern Atlantic Ocean, the Balearic Islands, in the Western Mediterranean Sea, and the autonomous cities of Ceuta and Melilla, in Africa. Peninsular Spain is bordered to the north by France, Andorra, and the Bay of Biscay; to the east and south by the Mediterranean Sea and Gibraltar; and to the west by Portugal and the Atlantic Ocean. Spain's capital and largest city is Madrid, and other major urban areas include Barcelona, Valencia, Seville, Zaragoza, M\u00e1laga, Murcia and Palma de Mallorca.\nIn early antiquity, the Iberian Peninsula was inhabited by Celts, Iberians, and other pre-Roman peoples. With the Roman conquest of the Iberian peninsula, the province of Hispania was established. Following the Romanisation and Christianisation of Hispania, the fall of the Western Roman Empire ushered in the inward migration of tribes from Central Europe, including the Visigoths, who formed the Visigothic Kingdom centred on Toledo. In the early eighth century, most of the peninsula was conquered by the Umayyad Caliphate, and during early Islamic rule, Al-Andalus became a dominant peninsular power centred on C\u00f3rdoba. Several Christian kingdoms emerged in Northern Iberia, chief among them Asturias, Le\u00f3n, Castile, Aragon and Navarre; made an intermittent southward military expansion and repopulation, known as the Reconquista, repelling Islamic rule in Iberia, which culminated with the Christian seizure of the Nasrid Kingdom of Granada in 1492. The dynastic union of the Crown of Castile and the Crown of Aragon in 1479 under the Catholic Monarchs is often considered the de facto unification of Spain as a nation state.\nDuring the Age of Discovery, Spain pioneered the exploration and conquest of the New World, made the first circumnavigation of the globe and formed one of the largest empires in history. The Spanish Empire reached a global scale and spread across all continents, underpinning the rise of a global trading system fueled primarily by precious metals. In the 18th century, the Bourbon Reforms, particularly the Nueva Planta decrees, centralized mainland Spain, strengthening royal authority and modernizing administrative structures. In the 19th century, after the victorious Peninsular War against Napoleonic occupation forces, the following political divisions between liberals and absolutists led to the breakaway of most of the American colonies. These political divisions finally converged in the 20th century with the Spanish Civil War, giving rise to the Francoist dictatorship that lasted until 1975. With the restoration of democracy and its entry into the European Union, the country experienced an economic boom that profoundly transformed it socially and politically. Since the Spanish Golden Age, Spanish art, architecture, music, poetry, painting, literature, and cuisine have been influential worldwide, particularly in Western Europe and the Americas. As a reflection of its large cultural wealth, Spain is the world's second-most visited country, has one of the world's largest numbers of World Heritage Sites, and it is the most popular destination for European students. Its cultural influence extends to over 600 million Hispanophones, making Spanish the world's second-most spoken native language and the world's most widely spoken Romance language.\nSpain is a secular parliamentary democracy and a constitutional monarchy, with King Felipe VI as head of state. A developed country, it is a major advanced capitalist economy, with the world's fifteenth-largest by both nominal GDP and PPP-adjusted GDP. Spain is a member of the United Nations, the European Union, the eurozone, North Atlantic Treaty Organisation (NATO), a permanent guest of the G20, and is part of many other international organisations such as the Council of Europe (CoE), the Organisation of Ibero-American States (OEI), the Union for the Mediterranean, the Organisation for Economic Co-operation and Development (OECD), the Organisation for Security and Co-operation in Europe (OSCE), and the World Trade Organisation (WTO).",
            "categories": [
                "Category:All Wikipedia articles needing clarification",
                "Category:All articles containing potentially dated statements",
                "Category:All articles with dead external links",
                "Category:All articles with unsourced statements",
                "Category:Articles containing Aragonese-language text",
                "Category:Articles containing Asturian-language text",
                "Category:Articles containing Basque-language text",
                "Category:Articles containing Catalan-language text",
                "Category:Articles containing Galician-language text",
                "Category:Articles containing Latin-language text"
            ],
            "id": 108
        },
        {
            "title": "Common starfish",
            "info_text": "The common starfish, common sea star or sugar starfish (Asterias rubens) is the most common and familiar starfish in the north-east Atlantic. Belonging to the family Asteriidae, it has five arms and usually grows to between 10\u201330 cm across, although larger specimens (up to 52 cm across) are known. The common starfish is usually orange or brownish in color, and sometimes violet; specimens found in deeper waters are pale. The common starfish is found on rocky and gravelly substrates where it feeds on mollusks and other benthic invertebrates.\n\n",
            "categories": [
                "Category:Articles with 'species' microformats",
                "Category:Articles with short description",
                "Category:Asterias",
                "Category:Asteriidae",
                "Category:Commons link from Wikidata",
                "Category:Echinoderms described in 1758",
                "Category:Short description is different from Wikidata",
                "Category:Taxa named by Carl Linnaeus"
            ],
            "id": 109
        },
        {
            "title": "P\u2013n junction",
            "info_text": "A p\u2013n junction is a combination of two types of semiconductor materials, p-type and n-type, in a single crystal. The \"n\" (negative) side contains freely-moving electrons, while the \"p\" (positive) side contains freely-moving electron holes. Connecting the two materials causes creation of a depletion region near the boundary, as the free electrons fill the available holes, which in turn allows electric current to pass through the junction only in one direction.\np\u2013n junctions represent the simplest case of a semiconductor electronic device; a p-n junction by itself, when connected on both sides to a circuit, is a diode. More complex circuit components can be created by further combinations of p-type and n-type semiconductors; for example, the bipolar junction transistor (BJT) is a semiconductor in the form n\u2013p\u2013n or p\u2013n\u2013p. Combinations of such semiconductor devices on a single chip allow for the creation of integrated circuits.\nSolar cells and light-emitting diodes (LEDs) are essentially p-n junctions where the semiconductor materials are chosen, and the component's geometry designed, to maximise the desired effect (light absorption or emission). A Schottky junction is a similar case to a p\u2013n junction, where instead of an n-type semiconductor, a metal directly serves the role of the \"negative\" charge provider.\n\n",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All articles that are too technical",
                "Category:Articles needing additional references from May 2022",
                "Category:Articles with multiple maintenance issues",
                "Category:Articles with short description",
                "Category:Commons category link is on Wikidata",
                "Category:Semiconductor structures",
                "Category:Short description is different from Wikidata",
                "Category:Wikipedia articles that are too technical from May 2022"
            ],
            "id": 110
        },
        {
            "title": "Panayiota Poirazi",
            "info_text": "Panayiota Poirazi is a neuroscientist known for her work in modelling dendritic computations. She is an elected member of the European Molecular Biology Organization (EMBO).",
            "categories": [
                "Category:1974 births",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Living people",
                "Category:Short description is different from Wikidata",
                "Category:University of Cyprus alumni",
                "Category:University of Southern California alumni",
                "Category:Women neuroscientists"
            ],
            "id": 111
        },
        {
            "title": "PDF",
            "info_text": "Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems. Based on the PostScript language, each PDF file encapsulates a complete description of a fixed-layout flat document, including the text, fonts, vector graphics, raster images and other information needed to display it. PDF has its roots in \"The Camelot Project\" initiated by Adobe co-founder John Warnock in 1991.\nPDF was standardized as ISO 32000 in 2008. The last edition as ISO 32000-2:2020 was published in December 2020.\nPDF files may contain a variety of content besides flat text and graphics including logical structuring elements, interactive elements such as annotations and form-fields, layers, rich media (including video content), three-dimensional objects using U3D or PRC, and various other data formats. The PDF specification also provides for encryption and digital signatures, file attachments, and metadata to enable workflows requiring these features.\n\n",
            "categories": [
                "Category:Adobe Inc.",
                "Category:All Wikipedia articles written in American English",
                "Category:All articles containing potentially dated statements",
                "Category:All articles needing additional references",
                "Category:All articles that may have off-topic sections",
                "Category:All articles with unsourced statements",
                "Category:Articles containing potentially dated statements from 2014",
                "Category:Articles needing additional references from November 2023",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from December 2020"
            ],
            "id": 112
        },
        {
            "title": "Random forest",
            "info_text": "Random forests or random decision forests is an ensemble learning method for classification, regression and other tasks that works by creating a multitude of decision trees during training. For classification tasks, the output of the random forest is the class selected by most trees. For regression tasks, the output is the average of the predictions of the trees. Random forests correct for decision trees' habit of overfitting to their training set.:\u200a587\u2013588\u200a\nThe first algorithm for random decision forests was created in 1995 by Tin Kam Ho using the random subspace method, which, in Ho's formulation, is a way to implement the \"stochastic discrimination\" approach to classification proposed by Eugene Kleinberg.\nAn extension of the algorithm was developed by Leo Breiman and Adele Cutler, who registered \"Random Forests\" as a trademark in 2006 (as of 2019, owned by Minitab, Inc.). The extension combines Breiman's \"bagging\" idea and random selection of features, introduced first by Ho and later independently by Amit and Geman in order to construct a collection of decision trees with controlled variance.",
            "categories": [
                "Category:All articles containing potentially dated statements",
                "Category:Articles containing potentially dated statements from 2019",
                "Category:Articles with short description",
                "Category:CS1 errors: missing periodical",
                "Category:Classification algorithms",
                "Category:Computational statistics",
                "Category:Decision theory",
                "Category:Decision trees",
                "Category:Ensemble learning",
                "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link"
            ],
            "id": 113
        },
        {
            "title": "Google Assistant",
            "info_text": "Google Assistant is a virtual assistant software application developed by Google that is primarily available on home automation and mobile devices. Based on artificial intelligence, Google Assistant can engage in two-way conversations, unlike the company's previous virtual assistant, Google Now.\nGoogle Assistant debuted in May 2016 as part of Google's messaging app Allo, and its voice-activated speaker Google Nest. After a period of exclusivity on the Google Pixel smartphones, it was deployed on other Android devices starting in February 2017, including third-party smartphones and Android Wear (now Wear OS), and was released as a standalone app on the iOS operating system in May 2017. Alongside the announcement of a software development kit in April 2017, Assistant has been further extended to support a large variety of devices, including cars and third-party smart home appliances. The functionality of Assistant can also be enhanced by third-party developers. At CES 2018, the first Assistant-powered smart displays (Smart speakers with video screens) were announced, with the first one being released in July 2018. In 2020, Google Assistant is already available on more than 1 billion devices.\nUsers primarily interact with Google Assistant through natural voice, though keyboard input is also supported. Assistant is able to answer questions, schedule events and alarms, adjust hardware settings on the user's device, show information from the user's Google account, play games, and more. Google has also announced that Assistant will be able to identify objects and gather visual information through the device's camera, and support purchasing products as well as sending money. Google Assistant is available in more than 90 countries and over 30 languages, and is used by more than 500 million users monthly.\nIn October 2023, a mobile version of the Gemini chatbot, originally titled Assistant with Bard and simply just Bard, was unveiled during the Pixel 8 event. It is set to replace Assistant as the main assistant on Android devices, although the original Assistant will remain optional. The chatbot was released on February 8, 2024, in the United States.\n\n",
            "categories": [
                "Category:2016 software",
                "Category:All articles with unsourced statements",
                "Category:Android (operating system) software",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from November 2023",
                "Category:CS1 errors: generic name",
                "Category:Google Play ID not in Wikidata",
                "Category:Google software",
                "Category:ITunes app ID not in Wikidata",
                "Category:Natural language processing software"
            ],
            "id": 114
        },
        {
            "title": "Latent diffusion model",
            "info_text": "The Latent Diffusion Model (LDM) is a diffusion model architecture developed by the CompVis (Computer Vision & Learning) group at LMU Munich.\nIntroduced in 2015, diffusion models (DMs) are trained with the objective of removing successive applications of noise (commonly Gaussian) on training images. The LDM is an improvement on standard DM by performing diffusion modeling in a latent space, and by allowing self-attention and cross-attention conditioning.\nLDMs are widely used in practical diffusion models. For instance, Stable Diffusion versions 1.1 to 2.1 were based on the LDM architecture.\n\n",
            "categories": [
                "Category:2021 software",
                "Category:Articles with short description",
                "Category:Artificial intelligence art",
                "Category:Deep learning",
                "Category:Generative artificial intelligence",
                "Category:Image processing",
                "Category:Short description is different from Wikidata",
                "Category:Text-to-image generation",
                "Category:Unsupervised learning"
            ],
            "id": 115
        },
        {
            "title": "Speech recognition",
            "info_text": "Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers. It is also known as automatic speech recognition (ASR), computer speech recognition or speech-to-text (STT). It incorporates knowledge and research in the computer science, linguistics and computer engineering fields. The reverse process is speech synthesis.\nSome speech recognition systems require \"training\" (also called \"enrollment\") where an individual speaker reads text or isolated vocabulary into the system. The system analyzes the person's specific voice and uses it to fine-tune the recognition of that person's speech, resulting in increased accuracy. Systems that do not use training are called \"speaker-independent\" systems. Systems that use training are called \"speaker dependent\".\nSpeech recognition applications include voice user interfaces such as voice dialing (e.g. \"call home\"), call routing (e.g. \"I would like to make a collect call\"), domotic appliance control, search key words (e.g. find a podcast where particular words were spoken), simple data entry (e.g., entering a credit card number), preparation of structured documents (e.g. a radiology report), determining speaker characteristics, speech-to-text processing (e.g., word processors or emails), and aircraft (usually termed direct voice input). Automatic pronunciation assessment is used in education such as for spoken language learning.\nThe term voice recognition or speaker identification refers to identifying the speaker, rather than what they are saying. Recognizing the speaker can simplify the task of translating speech in systems that have been trained on a specific person's voice or it can be used to authenticate or verify the identity of a speaker as part of a security process.\nFrom the technology perspective, speech recognition has a long history with several waves of major innovations. Most recently, the field has benefited from advances in deep learning and big data. The advances are evidenced not only by the surge of academic papers published in the field, but more importantly by the worldwide industry adoption of a variety of deep learning methods in designing and deploying speech recognition systems.",
            "categories": [
                "Category:All articles containing potentially dated statements",
                "Category:All articles with dead external links",
                "Category:All articles with unsourced statements",
                "Category:All articles with vague or ambiguous time",
                "Category:Articles containing potentially dated statements from 2017",
                "Category:Articles with dead external links from March 2023",
                "Category:Articles with permanently dead external links",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from December 2012",
                "Category:Articles with unsourced statements from March 2014"
            ],
            "id": 116
        },
        {
            "title": "MLH1",
            "info_text": "DNA mismatch repair protein Mlh1 or MutL protein homolog 1 is a protein that in humans is encoded by the MLH1 gene located on chromosome 3.  The gene is commonly associated with hereditary nonpolyposis colorectal cancer. Orthologs of human MLH1 have also been studied in other organisms including mouse and the budding yeast Saccharomyces cerevisiae.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:CS1 errors: periodical ignored",
                "Category:DNA repair",
                "Category:Human genes",
                "Category:Mutation",
                "Category:Oncogenes",
                "Category:Short description is different from Wikidata"
            ],
            "id": 117
        },
        {
            "title": "Text-to-video model",
            "info_text": "A text-to-video model is a machine learning model that uses a natural language description as input to produce a video relevant to the input text. Advancements during the 2020s in the generation of high-quality, text-conditioned videos have largely been driven by the development of video diffusion models.\n\n",
            "categories": [
                "Category:Algorithms",
                "Category:All articles needing additional references",
                "Category:Articles needing additional references from December 2024",
                "Category:Articles with limited geographic scope from August 2024",
                "Category:Articles with short description",
                "Category:Artificial intelligence engineering",
                "Category:Computers",
                "Category:Language",
                "Category:Natural language processing",
                "Category:Short description matches Wikidata"
            ],
            "id": 118
        },
        {
            "title": "Flowchart",
            "info_text": "A flowchart is a type of diagram that represents a workflow or process. A flowchart can also be defined as a diagrammatic representation of an algorithm, a step-by-step approach to solving a task.\nThe flowchart shows the steps as boxes of various kinds, and their order by connecting the boxes with arrows. This diagrammatic representation illustrates a solution model to a given problem. Flowcharts are used in analyzing, designing, documenting or managing a process or program in various fields.\n\n",
            "categories": [
                "Category:Algorithm description languages",
                "Category:American inventions",
                "Category:Articles with short description",
                "Category:CS1 maint: numeric names: authors list",
                "Category:Commons link is on Wikidata",
                "Category:Computer programming",
                "Category:Diagrams",
                "Category:Modeling languages",
                "Category:Quality control tools",
                "Category:Short description matches Wikidata"
            ],
            "id": 119
        },
        {
            "title": "George Sperling",
            "info_text": "George Sperling (born 1934) is an American cognitive psychologist, researcher, and educator. Sperling documented the existence of iconic memory (one of the sensory memory subtypes). Through several experiments,  he showed support for his hypothesis that human beings store a perfect image of the visual world for a brief moment, before it is discarded from memory. He was in the forefront in wanting to help the deaf population in terms of speech recognition. He argued that the telephone was created originally for the hearing impaired but it became popularized by the hearing community. He suggested with a sevenfold reduction in the bandwidth for video transmission, it can be useful for the improvement in American Sign Language communication. Sperling used a method of partial report to measure the time course of visual persistence (sensory memory).\nHe is a Distinguished Professor of both Cognitive Science and Neurobiology & Behavior at the University of California, Irvine.\n\n",
            "categories": [
                "Category:1934 births",
                "Category:20th-century American psychologists",
                "Category:APA Distinguished Scientific Award for an Early Career Contribution to Psychology recipients",
                "Category:All BLP articles lacking sources",
                "Category:All articles lacking reliable references",
                "Category:All articles with specifically marked weasel-worded phrases",
                "Category:All articles with unsourced statements",
                "Category:American cognitive neuroscientists",
                "Category:Articles lacking reliable references from December 2011",
                "Category:Articles with hCards"
            ],
            "id": 120
        },
        {
            "title": "Hamurabi (video game)",
            "info_text": "Hamurabi is a text-based strategy video game of land and resource management. It was first developed under the name King of Sumeria or The Sumer Game by Doug Dyment in 1968 at Digital Equipment Corporation as a computer game for fellow employee Richard Merrill's newly invented FOCAL programming language.\nThe game consists of ten rounds wherein the player, as the ancient Babylonian king Hammurabi, manages how much of their grain to spend on crops for the next round, feeding their people, and purchasing additional land, while dealing with random variations in crop yields and plagues. The Sumer Game was inspired by The Sumerian Game, a much more in-depth text-based economic simulation intended for children, developed from 1964 to 1966 by designer and elementary school teacher Mabel Addis and IBM programmer William McKay.\nMultiple versions of the game were created for the FOCAL language, but around 1971 David H. Ahl ported it to DEC BASIC and in 1973 published it in 101 BASIC Computer Games. This was later republished in Microsoft BASIC form in 1978's BASIC Computer Games. His expanded version of the game, titled Hamurabi, quickly became the more prominent version due to the popularity of both the book and the programming language. Hamurabi influenced many later strategy and simulation games and is also an antecedent to the city-building genre.",
            "categories": [
                "Category:1968 video games",
                "Category:Articles using Infobox video game using locally defined parameters",
                "Category:Articles using Wikidata infoboxes with locally defined images",
                "Category:Articles with Internet Archive links",
                "Category:Articles with short description",
                "Category:CP/M games",
                "Category:CS1: long volume value",
                "Category:Early history of video games",
                "Category:Good articles",
                "Category:Hammurabi"
            ],
            "id": 121
        },
        {
            "title": "Amharic",
            "info_text": "Amharic ( am-HARR-ik or  ahm-HAR-ik; native name: \u12a0\u121b\u122d\u129b, romanized: Amar\u0259\u00f1\u00f1a, IPA: [amar\u0268\u0272\u02d0a] ) is an Ethiopian Semitic language, which is a subgrouping within the Semitic branch of the Afroasiatic languages. It is spoken as a first language by the Amharas, and also serves as a lingua franca for all other populations residing in major cities and towns in Ethiopia.\nThe language serves as the official working language of the Ethiopian federal government, and is also the official or working language of several of Ethiopia's federal regions. In 2020 in Ethiopia, it had over 33.7 million mother-tongue speakers and more than 25.1 million second language speakers in 2019, making the total number of speakers over 58.8 million. Amharic is the largest, most widely spoken language in Ethiopia, and the second most spoken mother-tongue in Ethiopia (after Oromo). Amharic is also the second most widely spoken Semitic language in the world (after Arabic).\nAmharic is written left-to-right using a system that grew out of the Ge\u02bdez script. The segmental writing system in which consonant-vowel sequences are written as units is called an abugida (\u12a0\u1261\u130a\u12f3). The graphemes are called fid\u00e4l (\u134a\u12f0\u120d), which means \"script\", \"alphabet\", \"letter\", or \"character\".\nThere is no universally agreed-upon Romanization of Amharic into Latin script. The Amharic examples in the sections below use one system that is common among linguists specializing in Ethiopian Semitic languages.",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All articles with unsourced statements",
                "Category:All articles with vague or ambiguous time",
                "Category:Amharic language",
                "Category:Articles containing Amharic-language text",
                "Category:Articles containing Ge'ez-language text",
                "Category:Articles needing additional references from March 2011",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from June 2017",
                "Category:Articles with unsourced statements from November 2024"
            ],
            "id": 122
        },
        {
            "title": "Conjugate gradient method",
            "info_text": "In mathematics, the conjugate gradient method is an algorithm for the numerical solution of particular systems of linear equations, namely those whose matrix is positive-semidefinite. The conjugate gradient method is often implemented as an iterative algorithm, applicable to sparse systems that are too large to be handled by a direct implementation or other direct methods such as the Cholesky decomposition. Large sparse systems often arise when numerically solving partial differential equations or optimization problems.\nThe conjugate gradient method can also be used to solve unconstrained optimization problems such as energy minimization. It is commonly attributed to Magnus Hestenes and Eduard Stiefel, who programmed it on the Z4, and extensively researched it.\nThe biconjugate gradient method provides a generalization to non-symmetric matrices. Various nonlinear conjugate gradient methods seek minima of nonlinear optimization problems.\n\n",
            "categories": [
                "Category:Articles with example MATLAB/Octave code",
                "Category:Articles with short description",
                "Category:CS1 German-language sources (de)",
                "Category:CS1 maint: multiple names: authors list",
                "Category:Gradient methods",
                "Category:Numerical linear algebra",
                "Category:Short description is different from Wikidata"
            ],
            "id": 123
        },
        {
            "title": "Oxford English Dictionary",
            "info_text": "The Oxford English Dictionary (OED) is the principal historical dictionary of the English language, published by Oxford University Press (OUP), a University of Oxford publishing house. The dictionary, which published its first edition in 1884, traces the historical development of the English language, providing a comprehensive resource to scholars and academic researchers, and provides ongoing descriptions of English language usage in its variations around the world.\nIn 1857, work first began on the dictionary, though the first edition was not published  In until 1884. It began to be published in unbound fascicles as work continued on the project, under the name of A New English Dictionary on Historical Principles; Founded Mainly on the Materials Collected by The Philological Society. In 1895, the title The Oxford English Dictionary was first used unofficially on the covers of the series, and in 1928 the full dictionary was republished in 10 bound volumes. \nIn 1933, the title The Oxford English Dictionary fully replaced the former name in all occurrences in its reprinting as 12 volumes with a one-volume supplement. More supplements came over the years until 1989, when the second edition was published, comprising 21,728 pages in 20 volumes. Since 2000, compilation of a third edition of the dictionary has been underway, approximately half of which was complete by 2018.\nIn 1988, the first electronic version of the dictionary was made available, and the online version has been available since 2000. By April 2014, it was receiving over two million visits per month. The third edition of the dictionary is expected to be available exclusively in electronic form; the CEO of OUP has stated that it is unlikely that it will ever be printed.",
            "categories": [
                "Category:1884 non-fiction books",
                "Category:All articles with dead external links",
                "Category:Articles containing Dutch-language text",
                "Category:Articles containing French-language text",
                "Category:Articles containing Italian-language text",
                "Category:Articles containing Spanish-language text",
                "Category:Articles with dead external links from February 2022",
                "Category:Articles with permanently dead external links",
                "Category:Articles with short description",
                "Category:Culture of the United Kingdom"
            ],
            "id": 124
        },
        {
            "title": "Los Alamos chess",
            "info_text": "Los Alamos chess (or anti-clerical chess) is a chess variant played on a 6\u00d76 board without bishops. This was the first chess-like game played by a computer program. This program was written at Los Alamos Scientific Laboratory by Paul Stein and Mark Wells for the MANIAC I computer in 1956. The reduction of the board size and the number of pieces from standard chess was due to the very limited capacity of computers at the time. The computer still needed about 20 minutes between moves.\nThe program was very simple, containing only about 600 instructions. It was mostly a minimax tree search and could look four plies ahead. For scoring the board at the end of the four-ply lookahead, it estimates a score for material and a score for mobility, then adds them. Pseudocode for the chess program is described in Figure 11.4 of Newell, 2019. In 1958, a revised version was written for MANIAC II for full 8\u00d78 chess, though its pseudocode was never published. There is a record of a single game by it, circa November 1958 (Table 11.2 of Newell, 2019).",
            "categories": [
                "Category:1956 in chess",
                "Category:Articles with short description",
                "Category:Board games introduced in 1956",
                "Category:Chess variants",
                "Category:Computer chess",
                "Category:Short description matches Wikidata"
            ],
            "id": 125
        },
        {
            "title": "Shuji Nakamura",
            "info_text": "Shuji Nakamura (\u4e2d\u6751 \u4fee\u4e8c, Nakamura Sh\u016bji, born May 22, 1954) is a Japanese-American electronic engineer and inventor of the blue LED, a major breakthrough in lighting technology. Nakamura specializes in the field of semiconductor technology, and he is a professor of materials science at the College of Engineering of the University of California, Santa Barbara (UCSB).\nTogether with Isamu Akasaki and Hiroshi Amano, Nakamura received the 2014 Nobel Prize for Physics \"for the invention of efficient blue light-emitting diodes, which has enabled bright and energy-saving white light sources\". In 2015, his input into the commercialization and development of energy-efficient white LED lighting technology was recognized by the Global Energy Prize. In 2021, Nakamura, along with Akasaki, Nick Holonyak, M. George Craford, and Russell D. Dupuis, were awarded the Queen Elizabeth Prize for Engineering \"for the creation and development of LED lighting, which forms the basis of all solid-state lighting technology\".\n\n",
            "categories": [
                "Category:1954 births",
                "Category:20th-century American engineers",
                "Category:20th-century American inventors",
                "Category:21st-century American engineers",
                "Category:21st-century American inventors",
                "Category:All articles with dead external links",
                "Category:American Nobel laureates",
                "Category:American academics of Japanese descent",
                "Category:American electronics engineers",
                "Category:American scientists of Asian descent"
            ],
            "id": 126
        },
        {
            "title": "Ilya Sutskever",
            "info_text": "Ilya Sutskever  (born 8 December 1986) is a Canadian-Israeli-Russian computer scientist who specializes in machine learning.\nSutskever has made several major contributions to the field of deep learning. He is notably the co-inventor, with Alex Krizhevsky and Geoffrey Hinton, of AlexNet, a convolutional neural network.\nSutskever co-founded and is a former chief scientist at OpenAI. In 2023, he was one of the members of OpenAI's board that ousted Sam Altman from his position as CEO; Altman returned a week later, and Sutskever stepped down from the board. In June 2024, Sutskever co-founded the company Safe Superintelligence with Daniel Gross and Daniel Levy.",
            "categories": [
                "Category:1985 births",
                "Category:AI safety scientists",
                "Category:All Wikipedia articles written in Canadian English",
                "Category:Articles containing Russian-language text",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Artificial intelligence researchers",
                "Category:CS1 Hebrew-language sources (he)",
                "Category:Canadian computer scientists",
                "Category:Canadian expatriates in the United States"
            ],
            "id": 127
        },
        {
            "title": "DALL-E",
            "info_text": "DALL-E, DALL-E 2, and DALL-E 3 (stylised DALL\u00b7E, and pronounced DOLL-E) are text-to-image models developed by OpenAI using deep learning methodologies to generate digital images from natural language descriptions known as prompts.\nThe first version of DALL-E was announced in January 2021. In the following year, its successor DALL-E 2 was released. DALL-E 3 was released natively into ChatGPT for ChatGPT Plus and ChatGPT Enterprise customers in October 2023, with availability via OpenAI's API and \"Labs\" platform provided in early November. Microsoft implemented the model in Bing's Image Creator tool and plans to implement it into their Designer app.\n\n",
            "categories": [
                "Category:2021 software",
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from July 2022",
                "Category:Artificial intelligence art",
                "Category:ChatGPT",
                "Category:Commons category link from Wikidata",
                "Category:Deep learning software applications",
                "Category:Generative pre-trained transformers",
                "Category:OpenAI"
            ],
            "id": 128
        },
        {
            "title": "Chinchilla (language model)",
            "info_text": "Chinchilla is a family of large language models (LLMs) developed by the research team at Google DeepMind, presented in March 2022.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:Chatbots",
                "Category:Google DeepMind",
                "Category:Large language models",
                "Category:Short description matches Wikidata"
            ],
            "id": 129
        },
        {
            "title": "Quantum channel",
            "info_text": "In quantum information theory, a quantum channel is a communication channel which can transmit quantum information, as well as classical information.  An example of quantum information is the general dynamics of a qubit.  An example of classical information is a text document transmitted over the Internet.\nTerminologically, quantum channels are completely positive (CP) trace-preserving maps between spaces of operators.  In other words, a quantum channel is just a quantum operation viewed not merely as the reduced dynamics of a system but as a pipeline intended to carry quantum information.  (Some authors use the term \"quantum operation\" to include trace-decreasing maps while reserving \"quantum channel\" for strictly trace-preserving maps.)\n\n",
            "categories": [
                "Category:All articles lacking in-text citations",
                "Category:All articles with unsourced statements",
                "Category:Articles lacking in-text citations from December 2024",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from December 2024",
                "Category:Quantum information theory",
                "Category:Short description is different from Wikidata"
            ],
            "id": 130
        },
        {
            "title": "John N. Bahcall",
            "info_text": "John Norris Bahcall (December 30, 1934 \u2013 August 17, 2005) was an American astrophysicist and the Richard Black Professor for Astrophysics at the Institute for Advanced Study.  He was known for a wide range of contributions to solar, galactic and extragalactic astrophysics, including the solar neutrino problem, the development of the Hubble Space Telescope and for his leadership and development of the Institute for Advanced Study in Princeton.\n\n",
            "categories": [
                "Category:1934 births",
                "Category:2005 deaths",
                "Category:20th-century American Jews",
                "Category:21st-century American Jews",
                "Category:American astronomers",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Benjamin Franklin Medal (Franklin Institute) laureates",
                "Category:Burials at Princeton Cemetery",
                "Category:C. E. Byrd High School alumni"
            ],
            "id": 131
        },
        {
            "title": "Oliver Stone",
            "info_text": "William Oliver Stone (born (1946-09-15)September 15, 1946) is an American filmmaker. Stone is an acclaimed director, tackling subjects ranging from the Vietnam War, and American politics to musical biopics and crime dramas. He has received numerous accolades including three Academy Awards, a BAFTA Award, a Primetime Emmy Award, and five Golden Globe Awards.\nStone was born in New York City and later briefly attended Yale University. In 1967, Stone enlisted in the United States Army during the Vietnam War. He then served from 1967 to 1968 in the 25th Infantry Division and was twice wounded in action. For his service, he received military honors including a Bronze Star with \"V\" Device for valor, Purple Heart with Oak Leaf Cluster (to denote two wounds), an Air Medal and the Combat Infantryman Badge. His service in Vietnam would be the basis for his later career as a filmmaker in depicting the brutality of war.\nStone started his film career writing the screenplays for Midnight Express (1978), for which he won the Academy Award for Best Adapted Screenplay; Conan the Barbarian (1982); and Scarface (1983). He then rose to prominence as writer and director of the Vietnam War film dramas Platoon (1986) and Born on the Fourth of July (1989), receiving Academy Awards for Best Director for both films, the former of which also won Best Picture. He also directed Salvador (1986), Wall Street (1987) and its sequel Wall Street: Money Never Sleeps (2010), The Doors (1991), JFK (1991), Heaven & Earth (1993), Natural Born Killers (1994), Nixon (1995), Any Given Sunday (1999), W. (2008) and Snowden (2016).\nMany of Stone's films focus on controversial American political issues during the late 20th century, and as such were considered contentious at the times of their releases. Stone has been critical of the American foreign policy, which he considers to be driven by nationalist and imperialist agendas. He has approved of politicians Hugo Ch\u00e1vez and Vladimir Putin, the latter of whom was the subject of The Putin Interviews (2017). Like his subject matter, Stone is a controversial figure in American filmmaking, with some critics accusing him of promoting conspiracy theories.\n\n",
            "categories": [
                "Category:1946 births",
                "Category:20th-century American screenwriters",
                "Category:21st-century American Buddhists",
                "Category:21st-century American male writers",
                "Category:21st-century American non-fiction writers",
                "Category:21st-century American screenwriters",
                "Category:All Wikipedia articles written in American English",
                "Category:All articles with dead external links",
                "Category:All articles with unsourced statements",
                "Category:American anti\u2013Vietnam War activists"
            ],
            "id": 132
        },
        {
            "title": "COVID-19 pandemic in the United States",
            "info_text": "On December 31, 2019, China announced the discovery of a cluster of pneumonia cases in Wuhan. The first American case was reported on January 20, and Health and Human Services Secretary Alex Azar declared a public health emergency on January 31. Restrictions were placed on flights arriving from China, but the initial U.S. response to the pandemic was otherwise slow in terms of preparing the healthcare system, stopping other travel, and testing. The first known American deaths occurred in February and in late February President Donald Trump proposed allocating $2.5 billion to fight the outbreak. Instead, Congress approved $8.3 billion with only Senator Rand Paul and two House representatives (Andy Biggs and Ken Buck) voting against, and Trump signed the bill, the Coronavirus Preparedness and Response Supplemental Appropriations Act, 2020, on March 6. Trump declared a national emergency on March 13. The government also purchased large quantities of medical equipment, invoking the Defense Production Act of 1950 to assist. By mid-April, disaster declarations were made by all states and territories as they all had increasing cases. A second wave of infections began in June, following relaxed restrictions in several states, leading to daily cases surpassing 60,000. By mid-October, a third surge of cases began; there were over 200,000 new daily cases during parts of December 2020 and January 2021.\nCOVID-19 vaccines became available in December 2020, under emergency use, beginning the national vaccination program, with the first vaccine officially approved by the Food and Drug Administration (FDA) on August 23, 2021. Studies have shown them to be highly protective against severe illness, hospitalization, and death. In comparison with fully vaccinated people, the CDC found that those who were unvaccinated were from 5 to nearly 30 times more likely to become either infected or hospitalized. There has nonetheless been some vaccine hesitancy for various reasons, although side effects are rare. There were also numerous reports that unvaccinated COVID-19 patients strained the capacity of hospitals throughout the country, forcing many to turn away patients with life-threatening diseases.\nA fourth rise in infections began in March 2021 amidst the rise of the Alpha variant, a more easily transmissible variant first detected in the United Kingdom. That was followed by a rise of the Delta variant, an even more infectious mutation first detected in India, leading to increased efforts to ensure safety. The January 2022 emergence of the Omicron variant, which was first discovered in South Africa, led to record highs in hospitalizations and cases in early 2022, with as many as 1.5 million new infections reported in a single day. By the end of 2022, an estimated 77.5% of Americans had had COVID-19 at least once, according to the CDC.\nState and local responses to the pandemic during the public health emergency included the requirement to wear a face mask in specified situations (mask mandates), prohibition and cancellation of large-scale gatherings (including festivals and sporting events), stay-at-home orders, and school closures. Disproportionate numbers of cases were observed among Black and Latino populations, as well as elevated levels of vaccine hesitancy, and there was a sharp increase in reported incidents of xenophobia and racism against Asian Americans. Clusters of infections and deaths occurred in many areas. The COVID-19 pandemic also saw the emergence of misinformation and conspiracy theories, and highlighted weaknesses in the U.S. public health system.\nIn the United States, there have been 103,436,829 confirmed cases of COVID-19 with 1,210,707 confirmed deaths, the most of any country, and the 17th highest per capita worldwide. The COVID-19 pandemic ranks as the deadliest disaster in the country's history. It was the third-leading cause of death in the U.S. in 2020, behind heart disease and cancer. From 2019 to 2020, U.S. life expectancy dropped by three years for Hispanic and Latino Americans, 2.9 years for African Americans, and 1.2 years for white Americans. In 2021, U.S. deaths due to COVID-19 rose, and life expectancy fell.",
            "categories": [
                "Category:2020 disasters in the United States",
                "Category:2020 in the United States",
                "Category:2020s disasters in the United States",
                "Category:2021 disasters in the United States",
                "Category:2021 in the United States",
                "Category:2022 disasters in the United States",
                "Category:2022 in the United States",
                "Category:2023 disasters in the United States",
                "Category:2023 in the United States",
                "Category:All Wikipedia articles in need of updating"
            ],
            "id": 133
        },
        {
            "title": "Pnictogen",
            "info_text": "The pnictogens ( or ; from Ancient Greek: \u03c0\u03bd\u1fd1\u0301\u03b3\u03c9 \"to choke\" and -gen, \"generator\") are the chemical elements in group 15 of the periodic table. This group is also known as the nitrogen group or nitrogen family. Group 15 consists of the elements nitrogen (N), phosphorus (P), arsenic (As), antimony (Sb), bismuth (Bi), and moscovium (Mc).\nSince 1988, it has been called Group 15 by the IUPAC. Before that, in America it was called Group VA, owing to a text by H. C. Deming and the Sargent-Welch Scientific Company, while in Europe it was called Group VB, which the IUPAC had recommended in 1970. (Pronounced \"group five A\" and \"group five B\"; \"V\" is the Roman numeral 5). In semiconductor physics, it is still usually called Group V. The \"five\" (\"V\") in the historical names comes from the \"pentavalency\" of nitrogen, reflected by the stoichiometry of compounds such as N2O5. They have also been called the pentels.",
            "categories": [
                "Category:All Wikipedia articles written in American English",
                "Category:All articles with unsourced statements",
                "Category:Articles containing Ancient Greek (to 1453)-language text",
                "Category:Articles containing Dutch-language text",
                "Category:Articles containing German-language text",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from January 2024",
                "Category:Articles with unsourced statements from October 2015",
                "Category:Groups (periodic table)",
                "Category:Periodic table"
            ],
            "id": 134
        },
        {
            "title": "Xbox Game Studios",
            "info_text": "Xbox Game Studios (previously known as Microsoft Studios, Microsoft Game Studios, and Microsoft Games) is an American video game publisher based in Redmond, Washington. It was established in March 2000, spun out from an internal Games Group, for the development and publishing of video games for Microsoft Windows. It has since expanded to include games and other interactive entertainment for the namesake Xbox platforms, other desktop operating systems, Windows Mobile and other mobile platforms, web-based portals, and other game consoles.\nXbox Game Studios, alongside ZeniMax Media and Activision Blizzard, are part of the Microsoft Gaming division led by Phil Spencer, who is chief executive officer of the division.\n\n",
            "categories": [
                "Category:2000 establishments in Washington (state)",
                "Category:American companies established in 2000",
                "Category:Articles with short description",
                "Category:CS1 maint: numeric names: authors list",
                "Category:Companies based in Redmond, Washington",
                "Category:First-party video game developers",
                "Category:Microsoft Gaming",
                "Category:Official website different in Wikidata and Wikipedia",
                "Category:Pages with non-numeric formatnum arguments",
                "Category:Short description is different from Wikidata"
            ],
            "id": 135
        },
        {
            "title": "Highway network",
            "info_text": "In machine learning, the Highway Network was the first working very deep feedforward neural network with hundreds of layers, much deeper than previous neural networks.\nIt uses skip connections modulated by learned gating mechanisms to regulate information flow, inspired by long short-term memory (LSTM) recurrent neural networks.\nThe advantage of the Highway Network over other deep learning architectures is its ability to overcome or partially prevent the vanishing gradient problem, thus improving its optimization. Gating mechanisms are used to facilitate information flow across the many layers (\"information highways\").\nHighway Networks have found use in text sequence labeling and speech recognition tasks.\nIn 2014, the state of the art was training deep neural networks with 20 to 30 layers. Stacking too many layers led to a steep reduction in training accuracy, known as the \"degradation\" problem. In 2015, two techniques were developed to train such networks: the Highway Network (published in May), and the residual neural network, or ResNet (December). ResNet behaves like an open-gated Highway Net.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:Machine learning",
                "Category:Neural network architectures",
                "Category:Short description is different from Wikidata"
            ],
            "id": 136
        },
        {
            "title": "Digital Unlocked",
            "info_text": "Digital Unlocked is an initiative by Google in collaboration with the Indian School of Business and Ministry of Electronics and Information Technology to promote digital awareness and to help small scale businesses and startups to go digital in India. It was announced and launched by Google's CEO Sundar Pichai during his visit to India in January 2017.  Digital Unlocked is a training program for small and medium-size businesses in India to start using the Internet to expand their business. The programme is built across the different formats of online, offline and mobile. The Digital Unlocked's offline training is being conducted in partnership with Federation of Indian Chambers of Commerce & Industry and Indian School of Business.\nThe training program allows the users to set their own goals and then recommends the courses which will help them achieve their own set goals. After completing the goals, or in-between, the users can also choose to complete and learn other courses which are of interest to them. The courses cover a wide range of topics from using the opportunities which the digital media and world have to offer to the advanced tools which can help businesses in many ways. The training program also offer a Certification to those who complete all the courses and qualify in the final assessment.\n\n",
            "categories": [
                "Category:All Wikipedia articles written in Indian English",
                "Category:Articles with short description",
                "Category:Digital India initiatives",
                "Category:Google services",
                "Category:Internet in India",
                "Category:Ministry of Communications and Information Technology (India)",
                "Category:Short description matches Wikidata",
                "Category:Use Indian English from March 2019",
                "Category:Use dmy dates from March 2019"
            ],
            "id": 137
        },
        {
            "title": "Vanishing gradient problem",
            "info_text": "In machine learning, the vanishing gradient problem is encountered when training neural networks with gradient-based learning methods and backpropagation. In such methods, during each training iteration, each neural network weight receives an update proportional to the partial derivative of the loss function with respect to the current weight. The problem is that as the network depth or sequence length increases, the gradient magnitude typically is expected to decrease (or grow uncontrollably), slowing the training process. In the worst case, this may completely stop the neural network from further learning. As one example of this problem, traditional activation functions such as the hyperbolic tangent function have gradients in the range [-1,1], and backpropagation computes gradients using the chain rule. This has the effect of multiplying n of these small numbers to compute gradients of the early layers in an n-layer network, meaning that the gradient (error signal) decreases exponentially with n while the early layers train very slowly.\nBackpropagation allowed researchers to train supervised deep artificial neural networks from scratch, initially with little success. Hochreiter's diplom thesis of 1991 formally identified the reason for this failure in the \"vanishing gradient problem\", which not only affects many-layered feedforward networks, but also recurrent networks. The latter are trained by unfolding them into very deep feedforward networks, where a new layer is created for each time-step of an input sequence processed by the network (the combination of unfolding and backpropagation is termed backpropagation through time).\nWhen activation functions are used whose derivatives can take on larger values, one risk is encountering the related exploding gradient problem.\n\n",
            "categories": [
                "Category:All articles lacking reliable references",
                "Category:All articles with unsourced statements",
                "Category:Articles lacking reliable references from December 2017",
                "Category:Articles with multiple maintenance issues",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from June 2017",
                "Category:Artificial neural networks",
                "Category:Short description matches Wikidata",
                "Category:Use dmy dates from August 2019"
            ],
            "id": 138
        },
        {
            "title": "Paul Cohen",
            "info_text": "Paul Joseph Cohen (April 2, 1934 \u2013 March 23, 2007) was an American mathematician. He is best known for his proofs that the continuum hypothesis and the axiom of choice are independent from Zermelo\u2013Fraenkel set theory, for which he was awarded a Fields Medal.",
            "categories": [
                "Category:1934 births",
                "Category:2007 deaths",
                "Category:20th-century American mathematicians",
                "Category:21st-century American mathematicians",
                "Category:American people of Polish-Jewish descent",
                "Category:American set theorists",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Brooklyn College alumni",
                "Category:Fields Medalists"
            ],
            "id": 139
        },
        {
            "title": "Document-term matrix",
            "info_text": "A document-term matrix is a mathematical matrix that describes the frequency of terms that occur in each document in a collection. In a document-term matrix, rows correspond to documents in the collection and columns correspond to terms. This matrix is a specific instance of a document-feature matrix where \"features\" may refer to other properties of a document besides terms. It is also common to encounter the transpose, or term-document matrix where documents are the columns and terms are the rows. They are useful in the field of natural language processing and computational text analysis.\nWhile the value of the cells is commonly the raw count of a given term, there are various schemes for weighting the raw counts such as row normalizing (i.e. relative frequency/proportions) and tf-idf.\nTerms are commonly single words separated by whitespace or punctuation on either side (a.k.a. unigrams). In such a case, this is also referred to as \"bag of words\" representation because the counts of individual words is retained, but not the order of the words in the document.\n\n",
            "categories": [
                "Category:All articles needing additional references",
                "Category:Articles needing additional references from January 2021",
                "Category:Natural language processing"
            ],
            "id": 140
        },
        {
            "title": "Microsoft Software Updater",
            "info_text": "Microsoft Software Updater (earlier Nokia Software Updater and Ovi Suite Software Updater) is a Windows and OS X (though the Mac version is only in Beta) based application launched in 2006, that enables customers to update and recover their mobile device firmware of a S40 or S60 or Lumia device from any Internet enabled access point. To avoid data loss users are prompted with on-screen advice on how to safely update their device.\nIn 2015 Microsoft Mobile offers four distinct software update applications, the Microsoft Software Updater serves primarily to update their feature phones, while the Lumia Software Recovery Tool and Windows Phone Recovery Tools are applications used to update and recover Windows Phone devices, though the Lumia Software Recovery Tool also supports Symbian and other Nokia platforms, and the Nokia Care Suite enables users to install Microsoft Mobile firmware updates for Microsoft Lumia devices. Further Microsoft Mobile offers desktop synchronisation applications which also offer updates to device components such as the Nokia Suite and  its predecessor the Nokia PC Suite for legacy Nokia telephones, though the Nokia Suite also supports content migration for Microsoft Lumia devices such as messages, contacts, and device software.\nAll software suites except for the Windows Phone Recovery Tool were originally developed under Nokia while the Windows Phone Recovery Tool was created specifically for the Windows 10 Technical Preview for phones.\n\n",
            "categories": [
                "Category:Nokia services",
                "Category:Symbian software",
                "Category:Use dmy dates from July 2017",
                "Category:Windows Phone software"
            ],
            "id": 141
        },
        {
            "title": "Ai",
            "info_text": "AI most frequently refers to artificial intelligence, which is intelligence demonstrated by machines.\nAi, AI or A.I. may also refer to:",
            "categories": [
                "Category:All article disambiguation pages",
                "Category:All disambiguation pages",
                "Category:Articles containing Latin-language text",
                "Category:Articles containing traditional Chinese-language text",
                "Category:Disambiguation pages",
                "Category:Short description is different from Wikidata",
                "Category:Wikipedia pages semi-protected against vandalism"
            ],
            "id": 142
        },
        {
            "title": "Cyberattacks during the Russo-Georgian War",
            "info_text": "During the Russo-Georgian War, a series of cyberattacks swamped and disabled websites of numerous South Ossetian, Georgian, Russian and Azerbaijani organisations. The attacks were initiated three weeks before the shooting war began.",
            "categories": [
                "Category:2000s internet outages",
                "Category:2008 in Azerbaijan",
                "Category:2008 in Georgia (country)",
                "Category:2008 in Russia",
                "Category:2008 in South Ossetia",
                "Category:Articles with Russian-language sources (ru)",
                "Category:Articles with short description",
                "Category:CS1 Russian-language sources (ru)",
                "Category:CS1 uses Russian-language script (ru)",
                "Category:Cyberattacks"
            ],
            "id": 143
        },
        {
            "title": "Recurrent neural network",
            "info_text": "Recurrent neural networks (RNNs) are a class of artificial neural network commonly used for sequential data processing. Unlike feedforward neural networks, which process data in a single pass, RNNs process data across multiple time steps, making them well-adapted for modelling and processing text, speech, and time series.\nThe building block of RNNs is the recurrent unit. This unit maintains a hidden state, essentially a form of memory, which is updated at each time step based on the current input and the previous hidden state. This feedback loop allows the network to learn from past inputs, and incorporate that knowledge into its current processing.\nEarly RNNs suffered from the vanishing gradient problem, limiting their ability to learn long-range dependencies. This was solved by the long short-term memory (LSTM) variant in 1997, thus making it the standard architecture for RNN.\nRNNs have been applied to tasks such as unsegmented, connected handwriting recognition, speech recognition, natural language processing, and neural machine translation.\n\n",
            "categories": [
                "Category:All articles with dead external links",
                "Category:All articles with unsourced statements",
                "Category:Articles with dead external links from June 2024",
                "Category:Articles with permanently dead external links",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from June 2017",
                "Category:CS1: long volume value",
                "Category:CS1 Finnish-language sources (fi)",
                "Category:Neural network architectures",
                "Category:Short description is different from Wikidata"
            ],
            "id": 144
        },
        {
            "title": "K-mer",
            "info_text": "In bioinformatics, k-mers are substrings of length \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n contained within a biological sequence. Primarily used within the context of computational genomics and sequence analysis, in which k-mers are composed of nucleotides (i.e. A, T, G, and C), k-mers are capitalized upon to assemble DNA sequences, improve heterologous gene expression, identify species in metagenomic samples, and create attenuated vaccines. Usually, the term k-mer refers to all of a sequence's subsequences of length \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n, such that the sequence AGAT would have four monomers (A, G, A, and T), three 2-mers (AG, GA, AT), two 3-mers (AGA and GAT) and one 4-mer (AGAT). More generally, a sequence of length \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n will have \n  \n    \n      \n        L\n        \u2212\n        k\n        +\n        1\n      \n    \n    {\\displaystyle L-k+1}\n  \n k-mers and \n  \n    \n      \n        \n          n\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle n^{k}}\n  \n total possible k-mers, where \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n is number of possible monomers (e.g. four in the case of DNA).\n\n",
            "categories": [
                "Category:Amino acids",
                "Category:Applied mathematics",
                "Category:Articles with short description",
                "Category:Bioinformatics",
                "Category:Biophysics",
                "Category:CS1: long volume value",
                "Category:CS1 maint: multiple names: authors list",
                "Category:Computational biology",
                "Category:Nucleic acids",
                "Category:Short description is different from Wikidata"
            ],
            "id": 145
        },
        {
            "title": "Croscore fonts",
            "info_text": "The ChromeOS core fonts, also known as the Croscore fonts, are a collection of three TrueType font families: Arimo (sans-serif), Tinos (serif) and Cousine (monospace). These fonts are metrically compatible with Monotype Corporation\u2019s Arial, Times New Roman, and Courier New, the most commonly used fonts on Microsoft Windows, for which they are intended as open-source substitutes.\nGoogle licenses these fonts from Ascender Corporation under the Apache License 2.0.\nThe fonts were originally developed by Steve Matteson as Ascender Sans and Ascender Serif, and were also the basis for the Liberation fonts licensed by Red Hat under another open source license. In July 2012, version 2.0 of the Liberation fonts, based on the Croscore fonts, was released under the SIL Open Font License.\nThe fonts are also available at the Noto fonts repository at GitHub.",
            "categories": [
                "Category:Articles containing Polish-language text",
                "Category:Articles with short description",
                "Category:Cyrillic typefaces",
                "Category:Greek typefaces",
                "Category:IPA typefaces",
                "Category:Open-source typefaces",
                "Category:Short description is different from Wikidata",
                "Category:Unicode typefaces",
                "Category:Unified serif and sans-serif typeface families"
            ],
            "id": 146
        },
        {
            "title": "Dartmouth workshop",
            "info_text": "The Dartmouth Summer Research Project on Artificial Intelligence was a 1956 summer workshop widely considered to be the founding event of artificial intelligence as a field. The workshop has been referred to as the \"Constitutional Convention of AI\". The project's four organizers, those being Claude Shannon, John McCarthy, Nathaniel Rochester and Marvin Minsky, are considered some of the founding fathers of AI.\nThe project lasted approximately six to eight weeks and was essentially an extended brainstorming session. Eleven mathematicians and scientists originally planned to attend; not all of them attended, but more than ten others came for short times.\n\n",
            "categories": [
                "Category:1956 in computing",
                "Category:Articles with short description",
                "Category:Artificial intelligence conferences",
                "Category:Dartmouth College history",
                "Category:History of artificial intelligence",
                "Category:Pages with missing ISBNs",
                "Category:Philosophy of artificial intelligence",
                "Category:Short description is different from Wikidata",
                "Category:Wikipedia articles needing page number citations from July 2024"
            ],
            "id": 147
        },
        {
            "title": "Fantastic Adventures scandal",
            "info_text": "The Fantastic Adventures scandal was a 2019 scandal involving the YouTube channel Fantastic Adventures, run by Machelle Hackney Hobson of Maricopa, Arizona, in the United States. The scandal began when one of Hobson's biological children contacted the police after witnessing her adopted siblings being systematically abused by her mother. Hobson and the channel garnered worldwide media attention, given the degree of Hobson's child abuse.\n\n",
            "categories": [
                "Category:2010s YouTube controversies",
                "Category:2012 establishments in Arizona",
                "Category:2019 controversies in the United States",
                "Category:2019 disestablishments in Arizona",
                "Category:2019 scandals",
                "Category:21st-century American criminals",
                "Category:21st-century American women",
                "Category:American directors",
                "Category:American women comedians",
                "Category:Articles with short description"
            ],
            "id": 148
        },
        {
            "title": "Word embedding",
            "info_text": "In natural language processing, a word embedding is a representation of a word. The embedding is used in text analysis. Typically, the representation is a real-valued vector that encodes the meaning of the word in such a way that the words that are closer in the vector space are expected to be similar in meaning. Word embeddings can be obtained using language modeling and feature learning techniques, where words or phrases from the vocabulary are mapped to vectors of real numbers.\nMethods to generate this mapping include neural networks, dimensionality reduction on the word co-occurrence matrix, probabilistic models, explainable knowledge base method, and explicit representation in terms of the context in which words appear.\nWord and phrase embeddings, when used as the underlying input representation, have been shown to boost the performance in NLP tasks such as syntactic parsing and sentiment analysis.\n\n",
            "categories": [
                "Category:All articles lacking reliable references",
                "Category:Articles lacking reliable references from May 2024",
                "Category:Articles with short description",
                "Category:Artificial neural networks",
                "Category:CS1: long volume value",
                "Category:Computational linguistics",
                "Category:Language modeling",
                "Category:Natural language processing",
                "Category:Semantic relations",
                "Category:Short description matches Wikidata"
            ],
            "id": 149
        },
        {
            "title": "PyTorch",
            "info_text": "PyTorch is a machine learning library based on the Torch library, used for applications such as computer vision and natural language processing, originally developed by Meta AI and now part of the Linux Foundation umbrella. It is one of the most popular deep learning frameworks, alongside others such as TensorFlow and PaddlePaddle, offering free and open-source software released under the modified BSD license. Although the Python interface is more polished and the primary focus of development, PyTorch also has a C++ interface.\nA number of pieces of deep learning software are built on top of PyTorch, including Tesla Autopilot, Uber's Pyro, Hugging Face's Transformers, PyTorch Lightning, and Catalyst.\nPyTorch provides two high-level features:\n\nTensor computing (like NumPy) with strong acceleration via graphics processing units (GPU)\nDeep neural networks built on a tape-based automatic differentiation system\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:Deep learning software",
                "Category:Facebook software",
                "Category:Free science software",
                "Category:Free software programmed in C",
                "Category:Free software programmed in Python",
                "Category:Open-source artificial intelligence",
                "Category:Python (programming language) scientific libraries",
                "Category:Short description is different from Wikidata",
                "Category:Software using the BSD license"
            ],
            "id": 150
        },
        {
            "title": "Breathing",
            "info_text": "Breathing (spiration or ventilation) is the rhythmical process of moving air into (inhalation) and out of (exhalation) the lungs to facilitate gas exchange with the internal environment, mostly to flush out carbon dioxide and bring in oxygen.\nAll aerobic creatures need oxygen for cellular respiration, which extracts energy from the reaction of oxygen with molecules derived from food and produces carbon dioxide as a waste product. Breathing, or external respiration, brings air into the lungs where gas exchange takes place in the alveoli through diffusion. The body's circulatory system transports these gases to and from the cells, where cellular respiration takes place.\nThe breathing of all vertebrates with lungs consists of repetitive cycles of inhalation and exhalation through a highly branched system of tubes or airways which lead from the nose to the alveoli. The number of respiratory cycles per minute is the breathing or respiratory rate, and is one of the four primary vital signs of life. Under normal conditions the breathing depth and rate is automatically, and unconsciously, controlled by several homeostatic mechanisms which keep the partial pressures of carbon dioxide and oxygen in the arterial blood constant. Keeping the partial pressure of carbon dioxide in the arterial blood unchanged under a wide variety of physiological circumstances, contributes significantly to tight control of the pH of the extracellular fluids (ECF). Over-breathing (hyperventilation) increases the arterial partial pressure of carbon dioxide, causing a rise in the pH of the ECF. Under-breathing (hypoventilation), on the other hand, decreases the arterial partial pressure of carbon dioxide and lowers the pH of the ECF. Both cause distressing symptoms.\nBreathing has other important functions. It provides a mechanism for speech, laughter and similar expressions of the emotions. It is also used for reflexes such as yawning, coughing and sneezing. Animals that cannot thermoregulate by perspiration, because they lack sufficient sweat glands, may lose heat by evaporation through panting.",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles containing video clips",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from January 2021",
                "Category:CS1: unfit URL",
                "Category:Commons category link from Wikidata",
                "Category:Gases",
                "Category:Human body",
                "Category:Pages displaying wikidata descriptions as a fallback via Module:Annotated link",
                "Category:Reflexes"
            ],
            "id": 151
        },
        {
            "title": "Mamba (deep learning architecture)",
            "info_text": "Mamba is a deep learning architecture focused on sequence modeling. It was developed by researchers from Carnegie Mellon University and Princeton University to address some limitations of transformer models, especially in processing long sequences. It is based on the Structured State Space sequence (S4) model.\n\n",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from July 2024",
                "Category:Language modeling",
                "Category:Neural network architectures",
                "Category:Short description matches Wikidata"
            ],
            "id": 152
        },
        {
            "title": "Bazel (software)",
            "info_text": "Bazel () is a free and open-source software tool used for the automation of building and testing software.\nSimilar to build tools like Make, Apache Ant, and Apache Maven, Bazel builds software applications from source code using rules. Rules and macros are created in the Starlark language, a dialect of Python. There are built-in rules for building software written in Java, Kotlin, Scala, C, C++, Go, Python, Rust, JavaScript, Objective-C, and bash scripts. Bazel can produce software application packages suitable for deployment for the Android and iOS operating systems.\n\n",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All articles with a promotional tone",
                "Category:Articles needing additional references from February 2024",
                "Category:Articles with a promotional tone from October 2019",
                "Category:Articles with short description",
                "Category:Build automation",
                "Category:CS1 maint: multiple names: authors list",
                "Category:Compiling tools",
                "Category:Google software",
                "Category:Short description matches Wikidata"
            ],
            "id": 153
        },
        {
            "title": "TP-Link",
            "info_text": "TP-Link is a Chinese company that manufactures network equipment and smart home products. The company was established in 1996 in Shenzhen. TP-Link's main headquarters is located in Nanshan, Shenzhen; there is a smaller headquarters in Irvine, California. It has subsidiaries operating globally and owns several brands, including Deco, Tapo, Omada, VIGI, Aginet, Kasa Smart, and Mercusys. The company has been investigated by the governments of India and the United States for national security risks.",
            "categories": [
                "Category:1996 establishments in China",
                "Category:1996 in Shenzhen",
                "Category:All pages needing factual verification",
                "Category:Android (operating system) software",
                "Category:Articles containing Chinese-language text",
                "Category:Articles with short description",
                "Category:Chinese brands",
                "Category:Commons category link from Wikidata",
                "Category:Companies established in 1996",
                "Category:Computer companies of China"
            ],
            "id": 154
        },
        {
            "title": "Tom Szkutak",
            "info_text": "Tom Szkutak was Chief Financial Officer (CFO) and senior vice president at Amazon.com. Szkutak joined Amazon.com in October 2002 after 20 years at General Electric. On September 3, 2014, it was announced Szkutak will be leaving Amazon in June 2015 to pursue other interests and spend more time with his family. He was succeeded by Brian Olsavsky in late 2015.\nBefore joining Amazon.com, Szkutak served as CFO for GE Lighting. Prior to CFO position, Szkutak oversaw the GE Plastics finance operations for Europe, the Middle East, Africa and India. In addition, he was executive vice president of finance for GE Investments in Stamford, Connecticut.\nSzkutak received a BS, magna cum laude, in finance from Boston University.\n\n",
            "categories": [
                "Category:All stub articles",
                "Category:Amazon (company) people",
                "Category:American business biography stubs",
                "Category:American chief financial officers",
                "Category:Articles with hCards",
                "Category:Boston University School of Management alumni",
                "Category:General Electric people",
                "Category:Living people",
                "Category:Year of birth missing (living people)"
            ],
            "id": 155
        },
        {
            "title": "Google Lunar X Prize",
            "info_text": "The Google Lunar X Prize (GLXP) was a 2007\u20132018 inducement prize space competition organized by the X Prize Foundation, and sponsored by Google.  The challenge called for privately funded teams to be the first to land a lunar rover on the Moon, travel 500 meters, and transmit back to Earth high-definition video and images.\nThe original deadline was the end of 2014, with additional prize money for a landing by 2012. In 2015, XPRIZE announced that the competition deadline would be extended to December 2017 if at least one team could secure a verified launch contract by 31 December 2015. Two teams secured such a launch contract, and the deadline was extended. In August 2017, the deadline was extended again, to 31 March 2018.\nEntering 2018, five teams remained in the competition: SpaceIL, Moon Express, Synergy Moon, TeamIndus, and Team Hakuto, having secured verified launch contracts with Spaceflight Industries, Rocket Lab, Interorbital Systems, and ISRO (jointly for the last two teams).\nOn 23 January 2018, the X Prize Foundation announced that \"no team would be able to make a launch attempt to reach the Moon by the [31 March 2018] deadline...and the US$30 million Google Lunar XPRIZE will go unclaimed.\" On 5 April 2018, the X Prize Foundation announced that the Lunar XPRIZE would continue as a non-cash competition.\nOn 11 April 2019, the SpaceIL Beresheet spacecraft crashed while attempting to land on the moon.  The SpaceIL team was awarded a $1 million \"Moonshot Award\" by the X Prize Foundation in recognition of touching the surface of the Moon.\n\n",
            "categories": [
                "Category:All Wikipedia articles in need of updating",
                "Category:All articles with dead external links",
                "Category:All articles with unsourced statements",
                "Category:All articles with vague or ambiguous time",
                "Category:Articles with dead external links from June 2024",
                "Category:Articles with dead external links from May 2023",
                "Category:Articles with permanently dead external links",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from January 2018",
                "Category:Challenge awards"
            ],
            "id": 156
        },
        {
            "title": "Seymour Papert",
            "info_text": "Seymour Aubrey Papert (; 29 February 1928 \u2013 31 July 2016) was a South African-born American mathematician, computer scientist, and educator, who spent most of his career teaching and researching at MIT. He was one of the pioneers of artificial intelligence, and of the constructionist movement in education. He was co-inventor, with Wally Feurzeig and Cynthia Solomon, of the Logo programming language.",
            "categories": [
                "Category:1928 births",
                "Category:2016 deaths",
                "Category:20th-century American Jews",
                "Category:20th-century South African mathematicians",
                "Category:21st-century American Jews",
                "Category:21st-century South African mathematicians",
                "Category:All articles with unsourced statements",
                "Category:American cognitive psychologists",
                "Category:American people of Lithuanian-Jewish descent",
                "Category:Articles with hCards"
            ],
            "id": 157
        },
        {
            "title": "Retrieval-augmented generation",
            "info_text": "Retrieval-Augmented Generation (RAG) is a technique that grants generative artificial intelligence models information retrieval capabilities. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information to augment information drawn from its own vast, static training data. This allows LLMs to use domain-specific and/or updated information.  \nUse cases include providing chatbot access to internal company data or giving factual information only from an authoritative source.\n\n",
            "categories": [
                "Category:All articles containing potentially dated statements",
                "Category:All articles needing additional references",
                "Category:Articles containing potentially dated statements from 2023",
                "Category:Articles needing additional references from October 2024",
                "Category:Articles with short description",
                "Category:Generative artificial intelligence",
                "Category:Information retrieval systems",
                "Category:Large language models",
                "Category:Natural language processing",
                "Category:Short description is different from Wikidata"
            ],
            "id": 158
        },
        {
            "title": "BebaPay",
            "info_text": "BebaPay was a form of electronic ticketing platform in Nairobi, Kenya, that was developed by Google in partnership with Equity Bank. The product was launched in April 2013, after one year of piloting.",
            "categories": [
                "Category:2013 establishments in Kenya",
                "Category:Articles with short description",
                "Category:Computer companies established in 2013",
                "Category:Discontinued Google services",
                "Category:EngvarB from February 2016",
                "Category:Google",
                "Category:Kenyan companies established in 2013",
                "Category:Short description matches Wikidata",
                "Category:Use dmy dates from December 2020"
            ],
            "id": 159
        },
        {
            "title": "Bloomberg News",
            "info_text": "Bloomberg News (originally Bloomberg Business News) is an international news agency headquartered in New York City and a division of Bloomberg L.P. Content produced by Bloomberg News is disseminated through Bloomberg Terminals, Bloomberg Television, Bloomberg Radio, Bloomberg Businessweek, Bloomberg Markets, Bloomberg.com, and Bloomberg's mobile platforms. Since 2015, John Micklethwait has been editor-in-chief.\n\n",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from February 2020",
                "Category:Bloomberg L.P.",
                "Category:CS1 errors: generic name",
                "Category:Mass media companies based in New York City",
                "Category:News agencies based in the United States",
                "Category:Short description is different from Wikidata",
                "Category:Use mdy dates from April 2024"
            ],
            "id": 160
        },
        {
            "title": "Digital image",
            "info_text": "A digital image is an image composed of picture elements, also known as pixels, each with finite, discrete quantities of numeric representation for its intensity or gray level that is an output from its two-dimensional functions fed as input by its spatial coordinates denoted with x, y on the x-axis and y-axis, respectively. Depending on whether the image resolution is fixed, it may be of vector or raster type. By itself, the term \"digital image\" usually refers to raster images or bitmapped images (as opposed to vector images).\n\n",
            "categories": [
                "Category:All Wikipedia articles written in American English",
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from December 2019",
                "Category:CS1 errors: periodical ignored",
                "Category:CS1 maint: multiple names: authors list",
                "Category:Digital geometry",
                "Category:Digital imaging",
                "Category:Image processing",
                "Category:Pages using div col with small parameter"
            ],
            "id": 161
        },
        {
            "title": "Quantization (signal processing)",
            "info_text": "Quantization, in mathematics and digital signal processing, is the process of mapping input values from a large set (often a continuous set) to output values in a (countable) smaller set, often with a finite number of elements.  Rounding and truncation are typical examples of quantization processes.  Quantization is involved to some degree in nearly all digital signal processing, as the process of representing a signal in digital form ordinarily involves rounding.  Quantization also forms the core of essentially all lossy compression algorithms.\nThe difference between an input value and its quantized value (such as round-off error) is referred to as quantization error, noise or distortion.  A device or algorithmic function that performs quantization is called a quantizer.  An analog-to-digital converter is an example of a quantizer.\n\n",
            "categories": [
                "Category:All Wikipedia articles written in American English",
                "Category:Articles with short description",
                "Category:CS1: long volume value",
                "Category:Computer graphic artifacts",
                "Category:Data compression",
                "Category:Digital audio",
                "Category:Digital signal processing",
                "Category:Noise (electronics)",
                "Category:Short description matches Wikidata",
                "Category:Signal processing"
            ],
            "id": 162
        },
        {
            "title": "Nancy Kress",
            "info_text": "Nancy Anne Kress (born January 20, 1948) is an American science fiction writer. She began writing in 1976 but has achieved her greatest notice since the publication of her Hugo- and Nebula-winning novella Beggars in Spain (1991), which became a novel in 1993. She also won the Nebula Award for Best Novella in 2013 for After the Fall, Before the Fall, During the Fall, and in 2015 for Yesterday's Kin. In addition to her novels, Kress has written numerous short stories and is a regular columnist for Writer's Digest.  She is a regular at Clarion Workshops. During the winter of 2008/09, Nancy Kress was the Picador Guest Professor for Literature at the University of Leipzig's Institute for American Studies in Leipzig, Germany.",
            "categories": [
                "Category:1948 births",
                "Category:20th-century American novelists",
                "Category:20th-century American women writers",
                "Category:21st-century American novelists",
                "Category:21st-century American women writers",
                "Category:American science fiction writers",
                "Category:American women novelists",
                "Category:American women science fiction and fantasy writers",
                "Category:Articles with short description",
                "Category:Asimov's Science Fiction people"
            ],
            "id": 163
        },
        {
            "title": "Load\u2013store architecture",
            "info_text": "In computer engineering, a load\u2013store architecture (or a register\u2013register architecture) is an instruction set architecture that divides instructions into two categories: memory access (load and store between memory and registers) and ALU operations (which only occur between registers).:\u200a9\u201312\u200a\nSome RISC architectures such as PowerPC, SPARC, RISC-V, ARM, and MIPS are load\u2013store architectures.:\u200a9\u201312\u200a\nFor instance, in a load\u2013store approach both operands and destination for an ADD operation must be in registers. This differs from a register\u2013memory architecture (for example, a CISC instruction set architecture such as x86) in which one of the operands for the ADD operation may be in memory, while the other is in a register.:\u200a9\u201312\u200a\nThe earliest example of a load\u2013store architecture was the CDC 6600.:\u200a54\u201356\u200a Almost all vector processors (including many GPUs) use the load\u2013store approach.\n\n",
            "categories": [
                "Category:All articles lacking reliable references",
                "Category:All stub articles",
                "Category:Articles lacking reliable references from June 2020",
                "Category:Articles with short description",
                "Category:Computer architecture",
                "Category:Computer engineering stubs",
                "Category:Short description matches Wikidata"
            ],
            "id": 164
        },
        {
            "title": "Universal Disk Format",
            "info_text": "Universal Disk Format (UDF) is an open, vendor-neutral file system for computer data storage for a broad range of media. In practice, it has been most widely used for DVDs and newer optical disc formats, supplanting ISO 9660. Due to its design, it is very well suited to incremental updates on both write-once and re-writable optical media. UDF was developed and maintained by the Optical Storage Technology Association (OSTA).\nIn engineering terms, Universal Disk Format is a profile of the specifications known as ISO/IEC 13346 and ECMA-167.\n\n",
            "categories": [
                "Category:All Wikipedia articles in need of updating",
                "Category:Articles with short description",
                "Category:Disk file systems",
                "Category:Ecma standards",
                "Category:IEC standards",
                "Category:ISO standards",
                "Category:Short description matches Wikidata",
                "Category:Use dmy dates from September 2019",
                "Category:Wikipedia articles in need of updating from November 2020",
                "Category:Windows components"
            ],
            "id": 165
        },
        {
            "title": "Morphogenesis",
            "info_text": "Morphogenesis (from the Greek morph\u00ea shape and genesis creation, literally \"the generation of form\") is the biological process that causes a cell, tissue or organism to develop its shape. It is one of three fundamental aspects of developmental biology along with the control of tissue growth and patterning of cellular differentiation.\nThe process controls the organized spatial distribution of cells during the embryonic development of an organism. Morphogenesis can take place also in a mature organism, such as in the normal maintenance of tissue by stem cells or in regeneration of tissues after damage. Cancer is an example of highly abnormal and pathological tissue morphogenesis. Morphogenesis also describes the development of unicellular life forms that do not have an embryonic stage in their life cycle.  Morphogenesis is essential for the evolution of new forms.\nMorphogenesis is a mechanical process involving forces that generate mechanical stress, strain, and movement of cells, and can be induced by genetic programs according to the spatial patterning of cells within tissues. Abnormal morphogenesis is called dysmorphogenesis.\n\n",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from March 2024",
                "Category:Commons category link from Wikidata",
                "Category:Developmental biology",
                "Category:Evolutionary developmental biology",
                "Category:Morphology (biology)",
                "Category:Short description matches Wikidata"
            ],
            "id": 166
        },
        {
            "title": "LCEVC",
            "info_text": "Low Complexity Enhancement Video Coding (LCEVC) is a ISO/IEC video coding standard developed by the Moving Picture Experts Group (MPEG) under the project name MPEG-5 Part 2 LCEVC.\n\n",
            "categories": [
                "Category:All articles with dead external links",
                "Category:Articles with dead external links from August 2023",
                "Category:Articles with permanently dead external links",
                "Category:Articles with short description",
                "Category:CS1 Brazilian Portuguese-language sources (pt-br)",
                "Category:Film and video technology",
                "Category:Short description matches Wikidata",
                "Category:Video codecs",
                "Category:Video compression",
                "Category:Wikipedia articles needing clarification from April 2022"
            ],
            "id": 167
        },
        {
            "title": "Delaporte distribution",
            "info_text": "The Delaporte distribution is a discrete probability distribution that has received attention in actuarial science. It can be defined using the convolution of a negative binomial distribution with a Poisson distribution. Just as the negative binomial distribution can be viewed as a Poisson distribution where the mean parameter is itself a random variable with a gamma distribution, the Delaporte distribution can be viewed as a compound distribution based on a Poisson distribution, where there are two components to the mean parameter: a fixed component, which has the \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n  \n parameter, and a gamma-distributed variable component, which has the \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n  \n and \n  \n    \n      \n        \u03b2\n      \n    \n    {\\displaystyle \\beta }\n  \n parameters. The distribution is named for Pierre Delaporte, who analyzed it in relation to automobile accident claim counts in 1959, although it appeared in a different form as early as 1934 in a paper by Rolf von L\u00fcders, where it was called the Formel II distribution.",
            "categories": [
                "Category:CS1 French-language sources (fr)",
                "Category:CS1 German-language sources (de)",
                "Category:Compound probability distributions",
                "Category:Discrete distributions"
            ],
            "id": 168
        },
        {
            "title": "Errors and residuals",
            "info_text": "In statistics and optimization, errors and residuals are two closely related and easily confused measures of the deviation of an observed value of an element of a statistical sample from its \"true value\" (not necessarily observable). The error of an observation is the deviation of the observed value from the true value of a quantity of interest (for example, a population mean). The residual is the difference between the observed value and the estimated value of the quantity of interest (for example, a sample mean). The distinction is most important in regression analysis, where the concepts are sometimes called the regression errors and regression residuals and where they lead to the concept of studentized residuals.\nIn econometrics, \"errors\" are also called disturbances.",
            "categories": [
                "Category:All articles lacking in-text citations",
                "Category:Articles lacking in-text citations from September 2016",
                "Category:Articles with short description",
                "Category:Commons category link from Wikidata",
                "Category:Errors and residuals",
                "Category:Regression analysis",
                "Category:Short description is different from Wikidata",
                "Category:Statistical deviation and dispersion"
            ],
            "id": 169
        },
        {
            "title": "Walter Houser Brattain",
            "info_text": "Walter Houser Brattain (; February 10, 1902 \u2013 October 13, 1987) was an American physicist at Bell Labs who, along with fellow scientists John Bardeen and William Shockley, invented the point-contact transistor in December 1947. They shared the 1956 Nobel Prize in Physics for their invention. Brattain devoted much of his life to research on surface states.\n\n",
            "categories": [
                "Category:1902 births",
                "Category:1987 deaths",
                "Category:20th-century American inventors",
                "Category:20th-century American physicists",
                "Category:American Nobel laureates",
                "Category:American expatriates in China",
                "Category:American experimental physicists",
                "Category:American people of German descent",
                "Category:American people of Scottish descent",
                "Category:American quantum physicists"
            ],
            "id": 170
        },
        {
            "title": "Reddit",
            "info_text": "Reddit ( ) is an American social news aggregation, content rating, and forum social network. Registered users (commonly referred to as \"Redditors\") submit content to the site such as links, text posts, images, and videos, which are then voted up or down (\"upvoted\" or \"downvoted\") by other members. Posts are organized by subject into user-created boards called \"subreddits\". Submissions with more upvotes appear towards the top of their subreddit and, if they receive enough upvotes, ultimately on the site's front page. Reddit administrators moderate the communities. Moderation is also conducted by community-specific moderators, who are unpaid volunteers. It is operated by Reddit, Inc., based in San Francisco.\nAs of December 2024, Reddit is the 8th most-visited website in the world. According to data provided by Similarweb, 51.75% of the website traffic comes from the United States, followed by Canada at 7.01%, United Kingdom at 6.97%, Australia at 3.97%, Germany at 3% and the remaining 28.37% split among other worlds countries.\nReddit was founded by University of Virginia roommates Steve Huffman and Alexis Ohanian, as well as Aaron Swartz, in 2005. Cond\u00e9 Nast Publications acquired the site in October 2006. In 2011, Reddit became an independent subsidiary of Cond\u00e9 Nast's parent company, Advance Publications. In October 2014, Reddit raised $50 million in a funding round led by Sam Altman and including investors Marc Andreessen, Peter Thiel, Ron Conway, Snoop Dogg, and Jared Leto. Their investment valued the company at $500 million at the time. In July 2017, Reddit raised $200 million for a $1.8 billion valuation; Advance Publications remained the majority stakeholder. In February 2019, a $300 million funding round led by Tencent brought the company's valuation to $3 billion. In August 2021, a $700 million funding round led by Fidelity Investments raised that valuation to over $10 billion. The company then reportedly filed for an IPO in December 2021 with a valuation of $15 billion. Reddit debuted on the stock market on the morning of March 21, 2024, with the ticker symbol RDDT. The current market cap as of July 2024 is $10 billion. Reddit has been noted for its role in political activism, with notable left-wing and anti-theist subcultures on the website. \nReddit has received praise for many of its features, such as the ability to create several subreddits for niche communities and being a platform for raising publicity for numerous causes. As a result, it has grown to be one of the most visited websites on the Internet. It has also received criticism for the spread of misinformation and its voting system which can encourage online echo chambers. In its early years, Reddit also received controversy over hosting misogynistic content, including the doxxing of erotic models and revenge porn.",
            "categories": [
                "Category:2005 establishments in Massachusetts",
                "Category:2024 initial public offerings",
                "Category:Aggregation websites",
                "Category:All articles containing potentially dated statements",
                "Category:American social networking websites",
                "Category:Android (operating system) software",
                "Category:Articles containing potentially dated statements from 2018",
                "Category:Articles containing potentially dated statements from April 2018",
                "Category:Articles containing potentially dated statements from August 2018",
                "Category:Articles containing potentially dated statements from August 2021"
            ],
            "id": 171
        },
        {
            "title": "Crinoid",
            "info_text": "Crinoids are marine invertebrates that make up the class Crinoidea. Crinoids that remain attached to the sea floor by a stalk in their adult form are commonly called sea lilies, while the unstalked forms, called feather stars or comatulids, are members of the largest crinoid order, Comatulida. Crinoids are echinoderms in the phylum Echinodermata, which also includes the starfish, brittle stars, sea urchins and sea cucumbers.  They live in both shallow water and in depths of over 9,000 metres (30,000 ft).\nAdult crinoids are characterised by having the mouth located on the upper surface. This is surrounded by feeding arms, and is linked to a U-shaped gut, with the anus being located on the oral disc near the mouth. Although the basic echinoderm pattern of fivefold symmetry can be recognised, in most crinoids the five arms are subdivided into ten or more. These have feathery pinnules and are spread wide to gather planktonic particles from the water. At some stage in their lives, most crinoids have a short stem used to attach themselves to the substrate, but many live attached only as juveniles and become free-swimming as adults.\nThere are only about 700 living species of crinoid, but the class was much more abundant and diverse in the past. Some thick limestone beds dating to the mid-Paleozoic era to Jurassic period are almost entirely made up of disarticulated crinoid fragments.",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles with 'species' microformats",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from May 2020",
                "Category:Commons category link from Wikidata",
                "Category:Crinoidea",
                "Category:Extant Ordovician first appearances",
                "Category:Good articles",
                "Category:Paleozoic invertebrates",
                "Category:Short description matches Wikidata"
            ],
            "id": 172
        },
        {
            "title": "BuzzFeed",
            "info_text": "BuzzFeed, Inc. is an American Internet media, news and entertainment company with a focus on digital media. Based in New York City, BuzzFeed was founded in 2006 by Jonah Peretti and John S. Johnson III to focus on tracking viral content. Kenneth Lerer, co-founder and chairman of The Huffington Post, started as a co-founder and investor in BuzzFeed and is now the executive chairman.\nOriginally known for online quizzes, \"listicles\", and pop culture articles, the company has grown into a global media and technology company, providing coverage on a variety of topics including politics, DIY, animals, and business. BuzzFeed generates revenue through native advertising, a strategy that helps increase the likelihood of viewers reading through the content of advertisements.\nIn late 2011, BuzzFeed hired Ben Smith of Politico as editor-in-chief, to expand the site into long-form journalism and reportage under the BuzzFeed News banner. After years of investment in investigative journalism, by 2021 BuzzFeed News had won the National Magazine Award, the George Polk Award, and the Pulitzer Prize, and was nominated for the Michael Kelly Award. BuzzFeed News later moved to its own domain rather than existing as a section of the main BuzzFeed website. On April 20, 2023, Peretti announced that BuzzFeed would be shuttering BuzzFeed News and focusing its news efforts into HuffPost, laying off about 180 workers.\nA 2014 Pew Research Center survey found that in the United States, BuzzFeed was viewed as an unreliable source by the majority of respondents, regardless of age or political affiliation. The company's audience has been described as left-leaning.\n\n",
            "categories": [
                "Category:2006 establishments in New York City",
                "Category:2021 initial public offerings",
                "Category:All Wikipedia articles in need of updating",
                "Category:All Wikipedia articles written in American English",
                "Category:All articles containing potentially dated statements",
                "Category:All articles with unsourced statements",
                "Category:American entertainment websites",
                "Category:Articles containing potentially dated statements from 2016",
                "Category:Articles containing potentially dated statements from 2017",
                "Category:Articles with short description"
            ],
            "id": 173
        },
        {
            "title": "Peter Paul Rubens",
            "info_text": "Sir Peter Paul Rubens ( ROO-b\u0259nz; Dutch: [\u02c8pe\u02d0t\u0259r p\u028cul \u02c8ryb\u0259ns]; 28 June 1577 \u2013 30 May 1640) was a Flemish artist and diplomat. He is considered the most influential artist of the Flemish Baroque tradition. Rubens' highly charged compositions reference erudite aspects of classical and Christian history. His unique and immensely popular Baroque style emphasised movement, colour, and sensuality, which followed the immediate, dramatic artistic style promoted in the Counter-Reformation. Rubens was a painter producing altarpieces, portraits, landscapes, and history paintings of mythological and allegorical subjects. He was also a prolific designer of cartoons for the Flemish tapestry workshops and of frontispieces for the publishers in Antwerp.\nRubens was born and raised in the Holy Roman Empire (modern-day Germany) to parents who were refugees from Antwerp in the Duchy of Brabant in the Southern Netherlands (modern-day Belgium) and moved to Antwerp at about 12. In addition to running a large workshop in Antwerp that produced paintings popular with nobility and art collectors throughout Europe, Rubens was a classically educated humanist scholar and diplomat who was knighted by both Philip IV of Spain and Charles I of England. Rubens was a prolific artist. The catalogue of his works by Michael Jaff\u00e9 lists 1,403 pieces, excluding numerous copies made in his workshop.\nHis commissioned works were mostly history paintings, which included religious and mythological subjects, and hunt scenes. He painted portraits, especially of friends, and self-portraits, and in later life painted several landscapes. Rubens designed tapestries and prints, as well as his own house. He also oversaw the ephemeral decorations of the royal entry into Antwerp by the Cardinal-Infante Ferdinand of Austria in 1635. He wrote a book with illustrations of the palaces in Genoa, which was published in 1622 as Palazzi di Genova. The book was influential in spreading the Genoese palace style in Northern Europe. Rubens was an avid art collector and had one of the largest collections of art and books in Antwerp. He was also an art dealer and is known to have sold important art objects to George Villiers, 1st Duke of Buckingham.\nHe was one of the last major artists to make consistent use of wooden panels as a support medium, even for very large works, but used canvas as well, especially when the work needed to be sent a long distance. For altarpieces, he sometimes painted on slate to reduce reflection problems.",
            "categories": [
                "Category:1577 births",
                "Category:1640 deaths",
                "Category:16th-century Flemish painters",
                "Category:17th-century Flemish painters",
                "Category:17th-century diplomats from the Holy Roman Empire",
                "Category:Art collectors from Antwerp",
                "Category:Articles with Dutch-language sources (nl)",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Artists from the Habsburg Netherlands"
            ],
            "id": 174
        },
        {
            "title": "Healthcare in the United States",
            "info_text": "In the United States, healthcare is largely provided by private sector healthcare facilities, and paid for by a combination of public programs, private insurance, and out-of-pocket payments. The U.S. is the only developed country without a system of universal healthcare, and a significant proportion of its population lacks health insurance. The United States spends more on healthcare than any other country, both in absolute terms and as a percentage of GDP; however, this expenditure does not necessarily translate into better overall health outcomes compared to other developed nations. Coverage varies widely across the population, with certain groups, such as the elderly and low-income individuals, receiving more comprehensive care through government programs such as Medicaid and Medicare.\nThe U.S. healthcare system has been the subject of significant political debate and reform efforts, particularly in the areas of healthcare costs, insurance coverage, and the quality of care. Legislation such as the Affordable Care Act of 2010 has sought to address some of these issues, though challenges remain. Uninsured rates have fluctuated over time, and disparities in access to care exist based on factors such as income, race, and geographical location. The private insurance model predominates, and employer-sponsored insurance is a common way for individuals to obtain coverage.\nThe complex nature of the system, as well as its high costs, has led to ongoing discussions about the future of healthcare in the United States. At the same time, the United States is a global leader in medical innovation, measured either in terms of revenue or the number of new drugs and medical devices introduced. The Foundation for Research on Equal Opportunity concluded that the United States dominates science and technology, which \"was on full display during the COVID-19 pandemic, as the U.S. government [delivered] coronavirus vaccines far faster than anyone had ever done before\", but lags behind in fiscal sustainability, with \"[government] spending ... growing at an unsustainable rate\".\nIn the early 20th century, advances in medical technology and a focus on public health contributed to a shift in healthcare. The American Medical Association (AMA) worked to standardize medical education, and the introduction of employer-sponsored insurance plans marked the beginning of the modern health insurance system. More people were starting to get involved in healthcare like state actors, other professionals/practitioners, patients and clients, the judiciary, and business interests and employers. They had interest in medical regulations of professionals to ensure that services were provided by trained and educated people to minimize harm. The post\u2013World War II era saw a significant expansion in healthcare where more opportunities were offered to increase accessibility of services. The passage of the Hill\u2013Burton Act in 1946 provided federal funding for hospital construction, and Medicare and Medicaid were established in 1965 to provide healthcare coverage to the elderly and low-income populations, respectively.",
            "categories": [
                "Category:All Wikipedia articles in need of updating",
                "Category:All Wikipedia articles written in American English",
                "Category:All articles containing potentially dated statements",
                "Category:All articles lacking reliable references",
                "Category:All articles with dead external links",
                "Category:All articles with unsourced statements",
                "Category:All articles with vague or ambiguous time",
                "Category:Articles containing potentially dated statements from 2008",
                "Category:Articles containing potentially dated statements from 2013",
                "Category:Articles containing potentially dated statements from 2015"
            ],
            "id": 175
        },
        {
            "title": "Female intrasexual competition",
            "info_text": "Female intrasexual competition is competition between women over a potential mate. Such competition might include self-promotion, derogation of other women, and direct and indirect aggression toward other women. Factors that influence female intrasexual competition include the genetic quality of available mates, hormone levels, and interpersonal dynamics.\nThere are two modes of sexual selection: intersexual selection and intrasexual selection. Intersexual selection includes the display of desirable sexual characteristics to attract a potential mate. Intrasexual selection is competition between members of the same sex other over a potential mate.\nCompared to males, females tend to prefer subtle rather than overt forms of intrasexual competition.\n\n",
            "categories": [
                "Category:All articles with dead external links",
                "Category:Articles with dead external links from July 2022",
                "Category:Articles with short description",
                "Category:Evolutionary psychology",
                "Category:Sexual selection",
                "Category:Short description matches Wikidata",
                "Category:Women and sexuality"
            ],
            "id": 176
        },
        {
            "title": "Litre",
            "info_text": "The litre (Commonwealth spelling) or liter (American spelling) (SI symbols L and l, other symbol used: \u2113) is a metric unit of volume. It is equal to 1 cubic decimetre (dm3), 1000 cubic centimetres (cm3) or 0.001 cubic metres (m3). A cubic decimetre (or litre) occupies a volume of 10 cm \u00d7 10 cm \u00d7 10 cm (see figure) and is thus equal to one-thousandth of a cubic metre.\nThe original French metric system used the litre as a base unit. The word litre is derived from an older French unit, the litron, whose name came from Byzantine Greek\u2014where it was a unit of weight, not volume\u2014via Late Medieval Latin, and which equalled approximately 0.831 litres. The litre was also used in several subsequent versions of the metric system and is accepted for use with the SI, although not an SI unit\u2014the SI unit of volume is the cubic metre (m3). The spelling used by the International Bureau of Weights and Measures is \"litre\", a spelling which is shared by most English-speaking countries. The spelling \"liter\" is predominantly used in American English.\nOne litre of liquid water has a mass of almost exactly one kilogram, because the kilogram was originally defined in 1795 as the mass of one cubic decimetre of water at the temperature of melting ice (0 \u00b0C). Subsequent redefinitions of the metre and kilogram mean that this relationship is no longer exact.",
            "categories": [
                "Category:Alcohol measurement",
                "Category:All articles with incomplete citations",
                "Category:All articles with unsourced statements",
                "Category:Articles containing Dutch-language text",
                "Category:Articles containing French-language text",
                "Category:Articles containing German-language text",
                "Category:Articles containing Japanese-language text",
                "Category:Articles with incomplete citations from April 2020",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from October 2019"
            ],
            "id": 177
        },
        {
            "title": "Nicolas Cage",
            "info_text": "Nicolas Kim Coppola (born January 7, 1964), known professionally as Nicolas Cage, is an American actor and film producer. He is the recipient of various accolades, including an Academy Award, a Screen Actors Guild Award, and a Golden Globe Award as well as nominations for two BAFTA Awards. Known for his versatility as an actor, his participation in various film genres has gained him a cult following.\nBorn into the Coppola family, Cage began his career in films such as Fast Times at Ridgemont High (1982) and Valley Girl (1983), as well as various films by his uncle Francis Ford Coppola such as Rumble Fish (1983), The Cotton Club (1984), and Peggy Sue Got Married (1986). He received critical success for his roles in Moonstruck and  Raising Arizona (both 1987), before earning an Academy Award for Best Actor for the dramatic film Leaving Las Vegas (1995). He was Oscar-nominated for playing twins Charlie and Donald Kaufman in the comedy-drama film Adaptation (2002).\nCage established himself in mainstream action films, such as The Rock (1996), Con Air (1997), Face/Off (1997), Gone in 60 Seconds (2000), the National Treasure film series (2004\u20132007), the Ghost Rider film series (2007\u20132011), and Kick-Ass (2010). He also took on dramatic roles in City of Angels (1998), Bringing Out the Dead (1999),  The Family Man (2000), Matchstick Men (2003), and The Wicker Man (2006). He has voiced characters in The Croods film series (2013\u20132020) and in Spider-Man: Into the Spider-Verse (2018). He earned renewed critical recognition for his starring roles in Mandy (2018), Pig (2021), The Unbearable Weight of Massive Talent (2022), Dream Scenario (2023) and Longlegs (2024).\nCage owns the production company Saturn Films and has produced films such as Shadow of the Vampire (2000) and The Life of David Gale (2003), and has directed Sonny (2002). For his contributions to the film industry, he was inducted into the Hollywood Walk of Fame in 1998. He was ranked No. 40 in Empire magazine's The Top 100 Movie Stars of All Time list in 2007 and was placed No. 37 in Premiere's 100 Most Powerful People in Hollywood in 2008. Nicolas Cage was also voted one of the 50 greatest actors of all time in a 2022 readers' poll by Empire magazine.",
            "categories": [
                "Category:1964 births",
                "Category:20th-century American male actors",
                "Category:21st-century American male actors",
                "Category:All Wikipedia articles written in American English",
                "Category:All articles with style issues",
                "Category:American comic collectors",
                "Category:American male film actors",
                "Category:American male television actors",
                "Category:American male video game actors",
                "Category:American male voice actors"
            ],
            "id": 178
        },
        {
            "title": "Go (programming language)",
            "info_text": "Go is a statically typed, compiled high-level general purpose programming language. It is known for the simplicity of its syntax and the efficiency of development that it enables by the inclusion of a large standard library supplying many needs for common projects. It was designed at Google in 2009 by Robert Griesemer, Rob Pike, and Ken Thompson. It is syntactically similar to C, but also has memory safety, garbage collection, structural typing, and CSP-style concurrency. It is often referred to as Golang to avoid ambiguity and because of its former domain name, golang.org, but its proper name is Go.\nThere are two major implementations:\n\nThe original, self-hosting compiler toolchain, initially developed inside Google;\nA frontend written in C++, called gofrontend, originally a GCC frontend, providing gccgo, a GCC-based Go compiler; later extended to also support LLVM, providing an LLVM-based Go compiler called gollvm.\nA third-party source-to-source compiler, GopherJS, transpiles Go to JavaScript for front-end web development.",
            "categories": [
                "Category:All Wikipedia articles written in American English",
                "Category:All articles with failed verification",
                "Category:All articles with unsourced statements",
                "Category:American inventions",
                "Category:Articles prone to spam from June 2013",
                "Category:Articles with excerpts",
                "Category:Articles with failed verification from June 2022",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from December 2016",
                "Category:C programming language family"
            ],
            "id": 179
        },
        {
            "title": "Country music",
            "info_text": "Country (also called country and western) is a music genre originating in the southern regions of the United States, both the American South and the Southwest. First produced in the 1920s, country music is primarily focused on singing stories about working-class and blue-collar American life.\nCountry music is known for its ballads and dance tunes (i.e., \"honky-tonk music\") with simple form, folk lyrics, and harmonies generally accompanied by instruments such as banjos, fiddles, harmonicas, and many types of guitar (including acoustic, electric, steel, and resonator guitars). Though it is primarily rooted in various forms of American folk music, such as old-time music and Appalachian music, many other traditions, including Mexican, Irish, and Hawaiian music, have had a formative influence on the genre. Blues modes from blues music have been used extensively throughout its history as well.\nOnce called \"hillbilly music\", the term country music gained popularity in the 1940s. The genre came to encompass western music, which evolved parallel to hillbilly music from similar roots, in the mid-20th century. Contemporary styles of western music include Texas country, red dirt, and Hispano- and Mexican American-led Tejano and New Mexico music, which still exists alongside longstanding indigenous traditions.\nIn 2009, in the United States, country music was the most-listened-to rush-hour radio genre during the evening commute, and second-most popular in the morning commute.",
            "categories": [
                "Category:1920s in music",
                "Category:1930s in music",
                "Category:1940s in music",
                "Category:1950s in music",
                "Category:1960s in music",
                "Category:1970s in music",
                "Category:1980s in music",
                "Category:1990s in music",
                "Category:2000s in music",
                "Category:2010s in music"
            ],
            "id": 180
        },
        {
            "title": "Google ATAP",
            "info_text": "Google's Advanced Technology and Projects group (ATAP) is a skunkworks team and in-house technology incubator, created by former DARPA director Regina Dugan. ATAP is similar to X, but works on projects, granting project leaders time\u2014previously only two years\u2014in which to move a project from concept to proven product. According to Dugan, the ideal ATAP project combines technology and science, requires a certain amount of novel research, and creates a marketable product.  Historically, the ATAP team was born at Motorola Mobility and kept when Google sold Motorola Mobility to Lenovo in 2014; for this reason, ATAP ideas have tended to involve mobile hardware technology.\nThe team embodies principles that former Google VP Dugan used at DARPA. One of these principles is to create small teams of high performers.  Another is to make use of resources outside the organizational box; ATAP has worked with hundreds of partners in more than twenty countries, including schools, corporations, startups, governments, and nonprofits.  Standing contracts are in place with a number of top-flight schools, such as Stanford, Berkeley, MIT, and Caltech, to facilitate rapid research arrangements when needed.",
            "categories": [
                "Category:Articles with short description",
                "Category:Google",
                "Category:Research organizations in the United States",
                "Category:Short description matches Wikidata",
                "Category:Webarchive template wayback links"
            ],
            "id": 181
        },
        {
            "title": "Hans Georg Feichtinger",
            "info_text": "Hans Georg Feichtinger (born 16 June 1951) is an Austrian mathematician. He is  Professor in the mathematical faculty of the University of \nVienna. He is editor-in-chief of the Journal of Fourier Analysis and Applications (JFAA) and associate editor to several other journals. He is one of the founders and head of the Numerical Harmonic Analysis Group (NuHAG) at University of Vienna. Today Feichtinger's main field of research is harmonic analysis with a focus on time-frequency analysis.\n\n",
            "categories": [
                "Category:1951 births",
                "Category:20th-century Austrian mathematicians",
                "Category:21st-century Austrian mathematicians",
                "Category:Academic staff of the University of Vienna",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Living people",
                "Category:Short description is different from Wikidata",
                "Category:University of Vienna alumni",
                "Category:Use dmy dates from November 2019"
            ],
            "id": 182
        },
        {
            "title": "Hindi",
            "info_text": "Modern Standard Hindi (\u0906\u0927\u0941\u0928\u093f\u0915 \u092e\u093e\u0928\u0915 \u0939\u093f\u0928\u094d\u0926\u0940, \u0100dhunik M\u0101nak Hind\u012b), commonly referred to as Hindi, is the standardised variety of the Hindustani language written in the Devanagari script. It is the official language of India alongside English and the lingua franca of North India. Hindi is considered a Sanskritised register of Hindustani, which itself is based primarily on the Khariboli dialect of Delhi and neighbouring areas. It is an official language in nine states and three union territories and an additional official language in three other states. Hindi is also one of the 22 scheduled languages of the Republic of India.\nApart from the script and formal vocabulary, standard Hindi is mutually intelligible with standard Urdu, another recognised register of Hindustani, as both Hindi and Urdu share a core vocabulary base derived from Prakrit (a descendant of Sanskrit). Hindi is also spoken, to a lesser extent, in other parts of India (usually in a simplified or pidginised variety such as Bazaar Hindustani or Haflong Hindi). Outside India, several other languages are recognised officially as \"Hindi\" but do not refer to the Standard Hindi language described here and instead descend from other nearby languages, such as Awadhi and Bhojpuri. Such languages include Fiji Hindi, which has an official status in Fiji, and Caribbean Hindustani, which is spoken in Suriname, Trinidad and Tobago, and Guyana.\nHindi is the fourth most-spoken first language in the world, after Mandarin, Spanish and English. If counted together with the mutually intelligible Urdu, it is the third most-spoken language in the world, after Mandarin and English. According to reports of Ethnologue (2022, 25th edition) Hindi is the third most-spoken language in the world including first and second language speakers.\nHindi is the fastest growing language of India, followed by Kashmiri, Meitei, Gujarati and Bengali according to the 2011 census of India.",
            "categories": [
                "Category:All Wikipedia articles written in Indian English",
                "Category:All articles lacking reliable references",
                "Category:All articles that may contain original research",
                "Category:All articles with dead external links",
                "Category:All articles with unsourced statements",
                "Category:Articles containing Arabic-language text",
                "Category:Articles containing Hindi-language text",
                "Category:Articles containing Persian-language text",
                "Category:Articles containing Sanskrit-language text",
                "Category:Articles containing Shauraseni-language text"
            ],
            "id": 183
        },
        {
            "title": "Borel set",
            "info_text": "In mathematics, a Borel set is any set in a topological space that can be formed from open sets (or, equivalently, from closed sets) through the operations of countable union, countable intersection, and relative complement.  Borel sets are named after \u00c9mile Borel.\nFor a topological space X, the collection of all Borel sets on X forms a \u03c3-algebra, known as the Borel algebra or Borel \u03c3-algebra.  The Borel algebra on X is the smallest \u03c3-algebra containing all open sets (or, equivalently, all closed sets).\nBorel sets are important in measure theory, since any measure defined on the open sets of a space, or on the closed sets of a space, must also be defined on all Borel sets of that space. Any measure defined on the Borel sets is called a Borel measure.  Borel sets and the associated Borel hierarchy also play a fundamental role in descriptive set theory.\nIn some contexts, Borel sets are defined to be generated by the compact sets of the topological space, rather than the open sets. The two definitions are equivalent for many well-behaved spaces, including all Hausdorff \u03c3-compact spaces, but can be different in more pathological spaces.",
            "categories": [
                "Category:Articles with short description",
                "Category:CS1 French-language sources (fr)",
                "Category:Descriptive set theory",
                "Category:Module:Interwiki extra: additional interwiki links",
                "Category:Short description is different from Wikidata",
                "Category:Topology",
                "Category:Webarchive template wayback links",
                "Category:Wikipedia articles needing clarification from October 2024"
            ],
            "id": 184
        },
        {
            "title": "Back vowel",
            "info_text": "A back vowel is any in a class of vowel sound used in spoken languages. The defining characteristic of a back vowel is that the highest point of the tongue is positioned relatively back in the mouth without creating a constriction that would be classified as a consonant. Back vowels are sometimes also called dark vowels because they are perceived as sounding darker than the front vowels.\nNear-back vowels are essentially a type of back vowels; no language is known to contrast back and near-back vowels based on backness alone.\nThe category \"back vowel\" comprises both raised vowels and retracted vowels.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:Pages with plain IPA",
                "Category:Short description matches Wikidata",
                "Category:Vowels by backness"
            ],
            "id": 185
        },
        {
            "title": "Discovery and development of HIV-protease inhibitors",
            "info_text": "Many major physiological processes depend on regulation of proteolytic enzyme activity and there can be dramatic consequences when equilibrium between an enzyme and its substrates is disturbed. In this prospective, the discovery of small-molecule ligands, like protease inhibitors, that can modulate catalytic activities has an enormous therapeutic effect. Hence, inhibition of the HIV protease is one of the most important approaches for the therapeutic intervention in HIV infection and their development is regarded as major success of structure-based drug design. They are highly effective against HIV and have, since the 1990s, been a key component of anti-retroviral therapies for HIV/AIDS.\n\n",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles with unsourced statements from April 2021",
                "Category:Drug discovery",
                "Category:HIV/AIDS",
                "Category:Wikipedia articles needing page number citations from September 2015"
            ],
            "id": 186
        },
        {
            "title": "Davidon\u2013Fletcher\u2013Powell formula",
            "info_text": "The Davidon\u2013Fletcher\u2013Powell formula (or DFP; named after William C. Davidon, Roger Fletcher, and Michael J. D. Powell) finds the solution to the secant equation that is closest to the current estimate and satisfies the curvature condition. It was the first quasi-Newton method to generalize the secant method to a multidimensional problem. This update maintains the symmetry and positive definiteness of the Hessian matrix.\nGiven a function \n  \n    \n      \n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle f(x)}\n  \n, its gradient (\n  \n    \n      \n        \u2207\n        f\n      \n    \n    {\\displaystyle \\nabla f}\n  \n), and positive-definite Hessian matrix \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n, the Taylor series is\n\n  \n    \n      \n        f\n        (\n        \n          x\n          \n            k\n          \n        \n        +\n        \n          s\n          \n            k\n          \n        \n        )\n        =\n        f\n        (\n        \n          x\n          \n            k\n          \n        \n        )\n        +\n        \u2207\n        f\n        (\n        \n          x\n          \n            k\n          \n        \n        \n          )\n          \n            T\n          \n        \n        \n          s\n          \n            k\n          \n        \n        +\n        \n          \n            1\n            2\n          \n        \n        \n          s\n          \n            k\n          \n          \n            T\n          \n        \n        \n          B\n        \n        \n          s\n          \n            k\n          \n        \n        +\n        \u2026\n        ,\n      \n    \n    {\\displaystyle f(x_{k}+s_{k})=f(x_{k})+\\nabla f(x_{k})^{T}s_{k}+{\\frac {1}{2}}s_{k}^{T}{B}s_{k}+\\dots ,}\n  \n\nand the Taylor series of the gradient itself (secant equation)\n\n  \n    \n      \n        \u2207\n        f\n        (\n        \n          x\n          \n            k\n          \n        \n        +\n        \n          s\n          \n            k\n          \n        \n        )\n        =\n        \u2207\n        f\n        (\n        \n          x\n          \n            k\n          \n        \n        )\n        +\n        B\n        \n          s\n          \n            k\n          \n        \n        +\n        \u2026\n      \n    \n    {\\displaystyle \\nabla f(x_{k}+s_{k})=\\nabla f(x_{k})+Bs_{k}+\\dots }\n  \n\nis used to update \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n.  \nThe DFP formula finds a solution that is symmetric, positive-definite and closest to the current approximate value of \n  \n    \n      \n        \n          B\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle B_{k}}\n  \n:\n\n  \n    \n      \n        \n          B\n          \n            k\n            +\n            1\n          \n        \n        =\n        (\n        I\n        \u2212\n        \n          \u03b3\n          \n            k\n          \n        \n        \n          y\n          \n            k\n          \n        \n        \n          s\n          \n            k\n          \n          \n            T\n          \n        \n        )\n        \n          B\n          \n            k\n          \n        \n        (\n        I\n        \u2212\n        \n          \u03b3\n          \n            k\n          \n        \n        \n          s\n          \n            k\n          \n        \n        \n          y\n          \n            k\n          \n          \n            T\n          \n        \n        )\n        +\n        \n          \u03b3\n          \n            k\n          \n        \n        \n          y\n          \n            k\n          \n        \n        \n          y\n          \n            k\n          \n          \n            T\n          \n        \n        ,\n      \n    \n    {\\displaystyle B_{k+1}=(I-\\gamma _{k}y_{k}s_{k}^{T})B_{k}(I-\\gamma _{k}s_{k}y_{k}^{T})+\\gamma _{k}y_{k}y_{k}^{T},}\n  \n\nwhere\n\n  \n    \n      \n        \n          y\n          \n            k\n          \n        \n        =\n        \u2207\n        f\n        (\n        \n          x\n          \n            k\n          \n        \n        +\n        \n          s\n          \n            k\n          \n        \n        )\n        \u2212\n        \u2207\n        f\n        (\n        \n          x\n          \n            k\n          \n        \n        )\n        ,\n      \n    \n    {\\displaystyle y_{k}=\\nabla f(x_{k}+s_{k})-\\nabla f(x_{k}),}\n  \n\n  \n    \n      \n        \n          \u03b3\n          \n            k\n          \n        \n        =\n        \n          \n            1\n            \n              \n                y\n                \n                  k\n                \n                \n                  T\n                \n              \n              \n                s\n                \n                  k\n                \n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\gamma _{k}={\\frac {1}{y_{k}^{T}s_{k}}},}\n  \n\nand \n  \n    \n      \n        \n          B\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle B_{k}}\n  \n is a symmetric and positive-definite matrix.\nThe corresponding update to the inverse Hessian approximation \n  \n    \n      \n        \n          H\n          \n            k\n          \n        \n        =\n        \n          B\n          \n            k\n          \n          \n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle H_{k}=B_{k}^{-1}}\n  \n is given by\n\n  \n    \n      \n        \n          H\n          \n            k\n            +\n            1\n          \n        \n        =\n        \n          H\n          \n            k\n          \n        \n        \u2212\n        \n          \n            \n              \n                H\n                \n                  k\n                \n              \n              \n                y\n                \n                  k\n                \n              \n              \n                y\n                \n                  k\n                \n                \n                  T\n                \n              \n              \n                H\n                \n                  k\n                \n              \n            \n            \n              \n                y\n                \n                  k\n                \n                \n                  T\n                \n              \n              \n                H\n                \n                  k\n                \n              \n              \n                y\n                \n                  k\n                \n              \n            \n          \n        \n        +\n        \n          \n            \n              \n                s\n                \n                  k\n                \n              \n              \n                s\n                \n                  k\n                \n                \n                  T\n                \n              \n            \n            \n              \n                y\n                \n                  k\n                \n                \n                  T\n                \n              \n              \n                s\n                \n                  k\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle H_{k+1}=H_{k}-{\\frac {H_{k}y_{k}y_{k}^{T}H_{k}}{y_{k}^{T}H_{k}y_{k}}}+{\\frac {s_{k}s_{k}^{T}}{y_{k}^{T}s_{k}}}.}\n  \n\n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n is assumed to be positive-definite, and the vectors \n  \n    \n      \n        \n          s\n          \n            k\n          \n          \n            T\n          \n        \n      \n    \n    {\\displaystyle s_{k}^{T}}\n  \n and \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n must satisfy the curvature condition\n\n  \n    \n      \n        \n          s\n          \n            k\n          \n          \n            T\n          \n        \n        \n          y\n          \n            k\n          \n        \n        =\n        \n          s\n          \n            k\n          \n          \n            T\n          \n        \n        B\n        \n          s\n          \n            k\n          \n        \n        >\n        0.\n      \n    \n    {\\displaystyle s_{k}^{T}y_{k}=s_{k}^{T}Bs_{k}>0.}\n  \n\nThe DFP formula is quite effective, but it was soon superseded by the Broyden\u2013Fletcher\u2013Goldfarb\u2013Shanno formula, which is its dual (interchanging the roles of y and s).\n\n",
            "categories": [
                "Category:Optimization algorithms and methods"
            ],
            "id": 187
        },
        {
            "title": "Tesla Energy",
            "info_text": "Tesla Energy Operations, Inc. is the clean energy division of Tesla, Incorporated that develops, manufactures, sells and installs photovoltaic solar energy generation systems, battery energy storage products and other related products and services to residential, commercial and industrial customers.\nThe division was founded on April 30, 2015, when Tesla CEO Elon Musk announced that the company would apply the battery technology it developed for electric cars to a home energy storage system called the Powerwall. In November 2016, Tesla acquired SolarCity, in a US$2.6 billion deal, and added solar energy generation to Tesla Energy's business. This deal was controversial; at the time of the acquisition, SolarCity was facing liquidity issues.\nThe company's current power generation products include solar panels (manufactured by other companies for Tesla), the Tesla Solar Roof (a solar shingle system), and the Tesla Solar Inverter. The company also makes a large-scale energy storage system called the Megapack. Additionally, Tesla develops software to support its energy products.\nIn 2023, the company deployed solar energy systems capable of generating 223 megawatts (MW), a decrease of 36% over 2022, and deployed 14.7 gigawatt-hours (GWh) of battery energy storage products, an increase of 125% over 2022. The division generated $6.04 billion in revenue for the company in 2023, a 55% increase over 2022.",
            "categories": [
                "Category:2015 establishments in California",
                "Category:2016 mergers and acquisitions",
                "Category:All articles containing potentially dated statements",
                "Category:American companies established in 2015",
                "Category:Articles containing potentially dated statements from 2021",
                "Category:Articles containing potentially dated statements from April 2022",
                "Category:Articles containing potentially dated statements from December 2023",
                "Category:Articles with short description",
                "Category:Battery manufacturers",
                "Category:Commons category link is on Wikidata"
            ],
            "id": 188
        },
        {
            "title": "Transformer (deep learning architecture)",
            "info_text": "A transformer is a deep learning architecture that was developed by researchers at Google and is based on the multi-head attention mechanism, which was proposed in the 2017 paper \"Attention Is All You Need\". Text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished.\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLM) on large (language) datasets, such as the Wikipedia corpus and Common Crawl.\n\nTransformers were first developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).",
            "categories": [
                "Category:Articles with short description",
                "Category:CS1 errors: missing periodical",
                "Category:CS1 maint: multiple names: authors list",
                "Category:Google software",
                "Category:Neural network architectures",
                "Category:Short description is different from Wikidata",
                "Category:Webarchive template wayback links"
            ],
            "id": 189
        },
        {
            "title": "Washington (state)",
            "info_text": "Washington, officially the State of Washington, is a state in the Pacific Northwest region of the United States. It is often referred to as Washington state to distinguish it from the national capital, both named after George Washington (the first U.S. president). Washington borders the Pacific Ocean to the west, Oregon to the south, Idaho to the east, and shares an international border with the Canadian province of British Columbia to the north. Olympia is the state capital, and the most populous city is Seattle.\nWashington is the 18th-largest state, with an area of 71,362 square miles (184,830 km2), and the 13th-most populous state, with a population of just less than 8 million. The majority of Washington's residents live in the Seattle metropolitan area, the center of transportation, business, and industry on Puget Sound, an inlet of the Pacific Ocean consisting of numerous islands, deep fjords and bays carved out by glaciers. The remainder of the state consists of deep temperate rainforests in the west; mountain ranges in the west, center, northeast, and far southeast; and a semi-arid basin region in the east, center, and south, given over to intensive agriculture. Washington is the second most populous state on the West Coast and in the Western United States, after California. Mount Rainier, an active stratovolcano, is the state's highest elevation at 14,411 feet (4,392 meters), and is the most topographically prominent mountain in the contiguous U.S.\nWashington is a leading lumber producer, the largest producer of apples, hops, pears, blueberries, spearmint oil, and sweet cherries in the U.S., and ranks high in the production of apricots, asparagus, dry edible peas, grapes, lentils, peppermint oil, and potatoes. Livestock, livestock products, and commercial fishing\u2014particularly of salmon, halibut, and bottomfish\u2014are also significant contributors to the state's economy. Washington ranks second only to California in wine production. Manufacturing industries in Washington include aircraft, missiles, shipbuilding, and other transportation equipment, food processing, metals, and metal products, chemicals, and machinery.\nThe state was formed from the western part of the Washington Territory, which was ceded by the British Empire in the Oregon Treaty of 1846. It was admitted to the Union as the 42nd state in 1889. One of the wealthiest and most socially liberal states in the country, Washington consistently ranks among the top states for highest life expectancy and employment rates. It was one of the first states (alongside Colorado) to legalize medicinal and recreational cannabis, was among the first states to introduce same-sex marriage, and was one of only four states to have provided legal abortions on request before Roe v. Wade in 1973. Washington voters also approved a 2008 referendum on the legalization of physician-assisted suicide, making it one of 10 states to have legalized the practice.",
            "categories": [
                "Category:1889 establishments in the United States",
                "Category:All Wikipedia articles needing clarification",
                "Category:All Wikipedia articles written in American English",
                "Category:All articles containing potentially dated statements",
                "Category:All articles needing additional references",
                "Category:All articles to be expanded",
                "Category:All articles with dead external links",
                "Category:All articles with failed verification",
                "Category:All articles with too many examples",
                "Category:All articles with unsourced statements"
            ],
            "id": 190
        },
        {
            "title": "Road signs in Croatia",
            "info_text": "Road signs in Croatia are regulated in Pravilnik o prometnim znakovima signalizaciji i opremi na cestama. The shape and design of the road signs largely follow the road signs used in most European countries, including European Union countries (France, Germany, Italy etc.), to which Croatia joined in 2013. A similar design of road signs is used in the neighboring countries of the former Yugoslavia like Slovenia, Bosnia and Herzegovina, and also North Macedonia (the latter two are not members of the EU).\nThe former Yugoslavia had originally signed the Vienna Convention on Road Signs and Signals on November 8, 1968, and ratified it on June 6, 1977. Yugoslavia formerly used a yellow background on warning signs. After the breakup of Yugoslavia when Croatia declared its independence in 1991, the country succeeded to the Vienna Convention on November 2, 1993.\nCroatian signs use the Hrvatsko cestovno pismo (lit.\u2009'Croatian road font') for the text on their signs.",
            "categories": [
                "Category:Articles containing Croatian-language text",
                "Category:Articles with short description",
                "Category:CS1 Croatian-language sources (hr)",
                "Category:Road signs by country",
                "Category:Road transport in Croatia",
                "Category:Short description is different from Wikidata"
            ],
            "id": 191
        },
        {
            "title": "American Samoa",
            "info_text": "American Samoa is an unincorporated territory of the United States located in the Polynesia region of the South Pacific Ocean. Centered on 14.3\u00b0S 170.7\u00b0W\ufeff / -14.3; -170.7, it is 40 miles (64 km) southeast of the island country of Samoa, east of the International Date Line and the Wallis and Futuna Islands, west of the Cook Islands, north of Tonga, and some 310 miles (500 km) south of Tokelau. American Samoa is the southernmost territory of the United States, situated 2,200 miles (3,500 km) southwest of the U.S. state of Hawaii, and one of two U.S. territories south of the Equator, along with the uninhabited Jarvis Island and the Ofu-Olosega peak, which is a volcanic island in American Samoa.\nAmerican Samoa consists of the eastern part of the Samoan archipelago\u2014the inhabited volcanic islands of Tutuila, Aunu\u02bbu, Ofu, Olosega and Ta\u02bb\u016b and the uninhabited Rose Atoll\u2014as well as Swains Island, a remote coral atoll in the Tokelau volcanic island group. The total land area is 77 square miles (199 km2), slightly larger than Washington, D.C.; including its territorial waters, the total area is 117,500 square miles (304,000 km2), about the size of New Zealand. American Samoa has a tropical climate, with 90 percent of its land covered by rainforests. As of 2024, the population is approximately 47,400 and concentrated on Tutuila, which hosts the capital and largest settlement, Pago Pago. The vast majority of residents are indigenous ethnic Samoans, most of whom are fluent in the official languages, English and Samoan.\nInhabited by Polynesians since prehistory, American Samoa was first contacted by Europeans in the 18th century. The islands attracted missionaries, explorers, and mariners, particularly to the highly protected natural harbor of Pago Pago. The United States took possession of American Samoa in the late 19th century, developing it into a major naval outpost; the territory's strategic value was reinforced by the Second World War and subsequent Cold War. In 1967, American Samoa became self-governing with the adoption of a constitution; its local government is republican in form, with separate executive, legislative, and judicial branches. It remains officially unorganized and is thus directly administered by the federal government. American Samoa is listed among seventeen \"non-self-governing territories\" but is a member of several intergovernmental organizations, including the Pacific Community, Pacific Islands Forum (PIF), Alliance of Small Island States (AOSIS), and International Olympic Committee (IOC).\nDue to the territory's strategic location, the U.S. military has a significant presence and plays a major role in its economy and society. The territory is noted for having the highest rate of military enlistment of any U.S. state or territory; as of 2021, the local U.S. Army recruiting station in Pago Pago ranked first in recruitment.  Tuna products are the main exports, with the U.S. proper serving as the largest trading partner. Tourism is a nascent but underdeveloped sector, owing in part to the territory's relative geographic isolation, which also accounts for its high rate of poverty and emigration.\n\nResidents of American Samoa are politically disenfranchised, with no voting representation in the U.S. Congress. American Samoa is the only permanently inhabited territory of the United States in which citizenship is not granted at birth, and people born there are considered \"non-citizen nationals\" with limited rights. Citizenship is a controversial topic locally, as the government of American Samoa fears that it would lead to the erosion of traditional customs. It is the only U.S. territory with its own immigration system.",
            "categories": [
                "Category:1899 establishments in Oceania",
                "Category:All Wikipedia articles in need of updating",
                "Category:All Wikipedia articles written in American English",
                "Category:All articles containing potentially dated statements",
                "Category:All articles with unsourced statements",
                "Category:American Samoa",
                "Category:Archipelagoes of the United States",
                "Category:Articles containing Samoan-language text",
                "Category:Articles containing explicitly cited English-language text",
                "Category:Articles containing potentially dated statements from 2010"
            ],
            "id": 192
        },
        {
            "title": "Huawei IDEOS",
            "info_text": "The Huawei IDEOS U8150 is an Android smartphone manufactured by Huawei.\nIt is rebranded as S31HW by EMOBILE in Japan. It is also renamed the T-Mobile Comet in the United States.\n\n",
            "categories": [
                "Category:All stub articles",
                "Category:Android (operating system) devices",
                "Category:Articles with short description",
                "Category:Discontinued smartphones",
                "Category:Huawei smartphones",
                "Category:Mobile phone stubs",
                "Category:Mobile phones introduced in 2010",
                "Category:Short description matches Wikidata"
            ],
            "id": 193
        },
        {
            "title": "HarmonyOS NEXT",
            "info_text": "HarmonyOS NEXT (Chinese: \u9e3f\u8499\u661f\u6cb3\u7248; pinyin: H\u00f3ngm\u00e9ng X\u012bngh\u00e9b\u01cen) is a proprietary distributed operating system and a major iteration of HarmonyOS, developed by Huawei to support only HarmonyOS native apps. The operating system is primarily aimed at software and hardware developers that deal directly with Huawei. It does not include Android's AOSP core and is incompatible with Android applications.\nWhile discarding the common Unix-like Linux kernel, HarmonyOS NEXT also replaces the previous multikernel system with its own HarmonyOS microkernel. The rich execution environment (REE) version of HarmonyOS microkernel is placed at its core with a single framework as kernel mode. The new kernel architecture, built on OpenHarmony and its kernel abstraction layer, serves as user mode. The OS shares lineage with the lightweight LiteOS real-time operating system for resource-constrained devices like smart wearables and IoT products.\n\n",
            "categories": [
                "Category:2023 software",
                "Category:ARM operating systems",
                "Category:All articles needing additional references",
                "Category:All articles with unsourced statements",
                "Category:Articles containing simplified Chinese-language text",
                "Category:Articles needing additional references from May 2024",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from July 2024",
                "Category:CS1 Chinese (China)-language sources (zh-cn)",
                "Category:Commons category link is locally defined"
            ],
            "id": 194
        },
        {
            "title": "Nobel Prize in Chemistry",
            "info_text": "The Nobel Prize in Chemistry (Swedish: Nobelpriset i kemi) is awarded annually by the Royal Swedish Academy of Sciences to scientists in the various fields of chemistry. It is one of the five Nobel Prizes established by the will of Alfred Nobel in 1895, awarded for outstanding contributions in chemistry, physics, literature, peace, and physiology or medicine. This award is administered by the Nobel Foundation, and awarded by the Royal Swedish Academy of Sciences on proposal of the Nobel Committee for Chemistry which consists of five members elected by the Academy. The award is presented in Stockholm at an annual ceremony on 10 December, the anniversary of Nobel's death.\nThe first Nobel Prize in Chemistry was awarded in 1901 to Jacobus Henricus van 't Hoff, of the Netherlands, \"for his discovery of the laws of chemical dynamics and osmotic pressure in solutions\". From 1901 to 2024, the award has been bestowed on a total of 195 individuals. The 2024 Nobel Prize in Chemistry was awarded to Demis Hassabis and John Jumper for protein structure prediction and to David Baker for Computational Protein Design. As of 2022 only eight women had won the prize: Marie Curie (1911), her daughter Ir\u00e8ne Joliot-Curie(1935), Dorothy Hodgkin (1964), Ada Yonath (2009), Frances Arnold (2018), Emmanuelle Charpentier and Jennifer Doudna (2020), and Carolyn R. Bertozzi (2022).",
            "categories": [
                "Category:All articles containing potentially dated statements",
                "Category:All articles with unsourced statements",
                "Category:Articles containing Swedish-language text",
                "Category:Articles containing potentially dated statements from 2022",
                "Category:Articles with short description",
                "Category:Articles with specifically marked weasel-worded phrases from May 2024",
                "Category:Articles with unsourced statements from October 2024",
                "Category:Articles with unsourced statements from September 2022",
                "Category:Awards of the Royal Swedish Academy of Sciences",
                "Category:Chemistry awards"
            ],
            "id": 195
        },
        {
            "title": "Computational biology",
            "info_text": "Computational biology refers to the use of techniques in computer science, data analysis, mathematical modeling and computational simulations to understand biological systems and relationships. An intersection of computer science, biology, and data science, the field also has foundations in applied mathematics, molecular biology, cell biology, chemistry, and genetics.\n\n",
            "categories": [
                "Category:All articles with self-published sources",
                "Category:All articles with unsourced statements",
                "Category:Articles with excerpts",
                "Category:Articles with self-published sources from August 2024",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from August 2024",
                "Category:Articles with unsourced statements from January 2022",
                "Category:Articles with unsourced statements from November 2021",
                "Category:Bioinformatics",
                "Category:Computational biology"
            ],
            "id": 196
        },
        {
            "title": "Bayesian linear regression",
            "info_text": "Bayesian linear regression is a type of conditional modeling in which the mean of one variable is described by a linear combination of other variables, with the goal of obtaining the posterior probability of the regression coefficients (as well as other parameters describing the distribution of the regressand) and ultimately allowing the out-of-sample prediction of the regressand (often labelled \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n) conditional on observed values of the regressors (usually \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n). The simplest and most widely used version of this model is the normal linear model, in which \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n given \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is distributed Gaussian. In this model, and under a particular choice of prior probabilities for the parameters\u2014so-called conjugate priors\u2014the posterior can be found analytically. With more arbitrarily chosen priors, the posteriors generally have to be approximated.",
            "categories": [
                "Category:All articles lacking in-text citations",
                "Category:Articles lacking in-text citations from August 2011",
                "Category:Articles with short description",
                "Category:Bayesian inference",
                "Category:Short description is different from Wikidata",
                "Category:Single-equation methods (econometrics)"
            ],
            "id": 197
        },
        {
            "title": "AlphaGeometry",
            "info_text": "AlphaGeometry is an artificial intelligence (AI) program that can solve hard problems in Euclidean geometry. It was developed by DeepMind, a subsidiary of Google. The program solved 25 geometry problems out of 30 from the International Mathematical Olympiad (IMO) under competition time limits\u2014a performance almost as good as the average human gold medallist. For comparison, the previous AI program, called Wu's method, managed to solve only 10 problems.\nDeepMind published a paper about AlphaGeometry in the peer-reviewed journal Nature on 17 January 2024. AlphaGeometry was featured in MIT Technology Review on the same day.\nTraditional geometry programs are symbolic engines that rely exclusively on human-coded rules to generate rigorous proofs, which makes them lack flexibility in unusual situations. AlphaGeometry combines such a symbolic engine with a specialized large language model trained on synthetic data of geometrical proofs. When the symbolic engine doesn't manage to find a formal and rigorous proof on its own, it solicits the large language model, which suggests a geometrical construct to move forward. However, it is unclear how applicable this method is to other domains of mathematics or reasoning, because symbolic engines rely on domain-specific rules and because of the need for synthetic data.\n\n",
            "categories": [
                "Category:AI software",
                "Category:All stub articles",
                "Category:Articles with short description",
                "Category:Artificial intelligence stubs",
                "Category:Euclidean geometry",
                "Category:Google DeepMind",
                "Category:Short description matches Wikidata"
            ],
            "id": 198
        },
        {
            "title": "Bertrand Russell",
            "info_text": "Bertrand Arthur William Russell, 3rd Earl Russell,  (18 May 1872 \u2013 2 February 1970) was a British philosopher, logician, mathematician, and public intellectual. He had influence on mathematics, logic, set theory, and various areas of analytic philosophy.\nHe was one of the early 20th century's prominent logicians and a founder of analytic philosophy, along with his predecessor Gottlob Frege, his friend and colleague G. E. Moore, and his student and prot\u00e9g\u00e9 Ludwig Wittgenstein. Russell with Moore led the British \"revolt against idealism\". Together with his former teacher A. N. Whitehead, Russell wrote Principia Mathematica, a milestone in the development of classical logic and a major attempt to reduce the whole of mathematics to logic (see logicism). Russell's article \"On Denoting\" has been considered a \"paradigm of philosophy\".\nRussell was a pacifist who championed anti-imperialism and chaired the India League.  He went to prison for his pacifism during World War I, and initially supported appeasement against Adolf Hitler's Nazi Germany, before changing his view in 1943, describing war as a necessary \"lesser of two evils\". In the wake of World War II, he welcomed American global hegemony in preference to either Soviet hegemony or no (or ineffective) world leadership, even if it were to come at the cost of using their nuclear weapons. He would later criticise Stalinist totalitarianism, condemn the United States' involvement in the Vietnam War, and become an outspoken proponent of nuclear disarmament.\nIn 1950, Russell was awarded the Nobel Prize in Literature \"in recognition of his varied and significant writings in which he champions humanitarian ideals and freedom of thought\". He was also the recipient of the De Morgan Medal (1932), Sylvester Medal (1934), Kalinga Prize (1957), and Jerusalem Prize (1963).",
            "categories": [
                "Category:1872 births",
                "Category:1970 deaths",
                "Category:19th-century English essayists",
                "Category:19th-century English mathematicians",
                "Category:19th-century English philosophers",
                "Category:19th-century atheists",
                "Category:20th-century English essayists",
                "Category:20th-century English mathematicians",
                "Category:20th-century English philosophers",
                "Category:20th-century atheists"
            ],
            "id": 199
        },
        {
            "title": "Linux Foundation",
            "info_text": "The Linux Foundation (LF) is a non-profit organization established in 2000 to support Linux development and open-source software projects.\n\n",
            "categories": [
                "Category:All articles containing potentially dated statements",
                "Category:All articles lacking reliable references",
                "Category:All articles needing additional references",
                "Category:All articles with a promotional tone",
                "Category:Articles containing potentially dated statements from 2015",
                "Category:Articles containing potentially dated statements from September 2015",
                "Category:Articles lacking reliable references from August 2023",
                "Category:Articles needing additional references from June 2020",
                "Category:Articles with a promotional tone from March 2021",
                "Category:Articles with multiple maintenance issues"
            ],
            "id": 200
        },
        {
            "title": "Markov chain",
            "info_text": "In probability theory and statistics, a Markov chain or Markov process is a stochastic process describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. Informally, this may be thought of as, \"What happens next depends only on the state of affairs now.\" A countably infinite sequence, in which the chain moves state at discrete time steps, gives a discrete-time Markov chain (DTMC). A continuous-time process is called a continuous-time Markov chain (CTMC). Markov processes are named in honor of the Russian mathematician Andrey Markov.\nMarkov chains have many applications as statistical models of real-world processes. They provide the basis for general stochastic simulation methods known as Markov chain Monte Carlo, which are used for simulating sampling from complex probability distributions, and have found application in areas including Bayesian statistics, biology, chemistry, economics, finance, information theory, physics, signal processing, and speech processing.\nThe adjectives Markovian and Markov are used to describe something that is related to a Markov process.",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles containing German-language text",
                "Category:Articles containing Russian-language text",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from January 2025",
                "Category:Articles with unsourced statements from June 2024",
                "Category:CS1: long volume value",
                "Category:Graph theory",
                "Category:Markov models",
                "Category:Markov processes"
            ],
            "id": 201
        },
        {
            "title": "Huawei Mate X",
            "info_text": "The Huawei Mate X is an Android-based high end foldable smartphone  produced by Huawei. It was unveiled at MWC 2019 on 25 February 2019 and was originally scheduled to launch in June 2019, but the launch was pushed back to allow for extensive testing in light of the failures reported by users of a similar product, the Galaxy Fold from Samsung. The Mate X launched in China only in November 2019. Huawei announced the Mate Xs on 24 February 2020 as a hardware revision of the original Mate X; it was released in \"global markets\" outside China in March 2020. The device features a more durable display, improved hinge function and a redesigned cooling system, as well as the newer Kirin 990 5G SoC and Android 10 with EMUI 10.\n\n",
            "categories": [
                "Category:All stub articles",
                "Category:Android (operating system) devices",
                "Category:Articles with short description",
                "Category:Foldable smartphones",
                "Category:Huawei smartphones",
                "Category:Mobile phones introduced in 2019",
                "Category:Mobile phones with infrared transmitter",
                "Category:Mobile phones with multiple rear cameras",
                "Category:Mobile technology stubs",
                "Category:Phablets"
            ],
            "id": 202
        },
        {
            "title": "Matrix mechanics",
            "info_text": "Matrix mechanics is a formulation of quantum mechanics created by Werner Heisenberg, Max Born, and Pascual Jordan in 1925. It was the first conceptually autonomous and logically consistent formulation of quantum mechanics. Its account of quantum jumps supplanted the Bohr model's electron orbits. It did so by interpreting the physical properties of particles as matrices that evolve in time. It is equivalent to the Schr\u00f6dinger wave formulation of quantum mechanics, as manifest in Dirac's bra\u2013ket notation.\nIn some contrast to the wave formulation, it produces spectra of (mostly energy) operators by purely algebraic, ladder operator methods. Relying on these methods, Wolfgang Pauli derived the hydrogen atom spectrum in 1926, before the development of wave mechanics.",
            "categories": [
                "Category:Articles with short description",
                "Category:Quantum mechanics",
                "Category:Short description matches Wikidata",
                "Category:Webarchive template wayback links"
            ],
            "id": 203
        },
        {
            "title": "Peak signal-to-noise ratio",
            "info_text": "Peak signal-to-noise ratio (PSNR) is an engineering term for the ratio between the maximum possible power of a signal and the power of corrupting noise that affects the fidelity of its representation. Because many signals have a very wide dynamic range, PSNR is usually expressed as a logarithmic quantity using the decibel scale.\nPSNR is commonly used to quantify reconstruction quality for images and video subject to lossy compression.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:CS1 German-language sources (de)",
                "Category:CS1 errors: periodical ignored",
                "Category:Digital television",
                "Category:Engineering ratios",
                "Category:Film and video technology",
                "Category:Image compression",
                "Category:Noise (graphics)",
                "Category:Short description is different from Wikidata"
            ],
            "id": 204
        },
        {
            "title": "List of Huawei phones",
            "info_text": "The following is a list of Huawei phones. The date in brackets is the date of initial release.\nHuawei's two flagship smartphone lines are the Mate and Pura series.\n\n",
            "categories": [
                "Category:All articles with bare URLs for citations",
                "Category:Articles with PDF format bare URLs for citations",
                "Category:Articles with bare URLs for citations from August 2022",
                "Category:Articles with short description",
                "Category:CS1 French-language sources (fr)",
                "Category:Huawei mobile phones",
                "Category:Lists of mobile phones",
                "Category:Short description is different from Wikidata"
            ],
            "id": 205
        },
        {
            "title": "Design of experiments",
            "info_text": "The design of experiments, also known as experiment design or experimental design, is the design of any task that aims to describe and explain the variation of information under conditions that are hypothesized to reflect the variation. The term is generally associated with experiments in which the design introduces conditions that directly affect the variation, but may also refer to the design of quasi-experiments, in which natural conditions that influence the variation are selected for observation.\nIn its simplest form, an experiment aims at predicting the outcome by introducing a change of the preconditions, which is represented by one or more independent variables, also referred to as \"input variables\" or \"predictor variables.\" The change in one or more independent variables is generally hypothesized to result in a change in one or more dependent variables, also referred to as \"output variables\" or \"response variables.\" The experimental design may also identify control variables that must be held constant to prevent external factors from affecting the results. Experimental design involves not only the selection of suitable independent, dependent, and control variables, but planning the delivery of the experiment under statistically optimal conditions given the constraints of available resources.  There are multiple approaches for determining the set of design points (unique combinations of the settings of the independent variables) to be used in the experiment.\nMain concerns in experimental design include the establishment of validity, reliability, and replicability. For example, these concerns can be partially addressed by carefully choosing the independent variable, reducing the risk of measurement error, and ensuring that the documentation of the method is sufficiently detailed. Related concerns include achieving appropriate levels of statistical power and sensitivity.\nCorrectly designed experiments advance knowledge in the natural and social sciences and engineering, with design of experiments methodology recognised as a key tool in the successful implementation of a Quality by Design (QbD) framework. Other applications include marketing and policy making. The study of the design of experiments is an important topic in metascience.\n\n",
            "categories": [
                "Category:All articles needing expert attention",
                "Category:All articles that are too technical",
                "Category:All articles that may contain original research",
                "Category:Articles needing expert attention from August 2023",
                "Category:Articles that may contain original research from December 2020",
                "Category:Articles with short description",
                "Category:CS1 maint: numeric names: authors list",
                "Category:Commons category link from Wikidata",
                "Category:Design of experiments",
                "Category:Experiments"
            ],
            "id": 206
        },
        {
            "title": "De facto",
            "info_text": "De facto (, day FAK-toh, dee -\u2060, d\u0259 -\u2060; Latin: [de\u02d0 \u02c8fakto\u02d0] ; lit.\u2009'in fact') describes practices that exist in reality, regardless of whether they are officially recognized by laws or other formal norms. It is commonly used to refer to what happens in practice, in contrast with de jure ('by law').",
            "categories": [
                "Category:All articles needing examples",
                "Category:Articles needing examples from May 2024",
                "Category:Articles tagged with the inline citation overkill template from March 2024",
                "Category:Articles with limited geographic scope from October 2022",
                "Category:Articles with short description",
                "Category:CS1 Russian-language sources (ru)",
                "Category:Citation overkill",
                "Category:Latin legal terminology",
                "Category:Latin words and phrases",
                "Category:Pages including recorded pronunciations"
            ],
            "id": 207
        },
        {
            "title": "Frank Rosenblatt",
            "info_text": "Frank Rosenblatt (July 11, 1928 \u2013 July 11, 1971) was an American psychologist notable in the field of artificial intelligence. He is sometimes called the father of deep learning for his pioneering work on artificial neural networks.\n\n",
            "categories": [
                "Category:1928 births",
                "Category:1971 deaths",
                "Category:20th-century American psychologists",
                "Category:American artificial intelligence researchers",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Boating accident deaths",
                "Category:CS1 maint: multiple names: authors list",
                "Category:Cornell University alumni",
                "Category:Cornell University faculty"
            ],
            "id": 208
        },
        {
            "title": "Google Code-in",
            "info_text": "Google Code-in (GCI) was an international annual programming competition hosted by Google LLC that allowed pre-university students to complete tasks specified by various, partnering open source organizations. The contest was originally the Google Highly Open Participation Contest, but in 2010, the format was modified into its current state. Students that completed tasks won certificates and T-shirts. Each organization also selected two grand prize award winners who would earn a free trip to Google's Headquarters located in Mountain View, California. In 2020, Google announced cancellation of the contest.",
            "categories": [
                "Category:All articles lacking reliable references",
                "Category:All articles with dead external links",
                "Category:Articles lacking reliable references from June 2014",
                "Category:Articles with dead external links from February 2022",
                "Category:Articles with short description",
                "Category:Google events",
                "Category:Programming contests",
                "Category:Short description is different from Wikidata"
            ],
            "id": 209
        },
        {
            "title": "Dance-rock",
            "info_text": "Dance-rock is a dance-infused genre of rock music. It is a post-disco genre connected with pop rock and post-punk with fewer rhythm and blues influences. It originated in the early 1980s, following the decline in popularity of both punk and disco.\nExamples of early dance-rock include Gina X's \"No G.D.M.\", Russ Ballard's \"On the Rebound\", artists such as Dinosaur L, Liquid Liquid and Polyrock, and the compilation album Disco Not Disco.",
            "categories": [
                "Category:1970s in music",
                "Category:1980s in music",
                "Category:1990s in music",
                "Category:American styles of music",
                "Category:Articles with short description",
                "Category:British styles of music",
                "Category:Dance-rock",
                "Category:Fusion music genres",
                "Category:Post-disco",
                "Category:Rock music genres"
            ],
            "id": 210
        },
        {
            "title": "Cajun music",
            "info_text": "Cajun music (French: Musique cadienne), an emblematic music of Louisiana played by the Cajuns, is rooted in the ballads of the French-speaking Acadians of Canada. Although they are two separate genres, Cajun music is often mentioned in tandem with the Creole-based zydeco music. Both are from southwest Louisiana and share French and African origins. These French Louisiana sounds have influenced American popular music for many decades, especially country music, and have influenced pop culture through mass media, such as television commercials.",
            "categories": [
                "Category:Articles containing French-language text",
                "Category:Articles with hAudio microformats",
                "Category:Articles with short description",
                "Category:Cajun music",
                "Category:Short description is different from Wikidata"
            ],
            "id": 211
        },
        {
            "title": "History of YouTube",
            "info_text": "YouTube is an American online video-sharing platform headquartered in San Bruno, California, founded by three former PayPal employees\u2014Chad Hurley, Steve Chen, and Jawed Karim\u2014in February 2005. Google bought the site in November 2006 for US$1.65 billion, since which it operates as one of Google's subsidiaries.\nYouTube allows users to upload videos, view them, rate them with likes and dislikes, share them, add videos to playlists, report, make comments on videos, and subscribe to other users. The slogan \"Broadcast Yourself\" used for several years and the reference to user profiles as \"Channels\" signifies the premise upon which the platform is based, of allowing anyone to operate a personal broadcasting station in resemblance to television with the extension of video on demand.\nAs such, the platform offers a wide variety of user-generated and corporate media videos. Available content includes video clips, TV show clips, music videos, short and documentary films, audio recordings, movie trailers, live streams, and other content such as video blogging, short original videos, and educational videos.\nAs of February 2017, there were more than 400 hours of content uploaded to YouTube each minute, and one billion hours of content being watched on YouTube every day. As of October 2020, YouTube is the second-most popular website in the world, behind Google, according to Alexa Internet. As of May 2019, more than 500 hours of video content are uploaded to YouTube every minute. Based on reported quarterly advertising revenue, YouTube is estimated to have US$15 billion in annual revenues.\nYouTube has faced criticism over aspects of its operations, including its handling of copyrighted content contained within uploaded videos, its recommendation algorithms perpetuating videos that promote conspiracy theories and falsehoods, hosting videos ostensibly targeting children but containing violent or sexually suggestive content involving popular characters, videos of minors attracting pedophilic activities in their comment sections, and fluctuating policies on the types of content that is eligible to be monetized with advertising.",
            "categories": [
                "Category:21st century in the United States",
                "Category:All articles containing potentially dated statements",
                "Category:All articles with dead external links",
                "Category:All articles with failed verification",
                "Category:All articles with unsourced statements",
                "Category:Articles containing potentially dated statements from February 2017",
                "Category:Articles containing potentially dated statements from May 2019",
                "Category:Articles containing potentially dated statements from October 2020",
                "Category:Articles with dead external links from July 2014",
                "Category:Articles with dead external links from March 2017"
            ],
            "id": 212
        },
        {
            "title": "PayPal Park",
            "info_text": "PayPal Park (formerly Earthquakes Stadium and Avaya Stadium) is a soccer-specific stadium in San Jose, California. It is the home stadium of the San Jose Earthquakes of Major League Soccer (MLS) and Bay FC of the National Women's Soccer League (NWSL). The stadium is located on the Airport West site next to San Jose International Airport.\nPayPal Park officially opened on February 27, 2015, and has a capacity of approximately 18,000. The stadium features a canopy roof and some of the steepest-raked seating in Major League Soccer to provide a better view. Additionally, the area behind the northeast goal houses the largest outdoor bar in North America, a 2-acre (0.81 ha) fan zone and a double-sided video scoreboard. The suites and club seats are located at field level. The stadium is part of a mixed-use residential, retail, R&D, and hotel development.\nThe stadium was constructed privately with no public money provided by the city of San Jose. Additionally, Lewis Wolff, the then owner of the San Jose Earthquakes, offered to pay for the maintenance of the stadium for a 55-year time span. The team organization initially delayed the completion date to the middle of the 2014 MLS season, but later delayed it again to the 2015 season.\nThe seat pattern includes three different shades of blue as well as a smattering of red seats to pay homage to the club's NASL history. Additionally, the pattern contains the message \"Go EQ\" written in binary.\n\n",
            "categories": [
                "Category:2015 establishments in California",
                "Category:All Wikipedia articles written in American English",
                "Category:Articles with short description",
                "Category:Bay FC",
                "Category:Commons category link from Wikidata",
                "Category:Coordinates on Wikidata",
                "Category:Lacrosse venues in California",
                "Category:Major League Soccer stadiums",
                "Category:National Women's Soccer League stadiums",
                "Category:Pages using gadget WikiMiniAtlas"
            ],
            "id": 213
        },
        {
            "title": "List of elements by stability of isotopes",
            "info_text": "This is a list of chemical elements by the stability of their isotopes. Of the first 82 elements in the periodic table, 80 have isotopes considered to be stable. Overall, there are 251 known stable isotopes in total.\n\n",
            "categories": [
                "Category:All articles that may contain original research",
                "Category:All articles with unsourced statements",
                "Category:Articles that may contain original research from July 2022",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from January 2024",
                "Category:Articles with unsourced statements from May 2016",
                "Category:Lists of chemical elements",
                "Category:Short description is different from Wikidata"
            ],
            "id": 214
        },
        {
            "title": "Clarion Workshop",
            "info_text": "The Clarion Workshop is an American six-week workshop for aspiring science fiction and fantasy writers. Originally an outgrowth of Damon Knight's and Kate Wilhelm's Milford Writer's Conference, held at their home in Milford, Pennsylvania, it was founded in 1968 by Robin Scott Wilson at Clarion State College in Pennsylvania. Knight and Wilhelm were among the first teachers at the workshop.\nIn 1972, the workshop moved to Michigan State University. It moved again, in 2006, to the University of California, San Diego.\nIn 2015, the Clarion Foundation received an anonymous gift of $100,000 to found an endowment funding the workshop.\nThe Clarion Workshop events for 2020 and 2021 were cancelled due to the COVID-19 pandemic, with the students selected for 2020 slated to attend in 2022.",
            "categories": [
                "Category:1968 establishments in Pennsylvania",
                "Category:American writers' organizations",
                "Category:Articles with short description",
                "Category:Clarion University of Pennsylvania",
                "Category:Creative writing programs",
                "Category:Michigan State University",
                "Category:Projects established in 1968",
                "Category:Science fiction organizations",
                "Category:Short description is different from Wikidata",
                "Category:University of California, San Diego"
            ],
            "id": 215
        },
        {
            "title": "Razor shell",
            "info_text": "The razor shell, Ensis magnus, also called razor clam, razor fish or spoot (colloquially), is a bivalve of the family Pharidae. It is found on sandy beaches in Canada and northern Europe (north of the Bay of Biscay).\nIn some locations, the common name \"razor shell\" is also used to refer to members of the family Solenidae, including species of the genera Ensis and Solen, by some taxonomic classifications which include the family Pharidae within the family Solenidae. It prefers coarser sand than its relatives E. ensis and E. siliqua.",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles with 'species' microformats",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from September 2024",
                "Category:Marine molluscs of Europe",
                "Category:Marine molluscs of North America",
                "Category:Molluscs described in 1865",
                "Category:Molluscs of the Atlantic Ocean",
                "Category:Pharidae",
                "Category:Short description is different from Wikidata"
            ],
            "id": 216
        },
        {
            "title": "Huawei U1250",
            "info_text": "The Huawei U1250 is a mobile phone manufactured by Huawei, sold in Canada exclusively by Wind Mobile and by Virgin Mobile Australia as the Virgin VMX.",
            "categories": [
                "Category:All articles lacking sources",
                "Category:All stub articles",
                "Category:Articles lacking sources from September 2013",
                "Category:Articles with short description",
                "Category:Huawei mobile phones",
                "Category:Mobile phone stubs",
                "Category:Mobile phones introduced in 2009",
                "Category:Short description matches Wikidata"
            ],
            "id": 217
        },
        {
            "title": "Christian Examiner (California)",
            "info_text": "The Christian Examiner is an online Christian news site. Prior to July 1, 2014, it was a tabloid newspaper, published by Selah Media Group serving Southern California, Western Washington and the Minneapolis\u2013Saint Paul metropolitan area of Minnesota. In early 2014, the newspaper ceased publishing and the trademark, URLs and website were sold to the Christian Media Corporation (CMC Group) which operates Christian Post.\nIn 2014, Refreshed magazine was launched to replace the Christian Examiner.\n\n",
            "categories": [
                "Category:All stub articles",
                "Category:Articles with short description",
                "Category:Christian magazine stubs",
                "Category:Christian media",
                "Category:Short description is different from Wikidata"
            ],
            "id": 218
        },
        {
            "title": "Digital Wellbeing",
            "info_text": "Digital Wellbeing is a feature on Android developed by Google. It was announced during the Google I/O event 2018 as an approach that would help users learn how to balance their digital lives by tracking how much time they spend on any particular application.\n\n",
            "categories": [
                "Category:All articles with topics of unclear notability",
                "Category:All stub articles",
                "Category:Android (operating system) software",
                "Category:Articles with short description",
                "Category:Articles with topics of unclear notability from January 2024",
                "Category:CS1 Hindi-language sources (hi)",
                "Category:Google stubs",
                "Category:Official website not in Wikidata",
                "Category:Short description matches Wikidata"
            ],
            "id": 219
        },
        {
            "title": "Kalamazoo Gazette",
            "info_text": "The Kalamazoo Gazette is the daily newspaper in Kalamazoo, Michigan, and is part of MLive Media Group, Michigan's largest local media organization. The Gazette publishes seven days a week. Papers are available for home delivery on Thursday and Sunday.\n\n",
            "categories": [
                "Category:Advance Publications",
                "Category:All articles needing additional references",
                "Category:Articles needing additional references from March 2016",
                "Category:Articles slanted towards recent events from February 2016",
                "Category:Articles with multiple maintenance issues",
                "Category:Articles with short description",
                "Category:Mass media in Kalamazoo, Michigan",
                "Category:Newspapers established in 1834",
                "Category:Newspapers published in Michigan",
                "Category:Short description matches Wikidata"
            ],
            "id": 220
        },
        {
            "title": "Respiratory arrest",
            "info_text": "Respiratory arrest is a serious medical condition caused by apnea or respiratory dysfunction severe enough that it will not sustain the body (such as agonal breathing). Prolonged apnea refers to a patient who has stopped breathing for a long period of time. If the heart muscle contraction is intact, the condition is known as respiratory arrest. An abrupt stop of pulmonary gas exchange lasting for more than five minutes may permanently damage vital organs, especially the brain. Lack of oxygen to the brain causes loss of consciousness. Brain injury is likely if respiratory arrest goes untreated for more than three minutes, and death is almost certain if more than five minutes.\nDamage may be reversible if treated early enough. Respiratory arrest is a life-threatening medical emergency that requires immediate medical attention and management. To save a patient in respiratory arrest, the goal is to restore adequate ventilation and prevent further damage. Management interventions include supplying oxygen, opening the airway, and means of artificial ventilation. In some instances, an impending respiratory arrest could be predetermined by signs the patient is showing, such as the increased work of breathing. Respiratory arrest will ensue once the patient depletes their oxygen reserves and loses the effort to breathe.\nRespiratory arrest should be distinguished from respiratory failure. The former refers to the complete cessation of breathing, while respiratory failure is the inability to provide adequate ventilation for the body's requirements. Without intervention, both may lead to decreased oxygen in the blood (hypoxemia), elevated carbon dioxide level in the blood (hypercapnia), inadequate oxygen perfusion to tissue (hypoxia), and may be fatal. Respiratory arrest is also different from cardiac arrest, the failure of heart muscle contraction. If untreated, one may lead to the other.\n\n",
            "categories": [
                "Category:All articles lacking reliable references",
                "Category:All articles with unsourced statements",
                "Category:All pages needing cleanup",
                "Category:Articles containing how-to sections",
                "Category:Articles lacking reliable references from July 2019",
                "Category:Articles needing cleanup from January 2025",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from July 2019",
                "Category:CS1: long volume value",
                "Category:CS1 maint: location"
            ],
            "id": 221
        },
        {
            "title": "Aardvark (search engine)",
            "info_text": "Aardvark was a social search service that connected users live with friends or friends-of-friends who were able to answer their questions, also known as a knowledge market. Users submitted questions via the Aardvark website, email or instant messenger and Aardvark identified and facilitated a live chat or email conversation with one or more topic experts in the 'askers' extended social network. Aardvark was  used for asking subjective questions for which human judgment or recommendation was desired. It was also used extensively for technical support questions.  Users could also review  question and answer history and other settings on the Aardvark website.  Google acquired Aardvark for $50 million on February 11, 2010.\nIn September 2011, Google announced it would discontinue a number of its products, including Aardvark.",
            "categories": [
                "Category:Articles with short description",
                "Category:Community websites",
                "Category:Discontinued Google acquisitions",
                "Category:Discontinued Google services",
                "Category:Human-based computation",
                "Category:Internet properties disestablished in 2011",
                "Category:Internet properties established in 2008",
                "Category:Knowledge markets",
                "Category:Privately held companies based in California",
                "Category:Short description is different from Wikidata"
            ],
            "id": 222
        },
        {
            "title": "Blenheim Palace",
            "info_text": "Blenheim Palace ( BLEN-im) is a  country house in Woodstock, Oxfordshire, England. It is the seat of the Dukes of Marlborough. Originally called Blenheim Castle, it has been known as Blenheim Palace since the 19th century. One of England's largest houses, it was built between 1705 and 1722, and designated a UNESCO World Heritage Site in 1987.\nThe palace is named after the 1704 Battle of Blenheim. It was originally intended to be a reward to John Churchill, 1st Duke of Marlborough for his military triumphs against the French and Bavarians in the War of the Spanish Succession, culminating in the Battle of Blenheim. The land was given as a gift, and construction began in 1705, with some financial support from Queen Anne. The project soon became the subject of political infighting, with the Crown cancelling further financial support in 1712, Marlborough's three-year voluntary exile to the Continent, the fall from influence of his duchess, and lasting damage to the reputation of the architect Sir John Vanbrugh.\nDesigned in the rare, and short-lived, English Baroque style, architectural appreciation of the palace is as divided today as it was in the 1720s. It is unique in its combined use as a family home, mausoleum and national monument. The palace is notable as the birthplace and ancestral home of Sir Winston Churchill.\nFollowing the palace's completion, it became the home of the Churchill (later Spencer-Churchill) family for the next 300 years, and various members of the family have wrought changes to the interiors, park and gardens. At the end of the 19th century, the palace was saved from ruin by funds gained from the 9th Duke of Marlborough's marriage to American railroad heiress Consuelo Vanderbilt.\n\n",
            "categories": [
                "Category:1722 establishments in England",
                "Category:All articles containing potentially dated statements",
                "Category:Articles containing potentially dated statements from October 2016",
                "Category:Articles containing potentially dated statements from September 2022",
                "Category:Articles incorporating Cite DNB template",
                "Category:Articles with short description",
                "Category:Baroque palaces in the United Kingdom",
                "Category:Birthplaces of individual people",
                "Category:Coordinates on Wikidata",
                "Category:English Baroque architecture"
            ],
            "id": 223
        },
        {
            "title": "Master of Arts (Oxford, Cambridge and Dublin)",
            "info_text": "In the universities of Oxford, Cambridge, and Dublin, Bachelors of Arts (BAs) are promoted to the rank of Master of Arts (MA), typically upon application after three or four years after graduation. No further examination or study is required for this promotion, which is a mark of seniority rather than an additional postgraduate qualification. \nWhile these universities also award postgraduate master's degrees that require further study and examination, they do not award the title 'MA' for any postgraduate degree. This practice differs from that of most universities worldwide, where the MA reflects further postgraduate study. As a result, these degrees are often referred to as the Oxford and Cambridge MA and the Dublin or Trinity MA to distinguish them. Similarly, in the ancient Scottish universities, the degree of Master of Arts is awarded as an undergraduate degree in certain subjects.\nUpon promotion to MA, graduates no longer wear the academic dress or use the post-nominal letters associated with the Bachelor of Arts.\n\n",
            "categories": [
                "Category:Academic courses at the University of Cambridge",
                "Category:Academic courses at the University of Oxford",
                "Category:All articles needing additional references",
                "Category:All articles with unsourced statements",
                "Category:Articles needing additional references from November 2020",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from December 2015",
                "Category:Education in England",
                "Category:EngvarB from September 2013",
                "Category:Master's degrees"
            ],
            "id": 224
        },
        {
            "title": "Wesleyan University Press",
            "info_text": "Wesleyan University Press is a university press that is part of Wesleyan University in Middletown, Connecticut. The press is currently directed by Suzanna Tamminen, a published poet and essayist.",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:American companies established in 1957",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from September 2023",
                "Category:Book publishing companies based in Connecticut",
                "Category:Publishing companies established in 1957",
                "Category:Short description matches Wikidata",
                "Category:University presses of the United States",
                "Category:Wesleyan University"
            ],
            "id": 225
        },
        {
            "title": "Hy (programming language)",
            "info_text": "Hy is a dialect of the Lisp programming language designed to interact with Python by translating s-expressions into Python's abstract syntax tree (AST). Hy was introduced at Python Conference (PyCon) 2013 by Paul Tagliamonte. Lisp allows operating on code as data (metaprogramming), thus Hy can be used to write domain-specific languages.\nSimilar to Kawa's and Clojure's mappings onto the Java virtual machine (JVM), Hy is meant to operate as a transparent Lisp front-end for Python. It allows Python libraries, including the standard library, to be imported and accessed alongside Hy code with a compiling step where both languages are converted into Python's AST.\n\n",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from July 2017",
                "Category:Cross-platform free software",
                "Category:Lisp (programming language)",
                "Category:Lisp programming language family",
                "Category:Official website different in Wikidata and Wikipedia",
                "Category:Programming languages created in 2013",
                "Category:Short description matches Wikidata"
            ],
            "id": 226
        },
        {
            "title": "Valine",
            "info_text": "Valine (symbol Val or V) is an \u03b1-amino acid that is used in the biosynthesis of proteins. It contains an \u03b1-amino group (which is in the protonated \u2212NH3+ form under biological conditions), an \u03b1-carboxylic acid group (which is in the deprotonated \u2212COO\u2212 form under biological conditions), and a side chain isopropyl group, making it a non-polar aliphatic amino acid. Valine is essential in humans, meaning the body cannot synthesize it; it must be obtained from dietary sources which are foods that contain proteins, such as meats, dairy products, soy products, beans and legumes. It is encoded by all codons starting with GU (GUU, GUC, GUA, and GUG).",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Alpha-Amino acids",
                "Category:Articles containing unverified chemical infoboxes",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from October 2024",
                "Category:Articles without InChI source",
                "Category:Branched-chain amino acids",
                "Category:Chemical articles having a data page",
                "Category:Chemical articles with multiple CAS registry numbers",
                "Category:Chemical articles with multiple PubChem CIDs"
            ],
            "id": 227
        },
        {
            "title": "Toronto",
            "info_text": "Toronto is the most populous city in Canada and the capital city of the Canadian province of Ontario. With a population of 2,794,356 in 2021, it is the fourth-most populous city in North America. The city is the anchor of the Golden Horseshoe, an urban agglomeration of 9,765,188 people (as of 2021) surrounding the western end of Lake Ontario, while the Greater Toronto Area proper had a 2021 population of 6,712,341. Toronto is an international centre of business, finance, arts, sports, and culture and is one of the most multicultural and cosmopolitan cities in the world.\nIndigenous peoples have travelled through and inhabited the Toronto area, located on a broad sloping plateau interspersed with rivers, deep ravines, and urban forest, for more than 10,000 years. After the broadly disputed Toronto Purchase, when the Mississauga surrendered the area to the British Crown, the British established the town of York in 1793 and later designated it as the capital of Upper Canada. During the War of 1812, the town was the site of the Battle of York and suffered heavy damage by American troops. York was renamed and incorporated in 1834 as the city of Toronto. It was designated as the capital of the province of Ontario in 1867 during Canadian Confederation. The city proper has since expanded past its original limits through both annexation and amalgamation to its current area of 630.2 km2 (243.3 sq mi).\nThe diverse population of Toronto reflects its current and historical role as an important destination for immigrants to Canada. About half of its residents were born outside of Canada and over 200 ethnic origins are represented among its inhabitants. While the majority of Torontonians speak English as their primary language, over 160 languages are spoken in the city. The mayor of Toronto is elected by direct popular vote to serve as the chief executive of the city. The Toronto City Council is a unicameral legislative body, comprising 25 councillors since the 2018 municipal election, representing geographical wards throughout the city.\nToronto is a prominent centre for music, theatre, motion picture production, and television production, and is home to the headquarters of Canada's major national broadcast networks and media outlets. Its varied cultural institutions, which include numerous museums and galleries, festivals and public events, entertainment districts, national historic sites, and sports activities, attract over 43 million tourists each year. Toronto is known for its many skyscrapers and high-rise buildings, in particular the CN Tower, the tallest freestanding structure on land outside of Asia.\nThe city is home to the Toronto Stock Exchange, the headquarters of Canada's five largest banks, and the headquarters of many large Canadian and multinational corporations. Its economy is highly diversified with strengths in technology, design, financial services, life sciences, education, arts, fashion, aerospace, environmental innovation, food services, and tourism. Toronto is the third-largest tech hub in North America after Silicon Valley and New York City, and the fastest-growing hub.",
            "categories": [
                "Category:1834 establishments in Canada",
                "Category:All Wikipedia articles written in Canadian English",
                "Category:All articles lacking reliable references",
                "Category:All articles needing additional references",
                "Category:All articles with dead external links",
                "Category:All articles with unsourced statements",
                "Category:Articles containing Mohawk-language text",
                "Category:Articles lacking reliable references from June 2024",
                "Category:Articles needing additional references from July 2016",
                "Category:Articles tagged with the inline citation overkill template from September 2023"
            ],
            "id": 228
        },
        {
            "title": "Monte Carlo method",
            "info_text": "Monte Carlo methods, or Monte Carlo experiments, are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results. The underlying concept is to use randomness to solve problems that might be deterministic in principle. The name comes from the Monte Carlo Casino in Monaco, where the primary developer of the method, mathematician Stanis\u0142aw Ulam, was inspired by his uncle's gambling habits.\nMonte Carlo methods are mainly used in three distinct problem classes: optimization, numerical integration, and generating draws from a probability distribution. They can also be used to model phenomena with significant uncertainty in inputs, such as calculating the risk of a nuclear power plant failure. Monte Carlo methods are often implemented using computer simulations, and they can provide approximate solutions to problems that are otherwise intractable or too complex to analyze mathematically.\nMonte Carlo methods are widely used in various fields of science, engineering, and mathematics, such as physics, chemistry, biology, statistics, artificial intelligence, finance, and cryptography. They have also been applied to social sciences, such as sociology, psychology, and political science. Monte Carlo methods have been recognized as one of the most important and influential ideas of the 20th century, and they have enabled many scientific and technological breakthroughs.\nMonte Carlo methods also have some limitations and challenges, such as the trade-off between accuracy and computational cost, the curse of dimensionality, the reliability of random number generators, and the verification and validation of the results.\n\n",
            "categories": [
                "Category:All Wikipedia articles written in American English",
                "Category:All articles needing examples",
                "Category:Articles needing examples from May 2012",
                "Category:Articles with short description",
                "Category:CS1: long volume value",
                "Category:Commons category link is on Wikidata",
                "Category:Computational physics",
                "Category:Monte Carlo methods",
                "Category:Numerical analysis",
                "Category:Randomized algorithms"
            ],
            "id": 229
        },
        {
            "title": "Google Input Tools",
            "info_text": "Google Input Tools, also known as Google IME, is a set of input method editors by Google for 22 languages, including Amharic, Arabic, Bengali, Chinese, Greek, Gujarati, Hindi, Japanese, Kannada, Malayalam, Marathi, Nepali, Persian, Punjabi, Russian, Sanskrit, Serbian, Tamil, Telugu, Tigrinya, and Urdu. It is a virtual keyboard that allows users to type in their local language text directly in any application without the hassle of copying and pasting.\nAvailable as a Chrome extension, it was also available as a desktop application for Microsoft Windows until it was removed in May 2018.\n\n",
            "categories": [
                "Category:All stub articles",
                "Category:Articles with short description",
                "Category:Google services",
                "Category:Google stubs",
                "Category:Han pinyin input",
                "Category:Indic computing",
                "Category:Input method editor",
                "Category:Input methods",
                "Category:Linux text-related software",
                "Category:MacOS text-related software"
            ],
            "id": 230
        },
        {
            "title": "Val Logsdon Fitch",
            "info_text": "Val Logsdon Fitch (March 10, 1923 \u2013 February 5, 2015) was an American nuclear physicist who, with co-researcher James Cronin, was awarded the 1980 Nobel Prize in Physics for a 1964 experiment using the Alternating Gradient Synchrotron at Brookhaven National Laboratory that proved that certain subatomic reactions do not adhere to fundamental symmetry principles. Specifically, they proved, by examining the decay of K-mesons, that a reaction run in reverse does not retrace the path of the original reaction, which showed that the reactions of subatomic particles are not indifferent to time. Thus the phenomenon of CP violation was discovered. This demolished the faith that physicists had that natural laws were governed by symmetry.\nBorn on a cattle ranch near Merriman, Nebraska, Fitch was drafted into the U.S. Army during World War II, and worked on the Manhattan Project at the Los Alamos Laboratory in New Mexico. He later graduated from McGill University, and completed his PhD in physics in 1954 at Columbia University.  He was a member of the faculty at Princeton University from 1954 until his retirement in 2005.",
            "categories": [
                "Category:1923 births",
                "Category:2015 deaths",
                "Category:American Nobel laureates",
                "Category:American nuclear physicists",
                "Category:American particle physicists",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Brookhaven National Laboratory Nobel laureates",
                "Category:Brookhaven National Laboratory staff",
                "Category:Chadron State College alumni"
            ],
            "id": 231
        },
        {
            "title": "Load\u2013store unit",
            "info_text": "In computer engineering, a load\u2013store unit (LSU) is a specialized execution unit responsible for executing all load and store instructions, generating virtual addresses of load and store operations and loading data from memory or storing it back to memory from registers.\nThe load\u2013store unit usually includes a queue which acts as a waiting area for memory instructions, and the unit itself operates independently of other processor units.\nLoad\u2013store units may also be used in vector processing, and in such cases the term \"load\u2013store vector\" may be used.\nSome load\u2013store units are also capable of executing simple fixed-point and/or integer operations.\n\n",
            "categories": [
                "Category:All Wikipedia articles in need of updating",
                "Category:Articles with obsolete information from March 2017",
                "Category:Articles with short description",
                "Category:Computer architecture",
                "Category:Short description matches Wikidata"
            ],
            "id": 232
        },
        {
            "title": "Apology video",
            "info_text": "An apology video is a video in which a celebrity or influencer apologises for, or addresses, public criticism or backlash.",
            "categories": [
                "Category:All Wikipedia articles needing context",
                "Category:All pages needing cleanup",
                "Category:Articles with short description",
                "Category:Internet memes",
                "Category:Internet terminology",
                "Category:Short description is different from Wikidata",
                "Category:Wikipedia articles needing context from January 2024",
                "Category:YouTube"
            ],
            "id": 233
        },
        {
            "title": "Subsidiary",
            "info_text": "A subsidiary, subsidiary company, or daughter company is a company completely or partially owned or controlled by another company, called the parent company or holding company, which has legal and financial control over the subsidiary company. Unlike regional branches or divisions, subsidiaries are considered to be distinct entities from their parent companies; they are required to follow the laws of where they are incorporated, and they maintain their own executive leadership. Two or more subsidiaries primarily controlled by same entity/group are considered to be sister companies of each other.\nSubsidiaries are a common feature of modern business, and most multinational corporations organize their operations via the creation and purchase of subsidiary companies. Examples of holding companies are Berkshire Hathaway, Jefferies Financial Group, The Walt Disney Company, Warner Bros. Discovery, and Citigroup, which have subsidiaries involved in many different fields. More focused companies include IBM, Xerox, and Microsoft; they and their subsidiaries primarily operate within the tech sector. These, and others, organize their businesses into national and functional subsidiaries, often with multiple levels of subsidiaries.",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All articles with unsourced statements",
                "Category:Articles needing additional references from July 2022",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from April 2024",
                "Category:Articles with unsourced statements from November 2009",
                "Category:Business models",
                "Category:Business terms",
                "Category:Corporate subsidiaries",
                "Category:Legal entities"
            ],
            "id": 234
        },
        {
            "title": "List of Huawei phones",
            "info_text": "The following is a list of Huawei phones. The date in brackets is the date of initial release.\nHuawei's two flagship smartphone lines are the Mate and Pura series.\n\n",
            "categories": [
                "Category:All articles with bare URLs for citations",
                "Category:Articles with PDF format bare URLs for citations",
                "Category:Articles with bare URLs for citations from August 2022",
                "Category:Articles with short description",
                "Category:CS1 French-language sources (fr)",
                "Category:Huawei mobile phones",
                "Category:Lists of mobile phones",
                "Category:Short description is different from Wikidata"
            ],
            "id": 235
        },
        {
            "title": "Climate",
            "info_text": "Climate is the long-term weather pattern in a region, typically averaged over 30 years. More rigorously, it is the mean and variability of meteorological variables over a time spanning from months to millions of years. Some of the meteorological variables that are commonly measured are temperature, humidity, atmospheric pressure, wind, and precipitation. In a broader sense, climate is the state of the components of the climate system, including the atmosphere, hydrosphere, cryosphere, lithosphere and biosphere and the interactions between them. The climate of a location is affected by its latitude, longitude, terrain, altitude, land use and nearby water bodies and their currents.\nClimates can be classified according to the average and typical variables, most commonly temperature and precipitation. The most widely used classification scheme is the K\u00f6ppen climate classification. The Thornthwaite system, in use since 1948, incorporates evapotranspiration along with temperature and precipitation information and is used in studying biological diversity and how climate change affects it. The major classifications in Thornthwaite's climate classification are microthermal, mesothermal, and megathermal. Finally, the Bergeron and Spatial Synoptic Classification systems focus on the origin of air masses that define the climate of a region.\nPaleoclimatology is the study of ancient climates. Paleoclimatologists seek to explain climate variations for all parts of the Earth during any given geologic period, beginning with the time of the Earth's formation. Since very few direct observations of climate were available before the 19th century, paleoclimates are inferred from proxy variables. They include non-biotic evidence\u2014such as sediments found in lake beds and ice cores\u2014and biotic evidence\u2014such as tree rings and coral. Climate models are mathematical models of past, present, and future climates. Climate change may occur over long and short timescales due to various factors. Recent warming is discussed in terms of global warming, which results in redistributions of biota. For example, as climate scientist Lesley Ann Hughes has written: \"a 3 \u00b0C [5 \u00b0F] change in mean annual temperature corresponds to a shift in isotherms of approximately 300\u2013400 km [190\u2013250 mi] in latitude (in the temperate zone) or 500 m [1,600 ft] in elevation. Therefore, species are expected to move upwards in elevation or towards the poles in latitude in response to shifting climate zones.\"",
            "categories": [
                "Category:Articles with hAudio microformats",
                "Category:Articles with short description",
                "Category:CS1 maint: numeric names: authors list",
                "Category:Climate",
                "Category:Climatology",
                "Category:Commons category link is on Wikidata",
                "Category:Good articles",
                "Category:Meteorological concepts",
                "Category:Short description is different from Wikidata",
                "Category:Spoken articles"
            ],
            "id": 236
        },
        {
            "title": "Organometallic chemistry",
            "info_text": "Organometallic chemistry is the study of organometallic compounds, chemical compounds containing at least one chemical bond between a carbon atom of an organic molecule and a metal, including alkali, alkaline earth, and transition metals, and sometimes broadened to include metalloids like boron, silicon, and selenium, as well. Aside from bonds to organyl fragments or molecules, bonds to 'inorganic' carbon, like carbon monoxide (metal carbonyls), cyanide, or carbide, are generally considered to be organometallic as well.  Some related compounds such as transition metal hydrides and metal phosphine complexes are often included in discussions of organometallic compounds, though strictly speaking, they are not necessarily organometallic. The related but distinct term \"metalorganic compound\" refers to metal-containing compounds lacking direct metal-carbon bonds but which contain organic ligands.  Metal \u03b2-diketonates, alkoxides, dialkylamides, and metal phosphine complexes are representative members of this class.  The field of organometallic chemistry combines aspects of traditional inorganic and organic chemistry.\nOrganometallic compounds are widely used both stoichiometrically in research and industrial chemical reactions, as well as in the role of catalysts to increase the rates of such reactions (e.g., as in uses of homogeneous catalysis), where target molecules include polymers, pharmaceuticals, and many other types of practical products.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:CS1 German-language sources (de)",
                "Category:CS1 maint: location missing publisher",
                "Category:Organometallic chemistry",
                "Category:Short description is different from Wikidata",
                "Category:Use dmy dates from August 2021",
                "Category:Webarchive template wayback links",
                "Category:Wikipedia articles needing page number citations from October 2021"
            ],
            "id": 237
        },
        {
            "title": "Hemidactylus",
            "info_text": "Hemidactylus is a genus of the common gecko family, Gekkonidae. It has 195 described species, newfound ones being described every few years. These geckos are found in all the tropical regions of the world, extending into the subtropical parts of Africa and Europe. They excel in colonizing oceanic islands by rafting on flotsam, and are for example found across most of Polynesia. In some archipelagoes, cryptic species complexes are found.  Geckos like to live in and out of houses.  They have been introduced to many areas around the world.\nThis species is closely related to the genus Gehyra, which belongs to the same family in Gekkonidae.\nThe species are typically known as house geckos, due to their readiness to adapt to and coexist with humans, and can be easily encountered in human habitations.\n\n",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles containing Greek-language text",
                "Category:Articles using diversity taxobox",
                "Category:Articles with 'species' microformats",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from May 2016",
                "Category:Hemidactylus",
                "Category:Lizard genera",
                "Category:Short description is different from Wikidata",
                "Category:Taxa named by Lorenz Oken"
            ],
            "id": 238
        },
        {
            "title": "List of Welsh Nobel laureates",
            "info_text": "Listed below are the Nobel laureates born in Wales, in alphabetical order. Wales is a constituent part of the United Kingdom; this means that Welsh Nobel laureates are included in the list of Nobel laureates for Great Britain by the Nobel Foundation.",
            "categories": [
                "Category:Articles with short description",
                "Category:British Nobel laureates",
                "Category:Lists of Nobel laureates by nationality",
                "Category:Lists of Welsh people",
                "Category:Short description is different from Wikidata",
                "Category:Use British English from September 2011",
                "Category:Use dmy dates from December 2020",
                "Category:Welsh Nobel laureates"
            ],
            "id": 239
        },
        {
            "title": "Booking Holdings",
            "info_text": "Booking Holdings Inc. is an American travel technology company incorporated under Delaware General Corporation Law and based in Norwalk, Connecticut, that owns and operates several travel fare aggregators and travel fare metasearch engines including namesake and flagship Booking.com, Priceline.com, Agoda, Kayak, Cheapflights, Rentalcars.com, Momondo, and OpenTable. It operates websites in about 40 languages and 200 countries.\nThe company is ranked 243rd on the Fortune 500 list of the largest United States corporations by revenue. The company primarily derives its revenue from commissions, with a small portion derived from advertising. In 2023, consumers booked 1,049 million room nights of accommodation, 74 million rental car days, and 36 million airplane tickets using websites owned by Booking Holdings.:\u200a43\u200a\n\n",
            "categories": [
                "Category:1996 establishments in Connecticut",
                "Category:1999 initial public offerings",
                "Category:American companies established in 1996",
                "Category:Articles with short description",
                "Category:Booking Holdings",
                "Category:CS1 German-language sources (de)",
                "Category:Commons category link is on Wikidata",
                "Category:Companies based in Norwalk, Connecticut",
                "Category:Companies in the Nasdaq-100",
                "Category:Companies listed on the Nasdaq"
            ],
            "id": 240
        },
        {
            "title": "Outline of machine learning",
            "info_text": "The following outline is provided as an overview of, and topical guide to, machine learning:\nMachine learning (ML) is a subfield of artificial intelligence within computer science that evolved from the study of pattern recognition and computational learning theory. In 1959, Arthur Samuel defined machine learning as a \"field of study that gives computers the ability to learn without being explicitly programmed\". ML involves the study and construction of algorithms that can learn from and make predictions on data. These algorithms operate by building a model from a training set of example observations to make data-driven predictions or decisions expressed as outputs, rather than following strictly static program instructions.",
            "categories": [
                "Category:Articles with short description",
                "Category:Computing-related lists",
                "Category:Data mining",
                "Category:Dynamic lists",
                "Category:Machine learning",
                "Category:Outlines",
                "Category:Outlines of applied sciences",
                "Category:Pages using Sister project links with default search",
                "Category:Short description is different from Wikidata"
            ],
            "id": 241
        },
        {
            "title": "Canton and Enderbury Islands",
            "info_text": "The Canton and Enderbury Islands consist of the coral atolls of Canton Island (also Kanton) and Enderbury in the northeastern part of the Phoenix Islands, about 1,850 miles (3,000 km) south of Hawaii in the central Pacific Ocean.",
            "categories": [
                "Category:1939 establishments in Oceania",
                "Category:1979 disestablishments in Oceania",
                "Category:Articles with short description",
                "Category:Atolls of Kiribati",
                "Category:British Western Pacific Territories",
                "Category:CS1: unfit URL",
                "Category:Condominia (international law)",
                "Category:Coordinates on Wikidata",
                "Category:Former disputed islands",
                "Category:Pacific islands claimed under the Guano Islands Act"
            ],
            "id": 242
        },
        {
            "title": "Dartmouth Big Green men's soccer",
            "info_text": "The Dartmouth Big Green men's soccer program represents the Dartmouth College in all NCAA Division I men's college soccer competitions. Founded in 1915, the Big Green compete in the Ivy League. The Big Green are coached by Bo Oshoniyi, who has coached the program since 2018. The Big Green plays their home matches at Burnham Field, on the Dartmouth campus.\n\n",
            "categories": [
                "Category:1915 establishments in New Hampshire",
                "Category:All stub articles",
                "Category:Articles with short description",
                "Category:Association football clubs established in 1915",
                "Category:Dartmouth Big Green men's soccer",
                "Category:New Hampshire stubs",
                "Category:Northeastern United States soccer club stubs",
                "Category:Short description matches Wikidata"
            ],
            "id": 243
        },
        {
            "title": "Reinforcement learning from human feedback",
            "info_text": "In machine learning, reinforcement learning from human feedback (RLHF) is a technique to align an intelligent agent with human preferences. It involves training a reward model to represent preferences, which can then be used to train other models through reinforcement learning.\nIn classical reinforcement learning, an intelligent agent's goal is to learn a function that guides its behavior, called a policy. This function is iteratively updated to maximize rewards based on the agent's task performance. However, explicitly defining a reward function that accurately approximates human preferences is challenging. Therefore, RLHF seeks to train a \"reward model\" directly from human feedback. The reward model is first trained in a supervised manner to predict if a response to a given prompt is good (high reward) or bad (low reward) based on ranking data collected from human annotators. This model then serves as a reward function to improve an agent's policy through an optimization algorithm like proximal policy optimization.\n\nRLHF has applications in various domains in machine learning, including natural language processing tasks such as text summarization and conversational agents, computer vision tasks like text-to-image models, and the development of video game bots. While RLHF is an effective method of training models to act better in accordance with human preferences, it also faces challenges due to the way the human preference data is collected. Though RLHF does not require massive amounts of data to improve performance, sourcing high-quality preference data is still an expensive process. Furthermore, if the data is not carefully collected from a representative sample, the resulting model may exhibit unwanted biases.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:Good articles",
                "Category:Language modeling",
                "Category:Reinforcement learning",
                "Category:Short description is different from Wikidata"
            ],
            "id": 244
        },
        {
            "title": "Google AI",
            "info_text": "Google AI is a division of Google dedicated to artificial intelligence. It was announced at Google I/O 2017 by CEO Sundar Pichai.\nThis division has expanded its reach with research facilities in various parts of the world such as Zurich, Paris, Israel, and Beijing. In 2023, Google AI was part of the reorganization initiative that elevated its head, Jeff Dean, to the position of chief scientist at Google. This reorganization involved the merging of Google Brain and DeepMind, a UK-based company that Google acquired in 2014 that operated separately from the company's core research.\nIn March 2019 Google announced the creation of an Advanced Technology External Advisory Council (ATEAC) comprising eight members: Alessandro Acquisti, Bubacarr Bah, De Kai, Dyan Gibbens, Joanna Bryson, Kay Coles James, Luciano Floridi and William Joseph Burns.  Following objections from a large number of Google staff to the appointment of Kay Coles James, the Council was abandoned within one month of its establishment.\n\n",
            "categories": [
                "Category:All Wikipedia articles in need of updating",
                "Category:Articles with short description",
                "Category:Artificial intelligence laboratories",
                "Category:CS1 maint: location",
                "Category:Google",
                "Category:Short description matches Wikidata",
                "Category:Use mdy dates from February 2022",
                "Category:Webarchive template wayback links",
                "Category:Wikipedia articles in need of updating from December 2024"
            ],
            "id": 245
        },
        {
            "title": "Noise regulation",
            "info_text": "Noise regulation includes statutes or guidelines relating to sound transmission established by national, state or provincial and municipal levels of government. After the watershed passage of the United States Noise Control Act of 1972, other local and state governments passed further regulations.\nA noise regulation restricts the amount of noise, the duration of noise and the source of noise. It usually places restrictions for certain times of the day.\nAlthough the United Kingdom and Japan enacted national laws in 1960 and 1967 respectively, these laws were not at all comprehensive or fully enforceable as to address generally rising ambient noise, enforceable numerical source limits on aircraft and motor vehicles or comprehensive directives to local government. \nAccordingly, Greece established in 1996 according to Police Order 3 the hours of common quiet 15:00 to 17:30 and from 23:00 to 07:00 in the summer season and 15:30 to 17:30 and from 22:00 until 07:30.\nQuiet hours are times during a day or night when there are placed tighter restrictions on unnecessary or bothersome noise. They vary between jurisdictions and areas, but are typically in place during night-time, for example between 23:00 and 07:00, so as not to interfere with residents sleep. Some noise measurement standards which takes into account different times of the day are the American day-night average sound level (Ldn) standard or the European day\u2013evening\u2013night noise level (Lden) standard. Some jurisdictions also have wider noise restrictions in the weekends or on certain public holidays. Industrial or nightlife areas may be exempt or have fewer restrictions, while private institutions, hotels and universities may place additional restrictions on their guests.\n\n",
            "categories": [
                "Category:All Wikipedia articles needing clarification",
                "Category:All articles needing additional references",
                "Category:All articles with unsourced statements",
                "Category:Articles needing additional references from August 2010",
                "Category:Articles with limited geographic scope from April 2017",
                "Category:Articles with multiple maintenance issues",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from August 2010",
                "Category:Articles with unsourced statements from October 2015",
                "Category:CS1 errors: missing periodical"
            ],
            "id": 246
        },
        {
            "title": "Reinforcement learning",
            "info_text": "Reinforcement learning (RL) is an interdisciplinary area of machine learning and optimal control concerned with how an intelligent agent should take actions in a dynamic environment in order to maximize a reward signal. Reinforcement learning is one of the three basic machine learning paradigms, alongside supervised learning and unsupervised learning.\nQ-learning at its simplest stores data in tables. This approach becomes infeasible as the number of states/actions increases (e.g., if the state space or action space were continuous), as the probability of the agent visiting a particular state and performing a particular action diminishes. \nReinforcement learning differs from supervised learning in not needing labelled input-output pairs to be presented, and in not needing sub-optimal actions to be explicitly corrected. Instead, the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge) with the goal of maximizing the cumulative reward (the feedback of which might be incomplete or delayed). The search for this balance is known as the exploration-exploitation dilemma.\n\nThe environment is typically stated in the form of a Markov decision process (MDP), as many reinforcement learning algorithms use dynamic programming techniques. The main difference between classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the Markov decision process, and they target large MDPs where exact methods become infeasible.",
            "categories": [
                "Category:All articles needing additional references",
                "Category:Articles needing additional references from October 2022",
                "Category:Articles with short description",
                "Category:Belief revision",
                "Category:CS1 maint: location missing publisher",
                "Category:CS1 maint: multiple names: authors list",
                "Category:Markov models",
                "Category:Reinforcement learning",
                "Category:Short description is different from Wikidata",
                "Category:Wikipedia articles needing clarification from January 2020"
            ],
            "id": 247
        },
        {
            "title": "ISO 10161",
            "info_text": "ISO 10161 is the ISO standard, first published in 1993, that defines the interlibrary loan (ILL) application protocol for communication between various document exchange systems. It allows ILL systems at different libraries and residing on different hardware platforms and using different software packages such as VDX to communicate with each other to request and receive electronic documents. It is closely related to ISO 10160, the Interlibrary Loan Application Service Definition.\n\n",
            "categories": [
                "Category:All stub articles",
                "Category:Articles with short description",
                "Category:Computing stubs",
                "Category:ISO standards",
                "Category:Library automation",
                "Category:Short description matches Wikidata"
            ],
            "id": 248
        },
        {
            "title": "Council\u2013manager government",
            "info_text": "The council\u2013manager government is a form of local government commonly used for municipalities and counties in the United States and Ireland, in New Zealand regional councils, and in Canadian municipalities. In the council-manager government, an elected city council hires a manager to serve as chief executive; this manager can be replaced by a simple majority at any time. \n\n",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All articles with dead external links",
                "Category:Articles needing additional references from March 2014",
                "Category:Articles with dead external links from August 2017",
                "Category:Articles with permanently dead external links",
                "Category:Articles with short description",
                "Category:CS1: long volume value",
                "Category:Forms of local government",
                "Category:Local government in the Republic of Ireland",
                "Category:Local government in the United States"
            ],
            "id": 249
        },
        {
            "title": "James Cronin",
            "info_text": "James Watson Cronin (September 29, 1931 \u2013 August 25, 2016) was an American particle physicist.\nCronin and co-researcher Val Logsdon Fitch were awarded the 1980 Nobel Prize in Physics for a 1964 experiment that proved that certain subatomic reactions do not adhere to fundamental symmetry principles. Specifically, they proved, by examining the decay of kaons, that a reaction run in reverse does not merely retrace the path of the original reaction, which showed that the interactions of subatomic particles are not invariant under time reversal. Thus the phenomenon of CP violation was discovered.\nCronin received the Ernest Orlando Lawrence Award in 1976 for major experimental contributions to particle physics including fundamental work on weak interactions culminating in the discovery of asymmetry under time reversal. In 1999, he was awarded the National Medal of Science.\nCronin was Professor Emeritus at the University of Chicago winning the prestigious Quantrell Award and a spokesperson emeritus for the Auger project. He was a member of the Board of Sponsors of the Bulletin of the Atomic Scientists.\n\n",
            "categories": [
                "Category:1931 births",
                "Category:2016 deaths",
                "Category:American Nobel laureates",
                "Category:American nuclear physicists",
                "Category:Articles tagged with the inline citation overkill template from September 2021",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Citation overkill",
                "Category:Fellows of the American Physical Society",
                "Category:Foreign members of the Royal Society"
            ],
            "id": 250
        },
        {
            "title": "Google Marketing Platform",
            "info_text": "Google Marketing Platform is an online advertising and analytics platform developed by Google and launched on July 24, 2018. It unifies DoubleClick's advertising services (acquired in March 2008) and Google's own advertising and analytics services. Google Marketing Platform is mainly used by big advertisers to buy ads on the Internet.\nGoogle Ads (launched in 2000) and Google Ad Manager (launched in 2010) are not parts of Google Marketing Platform. The three brands are complementary tools targeting different types of ad buyers and presenting slightly different features.\n\n",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from January 2024",
                "Category:Digital marketing",
                "Category:Google services",
                "Category:Short description is different from Wikidata",
                "Category:Web analytics"
            ],
            "id": 251
        },
        {
            "title": "Comparison of Google Nexus tablets",
            "info_text": "The following is a comparative list of tablet computers belonging to the Google Nexus line of devices, using the Android operating system.",
            "categories": [
                "Category:Articles with short description",
                "Category:Computing comparisons",
                "Category:Google Nexus",
                "Category:Google lists",
                "Category:Short description is different from Wikidata",
                "Category:Tablet computers",
                "Category:Touchscreen portable media players"
            ],
            "id": 252
        },
        {
            "title": "Energy transition",
            "info_text": "An energy transition (or energy system transformation) is a major structural change to energy supply and consumption in an energy system. Currently, a transition to sustainable energy is underway to limit climate change. Most of the sustainable energy is renewable energy. Therefore, another term for energy transition is renewable energy transition. The current transition aims to reduce greenhouse gas emissions from energy quickly and sustainably, mostly by phasing-down fossil fuels and changing as many processes as possible to operate on low carbon electricity. A previous energy transition perhaps took place during the Industrial Revolution from 1760 onwards, from wood and other biomass to coal, followed by oil and later natural gas.\nOver three-quarters of the world's energy needs are met by burning fossil fuels, but this usage emits greenhouse gases. Energy production and consumption are responsible for most human-caused greenhouse gas emissions. To meet the goals of the 2015 Paris Agreement on climate change, emissions must be reduced as soon as possible and reach net-zero by mid-century. Since the late 2010s, the renewable energy transition has also been driven by the rapidly falling cost of both solar and wind power. After 2024, clean energy is cheaper than ever. Global solar module prices fell 35 percent to less than 9 cents/kWh. EV batteries saw their best price decline in seven years.Another benefit of the energy transition is its potential to reduce the health and environmental impacts of the energy industry. \nHeating of buildings is being electrified, with heat pumps being the most efficient technology by far. To improve the flexibility of electrical grids, the installation of energy storage and super grids are vital to enable the use of variable, weather-dependent technologies. However fossil-fuel subsidies are slowing the energy transition.",
            "categories": [
                "Category:All Wikipedia articles in need of updating",
                "Category:All accuracy disputes",
                "Category:All articles containing potentially dated statements",
                "Category:All articles lacking reliable references",
                "Category:All articles with unsourced statements",
                "Category:Articles containing potentially dated statements from 2020",
                "Category:Articles lacking reliable references from April 2024",
                "Category:Articles with disputed statements from April 2024",
                "Category:Articles with excerpts",
                "Category:Articles with short description"
            ],
            "id": 253
        },
        {
            "title": "Advertising agency",
            "info_text": "An advertising agency, often referred to as a creative agency or an ad agency, is a business dedicated to creating, planning, and handling advertising and sometimes other forms of promotion and marketing for its clients. An ad agency is generally independent of the client; it may be an internal department or agency that provides an outside point of view to the effort of selling the client's products or services, or an outside firm. An agency can also handle overall marketing and branding strategies promotions for its clients, which may include sales as well.\nTypical ad agency clients include businesses and corporations, non-profit organizations and private agencies. Agencies may be hired to produce television advertisements, radio advertisements, online advertising, out-of-home advertising, mobile marketing, and AR advertising, as part of an advertising campaign.\n\n",
            "categories": [
                "Category:Advertising agencies",
                "Category:All articles containing potentially dated statements",
                "Category:Articles containing potentially dated statements from 2017",
                "Category:Articles with short description",
                "Category:Short description matches Wikidata",
                "Category:Wikipedia indefinitely semi-protected pages"
            ],
            "id": 254
        },
        {
            "title": "Solar power in North Dakota",
            "info_text": "Solar power in North Dakota has been a little-used resource. The state ranks last on installed solar power in the United States, with .47 MW of installed capacity. Solar on rooftops can provide 24.6% of all electricity used in North Dakota from 3,300 MW of solar panels. The most cost effective application for solar panels is for pumping water at remote wells where solar panels can be installed for $800 vs. running power lines for $15,000/mile.",
            "categories": [
                "Category:Articles with short description",
                "Category:Commons category link from Wikidata",
                "Category:Energy in North Dakota",
                "Category:Pages using the EasyTimeline extension",
                "Category:Short description with empty Wikidata description",
                "Category:Solar power in the United States by state or territory",
                "Category:Webarchive template archiveis links",
                "Category:Webarchive template wayback links"
            ],
            "id": 255
        },
        {
            "title": "Material Exchange Format",
            "info_text": "Material Exchange Format (MXF) is a container format for professional digital video and audio media defined by a set of SMPTE standards. A typical example of its use is for delivering advertisements to TV stations and tapeless archiving of broadcast TV programs. It is also used as part of the Digital Cinema Package for delivering movies to commercial theaters.\n\n",
            "categories": [
                "Category:All accuracy disputes",
                "Category:Articles with disputed statements from October 2021",
                "Category:Articles with short description",
                "Category:Audiovisual introductions in 2004",
                "Category:Broadcasting standards",
                "Category:CS1 maint: bot: original URL status unknown",
                "Category:Computer-related introductions in 2004",
                "Category:Computer file formats",
                "Category:Film and video technology",
                "Category:SMPTE standards"
            ],
            "id": 256
        },
        {
            "title": "Holden Karnofsky",
            "info_text": "Holden Karnofsky is an American nonprofit executive. He is a co-founder and Director of AI Strategy of the research and grantmaking organization Open Philanthropy. Karnofsky co-founded the charity evaluator GiveWell with Elie Hassenfeld in 2007 and is vice chair of its board of directors.",
            "categories": [
                "Category:AI safety advocates",
                "Category:All articles containing potentially dated statements",
                "Category:American nonprofit businesspeople",
                "Category:American nonprofit chief executives",
                "Category:Articles containing potentially dated statements from 2020",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Consequentialists",
                "Category:Date of birth missing (living people)",
                "Category:Living people"
            ],
            "id": 257
        },
        {
            "title": "Retroflex consonant",
            "info_text": "A retroflex ( ), apico-domal, or cacuminal ( ) consonant is a coronal consonant where the tongue has a flat, concave, or even curled shape, and is articulated between the alveolar ridge and the hard palate. They are sometimes referred to as cerebral consonants\u2014especially in Indology.\nThe Latin-derived word retroflex means \"bent back\"; some retroflex consonants are pronounced with the tongue fully curled back so that articulation involves the underside of the tongue tip (subapical). These sounds are sometimes described as \"true\" retroflex consonants. However, retroflexes are commonly taken to include other consonants having a similar place of articulation without such extreme curling of the tongue; these may be articulated with the tongue tip (apical) or the tongue blade (laminal).",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All articles needing examples",
                "Category:All articles with unsourced statements",
                "Category:Articles containing Iaai-language text",
                "Category:Articles containing Torwali-language text",
                "Category:Articles containing Yi-language text",
                "Category:Articles containing Yokuts-language text",
                "Category:Articles needing additional references from August 2020",
                "Category:Articles needing examples from December 2020",
                "Category:Articles needing examples from March 2015"
            ],
            "id": 258
        },
        {
            "title": "The World of Interiors",
            "info_text": "The World of Interiors is a magazine published by Cond\u00e9 Nast with a total readership of 152,000. The glossy monthly magazine covers interior design.",
            "categories": [
                "Category:1981 establishments in the United Kingdom",
                "Category:All stub articles",
                "Category:Art magazine stubs",
                "Category:Articles with short description",
                "Category:Cond\u00e9 Nast magazines",
                "Category:Design magazines",
                "Category:Design stubs",
                "Category:English-language magazines",
                "Category:Magazines established in 1981",
                "Category:Magazines published in London"
            ],
            "id": 259
        },
        {
            "title": "Spectrum Sports (Florida)",
            "info_text": "Spectrum Sports (formerly known as Bright House Sports Network) was an American regional sports network serving the Tampa Bay and Orlando metropolitan areas of Florida, that was owned by cable television provider Charter Communications which exclusively carried the channel on Standard Definition channel 47 and High Definition channel 1147.",
            "categories": [
                "Category:Advance Publications",
                "Category:All articles needing additional references",
                "Category:Articles needing additional references from February 2012",
                "Category:Articles using infobox television channel",
                "Category:Articles with short description",
                "Category:CS1: unfit URL",
                "Category:Defunct local cable stations in the United States",
                "Category:Short description matches Wikidata",
                "Category:Spectrum Sports Channel",
                "Category:Television channels and stations disestablished in 2017"
            ],
            "id": 260
        },
        {
            "title": "Hyper CD-ROM",
            "info_text": "The Hyper CD-ROM is a claimed optical data storage device similar to the CD-ROM with a multilayer 3D structure, invented by Romanian scientist Eugen Pavel.\nThe technology is supposedly similar to FMD discs. The bit of data being held as a change in fluorescence characteristics once irradiated with one or two lasers. The target is irradiated with a pulse of laser(s) then a CCD or photodiode wait for an emitted light by the medium due to the Fluorescence effect (bit value set to \"1\" if emitted, else \"0\").",
            "categories": [
                "Category:120 mm discs",
                "Category:Accuracy disputes from January 2012",
                "Category:All accuracy disputes",
                "Category:All articles needing additional references",
                "Category:All stub articles",
                "Category:Articles needing additional references from March 2016",
                "Category:Articles with multiple maintenance issues",
                "Category:Articles with short description",
                "Category:Audio storage",
                "Category:Computer storage stubs"
            ],
            "id": 261
        },
        {
            "title": "Cornell University",
            "info_text": "Cornell University is a private Ivy League land-grant research university based in Ithaca, New York, United States. The university was founded in 1865 by Ezra Cornell and Andrew Dickson White. Since its founding, Cornell has been a co-educational and nonsectarian institution. As of fall 2023, the student body included 16,071 undergraduate and 10,207 graduate students from all 50 U.S. states and 130 countries.\nThe university is organized into eight undergraduate colleges and seven graduate divisions on its main Ithaca campus. Each college and academic division has near autonomy in defining its respective admission standards and academic curriculum. In addition to its primary campus in Ithaca, the university administers three satellite campuses, including two in New York City, the medical school and Cornell Tech, and a branch of the medical school in Al Rayyan, Qatar's Education City.\nCornell is one of three private land-grant universities in the United States. Among the university's eight undergraduate colleges, four are state-supported statutory or contract colleges through the State University of New York system, including the College of Agriculture and Life Sciences, the College of Human Ecology, the Industrial and Labor Relations School, and the Jeb E. Brooks School of Public Policy. Among Cornell's graduate schools, only the Veterinary Medicine College is supported by New York. The main campus of Cornell University in Ithaca spans 745 acres (301 ha).\nAs of October 2024, 64 Nobel laureates, 4 Turing Award winners, and 1 Fields Medalist have been affiliated with Cornell. Cornell counts more than 250,000 living alumni, which include 34 Marshall Scholars, 33 Rhodes Scholars, 29 Truman Scholars, 63 Olympic Medalists, 10 current Fortune 500 CEOs, and 35 billionaires.",
            "categories": [
                "Category:1865 establishments in New York (state)",
                "Category:All Wikipedia articles written in American English",
                "Category:All articles containing potentially dated statements",
                "Category:All articles with dead external links",
                "Category:All articles with unsourced statements",
                "Category:Articles containing Latin-language text",
                "Category:Articles containing potentially dated statements from 2023",
                "Category:Articles containing potentially dated statements from October 2024",
                "Category:Articles using NRISref without a reference number",
                "Category:Articles using infobox university"
            ],
            "id": 262
        },
        {
            "title": "64th Academy Awards",
            "info_text": "The 64th Academy Awards ceremony, presented by the Academy of Motion Picture Arts and Sciences (AMPAS), honored the best films of 1991 in the United States and took place on March 30, 1992, at the Dorothy Chandler Pavilion in Los Angeles beginning at 6:00 p.m. PST / 9:00 p.m. EST. During the ceremony, the Academy of Motion Picture Arts and Sciences presented Academy Awards (commonly referred to as Oscars) in 23 categories. The ceremony, televised in the United States by ABC, was produced by Gil Cates and directed by Jeff Margolis. Actor Billy Crystal hosted the show for the third consecutive year. Three weeks earlier, in a ceremony held at the Century Plaza Hotel in Los Angeles on March 7, the Academy Awards for Technical Achievement were presented by host Tom Hanks.\nThe Silence of the Lambs won five awards, including Best Picture. Other winners included Terminator 2: Judgment Day with four awards, Beauty and the Beast, Bugsy, and JFK with two, and City Slickers, Deadly Deception: General Electric, Nuclear Weapons and Our Environment, The Fisher King, In the Shadow of the Stars, Manipulation, Mediterraneo, Session Man, and Thelma & Louise with one. The telecast garnered more than 44 million viewers in the United States.\n\n",
            "categories": [
                "Category:1991 film awards",
                "Category:1992 awards in the United States",
                "Category:1992 in American cinema",
                "Category:1992 in Los Angeles",
                "Category:1992 in the United States",
                "Category:Academy Awards ceremonies",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Featured lists",
                "Category:March 1992 events in the United States"
            ],
            "id": 263
        },
        {
            "title": "Nebula Award for Best Short Story",
            "info_text": "The Nebula Award for Best Short Story is a literary award assigned each year by Science Fiction and Fantasy Writers Association (SFWA) for science fiction or fantasy short stories. A work of fiction is defined by the organization as a short story if it is less than 7,500 words; awards are also given out for longer works in the categories of novel, novella, and novelette.  To be eligible for Nebula Award consideration a short story must be published in English in the United States. Works published in English elsewhere in the world are also eligible provided they are released on either a website or in an electronic edition. The Nebula Award for Best Short Story has been awarded annually since 1966. The award has been described as one of \"the most important of the American science fiction awards\" and \"the science-fiction and fantasy equivalent\" of the Emmy Awards.\nNebula Award nominees and winners are chosen by members of SFWA, though the authors of the nominees do not need to be a member. Works are nominated each year by members in a period around December 15 through January 31, and the six works that receive the most nominations then form the final ballot, with additional nominees possible in the case of ties. Soon after, members are given a month to vote on the ballot, and the final results are presented at the Nebula Awards ceremony in May. Authors are not permitted to nominate their own works, and ties in the final vote are broken, if possible, by the number of nominations the works received. Beginning with the 2009 awards, the rules were changed to the current format. Prior to then, the eligibility period for nominations was defined as one year after the publication date of the work, which allowed the possibility for works to be nominated in the calendar year after their publication and then reach the final ballot in the calendar year after that. Works were added to a preliminary ballot for the year if they had ten or more nominations, which were then voted on to create a final ballot, to which the SFWA organizing panel was also allowed to add an additional work.\nDuring the 59 nomination years, 239 authors have had works nominated; 46 of these have won, including co-authors. One of these authors, Lisa Tuttle, refused her award, and in 1971 no winner was chosen as \"no award\" received the highest number of votes. Harlan Ellison won three times out of eight nominations, both the highest number of wins and the highest number of nominations of any author. Ten authors have won twice, with Karen Joy Fowler at seven and Gardner Dozois at six having the next highest nomination count after Ellison. Michael Swanwick has the most nominations for short story without winning at six, and Howard Waldrop and Gene Wolfe are next with five each. No other author has been nominated more than four times.\n\n",
            "categories": [
                "Category:1966 establishments in the United States",
                "Category:All Wikipedia articles written in American English",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Awards established in 1966",
                "Category:Featured lists",
                "Category:Nebula Awards",
                "Category:Short description is different from Wikidata",
                "Category:Short story awards",
                "Category:Use American English from September 2019"
            ],
            "id": 264
        },
        {
            "title": "Rosie Gray",
            "info_text": "Rosie Gray is a journalist covering politics and media. Previously a reporter for BuzzFeed News, she has also worked for The Atlantic.",
            "categories": [
                "Category:20th-century births",
                "Category:21st-century American journalists",
                "Category:21st-century American women journalists",
                "Category:21st-century American women writers",
                "Category:American reporters and correspondents",
                "Category:Articles with short description",
                "Category:BuzzFeed people",
                "Category:Journalists from Massachusetts",
                "Category:Living people",
                "Category:New York University alumni"
            ],
            "id": 265
        },
        {
            "title": "Benny Chor",
            "info_text": "Ben-Zion \"Benny\" Chor (23 December 1956 \u2013 10 June 2021) was an Israeli computer scientist. He was known for his research in cryptography, including traitor tracing, randomness extractors, private information retrieval, the security level and single-bit security of RSA encryption, and secret sharing. Beyond cryptography, he also made important contributions in distributed shared-memory consensus and in the discovery of patterns in gene expression data.\n\n",
            "categories": [
                "Category:1956 births",
                "Category:2021 deaths",
                "Category:Academic staff of Technion \u2013 Israel Institute of Technology",
                "Category:Academic staff of Tel Aviv University",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Hebrew University of Jerusalem alumni",
                "Category:Israeli computer scientists",
                "Category:Massachusetts Institute of Technology alumni",
                "Category:Scientists from Tel Aviv"
            ],
            "id": 266
        },
        {
            "title": "Free and open-source software",
            "info_text": "Free and open-source software (FOSS) is software that is available under an open-source license that grants the right to use, modify, and distribute the software, modified or not, to everyone free of charge. The public availability of the source code is, therefore, a necessary but not sufficient condition. FOSS is also a loosely associated movement of multiple organizations, foundations, communities and individuals who share basic philosophical perspectives and collaborate practically, but might diverge in detail questions. The historical precursor to this was the hobbyist and academic public domain software ecosystem of the 1960s to 1980s. FOSS is an inclusive umbrella term for free software and open-source software. FOSS is in contrast to proprietary software, which consists of software under restrictive copyright or licensing as well as software with undisclosed source code.\nThe rights granted to users of FOSS originate from the \"Four Essential Freedoms\" of the Free Software Definition and the criteria of The Open Source Definition. Other benefits of using FOSS include decreased software costs, increased security against malware, stability, privacy, opportunities for educational usage, and giving users more control over their own hardware. Free and open-source operating systems such as Linux distributions and descendants of BSD are widely used today, powering millions of servers, desktops, smartphones, and other devices. Free-software licenses and open-source licenses are used by many software packages today. The free software movement and the open-source software movement are online social movements behind widespread production, adoption and promotion of FOSS, with the former preferring to use the term free/libre and open-source software (FLOSS).\n\n",
            "categories": [
                "Category:All Wikipedia articles in need of updating",
                "Category:All Wikipedia articles needing context",
                "Category:All articles containing potentially dated statements",
                "Category:All articles needing additional references",
                "Category:All articles to be merged",
                "Category:All articles with unsourced statements",
                "Category:All pages needing cleanup",
                "Category:Articles containing potentially dated statements from August 2017",
                "Category:Articles containing potentially dated statements from June 2009",
                "Category:Articles contradicting other articles"
            ],
            "id": 267
        },
        {
            "title": "2018 Google data breach",
            "info_text": "The 2018 Google data breach was a major data privacy scandal in which the Google+ API exposed the private data of over five hundred thousand users.\nGoogle+ managers first noticed harvesting of personal data in March 2018, during a review following the Facebook\u2013Cambridge Analytica data scandal. The bug, despite having been fixed immediately, exposed the private data of approximately 500,000 Google+ users to the public. Google did not reveal the leak to the network's users. In November 2018, another data breach occurred following an update to the Google+ API. Although Google found no evidence of failure, approximately 52.5 million personal profiles were potentially exposed. In August 2019, Google declared a shutdown of Google+ due to low use and technological challenges.",
            "categories": [
                "Category:2018 in computing",
                "Category:Articles with short description",
                "Category:Data breaches",
                "Category:Google",
                "Category:Short description matches Wikidata"
            ],
            "id": 268
        },
        {
            "title": "Video Coding Experts Group",
            "info_text": "The Video Coding Experts Group or Visual Coding Experts Group (VCEG, also known as Question 6) is a working group of the ITU Telecommunication Standardization Sector (ITU-T) concerned with standards for compression coding of video, images, audio signals, biomedical waveforms, and other signals. It is responsible for standardization of the \"H.26x\" line of video coding standards, the \"T.8xx\" line of image coding standards, and related technologies.\nAdministratively, VCEG is the informal name of Question 6 (Visual, audio and signal coding) of Working Party 3 (Audiovisual technologies and intelligent immersive applications) of ITU-T Study Group 16 (Multimedia and related digital technologies). Its abbreviated title is ITU-T Q.6/SG16, or more simply, ITU-T Q6/16.\nThe goal of VCEG is to produce ITU-T Recommendations (international standards) for video coding and image coding methods appropriate for conversational (e.g. videoconferencing and video telephony) and non-conversational (e.g., streaming, broadcast, file download, media storage/playback, or digital cinema) audio/visual services. This mandate concerns the maintenance and extension of existing video coding recommendations, and laying the ground for new recommendations using advanced techniques to significantly improve the trade-offs between bit rate, quality, delay, and algorithm complexity. Video coding standards are desired with sufficient flexibility to accommodate a diverse number of transport types (Internet, LAN, Mobile, ISDN, GSTN, H.222.0, NGN, etc.).\nIn 2023, VCEG began working toward standardization of coding technology for biomedical signals and other waveform signals.\nQuestion 6 is part of Study Group 16, which is responsible for standards relating to multimedia service capabilities, and application capabilities (including those supported for next-generation networking). This encompasses multimedia terminals, systems (e.g., network signal processing equipment, multipoint conference units, gateways, gatekeepers, modems, and facsimile), protocols and signal processing (media coding).\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:International Telecommunication Union",
                "Category:Short description is different from Wikidata",
                "Category:Video compression",
                "Category:Videotelephony",
                "Category:Working groups"
            ],
            "id": 269
        },
        {
            "title": "RIPAC (microprocessor)",
            "info_text": "RIPAC was a VLSI single-chip microprocessor designed for automatic recognition of the connected speech, one of the first of this use.\nThe project of the microprocessor RIPAC started in 1984. RIPAC was aimed to provide efficient real-time speech recognition services to the italian telephone system provided by SIP. The microprocessor was presented in September 1986 at The Hague (Netherlands) at EUSPICO conference. It was composed of 70.000 transistors and structured as Harvard architecture.\nThe name RIPAC is the acronym for \"Riconoscimento del PArlato Connesso\", that means \"Recognition of the connected speech\" in Italian. The microprocessor was designed by the Italian companies CSELT and ELSAG and was produced by SGS: a combination of Hidden Markov Model and Dynamic Time Warping algorithms was used for processing speech signals. It was able to do real-time speech recognition of Italian and many languages with a good affordability. The chip, issued by U.S. Patent No. 4,907,278, worked at first run.\n\n",
            "categories": [
                "Category:Application-specific integrated circuits",
                "Category:Articles with short description",
                "Category:CS1 Italian-language sources (it)",
                "Category:Digital signal processors",
                "Category:Short description is different from Wikidata",
                "Category:Speech recognition",
                "Category:Speech recognition hardware"
            ],
            "id": 270
        },
        {
            "title": "Feature engineering",
            "info_text": "Feature engineering is a preprocessing step in supervised machine learning and statistical modeling which transforms raw data into a more effective set of inputs. Each input comprises several attributes, known as features. By providing models with relevant information, feature engineering significantly enhances their predictive accuracy and decision-making capability. \nBeyond machine learning, the principles of feature engineering are applied in various scientific fields, including physics. For example, physicists construct dimensionless numbers such as the Reynolds number in fluid dynamics, the Nusselt number in heat transfer, and the Archimedes number in sedimentation. They also develop first approximations of solutions, such as analytical solutions for the strength of materials in mechanics.",
            "categories": [
                "Category:All Wikipedia articles in need of updating",
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from January 2020",
                "Category:CS1 maint: location missing publisher",
                "Category:Data analysis",
                "Category:Machine learning",
                "Category:Short description is different from Wikidata",
                "Category:Wikipedia articles in need of updating from February 2024"
            ],
            "id": 271
        },
        {
            "title": "Europium",
            "info_text": "Europium is a chemical element; it has symbol Eu and atomic number 63. Europium is a silvery-white metal of the lanthanide series that reacts readily with air to form a dark oxide coating. It is the most chemically reactive, least dense, and softest of the lanthanide elements. It is soft enough to be cut with a knife. Europium was isolated in 1901 and named after the continent of Europe. Europium usually assumes the oxidation state +3, like other members of the lanthanide series, but compounds having oxidation state +2 are also common. All europium compounds with oxidation state +2 are slightly reducing. Europium has no significant biological role and is relatively non-toxic compared to other heavy metals. Most applications of europium exploit the phosphorescence of europium compounds. Europium is one of the rarest of the rare-earth elements on Earth.",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from August 2024",
                "Category:Chembox container only",
                "Category:Chembox having GHS data",
                "Category:Chemical elements",
                "Category:Chemical elements with body-centered cubic structure",
                "Category:Commons link from Wikidata",
                "Category:Europium",
                "Category:Good articles"
            ],
            "id": 272
        },
        {
            "title": "Health in Guinea-Bissau",
            "info_text": "The WHO's estimate of life expectancy for a female child born in Guinea-Bissau in 2008 was 49 years, and 47 years for a boy. in 2016 life expectancy had improved to 58 for men and 61 for women.\nThe prevalence of HIV-infection among the adult population is 1.8%. Only 20% of infected pregnant women receive anti retroviral coverage to prevent transmission to newborns.\nMalaria kills more residents; 9% of the population have reported infection, It causes three times as many deaths as AIDS. In 2008, fewer than half of children younger than five slept under antimalaria nets or had access to antimalarial drugs.\nDespite lowering rates in surrounding countries, cholera rates were reported in November 2012 to be on the rise, with 1,500 cases reported and nine deaths. A 2008 cholera epidemic in Guinea-Bissau affected 14,222 people and killed 225.\nThe 2010 maternal mortality rate per 100,000 live births for Guinea Bissau was 1000. This compares with 804.3 in 2008 and 966 in 1990. The under-5 mortality rate, per 1,000 live births, was 195 and the neonatal mortality as a percentage of under-5 mortality was 24. The number of midwives per 1,000 live births was 3; one out of eighteen pregnant women die as a result of pregnancy. According to a 2013 UNICEF report, 50% of women in Guinea Bissau had undergone female genital mutilation. In 2010, Guinea Bissau had the seventh-highest maternal mortality rate in the world.\nThe Human Rights Measurement Initiative finds that Guinea-Bissau is fulfilling 61.2% of what it should be fulfilling for the right to health based on its level of income. When looking at the right to health with respect to children, Guinea-Bissau achieves 85.8% of what is expected based on its current income. In regards to the right to health amongst the adult population, the country achieves only 70.8% of what is expected based on the nation's level of income. Guinea-Bissau falls into the \"very bad\" category when evaluating the right to reproductive health because the nation is fulfilling only 27.0% of what the nation is expected to achieve based on the resources (income) it has available.",
            "categories": [
                "Category:All articles containing potentially dated statements",
                "Category:All articles with unsourced statements",
                "Category:Articles containing potentially dated statements from 2008",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from February 2023",
                "Category:Health in Guinea-Bissau",
                "Category:Short description with empty Wikidata description",
                "Category:Webarchive template wayback links"
            ],
            "id": 273
        },
        {
            "title": "Guano",
            "info_text": "Guano (Spanish from Quechua: wanu) is the accumulated excrement of seabirds or bats. Guano is a highly effective fertilizer due to the high content of nitrogen, phosphate, and potassium, all key nutrients essential for plant growth. Guano was also, to a lesser extent, sought for the production of gunpowder and other explosive materials.\nThe 19th-century seabird guano trade played a pivotal role in the development of modern input-intensive farming. The demand for guano spurred the human colonization of remote bird islands in many parts of the world.\nUnsustainable seabird guano mining processes can result in permanent habitat destruction and the loss of millions of seabirds.\nBat guano is found in caves throughout the world. Many cave ecosystems are wholly dependent on bats to provide nutrients via their guano which supports bacteria, fungi, invertebrates, and vertebrates. The loss of bats from a cave can result in the extinction of species that rely on their guano. Unsustainable harvesting of bat guano may cause bats to abandon their roost.\nDemand for guano rapidly declined after 1910 with the development of the Haber\u2013Bosch process for extracting nitrogen from the atmosphere.",
            "categories": [
                "Category:Animal waste products",
                "Category:Articles containing Quechua-language text",
                "Category:Articles with short description",
                "Category:Bats and humans",
                "Category:Bird products",
                "Category:CS1 Spanish-language sources (es)",
                "Category:Caves",
                "Category:Commons category link from Wikidata",
                "Category:Good articles",
                "Category:Guano"
            ],
            "id": 274
        },
        {
            "title": "Neural plate",
            "info_text": "In embryology, the neural plate is a key developmental structure that serves as the basis for the nervous system. Cranial to the primitive node of the embryonic primitive streak, ectodermal tissue thickens and flattens to become the neural plate.  The region anterior to the primitive node can be generally referred to as the neural plate. Cells take on a columnar appearance in the process as they continue to lengthen and narrow.  The ends of the neural plate, known as the neural folds, push the ends of the plate up and together, folding into the neural tube, a structure critical to brain and spinal cord development.  This process as a whole is termed primary neurulation.\nSignaling proteins are also important in neural plate development, and aid in differentiating the tissue destined to become the neural plate. Examples of such proteins include bone morphogenetic proteins and cadherins. Expression of these proteins is essential to neural plate folding and subsequent neural tube\nformation.",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from October 2023",
                "Category:Embryology of nervous system",
                "Category:Short description matches Wikidata",
                "Category:Webarchive template wayback links",
                "Category:Wikipedia articles incorporating text from the 20th edition of Gray's Anatomy (1918)"
            ],
            "id": 275
        },
        {
            "title": "Solar power in Hawaii",
            "info_text": "The energy sector in Hawaii has rapidly adopted solar power due to the high costs of electricity, and good solar resources, and has one of the highest per capita rates of solar power in the United States. Hawaii's imported energy costs, mostly for imported petroleum and coal, are three to four times higher than the mainland, so Hawaii has motivation to become one of the highest users of solar energy. Hawaii was the first state in the United States to reach grid parity for photovoltaics. Its tropical location provides abundant ambient energy.\nMuch of Hawaii's solar capacity is distributed solar panels on individual homes and businesses. Hawaii's grid has had to deal with this unique situation by developing new technology for balancing the energy flows in areas with large amounts of solar power. In 2023, distributed solar produced 1,408 GWh while utility-scale solar produced 643 GWh. Hawaii had 1,808 MW of installed solar capacity in 2023. The largest utility-scale solar farm in Hawaii is the 60 MW Kuihelani Solar on Maui, which opened in 2024,  and includes 240 MWhr of battery storage As of 2024, solar power produced 19.5% of Hawaii's electricity.",
            "categories": [
                "Category:Articles with short description",
                "Category:Commons category link from Wikidata",
                "Category:Energy in Hawaii",
                "Category:Short description matches Wikidata",
                "Category:Solar power in Hawaii",
                "Category:Solar power in the United States by state or territory",
                "Category:Webarchive template wayback links"
            ],
            "id": 276
        },
        {
            "title": "Apache Beam",
            "info_text": "Apache Beam is an open source unified programming model to define and execute data processing pipelines, including ETL, batch and stream (continuous) processing. Beam Pipelines are defined using one of the provided SDKs and executed in one of the Beam\u2019s supported runners (distributed processing back-ends) including Apache Flink, Apache Samza, Apache Spark, and Google Cloud Dataflow.\n\n",
            "categories": [
                "Category:Apache Software Foundation",
                "Category:Apache Software Foundation projects",
                "Category:Articles with short description",
                "Category:Big data products",
                "Category:Cluster computing",
                "Category:Distributed stream processing",
                "Category:Free software programmed in Java (programming language)",
                "Category:Google software",
                "Category:Hadoop",
                "Category:Java platform"
            ],
            "id": 277
        },
        {
            "title": "Google Chat",
            "info_text": "Google Chat is a communication service developed by Google. Initially designed for teams and business environments, it has since been made available for general consumers. It provides direct messaging, group conversations, and spaces, which allow users to create and assign tasks and share files in a central place in addition to chatting. It can be accessed through its own website and app or through the Gmail website and app.\nIt was first launched as Hangouts Chat on March 9, 2017, as one of the two apps to constitute the replacement for Google Hangouts, the other being Google Meet. It was renamed to Google Chat on April 9, 2020. It was initially only available for the Google Workspace software suite, but in February 2021 Google began rolling out Google Chat in \"early access\" to regular consumer accounts until it became fully available in April 2021. Google deprecated the original Hangouts and replaced it with Chat on November 1, 2022.\n\n",
            "categories": [
                "Category:2017 software",
                "Category:All Wikipedia articles written in American English",
                "Category:Android (operating system) software",
                "Category:Articles with short description",
                "Category:CS1 maint: numeric names: authors list",
                "Category:Cross-platform software",
                "Category:Google instant messaging software",
                "Category:IOS software",
                "Category:Short description is different from Wikidata",
                "Category:Use American English from December 2022"
            ],
            "id": 278
        },
        {
            "title": "Sarah Gilbert",
            "info_text": "Dame Sarah Catherine Gilbert  FRS (born April 1962) is an English vaccinologist who is a Professor of Vaccinology at the University of Oxford and co-founder of Vaccitech. She specialises in the development of vaccines against influenza and emerging viral pathogens. She led the development and testing of the universal flu vaccine, which underwent clinical trials in 2011. \nIn January 2020, she read a report on ProMED-mail about four people in China suffering from a strange kind of pneumonia of unknown origin in Wuhan. Within two weeks, a vaccine had been designed at Oxford against the new pathogen, which later became known as COVID-19. On 30 December 2020, the Oxford\u2013AstraZeneca COVID-19 vaccine she co-developed with the Oxford Vaccine Group was approved for use in the UK. More than 3 billion doses of the vaccine were supplied to countries worldwide.\n\n",
            "categories": [
                "Category:1962 births",
                "Category:20th-century British scientists",
                "Category:20th-century English women scientists",
                "Category:21st-century British scientists",
                "Category:21st-century English women scientists",
                "Category:Academics of the University of Oxford",
                "Category:All articles containing potentially dated statements",
                "Category:Alumni of the University of East Anglia",
                "Category:Alumni of the University of Hull",
                "Category:Articles containing potentially dated statements from 2020"
            ],
            "id": 279
        },
        {
            "title": "Desia language",
            "info_text": "Desia, also Desiya, Kotia, Adivasi Odia, Desia Odia or Koraputia or Southwestern Odia, is an Indo-Aryan language variety (sociolinguistically considered as a dialect of Odia) spoken in Koraput, Nabarangpur, Rayagada, Malkangiri districts Odisha and in the hilly regions of Vishakhapatnam and Vizianagaram districts of Andhra Pradesh. The variant spoken in Koraput is called Koraputia.\nDesia serves as the lingua franca among the different ethnic groups in the area and is the major regional tribal-non-tribal dialect continuum of the undivided Koraput district of the Southwestern Odisha region.",
            "categories": [
                "Category:Articles containing Odia-language text",
                "Category:Articles with short description",
                "Category:Eastern Indo-Aryan languages",
                "Category:Language articles without reference field",
                "Category:Languages of Odisha",
                "Category:Odia language",
                "Category:Short description is different from Wikidata"
            ],
            "id": 280
        },
        {
            "title": "John B. Goodenough",
            "info_text": "John Bannister Goodenough ( GUUD-in-uf; July 25, 1922 \u2013 June 25, 2023) was an American materials scientist, a solid-state physicist, and a Nobel laureate in chemistry. From 1986 he was a professor of Materials Science, Electrical Engineering and Mechanical Engineering,  at the University of Texas at Austin. He is credited with \nidentifying the Goodenough\u2013Kanamori rules of the sign of the magnetic superexchange in materials, with developing materials for computer random-access memory and with inventing cathode materials for  lithium-ion batteries.\nGoodenough was born in Jena, Germany, to American parents. During and after graduating from Yale University, Goodenough served as a U.S. military meteorologist in World War II. He went on to obtain his Ph.D. in physics at the University of Chicago, became a researcher at MIT Lincoln Laboratory, and later the head of the Inorganic Chemistry Laboratory at the University of Oxford. \nGoodenough was awarded the National Medal of Science, the Copley Medal, the Fermi Award, the Draper Prize, and the Japan Prize. The John B. Goodenough Award in materials science is named for him. In 2019, he was awarded the Nobel Prize in Chemistry alongside M. Stanley Whittingham and Akira Yoshino; at 97 years old, he became the oldest Nobel laureate in history. From August 27, 2021, until his death, he was the oldest living Nobel Prize laureate.\n\n",
            "categories": [
                "Category:1922 births",
                "Category:2023 deaths",
                "Category:20th-century American physicists",
                "Category:21st-century American physicists",
                "Category:All articles with dead external links",
                "Category:All articles with unsourced statements",
                "Category:American Christians",
                "Category:American Nobel laureates",
                "Category:American materials scientists",
                "Category:American men centenarians"
            ],
            "id": 281
        },
        {
            "title": "ISO 11170",
            "info_text": "ISO 11170:2003 is an international standard which defines a sequence of tests for verifying filter elements. It can be used to check their hydraulic, mechanical and separation characteristics. ISO 11170 is not intended to qualify a filter for a particular duty or replicate conditions of service. This can only be done by a specific test protocol developed for the purpose, including actual conditions of use (for example the operating fluid). The procedure in ISO 11170 is applicable to individual fluids, or types of fluid having similar chemistry.",
            "categories": [
                "Category:All stub articles",
                "Category:Articles with short description",
                "Category:ISO standards",
                "Category:Short description matches Wikidata",
                "Category:Standards and measurement stubs",
                "Category:Use Oxford spelling from December 2011"
            ],
            "id": 282
        },
        {
            "title": "Laplace distribution",
            "info_text": "In probability theory and statistics, the Laplace distribution is a continuous probability distribution named after Pierre-Simon Laplace.  It is also sometimes called the double exponential distribution, because it can be thought of as two exponential distributions (with an additional location parameter) spliced together along the abscissa, although the term is also sometimes used to refer to the Gumbel distribution.  The difference between two independent identically distributed exponential random variables is governed by a Laplace distribution, as is a Brownian motion evaluated at an exponentially distributed random time.  Increments of Laplace motion or a variance gamma process evaluated over the time scale also have a Laplace distribution.",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from August 2022",
                "Category:Articles with unsourced statements from October 2023",
                "Category:Compound probability distributions",
                "Category:Continuous distributions",
                "Category:Exponential family distributions",
                "Category:Geometric stable distributions",
                "Category:Infinitely divisible probability distributions",
                "Category:Location-scale family probability distributions"
            ],
            "id": 283
        },
        {
            "title": "Chess",
            "info_text": "Chess is a board game for two players. It is sometimes called international chess or Western chess to distinguish it from related games such as xiangqi (Chinese chess) and shogi (Japanese chess).\nChess is an abstract strategy game which involves no hidden information and no elements of chance. It is played on a square game board called a chessboard containing 64 squares arranged in an 8\u00d78 grid. The players, referred to as \"White\" and \"Black\", each control sixteen pieces: one king, one queen, two rooks, two bishops, two knights, and eight pawns. White moves first, followed by Black; then moves alternate. The object of the game is to checkmate (threaten with inescapable capture) the enemy king. There are also several ways a game can end in a draw.\nThe recorded history of chess goes back at least to the emergence of a similar game, chaturanga, in seventh-century India. After its introduction in Persia, it spread to the Arab world and then to Europe. The modern rules of chess emerged in Europe at the end of the 15th century, with standardization and universal acceptance by the end of the 19th century. Today, chess is one of the world's most popular games, with millions of players worldwide. \nOrganized chess arose in the 19th century. Chess competition today is governed internationally by FIDE (F\u00e9d\u00e9ration Internationale des \u00c9checs; the International Chess Federation). The first universally recognized World Chess Champion, Wilhelm Steinitz, claimed his title in 1886; Gukesh Dommaraju is the current World Champion (2024).\nA huge body of chess theory has developed since the game's inception. Aspects of art are found in chess composition, and chess in its turn influenced Western culture and the arts, and has connections with other fields such as mathematics, computer science, and psychology. One of the goals of early computer scientists was to create a chess-playing machine. In 1997, Deep Blue became the first computer to beat a reigning World Champion in a match when it defeated Garry Kasparov. Today's chess engines are significantly stronger than the best human players and have deeply influenced the development of chess theory; however, chess is not a solved game.",
            "categories": [
                "Category:Abstract strategy games",
                "Category:All articles containing potentially dated statements",
                "Category:All articles with unsourced statements",
                "Category:Articles containing Arabic-language text",
                "Category:Articles containing Chinese-language text",
                "Category:Articles containing Persian-language text",
                "Category:Articles containing Sanskrit-language text",
                "Category:Articles containing Spanish-language text",
                "Category:Articles containing potentially dated statements from July 2023",
                "Category:Articles with hAudio microformats"
            ],
            "id": 284
        },
        {
            "title": "Kyodo News",
            "info_text": "Kyodo News (\u5171\u540c\u901a\u4fe1\u793e, Ky\u014dd\u014d Ts\u016bshinsha) is a nonprofit cooperative news agency based in Minato, Tokyo. It was established in November 1945 and it distributes news to almost all newspapers, and radio and television networks in Japan. The newspapers using its news have about 50 million subscribers. K. K. Kyodo News is Kyodo News' business arm, established in 1972. The subdivision Kyodo News International, founded in 1982, provides over 200 reports to international news media and is located in Rockefeller Center, New York City.\nTheir online news site is in Japanese, Chinese (Simplified and Traditional), Korean, and English.\nThe agency employs over 1,000 journalists and photographers, and maintains news exchange agreements with over 70 international media outlets.\nSatoshi Ishikawa is the news agency's president.\nKyodo News was formed by Furuno Inosuke, the president of the Domei News Agency, following the dissolution of Domei after World War II.",
            "categories": [
                "Category:1945 establishments in Japan",
                "Category:All articles containing potentially dated statements",
                "Category:Articles containing Japanese-language text",
                "Category:Articles containing potentially dated statements from April 2022",
                "Category:Articles needing translation from Japanese Wikipedia",
                "Category:Articles with short description",
                "Category:Cooperatives in Japan",
                "Category:Mass media companies based in Tokyo",
                "Category:Mass media companies established in 1945",
                "Category:Minato, Tokyo"
            ],
            "id": 285
        },
        {
            "title": "Axiom of infinity",
            "info_text": "In axiomatic set theory and the branches of mathematics and philosophy that use it, the axiom of infinity is one of the axioms of Zermelo\u2013Fraenkel set theory.  It guarantees the existence of at least one infinite set, namely a set containing the natural numbers. It was first published by Ernst Zermelo as part of his set theory in 1908.\n\n",
            "categories": [
                "Category:All articles needing additional references",
                "Category:Articles needing additional references from October 2019",
                "Category:Articles with short description",
                "Category:Articles with specifically marked weasel-worded phrases from March 2023",
                "Category:Axioms of set theory",
                "Category:Infinity",
                "Category:Short description is different from Wikidata"
            ],
            "id": 286
        },
        {
            "title": "2013 YouTube Music Awards",
            "info_text": "The 2013 YouTube Music Awards, abbreviated as the YTMA, was the inaugural music award show presented by YouTube. The inaugural award show was held on November 3, 2013, streamed live from Pier 36 in New York City, with additional shows in Seoul, Moscow, Rio de Janeiro, and London.\n\nUnlike other award shows, the winners were entirely voted on by fans. The show was directed by Spike Jonze.\"None of us have done anything live before or an awards show \u2013 in a way we're all like amateurs on YouTube ourselves, making our first video. So even if it's messy, it'll be live,\" Jonze admitted to Billboard.com.\n\n",
            "categories": [
                "Category:2013 YouTube events",
                "Category:2013 awards in the United States",
                "Category:2013 in American music",
                "Category:2013 in New York City",
                "Category:2013 music awards",
                "Category:Livestreams",
                "Category:November 2013 events in the United States"
            ],
            "id": 287
        },
        {
            "title": "Suno AI",
            "info_text": "Suno AI, or simply Suno, is a generative artificial intelligence music creation program designed to generate realistic songs that combine vocals and instrumentation, or are purely instrumental. Suno has been widely available since December 20, 2023, after the launch of a web application and a partnership with Microsoft, which included Suno as a plugin in Microsoft Copilot.\n\nThe program operates by producing songs based on text prompts provided by users. Suno does not disclose the dataset used to train its artificial intelligence but claims it has been safeguarded against plagiarism and copyright concerns.\n\n",
            "categories": [
                "Category:2023 software",
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from August 2024",
                "Category:Artificial intelligence art",
                "Category:IOS software",
                "Category:Music software",
                "Category:Short description is different from Wikidata",
                "Category:Web applications",
                "Category:Wikipedia semi-protected pages"
            ],
            "id": 288
        },
        {
            "title": "Rectum",
            "info_text": "The rectum (pl.: rectums or recta) is the final straight portion of the large intestine in humans and some other mammals, and the gut in others. Before expulsion through the anus or cloaca, the rectum stores the feces temporarily. The adult human rectum is about 12 centimetres (4.7 in) long, and begins at the rectosigmoid junction (the end of the sigmoid colon) at the level of the third sacral vertebra or the sacral promontory depending upon what definition is used. Its diameter is similar to that of the sigmoid colon at its commencement, but it is dilated near its termination, forming the rectal ampulla. It terminates at the level of the anorectal ring (the level of the puborectalis sling) or the dentate line, again depending upon which definition is used. In humans, the rectum is followed by the anal canal, which is about 4 centimetres (1.6 in) long, before the gastrointestinal tract terminates at the anal verge. The word rectum comes from the Latin r\u0113ctum intest\u012bnum, meaning straight intestine.",
            "categories": [
                "Category:All Wikipedia articles written in American English",
                "Category:All articles containing potentially dated statements",
                "Category:All articles needing additional references",
                "Category:All articles with unsourced statements",
                "Category:Anatomical terminology",
                "Category:Articles containing Latin-language text",
                "Category:Articles containing potentially dated statements from 2014",
                "Category:Articles needing additional references from January 2022",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from July 2020"
            ],
            "id": 289
        },
        {
            "title": "Rectangular Micro QR Code",
            "info_text": "Rectangular Micro QR Code (also known as rMQR Code) is two-dimensional (2D) matrix barcode  invented and standardized in 2022 by Denso Wave as ISO/IEC 23941. rMQR Code is designed as a rectangular variation of QR code and has the same parameters and applications as original QR code. But rMQR Code is more suitable for the rectangular areas and has difference between width and height up to 19 in R7x139 version. In this way it can be used in places where 1D barcodes are used. rMQR Code can replace Code 128 and Code 39 barcodes with more effective data encoding.\nrMQR Code consists of black squares and white square spaces arranged in a square grid on a white background. It has one finder pattern in left-top corner the same as in QR Code and small finder sub-pattern in right-bottom corner. Also, it has alignment and timing patterns to help with recognition. rMQR Code has Reed\u2013Solomon error correction with ability to restore data from corrupted barcodes. As other 2D matrix barcodes it can be read with camera-based readers.\nAs original QR code, rMQR Code can encode Unicode characters with Extended Channel Interpretation feature, bytes array and can natively encode Japanese characters in kanji encoding. In maximal R17x139 version rMQR Code can encode up to 361 numeric, 219 alphanumeric, 150 bytes and 92 kanji characters.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:Automatic identification and data capture",
                "Category:Barcodes",
                "Category:CS1 Japanese-language sources (ja)",
                "Category:Encodings",
                "Category:Japanese inventions",
                "Category:Short description is different from Wikidata"
            ],
            "id": 290
        },
        {
            "title": "Wayback Machine",
            "info_text": "The Wayback Machine is a digital archive of the World Wide Web founded by the Internet Archive, an American nonprofit organization based in San Francisco, California. Created in 1996 and launched to the public in 2001, it allows users to go \"back in time\" to see how websites looked in the past. Its founders, Brewster Kahle and Bruce Gilliat, developed the Wayback Machine to provide \"universal access to all knowledge\" by preserving archived copies of defunct web pages.\nLaunched on May 10, 1996, the Wayback Machine had saved more than 38.2 billion web pages by the end of 2009. As of November 2024, the Wayback Machine has archived more than 916 billion web pages and well over 100 petabytes of data.",
            "categories": [
                "Category:1996 establishments in California",
                "Category:501(c)(3) organizations",
                "Category:All articles containing potentially dated statements",
                "Category:All articles needing expert attention",
                "Category:All articles that are too technical",
                "Category:Articles containing potentially dated statements from 2009",
                "Category:Articles needing expert attention from October 2024",
                "Category:Articles with short description",
                "Category:CS1 German-language sources (de)",
                "Category:CS1 Russian-language sources (ru)"
            ],
            "id": 291
        },
        {
            "title": "Artificial neuron",
            "info_text": "An artificial neuron is a mathematical function conceived as a model of a biological neuron in a neural network. The artificial neuron is the elementary unit of an artificial neural network.\nThe design of the artificial neuron was inspired by biological neural circuitry. Its inputs are analogous to excitatory postsynaptic potentials and inhibitory postsynaptic potentials at neural dendrites, or activation. Its weights are analogous to synaptic weights, and its output is analogous to a neuron's action potential which is transmitted along its axon.\nUsually, each input is separately weighted, and the sum is often added to a term known as a bias (loosely corresponding to the threshold potential), before being passed through a nonlinear function known as an activation function. Depending on the task, these functions could have a sigmoid shape (e.g. for binary classification), but they may also take the form of other nonlinear functions, piecewise linear functions, or step functions. They are also often monotonically increasing, continuous, differentiable, and bounded. Non-monotonic, unbounded, and oscillating activation functions with multiple zeros that outperform sigmoidal and ReLU-like activation functions on many tasks have also been recently explored. The threshold function has inspired building logic gates referred to as threshold logic; applicable to building logic circuits resembling brain processing. For example, new devices such as memristors have been extensively used to develop such logic.\nThe artificial neuron activation function should not be confused with a linear system's transfer function.\nAn artificial neuron may be referred to as a semi-linear unit, Nv neuron, binary neuron, linear threshold function, or McCulloch\u2013Pitts (MCP) neuron, depending on the structure used.\nSimple artificial neurons, such as the McCulloch\u2013Pitts model, are sometimes described as \"caricature models\", since they are intended to reflect one or more neurophysiological observations, but without regard to realism. Artificial neurons can also refer to artificial cells in neuromorphic engineering that are similar to natural physical neurons.\n\n",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:American inventions",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from May 2018",
                "Category:Articles with unsourced statements from September 2024",
                "Category:Artificial neural networks",
                "Category:Bioinspiration",
                "Category:Short description matches Wikidata"
            ],
            "id": 292
        },
        {
            "title": "List of most-viewed Indian YouTube videos",
            "info_text": "This is a list of the most-watched Indian music videos on YouTube. Phonics Song with Two Words from children's channel ChuChu TV is the most viewed video in India and is the 7th most viewed YouTube video in the world. \"Why This Kolaveri Di\" become the first Indian music video to cross 100 million views. \"Swag Se Swagat\" became the first Indian music video to cross 500 million views on YouTube. \"Humpty the train on a fruits ride\" by \"Kiddiestv Hindi - Nursery Rhymes & Kids Songs\" became the first Hindi video on YouTube to cross 1 billion views on 26 December 2019 and is the most viewed Hindi video on YouTube. \"Chotu ke Golgappe\" uploaded by \"Khandeshi Movies\" is the first non-musical and non-children video to cross the 1 billion view mark in India and the world. It is also the first comedy skit video in India and the world to cross the 1 billion view mark. Hanuman chalisa becomes the first hymns(Bhajan) who got 4 billion+ views and views are growing drastically from day to day.\nAs of 24 May 2022, 38 videos have exceeded 1 billion views.",
            "categories": [
                "Category:All Wikipedia articles in need of updating",
                "Category:Articles with short description",
                "Category:Dynamic lists",
                "Category:India music-related lists",
                "Category:Lists of YouTube videos",
                "Category:Lists of most popular media",
                "Category:Short description is different from Wikidata",
                "Category:Use dmy dates from December 2020",
                "Category:Wikipedia articles in need of updating from February 2024"
            ],
            "id": 293
        },
        {
            "title": "Language politics",
            "info_text": "Language politics is the way language and linguistic differences between peoples are dealt with in the political arena. This could manifest as government recognition, as well as how language is treated in official capacities.\nThe topic covers many related issues. As such, this page serves as a central resource for multiple articles relating to the topic of language and politics. Below are some categories dealing with the overlap between language and politics, along with examples and links to other relevant pages.",
            "categories": [
                "Category:All articles needing additional references",
                "Category:Articles needing additional references from June 2008",
                "Category:Concepts in language policy",
                "Category:Linguistic controversies",
                "Category:Linguistic rights",
                "Category:Politics by region"
            ],
            "id": 294
        },
        {
            "title": "Huawei Y6",
            "info_text": "The Huawei Y6 is an Android smartphone developed and manufactured by Huawei. In China, the smartphone was introduced as the Honor 4A. Both were announced and released in July 2015.",
            "categories": [
                "Category:Android (operating system) devices",
                "Category:CS1 Russian-language sources (ru)",
                "Category:Discontinued smartphones",
                "Category:Huawei smartphones",
                "Category:Mobile phones introduced in 2015",
                "Category:Mobile phones with user-replaceable battery"
            ],
            "id": 295
        },
        {
            "title": "Root Sports Utah",
            "info_text": "Root Sports Utah was an American regional sports network that was owned by the AT&T Sports Networks subsidiary of AT&T Inc., as part of the AT&T SportsNet brand of networks and is an affiliate of Fox Sports Networks. Headquartered in Salt Lake City, Utah, the channel broadcasts regional coverage of sports events throughout Utah, namely the NBA's Utah Jazz and college teams including the Utah State Aggies, Utah Utes, BYU Cougars, and several other schools. Root Sports Utah was available on cable providers throughout the state of Utah, and nationwide on satellite via DirecTV and Dish Network.",
            "categories": [
                "Category:1989 establishments in Utah",
                "Category:2017 disestablishments in Utah",
                "Category:AT&T SportsNet",
                "Category:Articles using infobox television channel",
                "Category:Articles with short description",
                "Category:Fox Sports Networks",
                "Category:Prime Sports",
                "Category:Short description is different from Wikidata",
                "Category:Television channels and stations disestablished in 2017",
                "Category:Television channels and stations established in 1989"
            ],
            "id": 296
        },
        {
            "title": "Descriptive statistics",
            "info_text": "A descriptive statistic (in the count noun sense) is a summary statistic that quantitatively describes or summarizes features from a collection of information, while descriptive statistics (in the mass noun sense) is the process of using and analysing those statistics. Descriptive statistics is distinguished from inferential statistics (or inductive statistics) by its aim to summarize a sample, rather than use the data to learn about the population that the sample of data is thought to represent. This generally means that descriptive statistics, unlike inferential statistics, is not developed on the basis of probability theory, and are frequently nonparametric statistics. Even when a data analysis draws its main conclusions using inferential statistics, descriptive statistics are generally also presented. For example, in papers reporting on human subjects, typically a table is included giving the overall sample size, sample sizes in important subgroups (e.g., for each treatment or exposure group), and demographic or clinical characteristics such as the average age, the proportion of subjects of each sex, the proportion of subjects with related co-morbidities, etc.\nSome measures that are commonly used to describe a data set are measures of central tendency and measures of variability or dispersion. Measures of central tendency include the mean, median and mode, while measures of variability include the standard deviation (or variance), the minimum and maximum values of the variables, kurtosis and skewness.",
            "categories": [
                "Category:Articles with short description",
                "Category:Descriptive statistics",
                "Category:Short description is different from Wikidata"
            ],
            "id": 297
        },
        {
            "title": "FinFisher",
            "info_text": "FinFisher, also known as FinSpy, is surveillance software marketed by Lench IT Solutions plc, which markets the spyware through law enforcement channels.\nFinFisher can be covertly installed on targets' computers by exploiting security lapses in the update procedures of non-suspect software. The company has been criticized by human rights organizations for selling these capabilities to repressive or non-democratic states known for monitoring and imprisoning political dissidents. Egyptian dissidents who ransacked the offices of Egypt's secret police following the overthrow of Egyptian President Hosni Mubarak reported that they had discovered a contract with Gamma International for \u20ac287,000 for a license to run the FinFisher software. In 2014, an American citizen sued the Ethiopian government for surreptitiously installing FinSpy onto his computer in America and using it to wiretap his private Skype calls and monitor his entire family's every use of the computer for a period of months.\nLench IT Solutions plc has a UK-based branch, Gamma International Ltd in Andover, England, and a Germany-based branch, Gamma International GmbH in Munich. Gamma International is a subsidiary of the Gamma Group, specializing in surveillance and monitoring, including equipment, software, and training services. It was reportedly owned by William Louthean Nelson through a shell corporation in the British Virgin Islands. The shell corporation was signed by a nominee director in order to withhold the identity of the ultimate beneficiary, which was Nelson, a common system for companies that are established offshore.\nOn August 6, 2014, FinFisher source code, pricing, support history, and other related data were retrieved from the Gamma International internal network and made available on the Internet.\nThe FinFisher GmbH opened insolvency proceedings at the Munich Local Court on 02.12.2021, however this is only a restructuring and the company is to continue as Vilicius Holding GmbH.\n\n",
            "categories": [
                "Category:2012 in computing",
                "Category:All articles with dead external links",
                "Category:Articles with dead external links from April 2019",
                "Category:Articles with short description",
                "Category:CS1 Arabic-language sources (ar)",
                "Category:CS1 German-language sources (de)",
                "Category:Commons category link from Wikidata",
                "Category:Computer access control",
                "Category:Computer security software",
                "Category:Computer surveillance"
            ],
            "id": 298
        },
        {
            "title": "Land-use planning",
            "info_text": "Land use planning or Land-use regulation is the process of regulating the use of land by a central authority. Usually, this is done to promote more desirable social and environmental outcomes as well as a more efficient use of resources. More specifically, the goals of modern land use planning often include environmental conservation, restraint of urban sprawl, minimization of transport costs, prevention of land use conflicts, and a reduction in exposure to pollutants. In the pursuit of these goals, planners assume that regulating the use of land will change the patterns of human behavior, and that these changes are beneficial. The first assumption, that regulating land use changes the patterns of human behavior is widely accepted. However, the second assumption \u2013 that these changes are beneficial \u2013 is contested, and depends on the location and regulations being discussed.\nIn urban planning, land use planning seeks to order and regulate land use in an efficient and ethical way, thus preventing land use conflicts. Governments use land use planning to manage the development of land within their jurisdictions. In doing so, the governmental unit can plan for the needs of the community while safeguarding natural resources. To this end, it is the systematic assessment of land and water potential, alternatives for land use, and economic and social conditions in order to select and adopt the best land use options. Often one element of a comprehensive plan, a land use plan provides a vision for the future possibilities of development in neighborhoods, districts, cities, or any defined planning area.\nIn the United States, the terms land use planning, regional planning, urban planning, and urban design are often used interchangeably, and will depend on the state, county, and/or project in question. Despite confusing nomenclature, the essential function of land use planning remains the same whatever term is applied. The Canadian Institute of Planners offers a definition that land use planning means the scientific, aesthetic, and orderly disposition of land, resources, facilities and services with a view to securing the physical, economic and social efficiency, health and well-being of urban and rural communities. The American Planning Association states that the goal of land use planning is to further the welfare of people and their communities by creating convenient, equitable, healthful, efficient, and attractive environments for present and future generations. Land-use planning in England and Wales is founded on the Town and Country Planning Act 1947, with comparable legislation applicable in Scotland and Northern Ireland.\n\n",
            "categories": [
                "Category:Articles with limited geographic scope from November 2011",
                "Category:Articles with short description",
                "Category:Land use",
                "Category:Short description matches Wikidata",
                "Category:United States-centric",
                "Category:Wikipedia articles needing page number citations from January 2025"
            ],
            "id": 299
        },
        {
            "title": "Fitbit",
            "info_text": "Fitbit is a line of wireless-enabled wearable technology, physical fitness monitors and activity trackers such as smartwatches, pedometers and monitors for heart rate, quality of sleep, and stairs climbed as well as related software. It operated as an American consumer electronics and fitness company from 2007 to 2021.\nThe Fitbit brand name was originally owned by Fitbit, Inc., founded by James Park and Eric Freidman. The company was acquired by Google in January 2021 and was absorbed into the company's hardware division.\nIn 2019, Fitbit was the fifth largest wearable technology company in shipments. The company has sold more than 120 million devices and has 29 million users in over 100 countries.\n\n",
            "categories": [
                "Category:2007 establishments in Delaware",
                "Category:2015 initial public offerings",
                "Category:2021 mergers and acquisitions",
                "Category:All Wikipedia articles written in American English",
                "Category:American companies established in 2007",
                "Category:Android (operating system) software",
                "Category:Articles with short description",
                "Category:Commons category link is on Wikidata",
                "Category:Companies formerly listed on the New York Stock Exchange",
                "Category:Electronics companies established in 2007"
            ],
            "id": 300
        },
        {
            "title": "Emery N. Brown",
            "info_text": "Emery Neal Brown (born 1957) is an American statistician, computational neuroscientist, and anesthesiologist. He is the Warren M. Zapol Professor of Anesthesia at Harvard Medical School and at Massachusetts General Hospital (MGH), and a practicing anesthesiologist at MGH. At MIT he is the Edward Hood Taplin Professor of Medical Engineering and professor of computational neuroscience, the associate director of the Institute for Medical Engineering and Science, and the Director of the Harvard\u2013MIT Program in Health Sciences and Technology.\nIn 2015, Brown was elected a member of the National Academy of Engineering for the development of neural signal processing algorithms for understanding memory encoding and modeling of brain states of anesthesia. Brown is one of only 19 individuals who has been elected to all three branches of the National Academies of Sciences, Engineering, and Medicine, as well as the first African American and the first anesthesiologist to be elected to all three National Academies.\nIn 2020, he was awarded the Swartz Prize for Theoretical and Computational Neuroscience. In 2022 he was awarded the Gruber Neuroscience Prize, alongside theoretical neuroscientists Larry Abbott, Terrence Sejnowski and Haim Sompolinsky.\n\n",
            "categories": [
                "Category:1957 births",
                "Category:21st-century African-American academics",
                "Category:21st-century African-American physicians",
                "Category:21st-century African-American scientists",
                "Category:21st-century American academics",
                "Category:21st-century American physicians",
                "Category:American anesthesiologists",
                "Category:American neuroscientists",
                "Category:American statisticians",
                "Category:Articles with hCards"
            ],
            "id": 301
        },
        {
            "title": "Carl Shipp Marvel",
            "info_text": "Carl Shipp \"Speed\" Marvel (September 11, 1894 \u2013 January 4, 1988) was an American chemist who specialized in polymer chemistry. He made important contributions to U.S. synthetic rubber program during World War II, and later worked at developing polybenzimidazoles, temperature-resistant polymers that are used in the aerospace industry, in fire-fighting equipment, and as a replacement for asbestos. He has been described as \"one of the world's outstanding organic chemists\" and received numerous awards, including the 1956 Priestley Medal and the 1986 National Medal of Science, presented by President Ronald Reagan.",
            "categories": [
                "Category:1894 births",
                "Category:1988 deaths",
                "Category:20th-century American chemists",
                "Category:American organic chemists",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:CS1 errors: periodical ignored",
                "Category:CS1 maint: multiple names: authors list",
                "Category:National Medal of Science laureates",
                "Category:Polymer scientists and engineers"
            ],
            "id": 302
        },
        {
            "title": "VOB",
            "info_text": "VOB (for video object) is the container format in DVD-Video media. VOB can contain digital video, digital audio, subtitles, DVD menus and navigation contents multiplexed together into a stream form. Files in VOB format may be encrypted.\n\n",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from April 2012",
                "Category:Articles with unsourced statements from December 2008",
                "Category:Articles with unsourced statements from July 2017",
                "Category:DVD",
                "Category:Digital container formats",
                "Category:Filename extensions",
                "Category:Short description matches Wikidata"
            ],
            "id": 303
        },
        {
            "title": "A. E. Dyson",
            "info_text": "Anthony Edward Dyson, aka Tony Dyson (28 November 1928 \u2013 30 July 2002) was a British literary critic, university lecturer, educational activist and gay rights campaigner.\n\n",
            "categories": [
                "Category:1928 births",
                "Category:2002 deaths",
                "Category:20th-century British LGBTQ people",
                "Category:Academics of the University of East Anglia",
                "Category:All articles with unsourced statements",
                "Category:Alumni of Pembroke College, Cambridge",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from May 2022",
                "Category:British LGBTQ rights activists"
            ],
            "id": 304
        },
        {
            "title": "2016 Indian bank data breach",
            "info_text": "The 2016 Indian bank data breach was reported in October 2016. It was estimated 3.2 million debit cards were compromised. Major Indian banks, among them SBI, HDFC Bank, ICICI, YES Bank and Axis Bank, were among the worst hit. The breach went undetected for months and was first detected after several banks reported fraudulent use of their customers\u2019 cards in China and the United States, while these customers were in India. \nThis resulted in one of the India's biggest card replacement drives in banking history. The biggest Indian bank, the State Bank of India, announced the blocking and replacement of almost 600,000 debit cards.\nAn audit performed by SISA Information Security reports that the breach was due to malware injected into the payment gateway network of Hitachi Payment Systems.\n\n",
            "categories": [
                "Category:2016 in Indian economy",
                "Category:All stub articles",
                "Category:Articles with short description",
                "Category:Bank stubs",
                "Category:Banking in India",
                "Category:Crime stubs",
                "Category:Cyberattacks on banking industry",
                "Category:Cybercrime in India",
                "Category:Data breaches",
                "Category:Internet stubs"
            ],
            "id": 305
        },
        {
            "title": "Odia Braille",
            "info_text": "Odia Braille is one of the Bharati braille alphabets. Apart from using Hindi \u00e6 for Odia \u1e8f, it conforms to the letter values of the other Bharati scripts.",
            "categories": [
                "Category:Articles with short description",
                "Category:Bharati braille alphabets",
                "Category:Odia language",
                "Category:Short description matches Wikidata"
            ],
            "id": 306
        },
        {
            "title": "Carboboration",
            "info_text": "In organic chemistry, carboboration describes an addition of both a carbon and a boron moiety to certain carbon-containing double and triple bonds, such as alkenes, alkynes, and allenes.\nIn the synthesis of organic compounds, this chemical reaction is used to install a new carbon-carbon bond and carbon-boron bond. The product of carboboration reactions are organoborane compounds which prove to be useful in organic synthesis, containing both a new carbon group and a boron handle for further functionalization. This carbon-boron bond allows for organoboron chemistry, which facilitates a wide variety of chemical transformations such as oxidation and the Suzuki Reaction. The carbon-boron bond can be transformed into a variety of functional groups and moieties, making it highly useful in pharmaceutical chemistry and organic synthesis.\nCarboboration was developed soon after the advent and widespread use of hydroboration. Carboboration is often facilitated via catalysis, often employing transition metals, and usually involves an activated alkene or alkyne. The two most well-documented categories of carboboration are 1,1 and 1,2 carboboration, which differ in the regioselectivity of the incoming carbon group.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:CS1 German-language sources (de)",
                "Category:Carbon",
                "Category:Organic chemistry",
                "Category:Short description is different from Wikidata"
            ],
            "id": 307
        },
        {
            "title": "Complex programmable logic device",
            "info_text": "A complex programmable logic device (CPLD) is a programmable logic device with complexity between that of PALs and FPGAs, and architectural features of both. The main building block of the CPLD is a macrocell, which contains logic implementing disjunctive normal form expressions and more specialized logic operations.\n\n",
            "categories": [
                "Category:All articles needing additional references",
                "Category:Articles needing additional references from November 2013",
                "Category:Articles with short description",
                "Category:Commons category link is on Wikidata",
                "Category:Gate arrays",
                "Category:Hardware acceleration",
                "Category:Short description is different from Wikidata"
            ],
            "id": 308
        },
        {
            "title": "Google Data Liberation Front",
            "info_text": "The Google Data Liberation Front is an engineering team at Google whose \"goal is to make it easier for users to move their data in and out of Google products.\" The team, which consults with other engineering teams within Google on how to \"liberate\" Google products, currently supports 57 products. The purpose of the Data Liberation Front is to ensure that data can be migrated from Google once an individual or company stops using their services or the service is discontinued by Google.\n\n",
            "categories": [
                "Category:All Wikipedia articles in need of updating",
                "Category:All stub articles",
                "Category:Articles with short description",
                "Category:CS1 maint: url-status",
                "Category:Google services",
                "Category:Google stubs",
                "Category:Short description matches Wikidata",
                "Category:Wikipedia articles in need of updating from July 2016",
                "Category:World Wide Web stubs"
            ],
            "id": 309
        },
        {
            "title": "Empirical risk minimization",
            "info_text": "In statistical learning theory, the principle of empirical risk minimization defines a family of learning algorithms based on evaluating performance over a known and fixed dataset. The core idea is based on an application of the law of large numbers; more specifically, we cannot know exactly how well a predictive algorithm will work in practice (i.e. the \"true risk\") because we do not know the true distribution of the data, but we can instead estimate and optimize the performance of the algorithm on a known set of training data. The performance over the known set of training data is referred to as the \"empirical risk\".\n\n",
            "categories": [
                "Category:All articles to be expanded",
                "Category:All articles with unsourced statements",
                "Category:Articles to be expanded from February 2023",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from December 2023",
                "Category:Machine learning",
                "Category:Short description is different from Wikidata"
            ],
            "id": 310
        },
        {
            "title": "Discrete Fourier transform",
            "info_text": "In mathematics, the discrete Fourier transform (DFT) converts a finite sequence of equally-spaced samples of a function into a same-length sequence of equally-spaced samples of the discrete-time Fourier transform (DTFT), which is a complex-valued function of frequency. The interval at which the DTFT is sampled is the reciprocal of the duration of the input sequence.  An inverse DFT (IDFT) is a Fourier series, using the DTFT samples as coefficients of complex sinusoids at the corresponding DTFT frequencies. It has the same sample-values as the original input sequence.  The DFT is therefore said to be a frequency domain representation of the original input sequence.  If the original sequence spans all the non-zero values of a function, its DTFT is continuous (and periodic), and the DFT provides discrete samples of one cycle. If the original sequence is one cycle of a periodic function, the DFT provides all the non-zero values of one DTFT cycle.\nThe DFT is used in the Fourier analysis of many practical applications. In digital signal processing, the function is any quantity or signal that varies over time, such as the pressure of a sound wave, a radio signal, or daily temperature readings, sampled over a finite time interval (often defined by a window function). In image processing, the samples can be the values of pixels along a row or column of a raster image. The DFT is also used to efficiently solve partial differential equations, and to perform other operations such as convolutions or multiplying large integers.\nSince it deals with a finite amount of data, it can be implemented in computers by numerical algorithms or even dedicated hardware. These implementations usually employ efficient fast Fourier transform (FFT) algorithms; so much so that the terms \"FFT\" and \"DFT\" are often used interchangeably. Prior to its current usage, the \"FFT\" initialism may have also been used for the ambiguous term \"finite Fourier transform\".\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:CS1 maint: location",
                "Category:CS1 maint: multiple names: authors list",
                "Category:Digital signal processing",
                "Category:Discrete transforms",
                "Category:Fourier analysis",
                "Category:Numerical analysis",
                "Category:Short description is different from Wikidata",
                "Category:Unitary operators",
                "Category:Webarchive template wayback links"
            ],
            "id": 311
        },
        {
            "title": "COVID-19 pandemic",
            "info_text": "The COVID-19 pandemic (also known as the coronavirus pandemic and COVID pandemic), caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), began with an outbreak of COVID-19 in Wuhan, China, in December 2019. Soon after, it spread to other areas of Asia, and then worldwide in early 2020. The World Health Organization (WHO) declared the outbreak a public health emergency of international concern (PHEIC) on 30 January 2020, and assessed the outbreak as having become a pandemic on 11 March.\nCOVID-19 symptoms range from asymptomatic to deadly, but most commonly include fever, sore throat, nocturnal cough, and fatigue. Transmission of the virus is often through airborne particles. Mutations have produced many strains (variants) with varying degrees of infectivity and virulence. COVID-19 vaccines were developed rapidly and deployed to the general public beginning in December 2020, made available through government and international programmes such as COVAX, aiming to provide vaccine equity. Treatments include novel antiviral drugs and symptom control. Common mitigation measures during the public health emergency included travel restrictions, lockdowns, business restrictions and closures, workplace hazard controls, mask mandates, quarantines, testing systems, and contact tracing of the infected.\nThe pandemic caused severe social and economic disruption around the world, including the largest global recession since the Great Depression. Widespread supply shortages, including food shortages, were caused by supply chain disruptions and panic buying. Reduced human activity led to an unprecedented temporary decrease in pollution. Educational institutions and public areas were partially or fully closed in many jurisdictions, and many events were cancelled or postponed during 2020 and 2021. Telework became much more common for white-collar workers as the pandemic evolved. Misinformation circulated through social media and mass media, and political tensions intensified. The pandemic raised issues of racial and geographic discrimination, health equity, and the balance between public health imperatives and individual rights.\nThe WHO ended the PHEIC for COVID-19 on 5 May 2023. The disease has continued to circulate. However, as of 2024, experts were uncertain as to whether it was still a pandemic. Pandemics and their ends are not well-defined, and whether or not one has ended differs according to the definition used. As of 13 January 2025, COVID-19 has caused 7,079,912 confirmed deaths, and 18.2 to 33.5 million estimated deaths. The COVID-19 pandemic ranks as the fifth-deadliest pandemic or epidemic in history.",
            "categories": [
                "Category:2019 disasters in China",
                "Category:2019 disease outbreaks",
                "Category:2019 in international relations",
                "Category:2020 disease outbreaks",
                "Category:2020 in international relations",
                "Category:2020s in economic history",
                "Category:2021 disease outbreaks",
                "Category:2021 in international relations",
                "Category:2022 disease outbreaks",
                "Category:2022 in international relations"
            ],
            "id": 312
        },
        {
            "title": "Neutron cross section",
            "info_text": "In nuclear physics, the concept of a neutron cross section is used to express the likelihood of interaction between an incident neutron and a target nucleus. The neutron cross section \u03c3 can be defined as the area in cm2 for which the number of neutron-nuclei reactions taking place is equal to the product of the number of incident neutrons that would pass through the area and the number of target nuclei. In conjunction with the neutron flux, it enables the calculation of the reaction rate, for example to derive the thermal power of a nuclear power plant. The standard unit for measuring the cross section is the barn, which is equal to 10\u221228 m2 or 10\u221224 cm2. The larger the neutron cross section, the more likely a neutron will react with the nucleus.\nAn isotope (or nuclide) can be classified according to its neutron cross section and how it reacts to an incident neutron. Nuclides that tend to absorb a neutron and either decay or keep the neutron in its nucleus are neutron absorbers and will have a capture cross section for that reaction. Isotopes that undergo fission are fissionable fuels and have a corresponding fission cross section. The remaining isotopes will simply scatter the neutron, and have a scatter cross section. Some isotopes, like uranium-238, have nonzero cross sections of all three.\nIsotopes which have a large scatter cross section and a low mass are good neutron moderators (see chart below). Nuclides which have a large absorption cross section are neutron poisons if they are neither fissile nor undergo decay. A poison that is purposely inserted into a nuclear reactor for controlling its reactivity in the long term and improve its shutdown margin is called a burnable poison.",
            "categories": [
                "Category:All articles needing additional references",
                "Category:Articles needing additional references from September 2011",
                "Category:Articles with short description",
                "Category:CS1 maint: archived copy as title",
                "Category:Neutron",
                "Category:Nuclear physics",
                "Category:Short description is different from Wikidata",
                "Category:Webarchive template wayback links",
                "Category:Wikipedia articles needing page number citations from February 2022"
            ],
            "id": 313
        },
        {
            "title": "Ancient Greek",
            "info_text": "Ancient Greek (\u1f19\u03bb\u03bb\u03b7\u03bd\u1fd0\u03ba\u03ae, Hell\u0113nik\u1e17; [hell\u025b\u02d0nik\u025b\u0301\u02d0]) includes the forms of the Greek language used in ancient Greece and the ancient world from around 1500 BC to 300 BC. It is often roughly divided into the following periods: Mycenaean Greek (c.\u20091400\u20131200 BC), Dark Ages (c.\u20091200\u2013800 BC), the Archaic or Homeric period (c.\u2009800\u2013500 BC), and the Classical period (c.\u2009500\u2013300 BC).\nAncient Greek was the language of Homer and of fifth-century Athenian historians, playwrights, and philosophers. It has contributed many words to English vocabulary and has been a standard subject of study in educational institutions of the Western world since the Renaissance. This article primarily contains information about the Epic and Classical periods of the language, which are the best-attested periods and considered most typical of Ancient Greek.\nFrom the Hellenistic period (c.\u2009300 BC), Ancient Greek was followed by Koine Greek, which is regarded as a separate historical stage, though its earliest form closely resembles Attic Greek, and its latest form approaches Medieval Greek, and Koine may be classified as Ancient Greek in a wider sense. There were several regional dialects of Ancient Greek; Attic Greek developed into Koine.",
            "categories": [
                "Category:9th-century BC establishments in Greece",
                "Category:All Wikipedia articles in need of updating",
                "Category:All articles needing additional references",
                "Category:Ancient Greece",
                "Category:Ancient Greek",
                "Category:Articles containing Ancient Greek (to 1453)-language text",
                "Category:Articles containing Croatian-language text",
                "Category:Articles containing Dutch-language text",
                "Category:Articles containing Greek-language text",
                "Category:Articles containing Latin-language text"
            ],
            "id": 314
        },
        {
            "title": "SVOPC",
            "info_text": "SVOPC (Sinusoidal Voice Over Packet Coder) is a compression method for audio which is used by VOIP applications. It is a lossy speech compression codec designed specifically towards communication channels suffering from packet loss. It uses more bandwidth than best bandwidth-optimised codecs, but it is packet loss resistant instead.\nSkype Limited developed a codec called 'SVOPC' for Skype. It was first used in Skype 3.2 beta 53, released on March 28, 2007. Starting with Skype 4.0, SVOPC is replaced by SILK.\n\n",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All stub articles",
                "Category:Articles needing additional references from December 2007",
                "Category:Articles with short description",
                "Category:Audio codecs",
                "Category:Multimedia software stubs",
                "Category:Short description matches Wikidata",
                "Category:Skype",
                "Category:Speech codecs"
            ],
            "id": 315
        },
        {
            "title": "Charles K. Kao",
            "info_text": "Sir Charles Kao Kuen (simplified Chinese: \u9ad8\u951f; traditional Chinese: \u9ad8\u9315; pinyin: G\u0101o K\u016bn) (November 4, 1933 \u2013 September 23, 2018) was a Chinese physicist and Nobel laureate who contributed to the development and use of fibre optics in telecommunications. In the 1960s, Kao created various methods to combine glass fibres with lasers in order to transmit digital data, which laid the groundwork for the evolution of the Internet and the eventual creation of the World Wide Web.\nKao was born in Shanghai. His family settled in Hong Kong in 1949. He graduated from St. Joseph's College in Hong Kong in 1952 and went to London to study electrical engineering. In the 1960s, Kao worked at Standard Telecommunication Laboratories, the research center of Standard Telephones and Cables (STC) in Harlow, and it was here in 1966 that he laid the groundwork for fibre optics in communication. Known as the \"godfather of broadband\", the \"father of fibre optics\", and the \"father of fibre optic communications\", he continued his work in Hong Kong at the Chinese University of Hong Kong, and in the United States at ITT (the parent corporation for STC) and Yale University.  Kao was awarded the Nobel Prize in Physics for \"groundbreaking achievements concerning the transmission of light in fibres for optical communication\". In 2010, he was knighted by Queen Elizabeth II for \"services to fibre optic communications\".\nKao was a permanent resident of Hong Kong, and a citizen of the United Kingdom and the United States.",
            "categories": [
                "Category:1933 births",
                "Category:2018 deaths",
                "Category:Academics of Imperial College London",
                "Category:Academics of Queen Mary University of London",
                "Category:All Wikipedia articles written in Hong Kong English",
                "Category:All articles with dead external links",
                "Category:All articles with unsourced statements",
                "Category:Alumni of University College London",
                "Category:Alumni of University of London Worldwide",
                "Category:Alumni of the University of Greenwich"
            ],
            "id": 316
        },
        {
            "title": "Kauravi dialect",
            "info_text": "Kauravi (Hindi: \u0915\u094c\u0930\u0935\u0940, Urdu: \u06a9\u064e\u0648\u0631\u0648\u06cc), also known as Kha\u1e5b\u012bbol\u012b, is a dialect of Hindustani descended from Shauraseni Prakrit that is mainly spoken in northwestern Uttar Pradesh, outside of Delhi.\nModern Hindi and Urdu are two standard registers of Hindustani, descending from Old Hindi, originally called Hindavi and Delhavi which gained prestige when it was accepted along with Persian as a language of the courts. Before that, it was only a language the Persianate states (like Delhi Sultanate) spoke to their subjects in, and later as a sociolect of the same ruling classes.\nModern Kauravi contains some features, such as gemination and pitch accent, which give it a distinctive sound and differentiates it from Braj and Awadhi. Old Hindi developed into Hindustani and then into today's Hindi and Urdu registers.\n\n",
            "categories": [
                "Category:All articles with dead external links",
                "Category:Articles containing Hindi-language text",
                "Category:Articles containing Urdu-language text",
                "Category:Articles with dead external links from April 2023",
                "Category:Articles with permanently dead external links",
                "Category:Articles with short description",
                "Category:Central Indo-Aryan languages",
                "Category:Dialects of languages with ISO 639-3 code",
                "Category:EngvarB from October 2019",
                "Category:Indian words and phrases"
            ],
            "id": 317
        },
        {
            "title": "Observable",
            "info_text": "In physics, an observable is a physical property or physical quantity that can be measured. In classical mechanics, an observable is a real-valued \"function\" on the set of all possible system states, e.g., position and momentum. In quantum mechanics, an observable is an operator, or gauge, where the property of the quantum state  can be determined by some sequence of operations. For example, these operations might involve submitting the system to various electromagnetic fields and eventually reading a value.\nPhysically meaningful observables must also satisfy transformation laws that relate observations performed by different observers in different frames of reference. These transformation laws are automorphisms of the state space, that is bijective transformations that preserve certain mathematical properties of the space in question.",
            "categories": [
                "Category:All articles lacking in-text citations",
                "Category:Articles lacking in-text citations from May 2009",
                "Category:Articles with short description",
                "Category:Quantum mechanics",
                "Category:Short description is different from Wikidata",
                "Category:Webarchive template wayback links"
            ],
            "id": 318
        },
        {
            "title": "Allison McGeer",
            "info_text": "Allison Joan McGeer (born 1953) is a Canadian infectious disease specialist in the Sinai Health System, and a professor in the Department of Laboratory Medicine and Pathobiology at the University of Toronto. She also appointed at the Dalla Lana School of Public Health and a Senior Clinician Scientist at the Lunenfeld-Tanenbaum Research Institute, and is a partner of the National Collaborating Centre for Infectious Diseases. McGeer has led investigations into the severe acute respiratory syndrome outbreak in Toronto and worked alongside Donald Low. During the COVID-19 pandemic, McGeer has studied how SARS-CoV-2 survives in the air and has served on several provincial committees advising aspects of the Government of Ontario's pandemic response.",
            "categories": [
                "Category:1953 births",
                "Category:20th-century Canadian physicians",
                "Category:20th-century Canadian women physicians",
                "Category:20th-century Canadian women scientists",
                "Category:21st-century Canadian physicians",
                "Category:21st-century Canadian women physicians",
                "Category:Academic staff of the University of Toronto",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:CS1: unfit URL"
            ],
            "id": 319
        },
        {
            "title": "ISO/IEC 8859-4",
            "info_text": "ISO/IEC 8859-4:1998, Information technology \u2014 8-bit single-byte coded graphic character sets \u2014 Part 4: Latin alphabet No. 4, is part of the ISO/IEC 8859 series of ASCII-based standard character encodings, first edition published in 1988. It is informally referred to as Latin-4 or North European. It was designed to cover Estonian, Latvian, Lithuanian, Greenlandic, and S\u00e1mi. It has been largely superseded by ISO/IEC 8859-10 and Unicode. Microsoft has assigned code page 28594 a.k.a. Windows-28594 to ISO-8859-4 in Windows. IBM has assigned code page 914 (CCSID 914) to ISO 8859-4.\nISO-8859-4 is the IANA preferred charset name for this standard when supplemented with the C0 and C1 control codes from ISO/IEC 6429. ISO-IR 205 (called Code page 58258 by FreeDOS) replaces the generic Currency Sign at 0xA4 with the Euro Sign.",
            "categories": [
                "Category:Articles with short description",
                "Category:Computer-related introductions in 1988",
                "Category:Estonian language",
                "Category:Greenlandic language",
                "Category:ISO/IEC 8859",
                "Category:Latvian language",
                "Category:Lithuanian language",
                "Category:Short description matches Wikidata",
                "Category:S\u00e1mi languages",
                "Category:Webarchive template wayback links"
            ],
            "id": 320
        },
        {
            "title": "Staccato",
            "info_text": "Staccato ([stak\u02c8ka\u02d0to]; Italian for \"detached\") is a form of musical articulation. In modern notation, it signifies a note of shortened duration, separated from the note that may follow by silence. It has been described by theorists and has appeared in music since at least 1676.",
            "categories": [
                "Category:Articles with hAudio microformats",
                "Category:Articles with short description",
                "Category:Articulations (music)",
                "Category:Italian words and phrases",
                "Category:Musical notation",
                "Category:Pages using the Score extension",
                "Category:Pages with Italian IPA",
                "Category:Short description matches Wikidata"
            ],
            "id": 321
        },
        {
            "title": "BBC",
            "info_text": "The British Broadcasting Corporation (BBC) is a British public service broadcaster headquartered at Broadcasting House in London, England. Originally established in 1922 as the British Broadcasting Company, it evolved into its current state with its current name on New Year's Day 1927. The oldest and largest local and global broadcaster by stature and by number of employees, the BBC employs over 21,000 staff in total, of whom approximately 17,200 are in public-sector broadcasting.\nThe BBC was established under a royal charter, and operates under an agreement with the Secretary of State for Culture, Media and Sport. Its work is funded principally by an annual television licence fee which is charged to all British households, companies, and organisations using any type of equipment to receive or record live television broadcasts or to use the BBC's streaming service, iPlayer. The fee is set by the British Government, agreed by Parliament, and is used to fund the BBC's radio, TV, and online services covering the nations and regions of the UK. Since 1 April 2014, it has also funded the BBC World Service (launched in 1932 as the BBC Empire Service), which broadcasts in 28 languages and provides comprehensive TV, radio, and online services in Arabic and Persian.\nSome of the BBC's revenue comes from its commercial subsidiary BBC Studios (formerly BBC Worldwide), which sells BBC programmes and services internationally and also distributes the BBC's international 24-hour English-language news services BBC News, and from BBC.com, provided by BBC Global News Ltd. In 2009, the company was awarded the Queen's Award for Enterprise in recognition of its international achievements in business.\nSince its formation in 1922, the BBC has played a prominent role in British life and culture. It is sometimes informally referred to as the Beeb or Auntie. In 1923 it launched Radio Times (subtitled \"The official organ of the BBC\"), the first broadcast listings magazine; the 1988 Christmas edition sold 11 million copies, the biggest-selling edition of any British magazine in history.\n\n",
            "categories": [
                "Category:1922 establishments in England",
                "Category:All Wikipedia articles in need of updating",
                "Category:All articles containing potentially dated statements",
                "Category:Articles containing potentially dated statements from 2021",
                "Category:Articles containing potentially dated statements from December 2012",
                "Category:Articles with short description",
                "Category:BBC",
                "Category:British brands",
                "Category:British companies established in 1922",
                "Category:Department for Culture, Media and Sport"
            ],
            "id": 322
        },
        {
            "title": "McCoy Solar Energy Project",
            "info_text": "The McCoy Solar Energy Project is a 250 megawatt (MWAC) photovoltaic power plant near the city of Blythe in  Riverside County, California.\n\nIt occupies about 2,300 acres of mostly public land in the Mojave Desert.  The construction uses CdTe thin film panels from First Solar,  and the output is being sold to Southern California Edison under a power purchase agreement.\nThe project is located adjacent to the 235 MW Blythe Solar Energy Center, together forming a larger 485 MW complex.  The 550MW Desert Sunlight Solar Farm is located approximately 40miles west in Riverside County. The 450 MW Desert Quartzite project by First Solar, which got preliminary approval in early 2020, is also in the area.",
            "categories": [
                "Category:2016 establishments in California",
                "Category:Articles with short description",
                "Category:Buildings and structures in Riverside County, California",
                "Category:Coordinates on Wikidata",
                "Category:Energy infrastructure completed in 2016",
                "Category:Infobox mapframe without OSM relation ID on Wikidata",
                "Category:NextEra Energy",
                "Category:Pages using gadget WikiMiniAtlas",
                "Category:Pages using the Kartographer extension",
                "Category:Photovoltaic power stations in the United States"
            ],
            "id": 323
        },
        {
            "title": "ISO 7027",
            "info_text": "ISO 7027:1999 is an ISO standard for water quality that enables the determination of turbidity. The ISO 7027 technique is used to determine the concentration of suspended particles in a sample of water by measuring the incident light scattered at right angles from the sample. The scattered light is captured by a photodiode, which produces an electronic signal that is converted to a turbidity.",
            "categories": [
                "Category:All articles with topics of unclear notability",
                "Category:All stub articles",
                "Category:Articles with short description",
                "Category:Articles with topics of unclear notability from December 2023",
                "Category:ISO standards",
                "Category:Short description matches Wikidata",
                "Category:Water quality indicators",
                "Category:Water supply stubs"
            ],
            "id": 324
        },
        {
            "title": "Henry William Watson",
            "info_text": "Rev. Henry William Watson FRS (25 February 1827, Marylebone, London \u2013 11 January 1903, Brighton) was a mathematician and author of a number of mathematics books. He was an ordained priest and Cambridge Apostle.",
            "categories": [
                "Category:1827 births",
                "Category:1903 deaths",
                "Category:19th-century English mathematicians",
                "Category:Alumni of King's College London",
                "Category:Alumni of Trinity College, Cambridge",
                "Category:Articles incorporating Cite DNB template",
                "Category:Articles incorporating DNB12 text with Wikisource reference",
                "Category:Articles with short description",
                "Category:Fellows of the Royal Society",
                "Category:Pages using cite ODNB with id parameter"
            ],
            "id": 325
        },
        {
            "title": "Group 7 element",
            "info_text": "Group 7, numbered by IUPAC nomenclature, is a group of elements in the periodic table. It contains manganese (Mn), technetium (Tc), rhenium (Re) and bohrium (Bh). This group lies in the d-block of the periodic table, and are hence transition metals. This group is sometimes called the manganese group or manganese family after its lightest member; however, the group itself has not acquired a trivial name because it belongs to the broader grouping of the transition metals.\nThe group 7 elements tend to have a major group oxidation state (+7), although this trend is markedly less coherent than the previous groups. Like other groups, the members of this family show patterns in their electron configurations, especially the outermost shells resulting in trends in chemical behavior. In nature, manganese is a fairly common element, whereas rhenium is rare, technetium only occurs in trace quantities, and bohrium is entirely synthetic.",
            "categories": [
                "Category:Articles containing Latin-language text",
                "Category:Articles with short description",
                "Category:CS1 German-language sources (de)",
                "Category:CS1 maint: multiple names: authors list",
                "Category:Groups (periodic table)",
                "Category:Short description matches Wikidata"
            ],
            "id": 326
        },
        {
            "title": "Statistical learning theory",
            "info_text": "Statistical learning theory is a framework for machine learning drawing from the fields of statistics and functional analysis. Statistical learning theory deals with the statistical inference problem of finding a predictive function based on data. Statistical learning theory has led to successful applications in fields such as computer vision, speech recognition, and bioinformatics.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:Estimation theory",
                "Category:Machine learning",
                "Category:Short description is different from Wikidata"
            ],
            "id": 327
        },
        {
            "title": "Soul music",
            "info_text": "Soul music is a popular music genre that originated in African-American communities throughout the United States in the late 1950s and early 1960s. It has its roots in African-American gospel music and rhythm and blues. Soul music became popular for dancing and listening, and U.S. record labels such as Motown, Atlantic and Stax were influential in its  proliferation during the civil rights movement. Soul also became popular worldwide, directly influencing rock music and the music of Africa. It had a resurgence in the mid-to late 1990s with the subgenre neo soul, which incorporated modern production elements and hip hop influences.\nThe genre emerged from the power struggle to increase black Americans' awareness of their African ancestry, as a newfound consciousness led to the creation of music that boasted pride in being black. Soul music primarily combines elements of gospel, R&B and jazz. Catchy rhythms, stressed by handclaps and extemporaneous body movements, are an important hallmark of soul. Other characteristics are a call and response between the lead and backing vocalists,  an especially tense vocal sound, and occasional improvisational additions, twirls, and auxiliary sounds. Soul music is known for reflecting African-American identity and stressing the importance of African-American culture.  \nSoul music dominated the U.S. R&B charts in the 1960s, and many recordings crossed over into the pop charts in the U.S., United Kingdom, and elsewhere. Many prominent soul artists, including Ray Charles, Sam Cooke, Otis Redding, James Brown, Aretha Franklin, and various acts under the Motown label, such as The Supremes and The Temptations, were highly influential in the genre's development and all gained widespread popularity during this time. By 1968, the soul music genre had begun to splinter. Some soul artists moved to funk music, while other singers and groups developed slicker, more sophisticated, and in some cases more socially conscious varieties. By the early 1970s, soul music had begun to absorb influences from psychedelic rock and progressive rock, among other genres, leading to the creation of psychedelic soul and progressive soul. Prominent soul artists of this era include Marvin Gaye, Stevie Wonder, Curtis Mayfield, Isaac Hayes, Al Green, and Bill Withers. Neo soul, which adopted hip hop influences, emerged around 1994. \nOther subgenres of soul include the \"Motown sound\", a more rhythmic and pop-friendly  style that originated from the eponymous label; Southern soul, a driving, energetic variety combining R&B with southern gospel music influences; Memphis soul, a shimmering, sultry style; New Orleans soul, which emerged from the rhythm and blues style; Chicago soul, a lighter gospel-influenced sound; and Philadelphia soul, a lush orchestral variety with doo-wop-inspired vocals.",
            "categories": [
                "Category:African-American cultural history",
                "Category:African-American music",
                "Category:All Wikipedia articles written in American English",
                "Category:All articles needing additional references",
                "Category:All articles with failed verification",
                "Category:American styles of music",
                "Category:Articles needing additional references from January 2009",
                "Category:Articles needing additional references from May 2014",
                "Category:Articles with failed verification from February 2016",
                "Category:Articles with short description"
            ],
            "id": 328
        },
        {
            "title": "Particle-in-cell",
            "info_text": "In plasma physics, the particle-in-cell (PIC) method refers to a technique used to solve a certain class of partial differential equations.  In this method, individual particles (or fluid elements) in a Lagrangian frame are tracked in continuous phase space, whereas moments of the distribution such as densities and currents are computed simultaneously on Eulerian (stationary) mesh points.\nPIC methods were already in use as early as 1955,\neven before the first Fortran compilers were available. The method gained popularity for plasma simulation in the late 1950s and early 1960s by Buneman, Dawson, Hockney, Birdsall, Morse and others. In plasma physics applications, the method amounts to following the trajectories of charged particles in self-consistent electromagnetic (or electrostatic) fields computed on a fixed mesh. \n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:CS1 errors: external links",
                "Category:Computational electromagnetics",
                "Category:Computational fluid dynamics",
                "Category:Mathematical modeling",
                "Category:Numerical differential equations",
                "Category:Short description matches Wikidata"
            ],
            "id": 329
        },
        {
            "title": "BlitzMail",
            "info_text": "BlitzMail was an e-mail system used at Dartmouth College in Hanover, New Hampshire, United States. It was one of the earliest e-mail server/client packages. Use of BlitzMail ended in 2011, in favor of a Microsoft suite of email/online collaboration programs, but students still use the term \"blitz\" rather than \"email.\"\n\n",
            "categories": [
                "Category:All Wikipedia articles in need of updating",
                "Category:All articles containing potentially dated statements",
                "Category:All articles needing additional references",
                "Category:All articles with topics of unclear notability",
                "Category:Articles containing potentially dated statements from 2004",
                "Category:Articles needing additional references from January 2012",
                "Category:Articles with multiple maintenance issues",
                "Category:Articles with topics of unclear notability from November 2020",
                "Category:CS1 errors: missing periodical",
                "Category:Dartmouth College student life"
            ],
            "id": 330
        },
        {
            "title": "Funk rock",
            "info_text": "Funk rock is a fusion genre that mixes elements of funk and rock. James Brown and others declared that Little Richard and his mid-1950s road band, the Upsetters, were the first to put the funk in the rock and roll beat, with a biographer stating that their music \"spark[ed] the musical transition from fifties rock and roll to sixties funk\".\nFunk rock's earliest incarnation on record was heard in the late 1960s through the mid-1970s by acts such as Sly and the Family Stone, Parliament-Funkadelic, The Isley Brothers, Redbone, Rick Derringer, David Bowie, The Chambers Brothers, Cold Blood, Shuggie Otis, Aerosmith, Wild Cherry, the Average White Band, Gary Wright, Black Merda, Bar-Kays, Edwin Birdsong, Betty Davis, Trapeze and Mother's Finest. During the 1980s and 1990s funk rock music experienced a surge in popularity, with bands such as Prince & The Revolution, Tom Tom Club, Pigbag, INXS, Talking Heads, Devo, the Fine Young Cannibals and Cameo dabbling in the sound. Groups including Red Hot Chili Peppers, Rage Against the Machine, Incubus, Mr. Bungle, Primus and Faith No More also notably combined funk rock with metal, punk, hip hop and experimental music, leading to the emergence of the genre known as funk metal or \"punk-funk\".\nFunk rock is a fusion of funk music and rock music also from the point of view of instrumentation, in fact it incorporates that of both genres into itself, and the overall sound is shaped by a definitive bass or drum beat and by electric guitars.\n\n",
            "categories": [
                "Category:All Wikipedia articles written in American English",
                "Category:All articles lacking reliable references",
                "Category:All articles that may contain original research",
                "Category:Articles lacking reliable references from May 2008",
                "Category:Articles that may contain original research from May 2008",
                "Category:Articles with multiple maintenance issues",
                "Category:Articles with short description",
                "Category:Funk genres",
                "Category:Funk rock",
                "Category:Fusion music genres"
            ],
            "id": 331
        },
        {
            "title": "ArkTS",
            "info_text": "ArkTS is a high-level general-purpose, multi-paradigm, compiled, declarative, static type programming language developed by Huawei which is a extension superset of open-source TypeScript, in turn a superset of JavaScript formerly used in July 2022 HarmonyOS 3.0 version, alongside its evolved precursor, extended TypeScript (eTS) built for HarmonyOS development as a shift towards declarative programming. ArkTS compiles to machine code via its ahead-of-time compilation Ark Compiler. ArkTS was first released in September 30, 2021 on OpenHarmony, and the ArkTS toolchain has shipped in DevEco Studio since version 3.1, released in 2022. Since, OpenHarmony 4.0 release on October 26, 2023, ArkTS APIs has been added to the open source community to contribute.\nHuawei intended ArkTS to support many core concepts associated with extended TypeScript (eTS) based on TypeScript and in turn JavaScript from previous versions of HarmonyOS 3.0 with ArkUI declarative UI app development and 2.0 imperative app development alongside Java. ArkTS was introduced at Huawei's Developer Conference (HDC) 2022 in November 2022 on HarmonyOS 3.1 release.\nIt underwent an upgrade in HDC 2023 with HarmonyOS 4.0 API 10 and a major upgrade at January 18, 2024 HarmonyOS Ecology Developer Conference alongside, new Cangjie programming language announced by Huawei where both programming languages become the primary languages for the iterative HarmonyOS NEXT system version of HarmonyOS operating system.\nThe current version of ArkTS, was released on October 26, 2023, for open source OpenHarmony 4.0 API 10 with new ArkTS APIs via DevEco Studio 4.0 Canary build after HarmonyOS 4.0 release on August 4, 2023. Following current stable release, a preview released in January 2024, with OpenHarmony 4.1 Beta 1 API 11. Alongside, internal HarmonyOS NEXT Developer Preview 1 and 2 with latest API 11-12 preview based on latest version of OpenHarmony that features advanced syntax  that is matured on the 5.0 version of the DevEco Studio IDE that is syntactically rigorous and provides more complete and rich capabilities compared to previous versions.\n\n",
            "categories": [
                "Category:2021 software",
                "Category:All articles with topics of unclear notability",
                "Category:Articles with short description",
                "Category:Articles with topics of unclear notability from July 2024",
                "Category:CS1 uses Chinese-language script (zh)",
                "Category:Cross-platform software",
                "Category:Huawei products",
                "Category:JavaScript programming language family",
                "Category:Object-based programming languages",
                "Category:Programming languages created in 2021"
            ],
            "id": 332
        },
        {
            "title": "Blue Labour",
            "info_text": "Blue Labour is a British campaign group and political faction that seeks to promote blue-collar and culturally conservative values within the British Labour Party \u2013 particularly on immigration, crime, and community spirit \u2013 while remaining committed to labour rights and left-wing economic policies. It seeks to represent a traditional working-class approach to Labour politics. \nLaunched in 2009 as a counter to New Labour, the Blue Labour movement first rose to prominence after Labour's defeat in the 2010 general election, in which for the first time the party received fewer working-class votes than it did middle-class votes. The movement has influenced a handful of Labour MPs and frontbenchers; founder Maurice Glasman served as a close ally to Ed Miliband during his early years as Leader of the Opposition, before himself becoming a life peer in the House of Lords. The movement has also seen a resurgence of interest after the loss of red wall seats in the 2019 general election.\nBlue Labour argues that the party lost touch with its base by embracing anti-patriotism in the face of Brexit and by undermining solidarity in local communities through bureaucratic collectivism, social agendas, and neoliberal economics. It argues that whilst postwar Old Labour had become too uncritical of state power, New Labour far worsened this with an uncritical view of global markets as well. The group further advocates a switch to local and democratic community management and provision of services, rather than relying on a top-down welfare state which it sees as excessively bureaucratic. Economically it is described as a \"movement keen on guild socialism and continental corporatism\".\nThe Blue Labour position has been articulated in books such as Tangled Up in Blue (2011) by Rowenna Davis, Blue Labour: Forging a New Politics (2015) by Ian Geary and Adrian Pabst and Blue Labour: The Politics of the Common Good (2022) by Glasman himself. Additional elucidations on Blue Labour's ideas can be found in The Purple Book (2011) by Robert Philpot and Despised: Why the Modern Left Loathes the Working Class (2020) by Paul Embery. A number of commentators, including Adrian Pabst himself, have argued that, as leader of the Labour Party, Keir Starmer has adopted significant elements of Blue Labour's analysis and policies.",
            "categories": [
                "Category:Articles with short description",
                "Category:Blue Labour",
                "Category:Conservatism in the United Kingdom",
                "Category:Corporatism",
                "Category:EngvarB from December 2018",
                "Category:Guilds",
                "Category:Labour Party (UK) factions",
                "Category:Political terminology in the United Kingdom",
                "Category:Short description is different from Wikidata",
                "Category:Use dmy dates from February 2017"
            ],
            "id": 333
        },
        {
            "title": "Inductive logic programming",
            "info_text": "Inductive logic programming (ILP) is a subfield of symbolic artificial intelligence  which uses logic programming as a uniform representation for examples, background knowledge and hypotheses.  The term \"inductive\" here refers to philosophical (i.e. suggesting a theory to explain observed facts) rather than mathematical (i.e. proving a property for all members of a well-ordered set) induction. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesised logic program which entails all the positive and none of the negative examples.\n\nSchema: positive examples + negative examples + background knowledge \u21d2 hypothesis.\nInductive logic programming is particularly useful in bioinformatics and natural language processing.\n\n",
            "categories": [
                "Category:All articles containing potentially dated statements",
                "Category:All articles with dead external links",
                "Category:Articles containing potentially dated statements from 2022",
                "Category:Articles with dead external links from October 2022",
                "Category:Articles with permanently dead external links",
                "Category:CS1: long volume value",
                "Category:Free-content attribution",
                "Category:Free content from Frontiers Media",
                "Category:Inductive logic programming",
                "Category:Webarchive template wayback links"
            ],
            "id": 334
        },
        {
            "title": "Google Page Creator",
            "info_text": "Google Page Creator was a website creation and hosting service by Google  launched in beta in 2006. It was a tool for basic website design, requiring no HTML or CSS knowledge. Users just had to login to their Gmail account and got 100MB of hosting space and a Gmail-derived domain name and the service was completely free.\nIn September 2008, Google announced that it would not accept new sign-ups to Page Creator, instead encouraging users to use Google Sites. The service was shut down in 2009, whilst existing published pages migrated to Google Sites.\nThe Page Creator Beta was a good site for non-professionals looking for an easy way to host and publish their pages. However, it had pretty basic features such as templates and HTML editing, but not tools such as message boards, chats, or blogs.\nOne of the more famous use cases of the service was levarburton.com.\n\n",
            "categories": [
                "Category:All stub articles",
                "Category:Articles with short description",
                "Category:Discontinued Google services",
                "Category:Free web hosting services",
                "Category:Google stubs",
                "Category:Products and services discontinued in 2009",
                "Category:Short description matches Wikidata",
                "Category:Use mdy dates from December 2019"
            ],
            "id": 335
        },
        {
            "title": "COVID-19 pandemic in Toronto",
            "info_text": "The COVID-19 pandemic in Toronto is a viral pandemic of coronavirus disease 2019 (COVID-19), a novel infectious disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), localized in Toronto. Toronto is the most populous city in Canada, and the fourth most populous city in North America.\nOn January 23, 2020, the first identified case of COVID-19 in Canada during the pandemic was admitted to Sunnybrook Health Sciences Centre in Toronto. The individual was first described as showing fever and respiratory symptoms, however this was later confirmed as a presumptive positive case of COVID-19 on January 25, 2020. On March 17, 2020, the government of Ontario declared its first state of emergency during the pandemic, followed by Toronto mayor John Tory declaring a local state of emergency March 23, 2020. Initial restrictions preventing essential businesses from operating (such as the closure of indoor dining and personal care services) continued through until June 24, 2020, when the government of Ontario allowed Toronto to enter Stage 2 of reopening. Toronto introduced mask requirements at all public indoor settings on July 7, 2020. On July 31, 2020, Toronto was admitted into Stage 3 of reopening.\nDuring the summer of 2020, the city saw a significant decline of new cases, where the city had as low as 246 active cases at one point that August. Along with the province of Ontario and other areas of Canada, cases began to steadily rise in late summer and early autumn. Toronto, Peel Region, York Region and Ottawa began to face restrictions based on rising viral spread and were initially knocked back into a modified Stage 2 tier until the province introduced a new colour-coded Response Framework for the province involving five tiers based on regional COVID-19 numbers. In early October 2020, Toronto Public Health became so overwhelmed by new cases, it suspended extended contact tracing efforts. On November 23, 2020, Toronto was placed under lockdown, under which it remained until the province declared a province-wide shutdown beginning December 26, 2020. This included the declaration of a second state of emergency in January 2021 and stay-at-home orders for the entire province. Toronto remained under stay-at-home orders until March 8, 2021. On April 3, 2021, following an uptick in new cases in Ontario, (exacerbated by more aggressive variants of SARS-CoV-2) Toronto, along with the rest of the province entered a shutdown coupled with a stay-at-home order that lasted until June 2, 2021.\nIn December 2020, Health Canada approved the Pfizer\u2013BioNTech COVID-19 vaccine and the mRNA-1273 vaccine developed by Moderna. Widespread plans for COVID-19 vaccinations across Canada and the province began during the week of December 14, 2020. On February 26, 2021, Health Canada approved the Oxford\u2013AstraZeneca COVID-19 vaccine for use and on March 5, 2021, the Janssen COVID-19 vaccine was also approved. In conjunction with the Provincial rollout, the city has opened ten mass-vaccination sites across the city, with hospital and hospital-run vaccination sites, pop-up clinics, mobile clinics, pharmacies and family doctors participating in the administration of the approved vaccines.\nOn May 9, 2022, Mayor John Tory announced the termination of Toronto's COVID-19 state of emergency after being in effect for 777 consecutive days, the longest for any major city in the world.\n\n",
            "categories": [
                "Category:2020 disasters in Canada",
                "Category:2020 in Toronto",
                "Category:2021 disasters in Canada",
                "Category:2021 in Toronto",
                "Category:2022 disasters in Canada",
                "Category:2022 in Toronto",
                "Category:All Wikipedia articles in need of updating",
                "Category:All articles with dead external links",
                "Category:Articles with dead external links from January 2022",
                "Category:Articles with permanently dead external links"
            ],
            "id": 336
        },
        {
            "title": "Actions on Google",
            "info_text": "Actions on Google was a development platform for the Google Assistant. It allowed the third-party development of \"actions\"\u2014applets for the Google Assistant that provide extended functionality.\nGoogle renamed the service \"Conversational Actions\". Google discontinued the service. The last day of operation was June 12, 2023.",
            "categories": [
                "Category:All articles needing additional references",
                "Category:Articles needing additional references from November 2018",
                "Category:Articles with short description",
                "Category:Google software",
                "Category:Natural language processing software",
                "Category:Official website not in Wikidata",
                "Category:Short description matches Wikidata",
                "Category:Software developer communities",
                "Category:Web development software"
            ],
            "id": 337
        },
        {
            "title": "Harmony Intelligent Mobility Alliance",
            "info_text": "Harmony Intelligent Mobility Alliance, trading as HIMA (Chinese: \u9e3f\u8499\u667a\u884c; pinyin: H\u00f3ngm\u00e9ng Zh\u00ecx\u00edng) is an automotive alliance and sales network initiated and led by Chinese multinational technology company Huawei. Established in 2023, the members of the alliance include AITO (Seres Group), Luxeed (Chery), Stelato (BAIC BluePark), and Maextro (JAC Group).\nUnder HIMA, Huawei contributes in product planning, design, marketing, user experience, quality control and provides intelligent vehicle software and hardware for the traditional automobile manufacturers. Currently, HIMA only operates in mainland China.\n\n",
            "categories": [
                "Category:Articles containing Chinese-language text",
                "Category:Articles with short description",
                "Category:CS1 Chinese (China)-language sources (zh-cn)",
                "Category:CS1 Dutch-language sources (nl)",
                "Category:CS1 Simplified Chinese-language sources (zh-hans)",
                "Category:Car brands",
                "Category:Huawei",
                "Category:Huawei products",
                "Category:Short description matches Wikidata",
                "Category:Vehicles codeveloped with Huawei"
            ],
            "id": 338
        },
        {
            "title": "International Standard Audiovisual Number",
            "info_text": "International Standard Audiovisual Number (ISAN) is a unique identifier for audiovisual works and related versions, similar to ISBN for books. It was developed within an ISO (International Organization for Standardization) TC46/SC9 working group. ISAN is managed and run by ISAN-IA.\n\n",
            "categories": [
                "Category:All articles with vague or ambiguous time",
                "Category:Articles with short description",
                "Category:ISO standards",
                "Category:Identifiers",
                "Category:Music technology",
                "Category:Short description is different from Wikidata",
                "Category:Unique identifiers",
                "Category:Vague or ambiguous time from January 2017",
                "Category:Webarchive template wayback links"
            ],
            "id": 339
        },
        {
            "title": "Font",
            "info_text": "In metal typesetting, a font (American English)  or fount (Commonwealth English) is a particular size, weight and style of a typeface, defined as the set of fonts that share an overall design.\nFor instance, the typeface Bauer Bodoni (shown in the figure) includes fonts \"Roman\" (or \"regular\"), \"bold\" and \"italic\"; each of these exists in a variety of sizes. \nIn the digital description of fonts (computer fonts), the terms \"font\" and \"typeface\" are often used interchangeably. For example, when used in computers, each style is stored in a separate digital font file.\nIn both traditional typesetting and computing, the word \"font\" refers to the delivery mechanism of an instance of the typeface. In traditional typesetting, the font would be made from metal or wood type: to compose a page may require multiple fonts from the typeface or even multiple typefaces.",
            "categories": [
                "Category:All Wikipedia articles written in American English",
                "Category:All articles lacking reliable references",
                "Category:All articles with unsourced statements",
                "Category:Articles containing video clips",
                "Category:Articles lacking reliable references from November 2021",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from March 2023",
                "Category:Short description matches Wikidata",
                "Category:Typefaces",
                "Category:Typesetting"
            ],
            "id": 340
        },
        {
            "title": "YouTube Poop",
            "info_text": "A YouTube Poop (YTP) is a type of video mashup or edit created by remixing/editing pre-existing media sources, often carrying subcultural significance into a new video for humorous, vulgar, satirical, obscene, absurd, profane, annoying, confusing, or dramatic purposes. YouTube Poops are traditionally uploaded to the video sharing website YouTube, hence the name.\n\n",
            "categories": [
                "Category:2000s neologisms",
                "Category:2004 introductions",
                "Category:2004 neologisms",
                "Category:All Wikipedia articles written in American English",
                "Category:Articles with hAudio microformats",
                "Category:Articles with short description",
                "Category:CS1 Dutch-language sources (nl)",
                "Category:CS1 French-language sources (fr)",
                "Category:CS1 Italian-language sources (it)",
                "Category:Collage film"
            ],
            "id": 341
        },
        {
            "title": "Trace element",
            "info_text": "A trace element is a chemical element of a minute quantity, a trace amount, especially used in referring to a micronutrient, but is also used to refer to minor elements in the composition of a rock, or other chemical substance.\nIn nutrition, trace elements are classified into two groups: essential trace elements, and non-essential trace elements. Essential trace elements are needed for many physiological and biochemical processes in both plants and animals. Not only do trace elements play a role in biological processes but they also serve as catalysts to engage  in redox \u2013 oxidation and reduction mechanisms. Trace elements of some heavy metals have a biological role as essential micronutrients.",
            "categories": [
                "Category:Analytical chemistry",
                "Category:Articles with short description",
                "Category:Biochemistry",
                "Category:CS1 maint: multiple names: authors list",
                "Category:Geochemistry",
                "Category:Nutrition",
                "Category:Physiology",
                "Category:Short description is different from Wikidata"
            ],
            "id": 342
        },
        {
            "title": "D. Allan Bromley",
            "info_text": "David Allan Bromley (May 4, 1926 \u2013 February 10, 2005) was a Canadian-American physicist, academic administrator and science advisor to President George H. W. Bush. His field of research was the study of low-energy nuclear reactions and structure using heavy ion beams.\n\n",
            "categories": [
                "Category:1926 births",
                "Category:2005 deaths",
                "Category:20th-century American physicists",
                "Category:American nuclear physicists",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Canadian emigrants to the United States",
                "Category:Canadian nuclear physicists",
                "Category:Canadian physicists",
                "Category:Directors of the Office of Science and Technology Policy"
            ],
            "id": 343
        },
        {
            "title": "Project for Awesome",
            "info_text": "Project for Awesome (often abbreviated P4A) is a community-driven charitable movement on YouTube, created by the Green brothers, Hank and John, run through their VlogBrothers YouTube channel and through their online community known as Nerdfighteria. Formerly dubbed the Nerdfighter Power Project for Awesome, the project has taken place annually since 2007. The movement was started to have YouTubers create innovative videos promoting their favorite charity and upload it by a certain deadline, with the aim that their promoted charity gains more awareness, and donations from audiences.\nThe event lasts for 48 hours. From 2007 to 2019, the P4A took place in December, but in 2020 it was announced that the event would be moved to February moving forward.\n\n",
            "categories": [
                "Category:2000s in YouTube",
                "Category:2007 establishments in Montana",
                "Category:2010s in YouTube",
                "Category:2020s in YouTube",
                "Category:Articles containing video clips",
                "Category:Articles with short description",
                "Category:Charity fundraisers",
                "Category:Internet-based activism",
                "Category:Internet culture",
                "Category:Internet properties established in 2007"
            ],
            "id": 344
        },
        {
            "title": "Romanization of Armenian",
            "info_text": "There are various systems of romanization of the Armenian alphabet.\n\n",
            "categories": [
                "Category:ALA-LC romanization",
                "Category:All articles lacking in-text citations",
                "Category:Armenian alphabet",
                "Category:Articles lacking in-text citations from September 2017",
                "Category:Articles with short description",
                "Category:ISO standards",
                "Category:Romanization of Armenian",
                "Category:Short description is different from Wikidata"
            ],
            "id": 345
        },
        {
            "title": "Ilastik",
            "info_text": "ilastik  is a user-friendly free open source software for image classification and segmentation. No previous experience in image processing is required to run the software. Since 2018 ilastik is further developed and maintained by Anna Kreshuk's group at European Molecular Biology Laboratory.\n\n",
            "categories": [
                "Category:Computer vision software",
                "Category:Data mining and machine learning software",
                "Category:Free software programmed in Python",
                "Category:Image processing software",
                "Category:Image segmentation",
                "Category:Official website different in Wikidata and Wikipedia"
            ],
            "id": 346
        },
        {
            "title": "Yahoo Music Radio",
            "info_text": "Yahoo! Music Radio (formerly known as LAUNCHcast) was an Internet radio service.  The service, which featured both an advertising supported free version and a subscription fee-based premium version, allowed users to create personalized Internet radio stations by rating songs selected by a recommender system. Users were also able to listen to music from 150 preset Internet radio stations.",
            "categories": [
                "Category:1999 software",
                "Category:Articles with short description",
                "Category:Defunct radio stations in the United States",
                "Category:Internet properties disestablished in 2014",
                "Category:Internet properties established in 1999",
                "Category:Internet radio stations in the United States",
                "Category:Radio stations disestablished in 2014",
                "Category:Radio stations established in 1999",
                "Category:Short description is different from Wikidata",
                "Category:Use mdy dates from February 2021"
            ],
            "id": 347
        },
        {
            "title": "Measurement uncertainty",
            "info_text": "In metrology, measurement uncertainty is the expression of the statistical dispersion of the values attributed to a quantity measured on an interval or ratio scale. \nAll measurements are subject to uncertainty and a measurement result is complete only when it is accompanied by a statement of the associated uncertainty, such as the standard deviation. By international agreement, this uncertainty has a probabilistic basis and reflects incomplete knowledge of the quantity value. It is a non-negative parameter.\nThe measurement uncertainty is often taken as the standard deviation of a state-of-knowledge probability distribution over the possible values that could be attributed to a measured quantity. Relative uncertainty is  the measurement uncertainty relative to the magnitude of a particular single choice for the value for the measured quantity, when this choice is nonzero. This particular single choice is usually called the measured value, which may be optimal in some well-defined sense (e.g., a mean, median, or mode). Thus, the relative measurement uncertainty is the measurement uncertainty divided by the absolute value of the measured value, when the measured value is not zero.\n\n",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from December 2015",
                "Category:Measurement",
                "Category:Short description is different from Wikidata"
            ],
            "id": 348
        },
        {
            "title": "Google Chrome Frame",
            "info_text": "Google Chrome Frame was a plug-in designed for Internet Explorer based on the open-source Chromium project, first announced on September 22, 2009. It went stable in September 2010, on the first birthday of the project. It was discontinued on February 25, 2014 and is no longer supported.\nThe plug-in worked with Internet Explorer 6, 7, 8 and 9. It allowed suitably coded web pages to be displayed in Internet Explorer by Google Chrome's versions of the WebKit layout engine and V8 JavaScript engine. In a test by Computerworld, JavaScript code ran 10 times faster with the plug-in on Internet Explorer 8.\nDevelopment of Google Chrome Frame was required in order for Google Wave (now Apache Wave), which requires HTML5, to function in Internet Explorer.\nThe first stable version supporting Non-Admin Chrome Frame was rolled out on August 30, 2011. The newer Chrome Frame installer ran at Admin level by default and fell back to Non-Admin mode if the user didn't have the necessary permissions on their machine.",
            "categories": [
                "Category:Articles with short description",
                "Category:Discontinued Google software",
                "Category:Google Chrome",
                "Category:Short description matches Wikidata",
                "Category:Software based on WebKit"
            ],
            "id": 349
        },
        {
            "title": "Synth-pop",
            "info_text": "Synth-pop (short for synthesizer pop; also called techno-pop) is a music genre that first became prominent in the late 1970s and features the synthesizer as the dominant musical instrument. It was prefigured in the 1960s and early 1970s by the use of synthesizers in progressive rock, electronic, art rock, disco, and particularly the Krautrock of bands like Kraftwerk. It arose as a distinct genre in Japan and the United Kingdom in the post-punk era as part of the new wave movement of the late 1970s.\nElectronic musical synthesizers that could be used practically in a recording studio became available in the mid-1960s, and the mid-1970s saw the rise of electronic art musicians. After the breakthrough of Gary Numan in the UK Singles Chart in 1979, large numbers of artists began to enjoy success with a synthesizer-based sound in the early 1980s. In Japan, Yellow Magic Orchestra introduced the TR-808 rhythm machine to popular music, and the band would be a major influence on early British synth-pop acts. The development of inexpensive polyphonic synthesizers, the definition of MIDI and the use of dance beats, led to a more commercial and accessible sound for synth-pop. This, its adoption by the style-conscious acts from the New Romantic movement, together with the rise of MTV, led to success for large numbers of British synth-pop acts in the US during the Second British Invasion.\nThe term \"techno-pop\" was coined by Yuzuru Agi in his critique of Kraftwerk's The Man-Machine in 1978 and is considered a case of multiple discovery of naming. Hence, the term can be used interchangeably with \"synth-pop\", but is more frequently used to describe the scene of Japan. The term \"techno-pop\" became also popular in Europe, where it started: German band Kraftwerk's 1986 album was titled Techno Pop; English band the Buggles has a song named \"Technopop\" and Spanish band Mecano described their style as tecno-pop.\n\"Synth-pop\" is sometimes used interchangeably with \"electropop\", but \"electropop\" may also denote a variant of synth-pop that places more emphasis on a harder, more electronic sound. In the mid to late 1980s, duos such as Erasure and Pet Shop Boys adopted a style that was highly successful on the US dance charts, but by the end of the decade, the synth-pop of bands such as A-ha and Alphaville was giving way to house music and techno. Interest in synth-pop began to revive in the indietronica and electroclash movements in the late 1990s, and in the 2000s synth-pop enjoyed a widespread revival and commercial success.\nThe genre has received criticism for alleged lack of emotion and musicianship; prominent artists have spoken out against detractors who believed that synthesizers themselves composed and played the songs. Synth-pop music has established a place for the synthesizer as a major element of pop and rock music, directly influencing subsequent genres (including house music and Detroit techno) and has indirectly influenced many other genres, as well as individual recordings.",
            "categories": [
                "Category:1970s in music",
                "Category:1980s fads and trends",
                "Category:1980s in music",
                "Category:1990s in music",
                "Category:2000s in music",
                "Category:2010s in music",
                "Category:20th-century music genres",
                "Category:All articles with dead external links",
                "Category:Articles with dead external links from February 2024",
                "Category:Articles with permanently dead external links"
            ],
            "id": 350
        },
        {
            "title": "Allan H. Treman State Marine Park",
            "info_text": "Allan H. Treman State Marine Park is a 91-acre (0.37 km2) state park and marina located in the City of Ithaca in Tompkins County, New York, United States. The park is located at the south end of Cayuga Lake, one of the 11 Finger Lakes of New York. The park's namesake, Allan Hosie Treman (1899-1975) was a Cornell University law professor, Ithaca city counsel, and member of the Finger Lakes Park Commission. He is the son of Robert H. Treman, who also has a state park named in his honor.",
            "categories": [
                "Category:Articles with short description",
                "Category:Coordinates on Wikidata",
                "Category:Marine parks of New York (state)",
                "Category:Pages using gadget WikiMiniAtlas",
                "Category:Parks in Tompkins County, New York",
                "Category:Short description matches Wikidata",
                "Category:State parks of New York (state)",
                "Category:Tourist attractions in Ithaca, New York",
                "Category:Use mdy dates from August 2023"
            ],
            "id": 351
        },
        {
            "title": "ISBN",
            "info_text": "The International Standard Book Number (ISBN) is a numeric commercial book identifier that is intended to be unique. Publishers purchase or receive ISBNs from an affiliate of the International ISBN Agency.\nA different ISBN is assigned to each separate edition and variation of a publication, but not to a simple reprinting of an existing item. For example, an e-book, a paperback and a hardcover edition of the same book must each have a different ISBN, but an unchanged reprint of the hardcover edition keeps the same ISBN. The ISBN is ten digits long if assigned before 2007, and thirteen digits long if assigned on or after 1 January 2007. The method of assigning an ISBN is nation-specific and varies between countries, often depending on how large the publishing industry is within a country.\nThe first version of the ISBN identification format was devised in 1967, based upon the 9-digit Standard Book Numbering (SBN) created in 1966. The 10-digit ISBN format was developed by the International Organization for Standardization (ISO) and was published in 1970 as international standard ISO 2108 (any 9-digit SBN can be converted to a 10-digit ISBN by prefixing it with a zero).\nPrivately published books sometimes appear without an ISBN. The International ISBN Agency sometimes assigns ISBNs to such books on its own initiative.\nA separate identifier code of a similar kind, the International Standard Serial Number (ISSN), identifies periodical publications such as magazines and newspapers. The International Standard Music Number (ISMN) covers musical scores.\n\n",
            "categories": [
                "Category:All Wikipedia neutral point of view disputes",
                "Category:All articles containing potentially dated statements",
                "Category:All articles lacking reliable references",
                "Category:All articles that may contain original research",
                "Category:Articles containing French-language text",
                "Category:Articles containing German-language text",
                "Category:Articles containing Maltese-language text",
                "Category:Articles containing potentially dated statements from 2011",
                "Category:Articles lacking reliable references from May 2024",
                "Category:Articles that may contain original research from May 2019"
            ],
            "id": 352
        },
        {
            "title": "Generalized mean",
            "info_text": "In mathematics, generalized means (or power mean or H\u00f6lder mean from Otto H\u00f6lder) are a family of functions for aggregating sets of numbers. These include as special cases the Pythagorean means (arithmetic, geometric, and harmonic means).\n\n",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All articles with dead external links",
                "Category:Articles needing additional references from June 2020",
                "Category:Articles with dead external links from May 2024",
                "Category:Articles with example Haskell code",
                "Category:Articles with permanently dead external links",
                "Category:Articles with short description",
                "Category:Inequalities",
                "Category:Means",
                "Category:Short description matches Wikidata"
            ],
            "id": 353
        },
        {
            "title": "ISO 4",
            "info_text": "ISO 4 (Information and documentation \u2014 Rules for the abbreviation of title words and titles of publications) is an international standard which defines a uniform system for the abbreviation of serial publication titles, i.e., titles of publications such as scientific journals that are published in regular installments.\nThe International Organization for Standardization (ISO) has appointed the ISSN International Centre as the registration authority for ISO 4. It maintains the List of Title Word Abbreviations (LTWA), which contains standard abbreviations for words commonly found in serial titles. As of August 2017, the standard's most recent update came in 1997, when its third edition was released.\nA major use of ISO 4 is to abbreviate the names of scientific journals using the LTWA. For instance, under ISO 4 standards, the Journal of Biological Chemistry is cited as J. Biol. Chem., and the Journal of Polymer Science Part A should be cited as J. Polym. Sci. A (capitalization is not specified by the standard). The standard notes that \"Full stops shall only be used to indicate an abbreviation. Full stops may be omitted from abbreviated words in applications that require limited use of punctuation\" (section 4.6).\nIt was initially published in 1972 (ISO 4:1972), with a second edition published in 1984 (ISO 4:1984), and the third edition in 1997 (ISO 4:1997).",
            "categories": [
                "Category:All articles containing potentially dated statements",
                "Category:All stub articles",
                "Category:Articles containing potentially dated statements from August 2017",
                "Category:Articles with short description",
                "Category:ISO standards",
                "Category:Short description matches Wikidata",
                "Category:Standards and measurement stubs",
                "Category:Use Oxford spelling from December 2011",
                "Category:Use dmy dates from October 2019"
            ],
            "id": 354
        },
        {
            "title": "Criticism of Google",
            "info_text": "Criticism of Google includes concern for tax avoidance, misuse and manipulation of search results, its use of others' intellectual property, concerns that its compilation of data may violate people's privacy and collaboration with the US military on Google Earth to spy on users, censorship of search results and content, its cooperation with the Israeli military on Project Nimbus targeting Palestinians and the energy consumption of its servers as well as concerns over traditional business issues such as monopoly, restraint of trade, antitrust, patent infringement, indexing and presenting false information and propaganda in search results, and being an \"Ideological Echo Chamber\".\nGoogle's parent company, Alphabet Inc., is an American multinational public corporation invested in Internet search, cloud computing, and advertising technologies. Google hosts and develops a number of Internet-based services and products, and generates profit primarily from advertising through its Google Ads (formerly AdWords) program.\nGoogle's stated mission is \"to organize the world's information and make it universally accessible and useful\"; this mission, and the means used to accomplish it, have raised concerns among the company's critics. Much of the criticism pertains to issues that have not yet been addressed by cyber law.\nShona Ghosh, a journalist for Business Insider, noted that an increasing digital resistance movement against Google has grown.",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All articles to be expanded",
                "Category:All articles with dead external links",
                "Category:Articles containing video clips",
                "Category:Articles needing additional references from July 2024",
                "Category:Articles to be expanded from May 2020",
                "Category:Articles with dead external links from June 2024",
                "Category:Articles with short description",
                "Category:CS1 errors: generic name",
                "Category:CS1 maint: multiple names: authors list"
            ],
            "id": 355
        },
        {
            "title": "Fflick",
            "info_text": "fflick was a website devoted to reviews, information, and news of films based on information collected on Twitter. fflick was launched in August 2010 by Kurt Wilms and three other former Digg employees. It was acquired by Google in January 2011 and discontinued.\nSimilar to how Rotten Tomatoes or Metacritic aggregates movie reviews of new releases, fflick gathered tweets about a particular film in one place. The site categorized tweets into positive or negative reactions. It also allowed users to buy movie tickets, add certain films to their Netflix queues, and retweet other's tweets. You can also check out what certain \u201cinfluential\u201d users of Twitter think of certain films \u2014 a distinction that's made by comparing the number of one's followers versus the number of people they follow.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:Defunct online companies",
                "Category:Discontinued Google acquisitions",
                "Category:Film review websites",
                "Category:Google acquisitions",
                "Category:Internet properties disestablished in 2011",
                "Category:Internet properties established in 2010",
                "Category:Short description matches Wikidata",
                "Category:Twitter services and applications"
            ],
            "id": 356
        },
        {
            "title": "Helium",
            "info_text": "Helium (from Greek: \u1f25\u03bb\u03b9\u03bf\u03c2, romanized: helios, lit.\u2009'sun') is a chemical element; it has symbol He and atomic number 2. It is a colorless, odorless, non-toxic, inert, monatomic gas and the first in the noble gas group in the periodic table. Its boiling point is the lowest among all the elements, and it does not have a melting point at standard pressures. It is the second-lightest and second most abundant element in the observable universe, after hydrogen. It is present at about 24% of the total elemental mass, which is more than 12 times the mass of all the heavier elements combined. Its abundance is similar to this in both the Sun and Jupiter, because of the very high nuclear binding energy (per nucleon) of helium-4, with respect to the next three elements after helium. This helium-4 binding energy also accounts for why it is a product of both nuclear fusion and radioactive decay. The most common isotope of helium in the universe is helium-4, the vast majority of which was formed during the Big Bang. Large amounts of new helium are created by nuclear fusion of hydrogen in stars.\nHelium was first detected as an unknown, yellow spectral line signature in sunlight during a solar eclipse in 1868 by Georges Rayet, Captain C. T. Haig, Norman R. Pogson, and Lieutenant John Herschel, and was subsequently confirmed by French astronomer Jules Janssen. Janssen is often jointly credited with detecting the element, along with Norman Lockyer. Janssen recorded the helium spectral line during the solar eclipse of 1868, while Lockyer observed it from Britain. However, only Lockyer proposed that the line was due to a new element, which he named after the Sun. The formal discovery of the element was made in 1895 by chemists Sir William Ramsay, Per Teodor Cleve, and Nils Abraham Langlet, who found helium emanating from the uranium ore cleveite, which is now not regarded as a separate mineral species, but as a variety of uraninite. In 1903, large reserves of helium were found in natural gas fields in parts of the United States, by far the largest supplier of the gas today.\nLiquid helium is used in cryogenics (its largest single use, consuming about a quarter of production), and in the cooling of superconducting magnets, with its main commercial application in MRI scanners. Helium's other industrial uses\u2014as a pressurizing and purge gas, as a protective atmosphere for arc welding, and in processes such as growing crystals to make silicon wafers\u2014account for half of the gas produced. A small but well-known use is as a lifting gas in balloons and airships. As with any gas whose density differs from that of air, inhaling a small volume of helium temporarily changes the timbre and quality of the human voice. In scientific research, the behavior of the two fluid phases of helium-4 (helium I and helium II) is important to researchers studying quantum mechanics (in particular the property of superfluidity) and to those looking at the phenomena, such as superconductivity, produced in matter near absolute zero.\nOn Earth, it is relatively rare\u20145.2 ppm by volume in the atmosphere. Most terrestrial helium present today is created by the natural radioactive decay of heavy radioactive elements (thorium and uranium, although there are other examples), as the alpha particles emitted by such decays consist of helium-4 nuclei. This radiogenic helium is trapped with natural gas in concentrations as great as 7% by volume, from which it is extracted commercially by a low-temperature separation process called fractional distillation. Terrestrial helium is a non-renewable resource because once released into the atmosphere, it promptly escapes into space. Its supply is thought to be rapidly diminishing. However, some studies suggest that helium produced deep in the Earth by radioactive decay can collect in natural gas reserves in larger-than-expected quantities, in some cases having been released by volcanic activity.",
            "categories": [
                "Category:Airship technology",
                "Category:All articles containing potentially dated statements",
                "Category:All articles needing expert attention",
                "Category:Articles containing Greek-language text",
                "Category:Articles containing potentially dated statements from 2012",
                "Category:Articles containing potentially dated statements from 2021",
                "Category:Articles needing expert attention from November 2024",
                "Category:Articles with hAudio microformats",
                "Category:Articles with limited geographic scope from February 2022",
                "Category:Articles with short description"
            ],
            "id": 357
        },
        {
            "title": "Brazil",
            "info_text": "Brazil, officially the Federative Republic of Brazil, is the largest and easternmost country in South America. It is the world's fifth-largest country by area and the seventh largest by population, with over 203 million people. The country is a federation composed of 26 states and a Federal District, which hosts the capital, Bras\u00edlia. Its most populous city is S\u00e3o Paulo, followed by Rio de Janeiro. Brazil has the most Portuguese speakers in the world and is the only country in the Americas where Portuguese is an official language.\nBounded by the Atlantic Ocean on the east, Brazil has a coastline of 7,491 kilometers (4,655 mi). Covering roughly half of South America's land area, it borders all other countries and territories on the continent except Ecuador and Chile. Brazil encompasses a wide range of tropical and subtropical landscapes, as well as wetlands, savannas, plateaus, and low mountains. It contains most of the Amazon basin, including the world\u2019s largest river system and most extensive virgin tropical forest. Brazil has a diverse wildlife, a variety of ecological systems, and extensive natural resources spanning numerous protected habitats. The country ranks first among 17 megadiverse countries, with its natural heritage being the subject of significant global interest, as environmental degradation (through processes such as deforestation) directly affect global issues such as climate change and biodiversity loss.\nBrazil was inhabited by various indigenous peoples prior to the landing of Portuguese explorer Pedro \u00c1lvares Cabral in 1500. It was claimed and settled by Portugal, which forcibly imported enslaved Africans to work on plantations. Brazil remained a colony until 1815, when it was elevated to the rank of kingdom upon the formation of the United Kingdom of Portugal, Brazil and the Algarves after the transfer of the Portuguese court to Rio de Janeiro. Prince Pedro of Braganza declared the country's independence in 1822, establishing the Empire of Brazil, a unitary state governed under a parliamentary constitutional monarchy. Brazil's first constitution in 1824 established a bicameral legislature, now called the National Congress, and enshrined principles such as freedom of religion and the press, but retained slavery, which was gradually abolished throughout the 19th century until its final abolition in 1888. Brazil became a presidential republic following a military coup d'\u00e9tat in 1889. An authoritarian military dictatorship emerged in 1964 and ruled until 1985, after which civilian governance resumed. Brazil's current constitution, enacted in 1988, defines it as a democratic federal republic. \nBrazil is a regional and middle power and rising global power. It is an emerging, upper-middle income economy and newly industrialized country, with one of the 10 largest economies in the world in both nominal and PPP terms, the largest economy in Latin America and the Southern Hemisphere, and the largest share of wealth in South America. With a complex and highly diversified economy, Brazil is one of the world's major or primary exporters of various agricultural goods, mineral resources, and manufactured products. Due to its rich culture and history, the country ranks thirteenth in the world by number of UNESCO World Heritage Sites. Brazil is a founding member of the United Nations, the G20, BRICS, G4, Mercosur, Organization of American States, Organization of Ibero-American States, and the Community of Portuguese Language Countries; it is also an observer state of the Arab League and a major non-NATO ally of the United States.",
            "categories": [
                "Category:All Wikipedia articles written in American English",
                "Category:All accuracy disputes",
                "Category:All articles containing potentially dated statements",
                "Category:All articles with dead external links",
                "Category:All articles with style issues",
                "Category:All articles with unsourced statements",
                "Category:Articles containing Portuguese-language text",
                "Category:Articles containing potentially dated statements from 2021",
                "Category:Articles containing potentially dated statements from 2022",
                "Category:Articles containing potentially dated statements from July 2022"
            ],
            "id": 358
        },
        {
            "title": "Sarah Churchill (actress)",
            "info_text": "Sarah Millicent Hermione Touchet-Jesson, Baroness Audley (n\u00e9e Spencer-Churchill; 7 October 1914 \u2013 24 September 1982), was an English actress and dancer and a daughter of Winston Churchill.",
            "categories": [
                "Category:1914 births",
                "Category:1982 deaths",
                "Category:20th-century English actresses",
                "Category:Actresses from Kent",
                "Category:Actresses from London",
                "Category:All articles needing additional references",
                "Category:All articles with specifically marked weasel-worded phrases",
                "Category:All articles with unsourced statements",
                "Category:Articles needing additional references from May 2009",
                "Category:Articles with short description"
            ],
            "id": 359
        },
        {
            "title": "Cuisine of Toronto",
            "info_text": "The cuisine of Toronto reflects Toronto's size and multicultural diversity.  Ethnic neighbourhoods throughout the city focus on specific cuisines, such as authentic Chinese and Vietnamese found in the city's Chinatowns, Korean in Koreatown, Greek on The Danforth, Italian cuisine in Little Italy and Corso Italia, Bangladeshi cuisine in southwest Scarborough and East York, and Indian/Pakistani in Little India. Other world cuisines available in the city include Portuguese, Hungarian, Japanese, and Caribbean. Toronto's large Jewish population has given rise to many Jewish restaurants and delis, with varying adherence to kosher rules.",
            "categories": [
                "Category:Cuisine by city",
                "Category:Cuisine in Toronto"
            ],
            "id": 360
        },
        {
            "title": "Sanskrit",
            "info_text": "Sanskrit (; attributively \u0938\u0902\u0938\u094d\u0915\u0943\u0924-; nominally \u0938\u0902\u0938\u094d\u0915\u0943\u0924\u092e\u094d, sa\u1e43sk\u1e5btam,) is a classical language belonging to the Indo-Aryan branch of the Indo-European languages. It arose in South Asia after its predecessor languages had diffused there from the northwest in the late Bronze Age. Sanskrit is the sacred language of Hinduism, the language of classical Hindu philosophy, and of historical texts of Buddhism and Jainism. It was a link language in ancient and medieval South Asia, and upon transmission of Hindu and Buddhist culture to Southeast Asia, East Asia and Central Asia in the early medieval era, it became a language of religion and high culture, and of the political elites in some of these regions. As a result, Sanskrit had a lasting effect on the languages of South Asia, Southeast Asia and East Asia, especially in their formal and learned vocabularies.\nSanskrit generally connotes several Old Indo-Aryan language varieties. The most archaic of these is the Vedic Sanskrit found in the Rigveda, a collection of 1,028 hymns composed between 1500 and 1200 BCE by Indo-Aryan tribes migrating east from the mountains of what is today northern Afghanistan across northern Pakistan and into northwestern India. Vedic Sanskrit interacted with the preexisting ancient languages of the subcontinent, absorbing names of newly encountered plants and animals; in addition, the ancient Dravidian languages influenced Sanskrit's phonology and syntax. Sanskrit can also more narrowly refer to Classical Sanskrit, a refined and standardized grammatical form that emerged in the mid-1st millennium BCE and was codified in the most comprehensive of ancient grammars, the A\u1e63\u1e6d\u0101dhy\u0101y\u012b ('Eight chapters') of P\u0101\u1e47ini. The greatest dramatist in Sanskrit, K\u0101lid\u0101sa, wrote in classical Sanskrit, and the foundations of modern arithmetic were first described in classical Sanskrit. The two major Sanskrit epics, the Mah\u0101bh\u0101rata and the R\u0101m\u0101ya\u1e47a, however, were composed in a range of oral storytelling registers called Epic Sanskrit which was used in northern India between 400 BCE and 300 CE, and roughly contemporary with classical Sanskrit. In the following centuries, Sanskrit became tradition-bound, stopped being learned as a first language, and ultimately stopped developing as a living language.\nThe hymns of the Rigveda are notably similar to the most archaic poems of the Iranian and Greek language families, the Gathas of old Avestan and Iliad of Homer. As the Rigveda was orally transmitted by methods of memorisation of exceptional complexity, rigour and fidelity, as a single text without variant readings, its preserved archaic syntax and morphology are of vital importance in the reconstruction of the common ancestor language Proto-Indo-European. Sanskrit does not have an attested native script: from around the turn of the 1st-millennium CE, it has been written in various Brahmic scripts, and in the modern era most commonly in Devanagari.\nSanskrit's status, function, and place in India's cultural heritage are recognized by its inclusion in the Constitution of India's Eighth Schedule languages. However, despite attempts at revival, there are no first-language speakers of Sanskrit in India. In each of India's recent decennial censuses, several thousand citizens have reported Sanskrit to be their mother tongue, but the numbers are thought to signify a wish to be aligned with the prestige of the language. Sanskrit has been taught in traditional gurukulas since ancient times; it is widely taught today at the secondary school level.  The oldest Sanskrit college is the Benares Sanskrit College founded in 1791 during East India Company rule. Sanskrit continues to be widely used as a ceremonial and ritual language in Hindu and Buddhist hymns and chants.",
            "categories": [
                "Category:All Wikipedia articles written in Indian English",
                "Category:All articles lacking reliable references",
                "Category:All articles with unsourced statements",
                "Category:Articles containing Chinese-language text",
                "Category:Articles containing Sanskrit-language text",
                "Category:Articles containing undetermined-language text",
                "Category:Articles lacking reliable references from April 2016",
                "Category:Articles lacking reliable references from April 2021",
                "Category:Articles lacking reliable references from July 2023",
                "Category:Articles lacking reliable references from October 2014"
            ],
            "id": 361
        },
        {
            "title": "Hydraulics",
            "info_text": "Hydraulics (from Ancient Greek  \u1f55\u03b4\u03c9\u03c1 (h\u00fad\u014dr) 'water' and  \u03b1\u1f50\u03bb\u03cc\u03c2 (aul\u00f3s) 'pipe') is a technology and applied science using engineering, chemistry, and other sciences involving the mechanical properties and use of liquids. At a very basic level, hydraulics is the liquid counterpart of pneumatics, which concerns gases. Fluid mechanics provides the theoretical foundation for hydraulics, which focuses on applied engineering using the properties of fluids. In its fluid power applications, hydraulics is used for the generation, control, and transmission of power by the use of pressurized liquids. Hydraulic topics range through some parts of science and most of engineering modules, and they cover concepts such as pipe flow, dam design, fluidics, and fluid control circuitry. The principles of hydraulics are in use naturally in the human body within the vascular system and erectile tissue.\nFree surface hydraulics is the branch of hydraulics dealing with free surface flow, such as occurring in rivers, canals, lakes, estuaries, and seas. Its sub-field open-channel flow studies the flow in open channels.",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Ancient inventions",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from May 2010",
                "Category:Articles with unsourced statements from November 2016",
                "Category:CS1: unfit URL",
                "Category:CS1 European Spanish-language sources (es-es)",
                "Category:CS1 French-language sources (fr)",
                "Category:CS1 maint: archived copy as title",
                "Category:CS1 maint: multiple names: authors list"
            ],
            "id": 362
        },
        {
            "title": "Europium(III) phosphate",
            "info_text": "Europium(III) phosphate is one of the phosphates of europium, with the chemical formula of EuPO4. Other phosphates include europium(II) phosphate (Eu3(PO4)2) and europium(II,III) phosphate (Eu3Eu(PO4)3).",
            "categories": [
                "Category:Articles containing unverified chemical infoboxes",
                "Category:Articles with short description",
                "Category:Articles without EBI source",
                "Category:Articles without KEGG source",
                "Category:Articles without UNII source",
                "Category:CS1 maint: location missing publisher",
                "Category:Chemical articles with multiple CAS registry numbers",
                "Category:Chemical articles with multiple PubChem CIDs",
                "Category:Chemical articles with multiple compound IDs",
                "Category:Chemicals using indexlabels"
            ],
            "id": 363
        },
        {
            "title": "Bradley Efron",
            "info_text": "Bradley Efron (; born May 24, 1938) is an American statistician. Efron has been president of the American Statistical Association (2004) and of the Institute of Mathematical Statistics (1987\u20131988). He is a past editor (for theory and methods) of the Journal of the American Statistical Association, and he is the founding editor of the Annals of Applied Statistics. Efron is also the recipient of many awards (see below).\nEfron is especially known for proposing the bootstrap resampling technique, which has had a major impact in the field of statistics and virtually every area of statistical application. The bootstrap was one of the first computer-intensive statistical techniques, replacing traditional algebraic derivations with data-based computer simulations.",
            "categories": [
                "Category:1938 births",
                "Category:All BLP articles lacking sources",
                "Category:All articles with bare URLs for citations",
                "Category:All articles with unsourced statements",
                "Category:American bioinformaticians",
                "Category:American biostatisticians",
                "Category:American mathematical statisticians",
                "Category:American people of Russian-Jewish descent",
                "Category:Articles with PDF format bare URLs for citations",
                "Category:Articles with bare URLs for citations from March 2022"
            ],
            "id": 364
        },
        {
            "title": "DICOM",
            "info_text": "Digital Imaging and Communications in Medicine (DICOM) is a technical standard for the digital storage and transmission of medical images and related information. It includes a file format definition, which specifies the structure of a DICOM file, as well as a network communication protocol that uses TCP/IP to communicate between systems. The primary purpose of the standard is to facilitate communication between the software and hardware entities involved in medical imaging, especially those that are created by different manufacturers. Entities that utilize DICOM files include components of picture archiving and communication systems (PACS), such as imaging machines (modalities), radiological information systems (RIS), scanners, printers, computing servers, and networking hardware.\nThe DICOM standard has been widely adopted by hospitals and the medical software industry, and is sometimes used in smaller-scale applications, such as dentists' and doctors' offices.\nThe National Electrical Manufacturers Association (NEMA) holds the copyright to the published standard, which was developed by the DICOM Standards Committee (which includes some NEMA members. It is also known as NEMA standard PS3, and as ISO standard 12052:2017: \"Health informatics \u2013 Digital imaging and communication in medicine (DICOM) including workflow and data management\".\n\n",
            "categories": [
                "Category:All articles with incomplete citations",
                "Category:All articles with unsourced statements",
                "Category:Application layer protocols",
                "Category:Articles with incomplete citations from August 2020",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from December 2018",
                "Category:CS1 errors: external links",
                "Category:Computing in medical imaging",
                "Category:DICOM software",
                "Category:Short description matches Wikidata"
            ],
            "id": 365
        },
        {
            "title": "DigiPivot",
            "info_text": "DigiPivot is a skilling programme designed for women. It is launched by Google India.\n\n",
            "categories": [
                "Category:2020 establishments in India",
                "Category:All stub articles",
                "Category:Articles with short description",
                "Category:Google India",
                "Category:Google stubs",
                "Category:Short description matches Wikidata",
                "Category:Skill Development Programme",
                "Category:Skill Development Programme for women",
                "Category:Webarchive template wayback links"
            ],
            "id": 366
        },
        {
            "title": "Cache language model",
            "info_text": "A cache language model is a type of statistical language model. These occur in the natural language processing subfield of computer science and assign probabilities to given sequences of words by means of a probability distribution. Statistical language models are key components of  speech recognition systems and of many machine translation systems: they tell such systems which possible output word sequences are probable and which are improbable. The particular characteristic of a cache language model is that it contains a cache component and assigns relatively high probabilities to words or word sequences that occur elsewhere in a given text. The primary, but by no means sole, use of cache language models is in speech recognition systems.\nTo understand why it is a good idea for a statistical language model to contain a cache component one might consider someone who is dictating a letter about elephants to a speech recognition system. Standard (non-cache) N-gram language models will assign a very low probability to the word \"elephant\" because it is a very rare word in English. If the speech recognition system does not contain a cache component, the person dictating the letter may be annoyed: each time the word \"elephant\" is spoken another sequence of words with a higher probability according to the N-gram language model may be recognized (e.g., \"tell a plan\"). These erroneous sequences will have to be deleted manually and replaced in the text by \"elephant\" each time \"elephant\" is spoken. If the system has a cache language model, \"elephant\" will still probably be misrecognized the first time it is spoken and will have to be entered into the text manually; however, from this point on the system is aware that \"elephant\" is likely to occur again \u2013 the estimated probability of occurrence of \"elephant\" has been increased, making it more likely that if it is spoken it will be recognized correctly. Once \"elephant\" has occurred several times, the system is likely to recognize it correctly every time it is spoken until the letter has been completely dictated. This increase in the probability assigned to the occurrence of \"elephant\" is an example of a consequence of machine learning and more specifically of pattern recognition.\nThere exist variants of the cache language model in which not only single words but also multi-word sequences that have occurred previously are assigned higher probabilities (e.g., if \"San Francisco\" occurred near the beginning of the text subsequent instances of it would be assigned a higher probability).\nThe cache language model was first proposed in a paper published in 1990, after which the IBM speech-recognition group experimented with the concept. The group found that implementation of a form of cache language model yielded a 24% drop in word-error rates once the first few hundred words of a document had been dictated. A detailed survey of language modeling techniques concluded that the cache language model was one of the few new language modeling techniques that yielded improvements over the standard N-gram approach: \"Our caching results show that caching is by far the most useful technique for perplexity reduction at small and medium training data sizes\".\nThe development of the cache language model has generated considerable interest among those concerned with computational linguistics in general and statistical natural language processing in particular: recently, there has been interest in applying the cache language model in the field of statistical machine translation.\nThe success of the cache language model in improving word prediction rests on the human tendency to use words in a \"bursty\" fashion: when one is discussing a certain topic in a certain context, the frequency with which one uses certain words will be quite different from their frequencies when one is discussing other topics in other contexts. The traditional N-gram language models, which rely entirely on information from a very small number (four, three, or two) of words preceding the word to which a probability is to be assigned, do not adequately model this \"burstiness\".\nRecently, the cache language model concept \u2013 originally conceived for the N-gram statistical language model paradigm \u2013 has been adapted for use in the neural paradigm. For instance, recent work on continuous cache language models in the recurrent neural network (RNN) setting has applied the cache concept to much larger contexts than before, yielding significant reductions in perplexity. Another recent line of research involves incorporating a cache component in a feed-forward neural language model (FN-LM) to achieve rapid domain adaptation.\n\n",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles with unsourced statements from September 2011",
                "Category:Computational linguistics",
                "Category:Language modeling",
                "Category:Machine translation",
                "Category:Natural language processing",
                "Category:Speech processing",
                "Category:Speech recognition"
            ],
            "id": 367
        },
        {
            "title": "2018 Google walkouts",
            "info_text": "The 2018 Google walkouts occurred on November 1, 2018 at approximately 11 am. The walkout had a large number of participants. The employees demanded five concrete changes from the company: an end to forced arbitration; a commitment to end pay inequality; a transparent sexual harassment report; an inclusive process for reporting sexual misconduct; and elevate the Chief of Diversity to answer directly to the CEO and create an Employee Representative. A majority of the known organizers have left the company since the walkout and many continue to voice their concerns. Google agreed to end forced arbitration and create a private report of sexual assault, but has not provided any further details about the other demands.\n\n",
            "categories": [
                "Category:2018 protests",
                "Category:All Wikipedia articles in need of updating",
                "Category:All Wikipedia articles written in American English",
                "Category:Andy Rubin",
                "Category:Articles containing video clips",
                "Category:Articles with short description",
                "Category:CS1 maint: multiple names: authors list",
                "Category:Commons category link from Wikidata",
                "Category:Criticism of Google",
                "Category:History of Google"
            ],
            "id": 368
        },
        {
            "title": "URL",
            "info_text": "A uniform resource locator (URL), colloquially known as an address on the Web, is a reference to a resource that specifies its location on a computer network and a mechanism for retrieving it. A URL is a specific type of Uniform Resource Identifier (URI), although many people use the two terms interchangeably. URLs occur most commonly to reference web pages (HTTP/HTTPS) but are also used for file transfer (FTP), email (mailto), database access (JDBC), and many other applications.\nMost web browsers display the URL of a web page above the page in an address bar. A typical URL could have the form http://www.example.com/index.html, which indicates a protocol (http), a hostname (www.example.com), and a file name (index.html).",
            "categories": [
                "Category:Articles with short description",
                "Category:Identifiers",
                "Category:Internet properties established in 1994",
                "Category:Short description matches Wikidata",
                "Category:URL",
                "Category:Use dmy dates from May 2020",
                "Category:Wikipedia indefinitely semi-protected pages"
            ],
            "id": 369
        },
        {
            "title": "Organochromium chemistry",
            "info_text": "Organochromium chemistry is a branch of organometallic chemistry that deals with organic compounds containing a chromium to carbon bond and their reactions. The field is of some relevance to organic synthesis. The relevant oxidation states for organochromium complexes encompass the entire range of possible oxidation states from \u20134 (d10) in Na4[Cr\u2013IV(CO)4] to +6 (d0) in oxo-alkyl complexes like Cp*CrVI(=O)2Me.",
            "categories": [
                "Category:Organochromium compounds"
            ],
            "id": 370
        },
        {
            "title": "T. S. Eliot",
            "info_text": "Thomas Stearns Eliot  (26 September 1888 \u2013 4 January 1965) was a poet, essayist and playwright. He was a leading figure in English-language Modernist poetry where he reinvigorated the art through his use of language, writing style, and verse structure. He is also noted for his critical essays, which often re-evaluated long-held cultural beliefs.\nBorn in St. Louis, Missouri, to a prominent Boston Brahmin family, he moved to England in 1914 at the age of 25 and went on to settle, work, and marry there. He became a British subject in 1927 at the age of 39 and renounced his American citizenship.\nEliot first attracted widespread attention for his poem \"The Love Song of J. Alfred Prufrock\" from 1914 to 1915, which, at the time of its publication, was considered outlandish. It was followed by The Waste Land (1922), \"The Hollow Men\" (1925), \"Ash Wednesday\" (1930), and Four Quartets (1943). He wrote seven plays, notably Murder in the Cathedral (1935) and The Cocktail Party (1949). He was awarded the 1948 Nobel Prize in Literature, \"for his outstanding, pioneer contribution to present-day poetry\".",
            "categories": [
                "Category:1888 births",
                "Category:1965 deaths",
                "Category:20th-century American dramatists and playwrights",
                "Category:20th-century American essayists",
                "Category:20th-century American male writers",
                "Category:20th-century American poets",
                "Category:20th-century American writers",
                "Category:20th-century British essayists",
                "Category:20th-century British male writers",
                "Category:20th-century British poets"
            ],
            "id": 371
        },
        {
            "title": "ISO 5964",
            "info_text": "ISO 5964 was the ISO standard for the establishment and development of multilingual thesauri.  Its full title was Guidelines for the establishment and development of multilingual thesauri.  It was withdrawn in 2011, when replaced by ISO 25964-1. See more explanation on the official website for ISO 25964",
            "categories": [
                "Category:All stub articles",
                "Category:Articles with short description",
                "Category:ISO standards",
                "Category:Short description matches Wikidata",
                "Category:Standards and measurement stubs"
            ],
            "id": 372
        },
        {
            "title": "Jarvis Island",
            "info_text": "Jarvis Island (; formerly known as Bunker Island or Bunker's Shoal) is an uninhabited 4.5 km2 (1.7 sq mi) coral island located in the South Pacific Ocean, about halfway between Hawaii and the Cook Islands. It is an unincorporated, unorganized territory of the United States, administered by the United States Fish and Wildlife Service of the United States Department of the Interior as part of the National Wildlife Refuge system. Unlike most coral atolls, the lagoon on Jarvis is wholly dry.\nJarvis is one of the Line Islands and, for statistical purposes, is also grouped as one of the United States Minor Outlying Islands. Jarvis Island is the largest of three U.S. equatorial possessions, which include Baker Island and Howland Island.\nThe US claimed it in the 19th century and mined it for guano. In the 20th century, it was the subject of a small settlement. It was attacked during WW2 and evacuated, leaving some buildings and a day beacon. In modern times, it is managed as a nature reserve.",
            "categories": [
                "Category:1889 establishments in the British Empire",
                "Category:All articles using infobox lighthouse",
                "Category:Articles containing Hawaiian-language text",
                "Category:Articles with short description",
                "Category:Coordinates on Wikidata",
                "Category:Coral islands",
                "Category:Former populated places in Oceania",
                "Category:Important Bird Areas of United States Minor Outlying Islands",
                "Category:Important Bird Areas of the Line Islands",
                "Category:Infobox mapframe without OSM relation ID on Wikidata"
            ],
            "id": 373
        },
        {
            "title": "ColorOS",
            "info_text": "ColorOS is a user interface created by Oppo based on the Android Open Source Project. Initially, Realme phones used ColorOS until it was replaced by Realme UI in 2020. Realme UI uses some of ColorOS's apps. Starting from the OnePlus 9 series, OnePlus will preinstall ColorOS on all smartphones that are sold in mainland China instead of HydrogenOS (Chinese version of OxygenOS).\nThe first version of ColorOS was launched in September 2013. Oppo had released plenty of Android smartphones before then. It was not stock Android, but Oppo did not label it as ColorOS. Over the years, Oppo launched new official versions of the operating system. To make things less confusing, in 2020 the company revealed that it would adopt the same numbering scheme as mainline Android, and as such, ColorOS jumped from ColorOS 7 to ColorOS 11 with the launch of Android 11.\nIt was announced that ColorOS, OnePlus' Oxygen OS, and Realme UI will merge to form a single Android skin that will appear on all OnePlus, Oppo and Realme UI phones. However these plans were cancelled as the three UI's are being developed on the same codebase, but they are separate.\n\n",
            "categories": [
                "Category:ARM operating systems",
                "Category:All stub articles",
                "Category:Android (operating system)",
                "Category:Android (operating system) forks",
                "Category:Articles with short description",
                "Category:Custom Android firmware",
                "Category:Linux distributions",
                "Category:Mobile Linux",
                "Category:Operating system stubs",
                "Category:Short description is different from Wikidata"
            ],
            "id": 374
        },
        {
            "title": "Diffusion map",
            "info_text": "Diffusion maps is a dimensionality reduction or feature extraction algorithm introduced by Coifman and Lafon  which computes a family of embeddings of a data set into Euclidean space (often low-dimensional) whose coordinates can be computed from the eigenvectors and eigenvalues of a diffusion operator on the data. The Euclidean distance between points in the embedded space is equal to the \"diffusion distance\" between probability distributions centered at those points. Different from linear dimensionality reduction methods such as principal component analysis (PCA), diffusion maps are part of the family of nonlinear dimensionality reduction methods which focus on discovering the underlying manifold that the data has been sampled from. By integrating local similarities at different scales, diffusion maps give a global description of the data-set. Compared with other methods, the diffusion map algorithm is robust to noise perturbation and computationally inexpensive.\n\n",
            "categories": [
                "Category:Machine learning algorithms"
            ],
            "id": 375
        },
        {
            "title": "Xite",
            "info_text": "XITE (pronounced \"excite\") is a Dutch interactive music video platform founded in the Netherlands. The service operates linear and interactive television networks, and on-demand streaming services.\nXITE-branded services are currently available in the Netherlands, Belgium, Germany, the U.S., Canada, the United Kingdom and Ireland. In the U.S., Xite is available via Amazon Fire TV, Apple TV and Roku; as well as Comcast Xfinity and some Samsung TVs. Since December 2015, XITE's interactive TV app has been available on Ziggo in the Netherlands, and Ooredoo in Qatar.",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All articles with unsourced statements",
                "Category:Articles containing explicitly cited English-language text",
                "Category:Articles needing additional references from July 2024",
                "Category:Articles using infobox television channel",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from November 2020",
                "Category:CS1 Dutch-language sources (nl)",
                "Category:Music organisations based in the Netherlands",
                "Category:Music television channels"
            ],
            "id": 376
        },
        {
            "title": "BufferBox",
            "info_text": "BufferBox Inc. was a Canadian startup from the University of Waterloo, Ontario, Canada that leveraged parcel kiosks to provide consumers the convenience of picking up their online purchases 24/7. Founded by Jay Shah, Aditya Bali and Mike McCauley, BufferBox's mission was to make missed delivery notices a thing of the past. When consumers signed up for the service, they received a unique 'BufferBox address' to use as their shipping address when shopping online. Members then received an email notification with a unique unlock code as soon as their package was delivered which enabled them to pick up their package from their local BufferBox.\n\n",
            "categories": [
                "Category:2012 mergers and acquisitions",
                "Category:Articles with short description",
                "Category:Commons category link is on Wikidata",
                "Category:Companies based in Toronto",
                "Category:Google acquisitions",
                "Category:Short description matches Wikidata",
                "Category:Technology companies disestablished in 2014",
                "Category:Technology companies established in 2011",
                "Category:Transport companies disestablished in 2014",
                "Category:Transport companies established in 2011"
            ],
            "id": 377
        },
        {
            "title": "Rectal thermometry",
            "info_text": "Rectal thermometry is taking a person's temperature by inserting a thermometer into the rectum via the anus. This is generally regarded as the most accurate means of temperature-taking, but some may consider it to be an invasive or humiliating procedure. Thus, it is often used sparingly and primarily on infants, children, or adults for whom taking an oral temperature would risk injury (e.g., an unconscious patient, a post-oral surgery patient, or a person suffering a seizure) or be inaccurate (due to recently ingested liquids or breathing through the mouth).\n\n",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All articles that may contain original research",
                "Category:All articles with unsourced statements",
                "Category:Articles needing additional references from September 2019",
                "Category:Articles that may contain original research from April 2010",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from December 2023",
                "Category:Articles with unsourced statements from September 2019",
                "Category:Medical tests",
                "Category:Rectum"
            ],
            "id": 378
        },
        {
            "title": "Monte Carlo molecular modeling",
            "info_text": "Monte Carlo molecular modelling is the application of Monte Carlo methods to molecular problems. These problems can also be modelled by the molecular dynamics method. The difference is that this approach relies on equilibrium statistical mechanics rather than molecular dynamics. Instead of trying to reproduce the dynamics of a system, it generates states according to appropriate Boltzmann distribution. Thus, it is the application of the Metropolis Monte Carlo simulation to molecular systems. It is therefore also a particular subset of the more\ngeneral Monte Carlo method in statistical physics.\nIt employs a Markov chain procedure in order to determine a new state for a system from a previous one. According to its stochastic nature, this new state is accepted at random. Each trial usually counts as\na move. The avoidance of dynamics restricts the method to studies of static quantities only, but the freedom to choose moves makes the method very flexible. These moves must only satisfy a basic condition of\nbalance in order for the equilibrium to be properly described, but detailed balance, a stronger condition,\nis usually imposed when designing new algorithms. An additional advantage is that some systems, such as the Ising model, lack a dynamical description and are only defined by an energy prescription; for these the Monte Carlo approach is the only one feasible.\nThe great success of this method in statistical mechanics has led to various generalizations such as the method of simulated annealing for optimization, in which a fictitious temperature is introduced and then gradually lowered.\nA range of software packages have been developed specifically for the use of the Metropolis Monte Carlo method on molecular simulations. These include:\n\nBOSS\nCP2K\nMCPro\nSire\nProtoMS\nFaunus\n\n",
            "categories": [
                "Category:Molecular modelling",
                "Category:Monte Carlo methods",
                "Category:Stochastic models",
                "Category:Theoretical chemistry",
                "Category:Webarchive template wayback links"
            ],
            "id": 379
        },
        {
            "title": "Covalent bond",
            "info_text": "A covalent bond is a chemical bond that involves the sharing of electrons to form electron pairs between atoms. These electron pairs are known as shared pairs or bonding pairs. The stable balance of attractive and repulsive forces between atoms, when they share electrons, is known as covalent bonding. For many molecules, the sharing of electrons allows each atom to attain the equivalent of a full valence shell, corresponding to a stable electronic configuration. In organic chemistry, covalent bonding is much more common than ionic bonding.\nCovalent bonding also includes many kinds of interactions, including \u03c3-bonding, \u03c0-bonding, metal-to-metal bonding, agostic interactions, bent bonds, three-center two-electron bonds and three-center four-electron bonds. The term covalent bond dates from 1939. The prefix co- means jointly, associated in action, partnered to a lesser degree,  etc.; thus a \"co-valent bond\", in essence, means that the atoms share \"valence\", such as is discussed in valence bond theory.\nIn the molecule H2, the hydrogen atoms share the two electrons via covalent bonding. Covalency is greatest between atoms of similar electronegativities. Thus, covalent bonding does not necessarily require that the two atoms be of the same elements, only that they be of comparable electronegativity. Covalent bonding that entails the sharing of electrons over more than two atoms is said to be delocalized.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:Chemical bonding",
                "Category:Short description is different from Wikidata",
                "Category:Webarchive template wayback links"
            ],
            "id": 380
        },
        {
            "title": "Cloud albedo",
            "info_text": "Cloud albedo is a measure of the albedo or reflectivity of a cloud. Clouds regulate the amount of solar radiation absorbed by a planet and its solar surface irradiance. Generally, increased cloud cover correlates to a higher albedo and a lower absorption of solar energy. Cloud albedo strongly influences the Earth's energy budget, accounting for approximately half of Earth's albedo. Cloud albedo is influenced by the conditions of cloud formation and variations in cloud albedo depend on the total mass of water, the size and shape of the droplets or particles and their distribution in space. Thick clouds reflect a large amount of incoming solar radiation, translating to a high albedo. Thin clouds tend to transmit more solar radiation and, therefore, have a low albedo. Changes in cloud albedo caused by variations in cloud properties have a significant effect on global climate, having the ability to spiral into feedback loops.\n\n",
            "categories": [
                "Category:Articles with short description",
                "Category:Atmospheric radiation",
                "Category:Clouds",
                "Category:Satellite meteorology",
                "Category:Short description matches Wikidata"
            ],
            "id": 381
        },
        {
            "title": "Vogue China",
            "info_text": "Vogue China (Chinese: \u670d\u9970\u4e0e\u7f8e\u5bb9) is the Chinese edition of Vogue magazine. The magazine carries a mixture of local and foreign content. The magazine is published by Cond\u00e9 Nast in partnership with the state-owned China Pictorial Publishing House.\nThere are 16 editions of Vogue China published every year. As of November 2020, Vogue China circulated around 2 million copies. Mario Testino has described Vogue China as the world's \"most important Vogue\".",
            "categories": [
                "Category:2005 establishments in China",
                "Category:Articles containing Chinese-language text",
                "Category:Articles with Chinese-language sources (zh)",
                "Category:Articles with short description",
                "Category:CS1 maint: multiple names: authors list",
                "Category:Chinese-language magazines",
                "Category:Cond\u00e9 Nast magazines",
                "Category:Fashion magazines published in China",
                "Category:Magazines established in 2005",
                "Category:Magazines published in Beijing"
            ],
            "id": 382
        },
        {
            "title": "Inverse problem",
            "info_text": "An inverse problem in science is the process of calculating from a set of observations the causal factors that produced them: for example, calculating an image in X-ray computed tomography, source reconstruction in acoustics, or calculating the density of the Earth from measurements of its gravity field. It is called an inverse problem because it starts with the effects and then calculates the causes. It is the inverse of a forward problem, which starts with the causes and then calculates the effects.\nInverse problems are some of the most important mathematical problems in science and mathematics because they tell us about parameters that we cannot directly observe. They can be found in system identification, optics, radar, acoustics, communication theory, signal processing, medical imaging, computer vision, geophysics, oceanography, astronomy, remote sensing, natural language processing, machine learning, nondestructive testing, slope stability analysis and many other fields.",
            "categories": [
                "Category:All articles with dead external links",
                "Category:All articles with unsourced statements",
                "Category:Articles with dead external links from March 2024",
                "Category:Articles with permanently dead external links",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from November 2019",
                "Category:Articles with unsourced statements from September 2020",
                "Category:CS1 maint: location",
                "Category:Inverse problems",
                "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link"
            ],
            "id": 383
        },
        {
            "title": "1080p",
            "info_text": "1080p (1920 \u00d7 1080 progressively displayed pixels; also known as Full HD or FHD, and BT.709) is a set of HDTV high-definition video modes characterized by 1,920 pixels displayed across the screen horizontally and 1,080 pixels down the screen vertically; the p stands for progressive scan, i.e. non-interlaced. The term usually assumes a widescreen aspect ratio of 16:9, implying a resolution of 2.1 megapixels. It is often marketed as Full HD or FHD, to contrast 1080p with 720p resolution screens. Although 1080p is sometimes referred to as 2K resolution (meaning having a horizontal resolution of approximately 2,000 pixels), other sources differentiate between 1080p and (true) 2K resolution.\n1080p video signals are supported by ATSC standards in the United States and DVB standards in Europe. Applications of the 1080p standard include television broadcasts, Blu-ray Discs, smartphones, Internet content such as YouTube videos and Netflix TV shows and movies, consumer-grade televisions and projectors, computer monitors and video game consoles. Small camcorders, smartphones and digital cameras can capture still and moving images in 1080p (sometimes 4K, or even 8K) resolution.\n\n",
            "categories": [
                "Category:All articles needing additional references",
                "Category:All articles with unsourced statements",
                "Category:Articles needing additional references from April 2023",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from December 2015",
                "Category:Articles with unsourced statements from February 2019",
                "Category:Short description is different from Wikidata",
                "Category:Television terminology",
                "Category:Use mdy dates from March 2024",
                "Category:Video formats"
            ],
            "id": 384
        },
        {
            "title": "Encyclop\u00e6dia Britannica",
            "info_text": "The Encyclop\u00e6dia Britannica (Latin for 'British Encyclopaedia') is a general knowledge English-language encyclopaedia. It has been published by Encyclop\u00e6dia Britannica, Inc. since 1768, although the company has changed ownership seven times. The 2010 version of the 15th edition, which spans 32 volumes and 32,640 pages, was the last printed edition. Since 2016, it has been published exclusively as an online encyclopaedia.\nPrinted for 244 years, the Britannica was the longest-running in-print encyclopaedia in the English language. It was first published between 1768 and 1771 in Edinburgh, Scotland, in three volumes. The encyclopaedia grew in size; the second edition was 10 volumes, and by its fourth edition (1801\u20131810), it had expanded to 20 volumes. Its rising stature as a scholarly work helped recruit eminent contributors, and the 9th (1875\u20131889) and 11th editions (1911) are landmark encyclopaedias for scholarship and literary style. Starting with the 11th edition and following its acquisition by an American firm, the Britannica shortened and simplified articles to broaden its appeal to the North American market. \nIn 1933, the Britannica became the first encyclopaedia to adopt \"continuous revision\", in which the encyclopaedia is continually reprinted, with every article updated on a schedule. In the 21st century, the Britannica suffered first from competition with the digital multimedia encyclopaedia Microsoft Encarta, and later with the online peer-produced encyclopaedia Wikipedia.\nIn March 2012, it announced it would no longer publish printed editions and would focus instead on the online version.\nThe 15th edition (1974\u20132010) has a three-part structure: a 12-volume Microp\u00e6dia of short articles (generally fewer than 750 words), a 17-volume Macrop\u00e6dia of long articles (two to 310 pages), and a single Prop\u00e6dia volume to give a hierarchical outline of knowledge. The Microp\u00e6dia was meant for quick fact-checking and as a guide to the Macrop\u00e6dia; readers are advised to study the Prop\u00e6dia outline to understand a subject's context and to find more detailed articles. Over 70 years, the size of the Britannica has remained steady, with about 40 million words on half a million topics. Though published in the United States since 1901, the Britannica has for the most part maintained British English spelling.",
            "categories": [
                "Category:1768 establishments in Scotland",
                "Category:1768 non-fiction books",
                "Category:All Wikipedia articles in need of updating",
                "Category:All articles containing potentially dated statements",
                "Category:All articles needing rewrite",
                "Category:All articles that may contain original research",
                "Category:All articles with dead external links",
                "Category:All articles with unsourced statements",
                "Category:American encyclopedias",
                "Category:American online encyclopedias"
            ],
            "id": 385
        },
        {
            "title": "Minnesota Territory",
            "info_text": "The Territory of Minnesota was an organized incorporated territory of the United States that existed from March 3, 1849, until May 11, 1858, when the eastern portion of the territory was admitted to the Union as the State of Minnesota and the western portion became unorganized territory and shortly after was reorganized as part of the Dakota Territory.",
            "categories": [
                "Category:1849 establishments in Minnesota Territory",
                "Category:1858 disestablishments in the United States",
                "Category:All Wikipedia articles written in American English",
                "Category:Articles with short description",
                "Category:Commons category link is on Wikidata",
                "Category:Coordinates on Wikidata",
                "Category:Former country articles requiring maintenance",
                "Category:Former organized territories of the United States",
                "Category:Minnesota Territory",
                "Category:Pages using gadget WikiMiniAtlas"
            ],
            "id": 386
        },
        {
            "title": "1998 San Jose Clash season",
            "info_text": "The 1998 San Jose Clash season was the third season of the team's existence.",
            "categories": [
                "Category:1998 in sports in California",
                "Category:American soccer clubs 1998 season",
                "Category:Articles with short description",
                "Category:CS1 maint: archived copy as title",
                "Category:San Jose Earthquakes seasons",
                "Category:Short description is different from Wikidata",
                "Category:Use mdy dates from August 2023"
            ],
            "id": 387
        },
        {
            "title": "Global Biodiversity Information Facility",
            "info_text": "The Global Biodiversity Information Facility (GBIF) is an international organisation that focuses on making scientific data on biodiversity available via the Internet using web services. The data are provided by many institutions from around the world; GBIF's information architecture makes these data accessible and searchable through a single portal. Data available through the GBIF portal are primarily distribution data on plants, animals, fungi, and microbes for the world, and scientific names data.\nThe mission of the GBIF is to facilitate free and open access to biodiversity data worldwide to underpin sustainable development. Priorities, with an emphasis on promoting participation and working through partners, include mobilising biodiversity data, developing protocols and standards to ensure scientific integrity and interoperability, building an informatics architecture to allow the interlinking of diverse data types from disparate sources, promoting capacity building and catalysing development of analytical tools for improved decision-making.\nGBIF strives to form informatics linkages among digital data resources from across the spectrum of biological organisation, from genes to ecosystems, and to connect these to issues important to science, society and sustainability by using georeferencing and GIS tools. It works in partnership with other international organisations such as the Catalogue of Life partnership, Biodiversity Information Standards, the Consortium for the Barcode of Life (CBOL), the Encyclopedia of Life (EOL), and GEOSS. The biodiversity data available through the GBIF has increased by more than 1,150% in the past decade, partially due to the participation of citizen scientists.\nFrom 2002 to 2014, GBIF awarded a prestigious annual global award in the area of biodiversity informatics, the Ebbe Nielsen Prize, valued at \u20ac30,000. As of 2018, the GBIF Secretariat presents two annual prizes: the GBIF Ebbe Nielsen Challenge and the Young Researchers Award.",
            "categories": [
                "Category:All articles containing potentially dated statements",
                "Category:All articles lacking in-text citations",
                "Category:Articles containing potentially dated statements from 2018",
                "Category:Articles containing potentially dated statements from June 2020",
                "Category:Articles lacking in-text citations from November 2021",
                "Category:Articles with short description",
                "Category:Biodiversity",
                "Category:Biodiversity databases",
                "Category:Commons category link is on Wikidata",
                "Category:Ecology organizations"
            ],
            "id": 388
        },
        {
            "title": "Emmett Reid Dunn",
            "info_text": "Emmett Reid Dunn (November 21, 1894 \u2013 February 13, 1956) was an American herpetologist and educator who worked in Panama and studied salamanders in the Eastern United States.\n\n",
            "categories": [
                "Category:1894 births",
                "Category:1956 deaths",
                "Category:20th-century American botanists",
                "Category:20th-century American zoologists",
                "Category:All stub articles",
                "Category:American herpetologists",
                "Category:American taxonomists",
                "Category:American zoologist stubs",
                "Category:Articles with Internet Archive links",
                "Category:Articles with hCards"
            ],
            "id": 389
        },
        {
            "title": "Isabella Karle",
            "info_text": "Isabella Karle (December 2, 1921 \u2013 October 3, 2017) was an American chemist who was instrumental in developing techniques to extract plutonium chloride from a mixture containing plutonium oxide. For her scientific work, Karle received the Garvan\u2013Olin Medal, Gregori Aminoff Prize, Bower Award, National Medal of Science, and the Navy Distinguished Civilian Service Award (which is the Navy's highest form of recognition to civilian employees).\n\n",
            "categories": [
                "Category:1921 births",
                "Category:2017 deaths",
                "Category:American biophysicists",
                "Category:American crystallographers",
                "Category:American physical chemists",
                "Category:American women chemists",
                "Category:Articles with hCards",
                "Category:Articles with short description",
                "Category:Bijvoet Medal recipients",
                "Category:Commons category link is on Wikidata"
            ],
            "id": 390
        },
        {
            "title": "Group 9 element",
            "info_text": "Group 9, by modern IUPAC numbering, is a group (column) of chemical elements in the d-block of the periodic table. Members of Group 9 include cobalt (Co), rhodium (Rh), iridium (Ir) and meitnerium (Mt). These elements are among the rarest of the transition metals.\nLike other groups, the members of this family show patterns in electron configuration, especially in the outermost shells, resulting in trends in chemical behavior; however, rhodium deviates from the pattern.",
            "categories": [
                "Category:All articles with unsourced statements",
                "Category:Articles containing Greek-language text",
                "Category:Articles with short description",
                "Category:Articles with unsourced statements from March 2022",
                "Category:Groups (periodic table)",
                "Category:Short description matches Wikidata"
            ],
            "id": 391
        }
    ],
    "edges": [
        {
            "source": 0,
            "target": 1
        },
        {
            "source": 0,
            "target": 2
        },
        {
            "source": 0,
            "target": 3
        },
        {
            "source": 0,
            "target": 4
        },
        {
            "source": 0,
            "target": 5
        },
        {
            "source": 0,
            "target": 6
        },
        {
            "source": 0,
            "target": 7
        },
        {
            "source": 0,
            "target": 8
        },
        {
            "source": 0,
            "target": 9
        },
        {
            "source": 0,
            "target": 10
        },
        {
            "source": 0,
            "target": 11
        },
        {
            "source": 0,
            "target": 12
        },
        {
            "source": 0,
            "target": 13
        },
        {
            "source": 0,
            "target": 14
        },
        {
            "source": 0,
            "target": 15
        },
        {
            "source": 0,
            "target": 16
        },
        {
            "source": 0,
            "target": 17
        },
        {
            "source": 0,
            "target": 18
        },
        {
            "source": 0,
            "target": 19
        },
        {
            "source": 0,
            "target": 20
        },
        {
            "source": 0,
            "target": 21
        },
        {
            "source": 0,
            "target": 22
        },
        {
            "source": 0,
            "target": 23
        },
        {
            "source": 0,
            "target": 24
        },
        {
            "source": 0,
            "target": 25
        },
        {
            "source": 0,
            "target": 26
        },
        {
            "source": 0,
            "target": 27
        },
        {
            "source": 0,
            "target": 28
        },
        {
            "source": 0,
            "target": 29
        },
        {
            "source": 0,
            "target": 30
        },
        {
            "source": 0,
            "target": 31
        },
        {
            "source": 0,
            "target": 32
        },
        {
            "source": 0,
            "target": 33
        },
        {
            "source": 0,
            "target": 34
        },
        {
            "source": 0,
            "target": 35
        },
        {
            "source": 0,
            "target": 36
        },
        {
            "source": 0,
            "target": 37
        },
        {
            "source": 0,
            "target": 38
        },
        {
            "source": 0,
            "target": 39
        },
        {
            "source": 0,
            "target": 40
        },
        {
            "source": 0,
            "target": 41
        },
        {
            "source": 0,
            "target": 42
        },
        {
            "source": 0,
            "target": 43
        },
        {
            "source": 0,
            "target": 44
        },
        {
            "source": 0,
            "target": 45
        },
        {
            "source": 0,
            "target": 46
        },
        {
            "source": 0,
            "target": 47
        },
        {
            "source": 0,
            "target": 48
        },
        {
            "source": 0,
            "target": 49
        },
        {
            "source": 0,
            "target": 50
        },
        {
            "source": 0,
            "target": 51
        },
        {
            "source": 0,
            "target": 52
        },
        {
            "source": 0,
            "target": 53
        },
        {
            "source": 0,
            "target": 54
        },
        {
            "source": 0,
            "target": 55
        },
        {
            "source": 0,
            "target": 56
        },
        {
            "source": 0,
            "target": 57
        },
        {
            "source": 0,
            "target": 58
        },
        {
            "source": 0,
            "target": 59
        },
        {
            "source": 0,
            "target": 60
        },
        {
            "source": 0,
            "target": 61
        },
        {
            "source": 0,
            "target": 62
        },
        {
            "source": 0,
            "target": 63
        },
        {
            "source": 0,
            "target": 64
        },
        {
            "source": 0,
            "target": 65
        },
        {
            "source": 0,
            "target": 66
        },
        {
            "source": 0,
            "target": 67
        },
        {
            "source": 0,
            "target": 68
        },
        {
            "source": 0,
            "target": 69
        },
        {
            "source": 0,
            "target": 70
        },
        {
            "source": 0,
            "target": 71
        },
        {
            "source": 0,
            "target": 72
        },
        {
            "source": 0,
            "target": 73
        },
        {
            "source": 0,
            "target": 74
        },
        {
            "source": 0,
            "target": 75
        },
        {
            "source": 0,
            "target": 76
        },
        {
            "source": 0,
            "target": 77
        },
        {
            "source": 0,
            "target": 78
        },
        {
            "source": 0,
            "target": 79
        },
        {
            "source": 0,
            "target": 80
        },
        {
            "source": 0,
            "target": 81
        },
        {
            "source": 0,
            "target": 82
        },
        {
            "source": 0,
            "target": 83
        },
        {
            "source": 0,
            "target": 84
        },
        {
            "source": 0,
            "target": 85
        },
        {
            "source": 0,
            "target": 86
        },
        {
            "source": 0,
            "target": 87
        },
        {
            "source": 0,
            "target": 88
        },
        {
            "source": 0,
            "target": 89
        },
        {
            "source": 0,
            "target": 90
        },
        {
            "source": 0,
            "target": 91
        },
        {
            "source": 0,
            "target": 92
        },
        {
            "source": 0,
            "target": 93
        },
        {
            "source": 0,
            "target": 94
        },
        {
            "source": 0,
            "target": 95
        },
        {
            "source": 0,
            "target": 96
        },
        {
            "source": 0,
            "target": 97
        },
        {
            "source": 0,
            "target": 98
        },
        {
            "source": 0,
            "target": 99
        },
        {
            "source": 0,
            "target": 100
        },
        {
            "source": 1,
            "target": 25
        },
        {
            "source": 2,
            "target": 35
        },
        {
            "source": 2,
            "target": 193
        },
        {
            "source": 2,
            "target": 194
        },
        {
            "source": 3,
            "target": 19
        },
        {
            "source": 3,
            "target": 27
        },
        {
            "source": 3,
            "target": 191
        },
        {
            "source": 4,
            "target": 8
        },
        {
            "source": 4,
            "target": 21
        },
        {
            "source": 4,
            "target": 45
        },
        {
            "source": 4,
            "target": 35
        },
        {
            "source": 4,
            "target": 15
        },
        {
            "source": 4,
            "target": 75
        },
        {
            "source": 4,
            "target": 71
        },
        {
            "source": 4,
            "target": 47
        },
        {
            "source": 4,
            "target": 52
        },
        {
            "source": 4,
            "target": 0
        },
        {
            "source": 4,
            "target": 36
        },
        {
            "source": 4,
            "target": 50
        },
        {
            "source": 4,
            "target": 69
        },
        {
            "source": 4,
            "target": 80
        },
        {
            "source": 4,
            "target": 10
        },
        {
            "source": 4,
            "target": 38
        },
        {
            "source": 4,
            "target": 62
        },
        {
            "source": 4,
            "target": 25
        },
        {
            "source": 4,
            "target": 40
        },
        {
            "source": 4,
            "target": 48
        },
        {
            "source": 4,
            "target": 65
        },
        {
            "source": 4,
            "target": 67
        },
        {
            "source": 4,
            "target": 77
        },
        {
            "source": 4,
            "target": 11
        },
        {
            "source": 4,
            "target": 19
        },
        {
            "source": 4,
            "target": 23
        },
        {
            "source": 4,
            "target": 27
        },
        {
            "source": 4,
            "target": 173
        },
        {
            "source": 5,
            "target": 21
        },
        {
            "source": 5,
            "target": 6
        },
        {
            "source": 5,
            "target": 78
        },
        {
            "source": 5,
            "target": 44
        },
        {
            "source": 5,
            "target": 96
        },
        {
            "source": 5,
            "target": 45
        },
        {
            "source": 5,
            "target": 35
        },
        {
            "source": 5,
            "target": 46
        },
        {
            "source": 5,
            "target": 12
        },
        {
            "source": 5,
            "target": 4
        },
        {
            "source": 5,
            "target": 47
        },
        {
            "source": 5,
            "target": 99
        },
        {
            "source": 5,
            "target": 0
        },
        {
            "source": 5,
            "target": 79
        },
        {
            "source": 5,
            "target": 43
        },
        {
            "source": 5,
            "target": 50
        },
        {
            "source": 5,
            "target": 69
        },
        {
            "source": 5,
            "target": 80
        },
        {
            "source": 5,
            "target": 94
        },
        {
            "source": 5,
            "target": 51
        },
        {
            "source": 5,
            "target": 10
        },
        {
            "source": 5,
            "target": 38
        },
        {
            "source": 5,
            "target": 41
        },
        {
            "source": 5,
            "target": 25
        },
        {
            "source": 5,
            "target": 40
        },
        {
            "source": 5,
            "target": 98
        },
        {
            "source": 5,
            "target": 48
        },
        {
            "source": 5,
            "target": 65
        },
        {
            "source": 5,
            "target": 76
        },
        {
            "source": 5,
            "target": 11
        },
        {
            "source": 5,
            "target": 57
        },
        {
            "source": 5,
            "target": 32
        },
        {
            "source": 5,
            "target": 31
        },
        {
            "source": 5,
            "target": 23
        },
        {
            "source": 5,
            "target": 39
        },
        {
            "source": 5,
            "target": 60
        },
        {
            "source": 5,
            "target": 16
        },
        {
            "source": 5,
            "target": 68
        },
        {
            "source": 5,
            "target": 59
        },
        {
            "source": 5,
            "target": 27
        },
        {
            "source": 5,
            "target": 28
        },
        {
            "source": 5,
            "target": 115
        },
        {
            "source": 6,
            "target": 35
        },
        {
            "source": 6,
            "target": 17
        },
        {
            "source": 6,
            "target": 25
        },
        {
            "source": 6,
            "target": 27
        },
        {
            "source": 6,
            "target": 121
        },
        {
            "source": 6,
            "target": 125
        },
        {
            "source": 7,
            "target": 25
        },
        {
            "source": 7,
            "target": 27
        },
        {
            "source": 7,
            "target": 22
        },
        {
            "source": 7,
            "target": 101
        },
        {
            "source": 7,
            "target": 107
        },
        {
            "source": 7,
            "target": 109
        },
        {
            "source": 7,
            "target": 172
        },
        {
            "source": 7,
            "target": 190
        },
        {
            "source": 8,
            "target": 35
        },
        {
            "source": 8,
            "target": 15
        },
        {
            "source": 8,
            "target": 75
        },
        {
            "source": 8,
            "target": 71
        },
        {
            "source": 8,
            "target": 4
        },
        {
            "source": 8,
            "target": 0
        },
        {
            "source": 8,
            "target": 36
        },
        {
            "source": 8,
            "target": 38
        },
        {
            "source": 8,
            "target": 62
        },
        {
            "source": 8,
            "target": 25
        },
        {
            "source": 8,
            "target": 67
        },
        {
            "source": 8,
            "target": 77
        },
        {
            "source": 8,
            "target": 11
        },
        {
            "source": 8,
            "target": 27
        },
        {
            "source": 9,
            "target": 25
        },
        {
            "source": 9,
            "target": 27
        },
        {
            "source": 10,
            "target": 21
        },
        {
            "source": 10,
            "target": 6
        },
        {
            "source": 10,
            "target": 78
        },
        {
            "source": 10,
            "target": 44
        },
        {
            "source": 10,
            "target": 96
        },
        {
            "source": 10,
            "target": 45
        },
        {
            "source": 10,
            "target": 35
        },
        {
            "source": 10,
            "target": 46
        },
        {
            "source": 10,
            "target": 12
        },
        {
            "source": 10,
            "target": 4
        },
        {
            "source": 10,
            "target": 47
        },
        {
            "source": 10,
            "target": 99
        },
        {
            "source": 10,
            "target": 0
        },
        {
            "source": 10,
            "target": 36
        },
        {
            "source": 10,
            "target": 79
        },
        {
            "source": 10,
            "target": 43
        },
        {
            "source": 10,
            "target": 50
        },
        {
            "source": 10,
            "target": 69
        },
        {
            "source": 10,
            "target": 80
        },
        {
            "source": 10,
            "target": 94
        },
        {
            "source": 10,
            "target": 51
        },
        {
            "source": 10,
            "target": 38
        },
        {
            "source": 10,
            "target": 5
        },
        {
            "source": 10,
            "target": 41
        },
        {
            "source": 10,
            "target": 25
        },
        {
            "source": 10,
            "target": 40
        },
        {
            "source": 10,
            "target": 98
        },
        {
            "source": 10,
            "target": 48
        },
        {
            "source": 10,
            "target": 65
        },
        {
            "source": 10,
            "target": 76
        },
        {
            "source": 10,
            "target": 11
        },
        {
            "source": 10,
            "target": 57
        },
        {
            "source": 10,
            "target": 32
        },
        {
            "source": 10,
            "target": 31
        },
        {
            "source": 10,
            "target": 34
        },
        {
            "source": 10,
            "target": 23
        },
        {
            "source": 10,
            "target": 39
        },
        {
            "source": 10,
            "target": 60
        },
        {
            "source": 10,
            "target": 16
        },
        {
            "source": 10,
            "target": 68
        },
        {
            "source": 10,
            "target": 59
        },
        {
            "source": 10,
            "target": 27
        },
        {
            "source": 10,
            "target": 28
        },
        {
            "source": 10,
            "target": 184
        },
        {
            "source": 11,
            "target": 8
        },
        {
            "source": 11,
            "target": 21
        },
        {
            "source": 11,
            "target": 6
        },
        {
            "source": 11,
            "target": 78
        },
        {
            "source": 11,
            "target": 44
        },
        {
            "source": 11,
            "target": 96
        },
        {
            "source": 11,
            "target": 45
        },
        {
            "source": 11,
            "target": 35
        },
        {
            "source": 11,
            "target": 15
        },
        {
            "source": 11,
            "target": 75
        },
        {
            "source": 11,
            "target": 46
        },
        {
            "source": 11,
            "target": 71
        },
        {
            "source": 11,
            "target": 12
        },
        {
            "source": 11,
            "target": 4
        },
        {
            "source": 11,
            "target": 47
        },
        {
            "source": 11,
            "target": 99
        },
        {
            "source": 11,
            "target": 0
        },
        {
            "source": 11,
            "target": 36
        },
        {
            "source": 11,
            "target": 79
        },
        {
            "source": 11,
            "target": 43
        },
        {
            "source": 11,
            "target": 50
        },
        {
            "source": 11,
            "target": 69
        },
        {
            "source": 11,
            "target": 80
        },
        {
            "source": 11,
            "target": 94
        },
        {
            "source": 11,
            "target": 51
        },
        {
            "source": 11,
            "target": 10
        },
        {
            "source": 11,
            "target": 38
        },
        {
            "source": 11,
            "target": 5
        },
        {
            "source": 11,
            "target": 41
        },
        {
            "source": 11,
            "target": 62
        },
        {
            "source": 11,
            "target": 25
        },
        {
            "source": 11,
            "target": 40
        },
        {
            "source": 11,
            "target": 98
        },
        {
            "source": 11,
            "target": 48
        },
        {
            "source": 11,
            "target": 65
        },
        {
            "source": 11,
            "target": 76
        },
        {
            "source": 11,
            "target": 67
        },
        {
            "source": 11,
            "target": 77
        },
        {
            "source": 11,
            "target": 57
        },
        {
            "source": 11,
            "target": 31
        },
        {
            "source": 11,
            "target": 23
        },
        {
            "source": 11,
            "target": 39
        },
        {
            "source": 11,
            "target": 60
        },
        {
            "source": 11,
            "target": 68
        },
        {
            "source": 11,
            "target": 59
        },
        {
            "source": 11,
            "target": 27
        },
        {
            "source": 11,
            "target": 28
        },
        {
            "source": 11,
            "target": 144
        },
        {
            "source": 12,
            "target": 25
        },
        {
            "source": 12,
            "target": 162
        },
        {
            "source": 13,
            "target": 21
        },
        {
            "source": 13,
            "target": 6
        },
        {
            "source": 13,
            "target": 78
        },
        {
            "source": 13,
            "target": 44
        },
        {
            "source": 13,
            "target": 96
        },
        {
            "source": 13,
            "target": 45
        },
        {
            "source": 13,
            "target": 35
        },
        {
            "source": 13,
            "target": 84
        },
        {
            "source": 13,
            "target": 46
        },
        {
            "source": 13,
            "target": 12
        },
        {
            "source": 13,
            "target": 4
        },
        {
            "source": 13,
            "target": 47
        },
        {
            "source": 13,
            "target": 99
        },
        {
            "source": 13,
            "target": 0
        },
        {
            "source": 13,
            "target": 79
        },
        {
            "source": 13,
            "target": 43
        },
        {
            "source": 13,
            "target": 50
        },
        {
            "source": 13,
            "target": 69
        },
        {
            "source": 13,
            "target": 80
        },
        {
            "source": 13,
            "target": 94
        },
        {
            "source": 13,
            "target": 51
        },
        {
            "source": 13,
            "target": 10
        },
        {
            "source": 13,
            "target": 38
        },
        {
            "source": 13,
            "target": 5
        },
        {
            "source": 13,
            "target": 41
        },
        {
            "source": 13,
            "target": 25
        },
        {
            "source": 13,
            "target": 40
        },
        {
            "source": 13,
            "target": 98
        },
        {
            "source": 13,
            "target": 48
        },
        {
            "source": 13,
            "target": 65
        },
        {
            "source": 13,
            "target": 76
        },
        {
            "source": 13,
            "target": 11
        },
        {
            "source": 13,
            "target": 57
        },
        {
            "source": 13,
            "target": 19
        },
        {
            "source": 13,
            "target": 32
        },
        {
            "source": 13,
            "target": 31
        },
        {
            "source": 13,
            "target": 23
        },
        {
            "source": 13,
            "target": 39
        },
        {
            "source": 13,
            "target": 54
        },
        {
            "source": 13,
            "target": 16
        },
        {
            "source": 13,
            "target": 68
        },
        {
            "source": 13,
            "target": 59
        },
        {
            "source": 13,
            "target": 27
        },
        {
            "source": 13,
            "target": 28
        },
        {
            "source": 14,
            "target": 25
        },
        {
            "source": 15,
            "target": 8
        },
        {
            "source": 15,
            "target": 35
        },
        {
            "source": 15,
            "target": 75
        },
        {
            "source": 15,
            "target": 71
        },
        {
            "source": 15,
            "target": 4
        },
        {
            "source": 15,
            "target": 0
        },
        {
            "source": 15,
            "target": 36
        },
        {
            "source": 15,
            "target": 10
        },
        {
            "source": 15,
            "target": 38
        },
        {
            "source": 15,
            "target": 62
        },
        {
            "source": 15,
            "target": 25
        },
        {
            "source": 15,
            "target": 67
        },
        {
            "source": 15,
            "target": 77
        },
        {
            "source": 15,
            "target": 11
        },
        {
            "source": 15,
            "target": 19
        },
        {
            "source": 15,
            "target": 27
        },
        {
            "source": 15,
            "target": 104
        },
        {
            "source": 15,
            "target": 175
        },
        {
            "source": 15,
            "target": 196
        },
        {
            "source": 16,
            "target": 6
        },
        {
            "source": 16,
            "target": 0
        },
        {
            "source": 16,
            "target": 25
        },
        {
            "source": 16,
            "target": 27
        },
        {
            "source": 16,
            "target": 166
        },
        {
            "source": 17,
            "target": 35
        },
        {
            "source": 17,
            "target": 4
        },
        {
            "source": 17,
            "target": 25
        },
        {
            "source": 17,
            "target": 27
        },
        {
            "source": 18,
            "target": 87
        },
        {
            "source": 18,
            "target": 51
        },
        {
            "source": 18,
            "target": 38
        },
        {
            "source": 18,
            "target": 26
        },
        {
            "source": 18,
            "target": 106
        },
        {
            "source": 18,
            "target": 122
        },
        {
            "source": 18,
            "target": 146
        },
        {
            "source": 18,
            "target": 153
        },
        {
            "source": 18,
            "target": 179
        },
        {
            "source": 19,
            "target": 25
        },
        {
            "source": 19,
            "target": 27
        },
        {
            "source": 19,
            "target": 55
        },
        {
            "source": 19,
            "target": 163
        },
        {
            "source": 20,
            "target": 25
        },
        {
            "source": 20,
            "target": 143
        },
        {
            "source": 21,
            "target": 6
        },
        {
            "source": 21,
            "target": 78
        },
        {
            "source": 21,
            "target": 44
        },
        {
            "source": 21,
            "target": 96
        },
        {
            "source": 21,
            "target": 45
        },
        {
            "source": 21,
            "target": 35
        },
        {
            "source": 21,
            "target": 46
        },
        {
            "source": 21,
            "target": 12
        },
        {
            "source": 21,
            "target": 4
        },
        {
            "source": 21,
            "target": 47
        },
        {
            "source": 21,
            "target": 99
        },
        {
            "source": 21,
            "target": 0
        },
        {
            "source": 21,
            "target": 79
        },
        {
            "source": 21,
            "target": 43
        },
        {
            "source": 21,
            "target": 50
        },
        {
            "source": 21,
            "target": 69
        },
        {
            "source": 21,
            "target": 80
        },
        {
            "source": 21,
            "target": 94
        },
        {
            "source": 21,
            "target": 51
        },
        {
            "source": 21,
            "target": 10
        },
        {
            "source": 21,
            "target": 38
        },
        {
            "source": 21,
            "target": 5
        },
        {
            "source": 21,
            "target": 41
        },
        {
            "source": 21,
            "target": 40
        },
        {
            "source": 21,
            "target": 98
        },
        {
            "source": 21,
            "target": 48
        },
        {
            "source": 21,
            "target": 65
        },
        {
            "source": 21,
            "target": 76
        },
        {
            "source": 21,
            "target": 11
        },
        {
            "source": 21,
            "target": 57
        },
        {
            "source": 21,
            "target": 31
        },
        {
            "source": 21,
            "target": 23
        },
        {
            "source": 21,
            "target": 39
        },
        {
            "source": 21,
            "target": 60
        },
        {
            "source": 21,
            "target": 68
        },
        {
            "source": 21,
            "target": 59
        },
        {
            "source": 21,
            "target": 28
        },
        {
            "source": 21,
            "target": 127
        },
        {
            "source": 22,
            "target": 25
        },
        {
            "source": 22,
            "target": 27
        },
        {
            "source": 22,
            "target": 7
        },
        {
            "source": 23,
            "target": 21
        },
        {
            "source": 23,
            "target": 6
        },
        {
            "source": 23,
            "target": 78
        },
        {
            "source": 23,
            "target": 44
        },
        {
            "source": 23,
            "target": 96
        },
        {
            "source": 23,
            "target": 45
        },
        {
            "source": 23,
            "target": 35
        },
        {
            "source": 23,
            "target": 46
        },
        {
            "source": 23,
            "target": 12
        },
        {
            "source": 23,
            "target": 4
        },
        {
            "source": 23,
            "target": 47
        },
        {
            "source": 23,
            "target": 99
        },
        {
            "source": 23,
            "target": 0
        },
        {
            "source": 23,
            "target": 79
        },
        {
            "source": 23,
            "target": 43
        },
        {
            "source": 23,
            "target": 50
        },
        {
            "source": 23,
            "target": 69
        },
        {
            "source": 23,
            "target": 80
        },
        {
            "source": 23,
            "target": 94
        },
        {
            "source": 23,
            "target": 51
        },
        {
            "source": 23,
            "target": 10
        },
        {
            "source": 23,
            "target": 38
        },
        {
            "source": 23,
            "target": 5
        },
        {
            "source": 23,
            "target": 41
        },
        {
            "source": 23,
            "target": 25
        },
        {
            "source": 23,
            "target": 40
        },
        {
            "source": 23,
            "target": 98
        },
        {
            "source": 23,
            "target": 48
        },
        {
            "source": 23,
            "target": 65
        },
        {
            "source": 23,
            "target": 76
        },
        {
            "source": 23,
            "target": 11
        },
        {
            "source": 23,
            "target": 57
        },
        {
            "source": 23,
            "target": 31
        },
        {
            "source": 23,
            "target": 39
        },
        {
            "source": 23,
            "target": 60
        },
        {
            "source": 23,
            "target": 68
        },
        {
            "source": 23,
            "target": 59
        },
        {
            "source": 23,
            "target": 27
        },
        {
            "source": 23,
            "target": 28
        },
        {
            "source": 24,
            "target": 35
        },
        {
            "source": 24,
            "target": 25
        },
        {
            "source": 25,
            "target": 19
        },
        {
            "source": 25,
            "target": 112
        },
        {
            "source": 25,
            "target": 167
        },
        {
            "source": 26,
            "target": 45
        },
        {
            "source": 26,
            "target": 35
        },
        {
            "source": 26,
            "target": 46
        },
        {
            "source": 26,
            "target": 0
        },
        {
            "source": 26,
            "target": 51
        },
        {
            "source": 26,
            "target": 38
        },
        {
            "source": 26,
            "target": 156
        },
        {
            "source": 26,
            "target": 198
        },
        {
            "source": 27,
            "target": 42
        },
        {
            "source": 27,
            "target": 35
        },
        {
            "source": 27,
            "target": 25
        },
        {
            "source": 27,
            "target": 19
        },
        {
            "source": 28,
            "target": 21
        },
        {
            "source": 28,
            "target": 6
        },
        {
            "source": 28,
            "target": 78
        },
        {
            "source": 28,
            "target": 44
        },
        {
            "source": 28,
            "target": 96
        },
        {
            "source": 28,
            "target": 45
        },
        {
            "source": 28,
            "target": 35
        },
        {
            "source": 28,
            "target": 46
        },
        {
            "source": 28,
            "target": 12
        },
        {
            "source": 28,
            "target": 4
        },
        {
            "source": 28,
            "target": 47
        },
        {
            "source": 28,
            "target": 99
        },
        {
            "source": 28,
            "target": 0
        },
        {
            "source": 28,
            "target": 79
        },
        {
            "source": 28,
            "target": 43
        },
        {
            "source": 28,
            "target": 50
        },
        {
            "source": 28,
            "target": 69
        },
        {
            "source": 28,
            "target": 80
        },
        {
            "source": 28,
            "target": 94
        },
        {
            "source": 28,
            "target": 51
        },
        {
            "source": 28,
            "target": 10
        },
        {
            "source": 28,
            "target": 38
        },
        {
            "source": 28,
            "target": 5
        },
        {
            "source": 28,
            "target": 41
        },
        {
            "source": 28,
            "target": 25
        },
        {
            "source": 28,
            "target": 40
        },
        {
            "source": 28,
            "target": 98
        },
        {
            "source": 28,
            "target": 48
        },
        {
            "source": 28,
            "target": 65
        },
        {
            "source": 28,
            "target": 76
        },
        {
            "source": 28,
            "target": 11
        },
        {
            "source": 28,
            "target": 57
        },
        {
            "source": 28,
            "target": 32
        },
        {
            "source": 28,
            "target": 31
        },
        {
            "source": 28,
            "target": 34
        },
        {
            "source": 28,
            "target": 23
        },
        {
            "source": 28,
            "target": 39
        },
        {
            "source": 28,
            "target": 60
        },
        {
            "source": 28,
            "target": 16
        },
        {
            "source": 28,
            "target": 68
        },
        {
            "source": 28,
            "target": 59
        },
        {
            "source": 28,
            "target": 27
        },
        {
            "source": 28,
            "target": 113
        },
        {
            "source": 30,
            "target": 42
        },
        {
            "source": 30,
            "target": 35
        },
        {
            "source": 30,
            "target": 4
        },
        {
            "source": 30,
            "target": 63
        },
        {
            "source": 30,
            "target": 0
        },
        {
            "source": 30,
            "target": 90
        },
        {
            "source": 31,
            "target": 21
        },
        {
            "source": 31,
            "target": 6
        },
        {
            "source": 31,
            "target": 78
        },
        {
            "source": 31,
            "target": 44
        },
        {
            "source": 31,
            "target": 96
        },
        {
            "source": 31,
            "target": 45
        },
        {
            "source": 31,
            "target": 35
        },
        {
            "source": 31,
            "target": 46
        },
        {
            "source": 31,
            "target": 12
        },
        {
            "source": 31,
            "target": 4
        },
        {
            "source": 31,
            "target": 47
        },
        {
            "source": 31,
            "target": 99
        },
        {
            "source": 31,
            "target": 0
        },
        {
            "source": 31,
            "target": 79
        },
        {
            "source": 31,
            "target": 43
        },
        {
            "source": 31,
            "target": 50
        },
        {
            "source": 31,
            "target": 69
        },
        {
            "source": 31,
            "target": 80
        },
        {
            "source": 31,
            "target": 94
        },
        {
            "source": 31,
            "target": 51
        },
        {
            "source": 31,
            "target": 10
        },
        {
            "source": 31,
            "target": 38
        },
        {
            "source": 31,
            "target": 5
        },
        {
            "source": 31,
            "target": 41
        },
        {
            "source": 31,
            "target": 40
        },
        {
            "source": 31,
            "target": 98
        },
        {
            "source": 31,
            "target": 48
        },
        {
            "source": 31,
            "target": 65
        },
        {
            "source": 31,
            "target": 76
        },
        {
            "source": 31,
            "target": 11
        },
        {
            "source": 31,
            "target": 57
        },
        {
            "source": 31,
            "target": 34
        },
        {
            "source": 31,
            "target": 23
        },
        {
            "source": 31,
            "target": 39
        },
        {
            "source": 31,
            "target": 60
        },
        {
            "source": 31,
            "target": 68
        },
        {
            "source": 31,
            "target": 59
        },
        {
            "source": 31,
            "target": 28
        },
        {
            "source": 31,
            "target": 149
        },
        {
            "source": 31,
            "target": 158
        },
        {
            "source": 32,
            "target": 0
        },
        {
            "source": 32,
            "target": 36
        },
        {
            "source": 32,
            "target": 43
        },
        {
            "source": 32,
            "target": 5
        },
        {
            "source": 32,
            "target": 25
        },
        {
            "source": 32,
            "target": 27
        },
        {
            "source": 33,
            "target": 25
        },
        {
            "source": 33,
            "target": 27
        },
        {
            "source": 34,
            "target": 99
        },
        {
            "source": 34,
            "target": 25
        },
        {
            "source": 34,
            "target": 105
        },
        {
            "source": 34,
            "target": 168
        },
        {
            "source": 34,
            "target": 197
        },
        {
            "source": 35,
            "target": 8
        },
        {
            "source": 35,
            "target": 21
        },
        {
            "source": 35,
            "target": 6
        },
        {
            "source": 35,
            "target": 78
        },
        {
            "source": 35,
            "target": 44
        },
        {
            "source": 35,
            "target": 42
        },
        {
            "source": 35,
            "target": 96
        },
        {
            "source": 35,
            "target": 45
        },
        {
            "source": 35,
            "target": 15
        },
        {
            "source": 35,
            "target": 75
        },
        {
            "source": 35,
            "target": 46
        },
        {
            "source": 35,
            "target": 71
        },
        {
            "source": 35,
            "target": 12
        },
        {
            "source": 35,
            "target": 4
        },
        {
            "source": 35,
            "target": 47
        },
        {
            "source": 35,
            "target": 99
        },
        {
            "source": 35,
            "target": 0
        },
        {
            "source": 35,
            "target": 36
        },
        {
            "source": 35,
            "target": 79
        },
        {
            "source": 35,
            "target": 142
        },
        {
            "source": 36,
            "target": 8
        },
        {
            "source": 36,
            "target": 35
        },
        {
            "source": 36,
            "target": 15
        },
        {
            "source": 36,
            "target": 75
        },
        {
            "source": 36,
            "target": 71
        },
        {
            "source": 36,
            "target": 20
        },
        {
            "source": 36,
            "target": 0
        },
        {
            "source": 36,
            "target": 43
        },
        {
            "source": 36,
            "target": 10
        },
        {
            "source": 36,
            "target": 62
        },
        {
            "source": 36,
            "target": 25
        },
        {
            "source": 36,
            "target": 67
        },
        {
            "source": 36,
            "target": 77
        },
        {
            "source": 36,
            "target": 11
        },
        {
            "source": 36,
            "target": 27
        },
        {
            "source": 36,
            "target": 171
        },
        {
            "source": 36,
            "target": 178
        },
        {
            "source": 37,
            "target": 25
        },
        {
            "source": 37,
            "target": 61
        },
        {
            "source": 37,
            "target": 117
        },
        {
            "source": 38,
            "target": 8
        },
        {
            "source": 38,
            "target": 21
        },
        {
            "source": 38,
            "target": 92
        },
        {
            "source": 38,
            "target": 35
        },
        {
            "source": 38,
            "target": 15
        },
        {
            "source": 38,
            "target": 75
        },
        {
            "source": 38,
            "target": 71
        },
        {
            "source": 38,
            "target": 4
        },
        {
            "source": 38,
            "target": 47
        },
        {
            "source": 38,
            "target": 0
        },
        {
            "source": 38,
            "target": 36
        },
        {
            "source": 38,
            "target": 50
        },
        {
            "source": 38,
            "target": 69
        },
        {
            "source": 38,
            "target": 80
        },
        {
            "source": 38,
            "target": 51
        },
        {
            "source": 38,
            "target": 10
        },
        {
            "source": 38,
            "target": 137
        },
        {
            "source": 38,
            "target": 159
        },
        {
            "source": 39,
            "target": 21
        },
        {
            "source": 39,
            "target": 6
        },
        {
            "source": 39,
            "target": 78
        },
        {
            "source": 39,
            "target": 44
        },
        {
            "source": 39,
            "target": 96
        },
        {
            "source": 39,
            "target": 45
        },
        {
            "source": 39,
            "target": 35
        },
        {
            "source": 39,
            "target": 46
        },
        {
            "source": 39,
            "target": 12
        },
        {
            "source": 39,
            "target": 4
        },
        {
            "source": 39,
            "target": 47
        },
        {
            "source": 39,
            "target": 99
        },
        {
            "source": 39,
            "target": 0
        },
        {
            "source": 39,
            "target": 79
        },
        {
            "source": 39,
            "target": 43
        },
        {
            "source": 39,
            "target": 50
        },
        {
            "source": 39,
            "target": 69
        },
        {
            "source": 39,
            "target": 80
        },
        {
            "source": 39,
            "target": 94
        },
        {
            "source": 39,
            "target": 51
        },
        {
            "source": 39,
            "target": 10
        },
        {
            "source": 39,
            "target": 38
        },
        {
            "source": 39,
            "target": 5
        },
        {
            "source": 39,
            "target": 41
        },
        {
            "source": 39,
            "target": 40
        },
        {
            "source": 39,
            "target": 98
        },
        {
            "source": 39,
            "target": 48
        },
        {
            "source": 39,
            "target": 65
        },
        {
            "source": 39,
            "target": 76
        },
        {
            "source": 39,
            "target": 11
        },
        {
            "source": 39,
            "target": 57
        },
        {
            "source": 39,
            "target": 31
        },
        {
            "source": 39,
            "target": 23
        },
        {
            "source": 39,
            "target": 60
        },
        {
            "source": 39,
            "target": 68
        },
        {
            "source": 39,
            "target": 59
        },
        {
            "source": 39,
            "target": 28
        },
        {
            "source": 39,
            "target": 187
        },
        {
            "source": 40,
            "target": 21
        },
        {
            "source": 40,
            "target": 6
        },
        {
            "source": 40,
            "target": 78
        },
        {
            "source": 40,
            "target": 44
        },
        {
            "source": 40,
            "target": 96
        },
        {
            "source": 40,
            "target": 45
        },
        {
            "source": 40,
            "target": 35
        },
        {
            "source": 40,
            "target": 46
        },
        {
            "source": 40,
            "target": 12
        },
        {
            "source": 40,
            "target": 4
        },
        {
            "source": 40,
            "target": 47
        },
        {
            "source": 40,
            "target": 99
        },
        {
            "source": 40,
            "target": 0
        },
        {
            "source": 40,
            "target": 79
        },
        {
            "source": 40,
            "target": 43
        },
        {
            "source": 40,
            "target": 50
        },
        {
            "source": 40,
            "target": 69
        },
        {
            "source": 40,
            "target": 80
        },
        {
            "source": 40,
            "target": 94
        },
        {
            "source": 40,
            "target": 51
        },
        {
            "source": 40,
            "target": 10
        },
        {
            "source": 40,
            "target": 38
        },
        {
            "source": 40,
            "target": 5
        },
        {
            "source": 40,
            "target": 41
        },
        {
            "source": 40,
            "target": 98
        },
        {
            "source": 40,
            "target": 48
        },
        {
            "source": 40,
            "target": 65
        },
        {
            "source": 40,
            "target": 76
        },
        {
            "source": 40,
            "target": 11
        },
        {
            "source": 40,
            "target": 57
        },
        {
            "source": 40,
            "target": 31
        },
        {
            "source": 40,
            "target": 23
        },
        {
            "source": 40,
            "target": 39
        },
        {
            "source": 40,
            "target": 60
        },
        {
            "source": 40,
            "target": 68
        },
        {
            "source": 40,
            "target": 59
        },
        {
            "source": 40,
            "target": 28
        },
        {
            "source": 40,
            "target": 102
        },
        {
            "source": 40,
            "target": 128
        },
        {
            "source": 40,
            "target": 136
        },
        {
            "source": 40,
            "target": 161
        },
        {
            "source": 41,
            "target": 21
        },
        {
            "source": 41,
            "target": 6
        },
        {
            "source": 41,
            "target": 78
        },
        {
            "source": 41,
            "target": 44
        },
        {
            "source": 41,
            "target": 96
        },
        {
            "source": 41,
            "target": 45
        },
        {
            "source": 41,
            "target": 35
        },
        {
            "source": 41,
            "target": 46
        },
        {
            "source": 41,
            "target": 12
        },
        {
            "source": 41,
            "target": 4
        },
        {
            "source": 41,
            "target": 47
        },
        {
            "source": 41,
            "target": 99
        },
        {
            "source": 41,
            "target": 0
        },
        {
            "source": 41,
            "target": 79
        },
        {
            "source": 41,
            "target": 43
        },
        {
            "source": 41,
            "target": 50
        },
        {
            "source": 41,
            "target": 69
        },
        {
            "source": 41,
            "target": 80
        },
        {
            "source": 41,
            "target": 94
        },
        {
            "source": 41,
            "target": 51
        },
        {
            "source": 41,
            "target": 10
        },
        {
            "source": 41,
            "target": 38
        },
        {
            "source": 41,
            "target": 5
        },
        {
            "source": 41,
            "target": 40
        },
        {
            "source": 41,
            "target": 98
        },
        {
            "source": 41,
            "target": 48
        },
        {
            "source": 41,
            "target": 65
        },
        {
            "source": 41,
            "target": 76
        },
        {
            "source": 41,
            "target": 11
        },
        {
            "source": 41,
            "target": 57
        },
        {
            "source": 41,
            "target": 31
        },
        {
            "source": 41,
            "target": 23
        },
        {
            "source": 41,
            "target": 39
        },
        {
            "source": 41,
            "target": 60
        },
        {
            "source": 41,
            "target": 68
        },
        {
            "source": 41,
            "target": 59
        },
        {
            "source": 41,
            "target": 28
        },
        {
            "source": 42,
            "target": 72
        },
        {
            "source": 42,
            "target": 2
        },
        {
            "source": 42,
            "target": 25
        },
        {
            "source": 42,
            "target": 14
        },
        {
            "source": 42,
            "target": 27
        },
        {
            "source": 42,
            "target": 83
        },
        {
            "source": 42,
            "target": 30
        },
        {
            "source": 42,
            "target": 108
        },
        {
            "source": 42,
            "target": 155
        },
        {
            "source": 42,
            "target": 183
        },
        {
            "source": 43,
            "target": 21
        },
        {
            "source": 43,
            "target": 6
        },
        {
            "source": 43,
            "target": 78
        },
        {
            "source": 43,
            "target": 44
        },
        {
            "source": 43,
            "target": 96
        },
        {
            "source": 43,
            "target": 45
        },
        {
            "source": 43,
            "target": 35
        },
        {
            "source": 43,
            "target": 46
        },
        {
            "source": 43,
            "target": 12
        },
        {
            "source": 43,
            "target": 4
        },
        {
            "source": 43,
            "target": 47
        },
        {
            "source": 43,
            "target": 99
        },
        {
            "source": 43,
            "target": 0
        },
        {
            "source": 43,
            "target": 79
        },
        {
            "source": 43,
            "target": 50
        },
        {
            "source": 43,
            "target": 69
        },
        {
            "source": 43,
            "target": 80
        },
        {
            "source": 43,
            "target": 89
        },
        {
            "source": 43,
            "target": 94
        },
        {
            "source": 43,
            "target": 51
        },
        {
            "source": 43,
            "target": 10
        },
        {
            "source": 43,
            "target": 38
        },
        {
            "source": 43,
            "target": 5
        },
        {
            "source": 43,
            "target": 41
        },
        {
            "source": 43,
            "target": 25
        },
        {
            "source": 43,
            "target": 40
        },
        {
            "source": 43,
            "target": 98
        },
        {
            "source": 43,
            "target": 48
        },
        {
            "source": 43,
            "target": 65
        },
        {
            "source": 43,
            "target": 76
        },
        {
            "source": 43,
            "target": 11
        },
        {
            "source": 43,
            "target": 57
        },
        {
            "source": 43,
            "target": 31
        },
        {
            "source": 43,
            "target": 23
        },
        {
            "source": 43,
            "target": 39
        },
        {
            "source": 43,
            "target": 60
        },
        {
            "source": 43,
            "target": 68
        },
        {
            "source": 43,
            "target": 59
        },
        {
            "source": 43,
            "target": 27
        },
        {
            "source": 43,
            "target": 28
        },
        {
            "source": 43,
            "target": 133
        },
        {
            "source": 43,
            "target": 180
        },
        {
            "source": 44,
            "target": 35
        },
        {
            "source": 44,
            "target": 88
        },
        {
            "source": 44,
            "target": 131
        },
        {
            "source": 44,
            "target": 139
        },
        {
            "source": 44,
            "target": 147
        },
        {
            "source": 45,
            "target": 35
        },
        {
            "source": 45,
            "target": 0
        },
        {
            "source": 45,
            "target": 43
        },
        {
            "source": 45,
            "target": 25
        },
        {
            "source": 46,
            "target": 21
        },
        {
            "source": 46,
            "target": 6
        },
        {
            "source": 46,
            "target": 78
        },
        {
            "source": 46,
            "target": 44
        },
        {
            "source": 46,
            "target": 96
        },
        {
            "source": 46,
            "target": 45
        },
        {
            "source": 46,
            "target": 35
        },
        {
            "source": 46,
            "target": 12
        },
        {
            "source": 46,
            "target": 4
        },
        {
            "source": 46,
            "target": 47
        },
        {
            "source": 46,
            "target": 99
        },
        {
            "source": 46,
            "target": 0
        },
        {
            "source": 46,
            "target": 79
        },
        {
            "source": 46,
            "target": 43
        },
        {
            "source": 46,
            "target": 50
        },
        {
            "source": 46,
            "target": 69
        },
        {
            "source": 46,
            "target": 80
        },
        {
            "source": 46,
            "target": 94
        },
        {
            "source": 46,
            "target": 51
        },
        {
            "source": 46,
            "target": 10
        },
        {
            "source": 46,
            "target": 38
        },
        {
            "source": 46,
            "target": 5
        },
        {
            "source": 46,
            "target": 41
        },
        {
            "source": 46,
            "target": 25
        },
        {
            "source": 46,
            "target": 40
        },
        {
            "source": 46,
            "target": 98
        },
        {
            "source": 46,
            "target": 48
        },
        {
            "source": 46,
            "target": 65
        },
        {
            "source": 46,
            "target": 76
        },
        {
            "source": 46,
            "target": 11
        },
        {
            "source": 46,
            "target": 57
        },
        {
            "source": 46,
            "target": 32
        },
        {
            "source": 46,
            "target": 31
        },
        {
            "source": 46,
            "target": 23
        },
        {
            "source": 46,
            "target": 39
        },
        {
            "source": 46,
            "target": 60
        },
        {
            "source": 46,
            "target": 16
        },
        {
            "source": 46,
            "target": 68
        },
        {
            "source": 46,
            "target": 59
        },
        {
            "source": 46,
            "target": 27
        },
        {
            "source": 46,
            "target": 28
        },
        {
            "source": 46,
            "target": 129
        },
        {
            "source": 46,
            "target": 138
        },
        {
            "source": 47,
            "target": 21
        },
        {
            "source": 47,
            "target": 4
        },
        {
            "source": 47,
            "target": 0
        },
        {
            "source": 47,
            "target": 50
        },
        {
            "source": 47,
            "target": 69
        },
        {
            "source": 47,
            "target": 80
        },
        {
            "source": 47,
            "target": 10
        },
        {
            "source": 47,
            "target": 38
        },
        {
            "source": 47,
            "target": 40
        },
        {
            "source": 47,
            "target": 65
        },
        {
            "source": 47,
            "target": 23
        },
        {
            "source": 48,
            "target": 21
        },
        {
            "source": 48,
            "target": 6
        },
        {
            "source": 48,
            "target": 78
        },
        {
            "source": 48,
            "target": 44
        },
        {
            "source": 48,
            "target": 96
        },
        {
            "source": 48,
            "target": 45
        },
        {
            "source": 48,
            "target": 35
        },
        {
            "source": 48,
            "target": 46
        },
        {
            "source": 48,
            "target": 12
        },
        {
            "source": 48,
            "target": 4
        },
        {
            "source": 48,
            "target": 47
        },
        {
            "source": 48,
            "target": 99
        },
        {
            "source": 48,
            "target": 0
        },
        {
            "source": 48,
            "target": 79
        },
        {
            "source": 48,
            "target": 43
        },
        {
            "source": 48,
            "target": 50
        },
        {
            "source": 48,
            "target": 69
        },
        {
            "source": 48,
            "target": 80
        },
        {
            "source": 48,
            "target": 94
        },
        {
            "source": 48,
            "target": 51
        },
        {
            "source": 48,
            "target": 10
        },
        {
            "source": 48,
            "target": 38
        },
        {
            "source": 48,
            "target": 140
        },
        {
            "source": 48,
            "target": 148
        },
        {
            "source": 49,
            "target": 100
        },
        {
            "source": 49,
            "target": 25
        },
        {
            "source": 49,
            "target": 27
        },
        {
            "source": 49,
            "target": 186
        },
        {
            "source": 50,
            "target": 21
        },
        {
            "source": 50,
            "target": 6
        },
        {
            "source": 50,
            "target": 78
        },
        {
            "source": 50,
            "target": 44
        },
        {
            "source": 50,
            "target": 96
        },
        {
            "source": 50,
            "target": 45
        },
        {
            "source": 50,
            "target": 35
        },
        {
            "source": 50,
            "target": 46
        },
        {
            "source": 50,
            "target": 12
        },
        {
            "source": 50,
            "target": 4
        },
        {
            "source": 50,
            "target": 47
        },
        {
            "source": 50,
            "target": 99
        },
        {
            "source": 50,
            "target": 0
        },
        {
            "source": 50,
            "target": 79
        },
        {
            "source": 50,
            "target": 43
        },
        {
            "source": 50,
            "target": 69
        },
        {
            "source": 50,
            "target": 80
        },
        {
            "source": 50,
            "target": 94
        },
        {
            "source": 50,
            "target": 51
        },
        {
            "source": 50,
            "target": 10
        },
        {
            "source": 50,
            "target": 38
        },
        {
            "source": 50,
            "target": 5
        },
        {
            "source": 50,
            "target": 41
        },
        {
            "source": 50,
            "target": 25
        },
        {
            "source": 50,
            "target": 40
        },
        {
            "source": 50,
            "target": 98
        },
        {
            "source": 50,
            "target": 48
        },
        {
            "source": 50,
            "target": 65
        },
        {
            "source": 50,
            "target": 76
        },
        {
            "source": 50,
            "target": 11
        },
        {
            "source": 50,
            "target": 57
        },
        {
            "source": 50,
            "target": 31
        },
        {
            "source": 50,
            "target": 23
        },
        {
            "source": 50,
            "target": 39
        },
        {
            "source": 50,
            "target": 60
        },
        {
            "source": 50,
            "target": 68
        },
        {
            "source": 50,
            "target": 59
        },
        {
            "source": 50,
            "target": 28
        },
        {
            "source": 51,
            "target": 21
        },
        {
            "source": 51,
            "target": 6
        },
        {
            "source": 51,
            "target": 78
        },
        {
            "source": 51,
            "target": 44
        },
        {
            "source": 51,
            "target": 96
        },
        {
            "source": 51,
            "target": 45
        },
        {
            "source": 51,
            "target": 35
        },
        {
            "source": 51,
            "target": 46
        },
        {
            "source": 51,
            "target": 12
        },
        {
            "source": 51,
            "target": 4
        },
        {
            "source": 51,
            "target": 47
        },
        {
            "source": 51,
            "target": 99
        },
        {
            "source": 51,
            "target": 0
        },
        {
            "source": 51,
            "target": 79
        },
        {
            "source": 51,
            "target": 43
        },
        {
            "source": 51,
            "target": 50
        },
        {
            "source": 51,
            "target": 69
        },
        {
            "source": 51,
            "target": 80
        },
        {
            "source": 51,
            "target": 94
        },
        {
            "source": 51,
            "target": 10
        },
        {
            "source": 51,
            "target": 38
        },
        {
            "source": 51,
            "target": 26
        },
        {
            "source": 51,
            "target": 114
        },
        {
            "source": 51,
            "target": 160
        },
        {
            "source": 51,
            "target": 181
        },
        {
            "source": 52,
            "target": 4
        },
        {
            "source": 52,
            "target": 69
        },
        {
            "source": 52,
            "target": 80
        },
        {
            "source": 53,
            "target": 5
        },
        {
            "source": 53,
            "target": 33
        },
        {
            "source": 54,
            "target": 21
        },
        {
            "source": 54,
            "target": 6
        },
        {
            "source": 54,
            "target": 78
        },
        {
            "source": 54,
            "target": 44
        },
        {
            "source": 54,
            "target": 96
        },
        {
            "source": 54,
            "target": 45
        },
        {
            "source": 54,
            "target": 35
        },
        {
            "source": 54,
            "target": 84
        },
        {
            "source": 54,
            "target": 46
        },
        {
            "source": 54,
            "target": 12
        },
        {
            "source": 54,
            "target": 4
        },
        {
            "source": 54,
            "target": 47
        },
        {
            "source": 54,
            "target": 99
        },
        {
            "source": 54,
            "target": 0
        },
        {
            "source": 54,
            "target": 79
        },
        {
            "source": 54,
            "target": 43
        },
        {
            "source": 54,
            "target": 50
        },
        {
            "source": 54,
            "target": 69
        },
        {
            "source": 54,
            "target": 80
        },
        {
            "source": 54,
            "target": 94
        },
        {
            "source": 54,
            "target": 51
        },
        {
            "source": 54,
            "target": 10
        },
        {
            "source": 54,
            "target": 38
        },
        {
            "source": 54,
            "target": 5
        },
        {
            "source": 54,
            "target": 41
        },
        {
            "source": 54,
            "target": 25
        },
        {
            "source": 54,
            "target": 40
        },
        {
            "source": 54,
            "target": 98
        },
        {
            "source": 54,
            "target": 48
        },
        {
            "source": 54,
            "target": 65
        },
        {
            "source": 54,
            "target": 76
        },
        {
            "source": 54,
            "target": 11
        },
        {
            "source": 54,
            "target": 57
        },
        {
            "source": 54,
            "target": 19
        },
        {
            "source": 54,
            "target": 32
        },
        {
            "source": 54,
            "target": 31
        },
        {
            "source": 54,
            "target": 23
        },
        {
            "source": 54,
            "target": 39
        },
        {
            "source": 54,
            "target": 16
        },
        {
            "source": 54,
            "target": 68
        },
        {
            "source": 54,
            "target": 59
        },
        {
            "source": 54,
            "target": 27
        },
        {
            "source": 54,
            "target": 28
        },
        {
            "source": 55,
            "target": 25
        },
        {
            "source": 55,
            "target": 27
        },
        {
            "source": 55,
            "target": 110
        },
        {
            "source": 55,
            "target": 134
        },
        {
            "source": 55,
            "target": 170
        },
        {
            "source": 56,
            "target": 25
        },
        {
            "source": 56,
            "target": 27
        },
        {
            "source": 57,
            "target": 35
        },
        {
            "source": 58,
            "target": 27
        },
        {
            "source": 58,
            "target": 151
        },
        {
            "source": 59,
            "target": 21
        },
        {
            "source": 59,
            "target": 6
        },
        {
            "source": 59,
            "target": 78
        },
        {
            "source": 59,
            "target": 44
        },
        {
            "source": 59,
            "target": 96
        },
        {
            "source": 59,
            "target": 45
        },
        {
            "source": 59,
            "target": 35
        },
        {
            "source": 59,
            "target": 46
        },
        {
            "source": 59,
            "target": 12
        },
        {
            "source": 59,
            "target": 4
        },
        {
            "source": 59,
            "target": 47
        },
        {
            "source": 59,
            "target": 99
        },
        {
            "source": 59,
            "target": 0
        },
        {
            "source": 59,
            "target": 79
        },
        {
            "source": 59,
            "target": 43
        },
        {
            "source": 59,
            "target": 50
        },
        {
            "source": 59,
            "target": 69
        },
        {
            "source": 59,
            "target": 80
        },
        {
            "source": 59,
            "target": 94
        },
        {
            "source": 59,
            "target": 51
        },
        {
            "source": 59,
            "target": 10
        },
        {
            "source": 59,
            "target": 38
        },
        {
            "source": 59,
            "target": 5
        },
        {
            "source": 59,
            "target": 41
        },
        {
            "source": 59,
            "target": 25
        },
        {
            "source": 59,
            "target": 40
        },
        {
            "source": 59,
            "target": 98
        },
        {
            "source": 59,
            "target": 48
        },
        {
            "source": 59,
            "target": 65
        },
        {
            "source": 59,
            "target": 76
        },
        {
            "source": 59,
            "target": 11
        },
        {
            "source": 59,
            "target": 57
        },
        {
            "source": 59,
            "target": 31
        },
        {
            "source": 59,
            "target": 23
        },
        {
            "source": 59,
            "target": 39
        },
        {
            "source": 59,
            "target": 60
        },
        {
            "source": 59,
            "target": 68
        },
        {
            "source": 59,
            "target": 28
        },
        {
            "source": 59,
            "target": 116
        },
        {
            "source": 60,
            "target": 21
        },
        {
            "source": 60,
            "target": 6
        },
        {
            "source": 60,
            "target": 78
        },
        {
            "source": 60,
            "target": 44
        },
        {
            "source": 60,
            "target": 96
        },
        {
            "source": 60,
            "target": 45
        },
        {
            "source": 60,
            "target": 35
        },
        {
            "source": 60,
            "target": 84
        },
        {
            "source": 60,
            "target": 46
        },
        {
            "source": 60,
            "target": 12
        },
        {
            "source": 60,
            "target": 4
        },
        {
            "source": 60,
            "target": 47
        },
        {
            "source": 60,
            "target": 99
        },
        {
            "source": 60,
            "target": 0
        },
        {
            "source": 60,
            "target": 79
        },
        {
            "source": 60,
            "target": 43
        },
        {
            "source": 60,
            "target": 50
        },
        {
            "source": 60,
            "target": 69
        },
        {
            "source": 60,
            "target": 80
        },
        {
            "source": 60,
            "target": 94
        },
        {
            "source": 60,
            "target": 51
        },
        {
            "source": 60,
            "target": 10
        },
        {
            "source": 60,
            "target": 38
        },
        {
            "source": 60,
            "target": 5
        },
        {
            "source": 60,
            "target": 41
        },
        {
            "source": 60,
            "target": 25
        },
        {
            "source": 60,
            "target": 40
        },
        {
            "source": 60,
            "target": 98
        },
        {
            "source": 60,
            "target": 48
        },
        {
            "source": 60,
            "target": 65
        },
        {
            "source": 60,
            "target": 76
        },
        {
            "source": 60,
            "target": 11
        },
        {
            "source": 60,
            "target": 57
        },
        {
            "source": 60,
            "target": 19
        },
        {
            "source": 60,
            "target": 32
        },
        {
            "source": 60,
            "target": 31
        },
        {
            "source": 60,
            "target": 23
        },
        {
            "source": 60,
            "target": 39
        },
        {
            "source": 60,
            "target": 54
        },
        {
            "source": 60,
            "target": 16
        },
        {
            "source": 60,
            "target": 68
        },
        {
            "source": 60,
            "target": 59
        },
        {
            "source": 60,
            "target": 27
        },
        {
            "source": 60,
            "target": 28
        },
        {
            "source": 61,
            "target": 25
        },
        {
            "source": 61,
            "target": 66
        },
        {
            "source": 61,
            "target": 27
        },
        {
            "source": 61,
            "target": 124
        },
        {
            "source": 61,
            "target": 174
        },
        {
            "source": 61,
            "target": 177
        },
        {
            "source": 62,
            "target": 8
        },
        {
            "source": 62,
            "target": 35
        },
        {
            "source": 62,
            "target": 15
        },
        {
            "source": 62,
            "target": 75
        },
        {
            "source": 62,
            "target": 71
        },
        {
            "source": 62,
            "target": 0
        },
        {
            "source": 62,
            "target": 36
        },
        {
            "source": 62,
            "target": 67
        },
        {
            "source": 62,
            "target": 77
        },
        {
            "source": 62,
            "target": 11
        },
        {
            "source": 63,
            "target": 42
        },
        {
            "source": 63,
            "target": 87
        },
        {
            "source": 63,
            "target": 72
        },
        {
            "source": 63,
            "target": 27
        },
        {
            "source": 63,
            "target": 30
        },
        {
            "source": 63,
            "target": 141
        },
        {
            "source": 63,
            "target": 154
        },
        {
            "source": 63,
            "target": 165
        },
        {
            "source": 64,
            "target": 25
        },
        {
            "source": 64,
            "target": 27
        },
        {
            "source": 65,
            "target": 21
        },
        {
            "source": 65,
            "target": 6
        },
        {
            "source": 65,
            "target": 78
        },
        {
            "source": 65,
            "target": 44
        },
        {
            "source": 65,
            "target": 96
        },
        {
            "source": 65,
            "target": 45
        },
        {
            "source": 65,
            "target": 35
        },
        {
            "source": 65,
            "target": 46
        },
        {
            "source": 65,
            "target": 12
        },
        {
            "source": 65,
            "target": 4
        },
        {
            "source": 65,
            "target": 47
        },
        {
            "source": 65,
            "target": 99
        },
        {
            "source": 65,
            "target": 0
        },
        {
            "source": 65,
            "target": 79
        },
        {
            "source": 65,
            "target": 43
        },
        {
            "source": 65,
            "target": 50
        },
        {
            "source": 65,
            "target": 69
        },
        {
            "source": 65,
            "target": 80
        },
        {
            "source": 65,
            "target": 94
        },
        {
            "source": 65,
            "target": 51
        },
        {
            "source": 65,
            "target": 10
        },
        {
            "source": 65,
            "target": 38
        },
        {
            "source": 65,
            "target": 5
        },
        {
            "source": 65,
            "target": 41
        },
        {
            "source": 65,
            "target": 25
        },
        {
            "source": 65,
            "target": 40
        },
        {
            "source": 65,
            "target": 98
        },
        {
            "source": 65,
            "target": 48
        },
        {
            "source": 65,
            "target": 76
        },
        {
            "source": 65,
            "target": 11
        },
        {
            "source": 65,
            "target": 57
        },
        {
            "source": 65,
            "target": 31
        },
        {
            "source": 65,
            "target": 23
        },
        {
            "source": 65,
            "target": 39
        },
        {
            "source": 65,
            "target": 60
        },
        {
            "source": 65,
            "target": 68
        },
        {
            "source": 65,
            "target": 59
        },
        {
            "source": 65,
            "target": 28
        },
        {
            "source": 65,
            "target": 103
        },
        {
            "source": 65,
            "target": 123
        },
        {
            "source": 66,
            "target": 27
        },
        {
            "source": 67,
            "target": 8
        },
        {
            "source": 67,
            "target": 35
        },
        {
            "source": 67,
            "target": 15
        },
        {
            "source": 67,
            "target": 75
        },
        {
            "source": 67,
            "target": 84
        },
        {
            "source": 67,
            "target": 71
        },
        {
            "source": 67,
            "target": 99
        },
        {
            "source": 67,
            "target": 0
        },
        {
            "source": 67,
            "target": 36
        },
        {
            "source": 67,
            "target": 62
        },
        {
            "source": 67,
            "target": 25
        },
        {
            "source": 67,
            "target": 77
        },
        {
            "source": 67,
            "target": 11
        },
        {
            "source": 67,
            "target": 27
        },
        {
            "source": 67,
            "target": 145
        },
        {
            "source": 68,
            "target": 21
        },
        {
            "source": 68,
            "target": 6
        },
        {
            "source": 68,
            "target": 78
        },
        {
            "source": 68,
            "target": 44
        },
        {
            "source": 68,
            "target": 96
        },
        {
            "source": 68,
            "target": 45
        },
        {
            "source": 68,
            "target": 35
        },
        {
            "source": 68,
            "target": 46
        },
        {
            "source": 68,
            "target": 12
        },
        {
            "source": 68,
            "target": 4
        },
        {
            "source": 68,
            "target": 47
        },
        {
            "source": 68,
            "target": 99
        },
        {
            "source": 68,
            "target": 0
        },
        {
            "source": 68,
            "target": 79
        },
        {
            "source": 68,
            "target": 43
        },
        {
            "source": 68,
            "target": 50
        },
        {
            "source": 68,
            "target": 69
        },
        {
            "source": 68,
            "target": 80
        },
        {
            "source": 68,
            "target": 94
        },
        {
            "source": 68,
            "target": 51
        },
        {
            "source": 68,
            "target": 10
        },
        {
            "source": 68,
            "target": 38
        },
        {
            "source": 68,
            "target": 5
        },
        {
            "source": 68,
            "target": 41
        },
        {
            "source": 68,
            "target": 25
        },
        {
            "source": 68,
            "target": 40
        },
        {
            "source": 68,
            "target": 98
        },
        {
            "source": 68,
            "target": 48
        },
        {
            "source": 68,
            "target": 65
        },
        {
            "source": 68,
            "target": 76
        },
        {
            "source": 68,
            "target": 11
        },
        {
            "source": 68,
            "target": 57
        },
        {
            "source": 68,
            "target": 14
        },
        {
            "source": 68,
            "target": 31
        },
        {
            "source": 68,
            "target": 23
        },
        {
            "source": 68,
            "target": 39
        },
        {
            "source": 68,
            "target": 54
        },
        {
            "source": 68,
            "target": 60
        },
        {
            "source": 68,
            "target": 59
        },
        {
            "source": 68,
            "target": 27
        },
        {
            "source": 68,
            "target": 83
        },
        {
            "source": 68,
            "target": 28
        },
        {
            "source": 68,
            "target": 152
        },
        {
            "source": 69,
            "target": 21
        },
        {
            "source": 69,
            "target": 6
        },
        {
            "source": 69,
            "target": 78
        },
        {
            "source": 69,
            "target": 44
        },
        {
            "source": 69,
            "target": 96
        },
        {
            "source": 69,
            "target": 45
        },
        {
            "source": 69,
            "target": 35
        },
        {
            "source": 69,
            "target": 46
        },
        {
            "source": 69,
            "target": 12
        },
        {
            "source": 69,
            "target": 4
        },
        {
            "source": 69,
            "target": 47
        },
        {
            "source": 69,
            "target": 99
        },
        {
            "source": 69,
            "target": 52
        },
        {
            "source": 69,
            "target": 0
        },
        {
            "source": 69,
            "target": 79
        },
        {
            "source": 69,
            "target": 43
        },
        {
            "source": 69,
            "target": 50
        },
        {
            "source": 69,
            "target": 80
        },
        {
            "source": 69,
            "target": 94
        },
        {
            "source": 69,
            "target": 51
        },
        {
            "source": 69,
            "target": 10
        },
        {
            "source": 69,
            "target": 38
        },
        {
            "source": 69,
            "target": 5
        },
        {
            "source": 69,
            "target": 41
        },
        {
            "source": 69,
            "target": 40
        },
        {
            "source": 69,
            "target": 98
        },
        {
            "source": 69,
            "target": 48
        },
        {
            "source": 69,
            "target": 65
        },
        {
            "source": 69,
            "target": 76
        },
        {
            "source": 69,
            "target": 11
        },
        {
            "source": 69,
            "target": 57
        },
        {
            "source": 69,
            "target": 32
        },
        {
            "source": 69,
            "target": 31
        },
        {
            "source": 69,
            "target": 23
        },
        {
            "source": 69,
            "target": 39
        },
        {
            "source": 69,
            "target": 60
        },
        {
            "source": 69,
            "target": 16
        },
        {
            "source": 69,
            "target": 68
        },
        {
            "source": 69,
            "target": 59
        },
        {
            "source": 69,
            "target": 28
        },
        {
            "source": 69,
            "target": 118
        },
        {
            "source": 69,
            "target": 189
        },
        {
            "source": 70,
            "target": 25
        },
        {
            "source": 70,
            "target": 22
        },
        {
            "source": 71,
            "target": 8
        },
        {
            "source": 71,
            "target": 35
        },
        {
            "source": 71,
            "target": 15
        },
        {
            "source": 71,
            "target": 75
        },
        {
            "source": 71,
            "target": 0
        },
        {
            "source": 71,
            "target": 36
        },
        {
            "source": 71,
            "target": 62
        },
        {
            "source": 71,
            "target": 67
        },
        {
            "source": 71,
            "target": 77
        },
        {
            "source": 71,
            "target": 11
        },
        {
            "source": 72,
            "target": 42
        },
        {
            "source": 73,
            "target": 35
        },
        {
            "source": 74,
            "target": 25
        },
        {
            "source": 74,
            "target": 27
        },
        {
            "source": 74,
            "target": 132
        },
        {
            "source": 75,
            "target": 8
        },
        {
            "source": 75,
            "target": 35
        },
        {
            "source": 75,
            "target": 15
        },
        {
            "source": 75,
            "target": 71
        },
        {
            "source": 75,
            "target": 4
        },
        {
            "source": 75,
            "target": 0
        },
        {
            "source": 75,
            "target": 36
        },
        {
            "source": 75,
            "target": 62
        },
        {
            "source": 75,
            "target": 25
        },
        {
            "source": 75,
            "target": 67
        },
        {
            "source": 75,
            "target": 77
        },
        {
            "source": 75,
            "target": 11
        },
        {
            "source": 75,
            "target": 27
        },
        {
            "source": 76,
            "target": 21
        },
        {
            "source": 76,
            "target": 6
        },
        {
            "source": 76,
            "target": 78
        },
        {
            "source": 76,
            "target": 44
        },
        {
            "source": 76,
            "target": 96
        },
        {
            "source": 76,
            "target": 45
        },
        {
            "source": 76,
            "target": 35
        },
        {
            "source": 76,
            "target": 46
        },
        {
            "source": 76,
            "target": 12
        },
        {
            "source": 76,
            "target": 4
        },
        {
            "source": 76,
            "target": 47
        },
        {
            "source": 76,
            "target": 99
        },
        {
            "source": 76,
            "target": 0
        },
        {
            "source": 76,
            "target": 79
        },
        {
            "source": 76,
            "target": 43
        },
        {
            "source": 76,
            "target": 50
        },
        {
            "source": 76,
            "target": 69
        },
        {
            "source": 76,
            "target": 80
        },
        {
            "source": 76,
            "target": 94
        },
        {
            "source": 76,
            "target": 51
        },
        {
            "source": 76,
            "target": 10
        },
        {
            "source": 76,
            "target": 38
        },
        {
            "source": 76,
            "target": 5
        },
        {
            "source": 76,
            "target": 41
        },
        {
            "source": 76,
            "target": 25
        },
        {
            "source": 76,
            "target": 40
        },
        {
            "source": 76,
            "target": 98
        },
        {
            "source": 76,
            "target": 48
        },
        {
            "source": 76,
            "target": 65
        },
        {
            "source": 76,
            "target": 11
        },
        {
            "source": 76,
            "target": 57
        },
        {
            "source": 76,
            "target": 32
        },
        {
            "source": 76,
            "target": 31
        },
        {
            "source": 76,
            "target": 23
        },
        {
            "source": 76,
            "target": 39
        },
        {
            "source": 76,
            "target": 60
        },
        {
            "source": 76,
            "target": 16
        },
        {
            "source": 76,
            "target": 68
        },
        {
            "source": 76,
            "target": 59
        },
        {
            "source": 76,
            "target": 27
        },
        {
            "source": 76,
            "target": 28
        },
        {
            "source": 76,
            "target": 102
        },
        {
            "source": 77,
            "target": 0
        },
        {
            "source": 77,
            "target": 25
        },
        {
            "source": 77,
            "target": 27
        },
        {
            "source": 77,
            "target": 130
        },
        {
            "source": 78,
            "target": 35
        },
        {
            "source": 78,
            "target": 0
        },
        {
            "source": 78,
            "target": 27
        },
        {
            "source": 79,
            "target": 21
        },
        {
            "source": 79,
            "target": 6
        },
        {
            "source": 79,
            "target": 78
        },
        {
            "source": 79,
            "target": 44
        },
        {
            "source": 79,
            "target": 96
        },
        {
            "source": 79,
            "target": 45
        },
        {
            "source": 79,
            "target": 35
        },
        {
            "source": 79,
            "target": 46
        },
        {
            "source": 79,
            "target": 12
        },
        {
            "source": 79,
            "target": 4
        },
        {
            "source": 79,
            "target": 47
        },
        {
            "source": 79,
            "target": 99
        },
        {
            "source": 79,
            "target": 0
        },
        {
            "source": 79,
            "target": 43
        },
        {
            "source": 79,
            "target": 50
        },
        {
            "source": 79,
            "target": 69
        },
        {
            "source": 79,
            "target": 80
        },
        {
            "source": 79,
            "target": 94
        },
        {
            "source": 79,
            "target": 51
        },
        {
            "source": 79,
            "target": 10
        },
        {
            "source": 79,
            "target": 38
        },
        {
            "source": 79,
            "target": 5
        },
        {
            "source": 79,
            "target": 41
        },
        {
            "source": 79,
            "target": 25
        },
        {
            "source": 79,
            "target": 40
        },
        {
            "source": 79,
            "target": 98
        },
        {
            "source": 79,
            "target": 48
        },
        {
            "source": 79,
            "target": 65
        },
        {
            "source": 79,
            "target": 76
        },
        {
            "source": 79,
            "target": 11
        },
        {
            "source": 79,
            "target": 57
        },
        {
            "source": 79,
            "target": 32
        },
        {
            "source": 79,
            "target": 31
        },
        {
            "source": 79,
            "target": 34
        },
        {
            "source": 79,
            "target": 23
        },
        {
            "source": 79,
            "target": 39
        },
        {
            "source": 79,
            "target": 60
        },
        {
            "source": 79,
            "target": 16
        },
        {
            "source": 79,
            "target": 68
        },
        {
            "source": 79,
            "target": 59
        },
        {
            "source": 79,
            "target": 27
        },
        {
            "source": 80,
            "target": 21
        },
        {
            "source": 80,
            "target": 6
        },
        {
            "source": 80,
            "target": 78
        },
        {
            "source": 80,
            "target": 44
        },
        {
            "source": 80,
            "target": 96
        },
        {
            "source": 80,
            "target": 45
        },
        {
            "source": 80,
            "target": 35
        },
        {
            "source": 80,
            "target": 46
        },
        {
            "source": 80,
            "target": 12
        },
        {
            "source": 80,
            "target": 4
        },
        {
            "source": 80,
            "target": 47
        },
        {
            "source": 80,
            "target": 99
        },
        {
            "source": 80,
            "target": 52
        },
        {
            "source": 80,
            "target": 0
        },
        {
            "source": 80,
            "target": 79
        },
        {
            "source": 80,
            "target": 43
        },
        {
            "source": 80,
            "target": 50
        },
        {
            "source": 80,
            "target": 69
        },
        {
            "source": 80,
            "target": 94
        },
        {
            "source": 80,
            "target": 51
        },
        {
            "source": 80,
            "target": 10
        },
        {
            "source": 80,
            "target": 38
        },
        {
            "source": 80,
            "target": 5
        },
        {
            "source": 80,
            "target": 41
        },
        {
            "source": 80,
            "target": 25
        },
        {
            "source": 80,
            "target": 40
        },
        {
            "source": 80,
            "target": 98
        },
        {
            "source": 80,
            "target": 48
        },
        {
            "source": 80,
            "target": 65
        },
        {
            "source": 80,
            "target": 76
        },
        {
            "source": 80,
            "target": 11
        },
        {
            "source": 80,
            "target": 57
        },
        {
            "source": 80,
            "target": 19
        },
        {
            "source": 80,
            "target": 32
        },
        {
            "source": 80,
            "target": 31
        },
        {
            "source": 80,
            "target": 23
        },
        {
            "source": 80,
            "target": 39
        },
        {
            "source": 80,
            "target": 60
        },
        {
            "source": 80,
            "target": 16
        },
        {
            "source": 80,
            "target": 68
        },
        {
            "source": 80,
            "target": 59
        },
        {
            "source": 80,
            "target": 27
        },
        {
            "source": 80,
            "target": 28
        },
        {
            "source": 82,
            "target": 35
        },
        {
            "source": 82,
            "target": 25
        },
        {
            "source": 82,
            "target": 27
        },
        {
            "source": 82,
            "target": 164
        },
        {
            "source": 83,
            "target": 0
        },
        {
            "source": 83,
            "target": 25
        },
        {
            "source": 83,
            "target": 60
        },
        {
            "source": 83,
            "target": 27
        },
        {
            "source": 84,
            "target": 12
        },
        {
            "source": 84,
            "target": 5
        },
        {
            "source": 84,
            "target": 25
        },
        {
            "source": 84,
            "target": 19
        },
        {
            "source": 84,
            "target": 60
        },
        {
            "source": 84,
            "target": 27
        },
        {
            "source": 84,
            "target": 111
        },
        {
            "source": 86,
            "target": 0
        },
        {
            "source": 86,
            "target": 150
        },
        {
            "source": 87,
            "target": 185
        },
        {
            "source": 87,
            "target": 192
        },
        {
            "source": 88,
            "target": 44
        },
        {
            "source": 88,
            "target": 35
        },
        {
            "source": 88,
            "target": 25
        },
        {
            "source": 88,
            "target": 120
        },
        {
            "source": 88,
            "target": 176
        },
        {
            "source": 89,
            "target": 25
        },
        {
            "source": 89,
            "target": 27
        },
        {
            "source": 89,
            "target": 182
        },
        {
            "source": 90,
            "target": 2
        },
        {
            "source": 90,
            "target": 30
        },
        {
            "source": 90,
            "target": 135
        },
        {
            "source": 92,
            "target": 35
        },
        {
            "source": 92,
            "target": 25
        },
        {
            "source": 92,
            "target": 19
        },
        {
            "source": 92,
            "target": 27
        },
        {
            "source": 94,
            "target": 21
        },
        {
            "source": 94,
            "target": 6
        },
        {
            "source": 94,
            "target": 78
        },
        {
            "source": 94,
            "target": 44
        },
        {
            "source": 94,
            "target": 96
        },
        {
            "source": 94,
            "target": 45
        },
        {
            "source": 94,
            "target": 35
        },
        {
            "source": 94,
            "target": 46
        },
        {
            "source": 94,
            "target": 12
        },
        {
            "source": 94,
            "target": 4
        },
        {
            "source": 94,
            "target": 47
        },
        {
            "source": 94,
            "target": 99
        },
        {
            "source": 94,
            "target": 0
        },
        {
            "source": 94,
            "target": 79
        },
        {
            "source": 94,
            "target": 43
        },
        {
            "source": 94,
            "target": 50
        },
        {
            "source": 94,
            "target": 69
        },
        {
            "source": 94,
            "target": 80
        },
        {
            "source": 94,
            "target": 51
        },
        {
            "source": 94,
            "target": 10
        },
        {
            "source": 94,
            "target": 38
        },
        {
            "source": 94,
            "target": 5
        },
        {
            "source": 94,
            "target": 41
        },
        {
            "source": 94,
            "target": 40
        },
        {
            "source": 94,
            "target": 98
        },
        {
            "source": 94,
            "target": 48
        },
        {
            "source": 94,
            "target": 65
        },
        {
            "source": 94,
            "target": 76
        },
        {
            "source": 94,
            "target": 11
        },
        {
            "source": 94,
            "target": 57
        },
        {
            "source": 94,
            "target": 32
        },
        {
            "source": 94,
            "target": 31
        },
        {
            "source": 94,
            "target": 23
        },
        {
            "source": 94,
            "target": 39
        },
        {
            "source": 94,
            "target": 54
        },
        {
            "source": 94,
            "target": 60
        },
        {
            "source": 94,
            "target": 16
        },
        {
            "source": 94,
            "target": 68
        },
        {
            "source": 94,
            "target": 59
        },
        {
            "source": 94,
            "target": 27
        },
        {
            "source": 94,
            "target": 28
        },
        {
            "source": 94,
            "target": 157
        },
        {
            "source": 95,
            "target": 0
        },
        {
            "source": 95,
            "target": 25
        },
        {
            "source": 95,
            "target": 27
        },
        {
            "source": 96,
            "target": 35
        },
        {
            "source": 96,
            "target": 0
        },
        {
            "source": 96,
            "target": 188
        },
        {
            "source": 98,
            "target": 35
        },
        {
            "source": 98,
            "target": 80
        },
        {
            "source": 98,
            "target": 25
        },
        {
            "source": 98,
            "target": 126
        },
        {
            "source": 98,
            "target": 195
        },
        {
            "source": 99,
            "target": 21
        },
        {
            "source": 99,
            "target": 6
        },
        {
            "source": 99,
            "target": 78
        },
        {
            "source": 99,
            "target": 44
        },
        {
            "source": 99,
            "target": 96
        },
        {
            "source": 99,
            "target": 45
        },
        {
            "source": 99,
            "target": 35
        },
        {
            "source": 99,
            "target": 46
        },
        {
            "source": 99,
            "target": 12
        },
        {
            "source": 99,
            "target": 4
        },
        {
            "source": 99,
            "target": 47
        },
        {
            "source": 99,
            "target": 64
        },
        {
            "source": 99,
            "target": 0
        },
        {
            "source": 99,
            "target": 79
        },
        {
            "source": 99,
            "target": 43
        },
        {
            "source": 99,
            "target": 50
        },
        {
            "source": 99,
            "target": 69
        },
        {
            "source": 99,
            "target": 80
        },
        {
            "source": 99,
            "target": 94
        },
        {
            "source": 99,
            "target": 51
        },
        {
            "source": 99,
            "target": 10
        },
        {
            "source": 99,
            "target": 38
        },
        {
            "source": 99,
            "target": 5
        },
        {
            "source": 99,
            "target": 41
        },
        {
            "source": 99,
            "target": 25
        },
        {
            "source": 99,
            "target": 40
        },
        {
            "source": 99,
            "target": 98
        },
        {
            "source": 99,
            "target": 48
        },
        {
            "source": 99,
            "target": 65
        },
        {
            "source": 99,
            "target": 76
        },
        {
            "source": 99,
            "target": 11
        },
        {
            "source": 99,
            "target": 57
        },
        {
            "source": 99,
            "target": 169
        },
        {
            "source": 100,
            "target": 49
        },
        {
            "source": 100,
            "target": 25
        },
        {
            "source": 100,
            "target": 27
        },
        {
            "source": 100,
            "target": 119
        },
        {
            "source": 101,
            "target": 25
        },
        {
            "source": 101,
            "target": 7
        },
        {
            "source": 102,
            "target": 44
        },
        {
            "source": 102,
            "target": 0
        },
        {
            "source": 102,
            "target": 25
        },
        {
            "source": 102,
            "target": 27
        },
        {
            "source": 102,
            "target": 126
        },
        {
            "source": 102,
            "target": 279
        },
        {
            "source": 103,
            "target": 44
        },
        {
            "source": 103,
            "target": 45
        },
        {
            "source": 103,
            "target": 106
        },
        {
            "source": 103,
            "target": 104
        },
        {
            "source": 103,
            "target": 25
        },
        {
            "source": 103,
            "target": 213
        },
        {
            "source": 103,
            "target": 262
        },
        {
            "source": 104,
            "target": 198
        },
        {
            "source": 104,
            "target": 35
        },
        {
            "source": 104,
            "target": 153
        },
        {
            "source": 104,
            "target": 159
        },
        {
            "source": 104,
            "target": 160
        },
        {
            "source": 104,
            "target": 173
        },
        {
            "source": 104,
            "target": 4
        },
        {
            "source": 104,
            "target": 129
        },
        {
            "source": 104,
            "target": 146
        },
        {
            "source": 104,
            "target": 137
        },
        {
            "source": 104,
            "target": 148
        },
        {
            "source": 104,
            "target": 222
        },
        {
            "source": 104,
            "target": 240
        },
        {
            "source": 104,
            "target": 277
        },
        {
            "source": 105,
            "target": 197
        },
        {
            "source": 105,
            "target": 99
        },
        {
            "source": 105,
            "target": 169
        },
        {
            "source": 105,
            "target": 25
        },
        {
            "source": 105,
            "target": 34
        },
        {
            "source": 105,
            "target": 27
        },
        {
            "source": 107,
            "target": 25
        },
        {
            "source": 107,
            "target": 124
        },
        {
            "source": 107,
            "target": 27
        },
        {
            "source": 107,
            "target": 274
        },
        {
            "source": 108,
            "target": 253
        },
        {
            "source": 109,
            "target": 7
        },
        {
            "source": 109,
            "target": 216
        },
        {
            "source": 110,
            "target": 25
        },
        {
            "source": 111,
            "target": 25
        },
        {
            "source": 111,
            "target": 27
        },
        {
            "source": 112,
            "target": 119
        },
        {
            "source": 112,
            "target": 104
        },
        {
            "source": 112,
            "target": 282
        },
        {
            "source": 113,
            "target": 46
        },
        {
            "source": 113,
            "target": 99
        },
        {
            "source": 113,
            "target": 0
        },
        {
            "source": 113,
            "target": 94
        },
        {
            "source": 113,
            "target": 10
        },
        {
            "source": 113,
            "target": 25
        },
        {
            "source": 113,
            "target": 152
        },
        {
            "source": 113,
            "target": 14
        },
        {
            "source": 113,
            "target": 32
        },
        {
            "source": 113,
            "target": 144
        },
        {
            "source": 113,
            "target": 16
        },
        {
            "source": 113,
            "target": 27
        },
        {
            "source": 114,
            "target": 198
        },
        {
            "source": 114,
            "target": 42
        },
        {
            "source": 114,
            "target": 35
        },
        {
            "source": 114,
            "target": 153
        },
        {
            "source": 114,
            "target": 159
        },
        {
            "source": 114,
            "target": 129
        },
        {
            "source": 114,
            "target": 146
        },
        {
            "source": 114,
            "target": 137
        },
        {
            "source": 114,
            "target": 148
        },
        {
            "source": 114,
            "target": 51
        },
        {
            "source": 114,
            "target": 179
        },
        {
            "source": 114,
            "target": 104
        },
        {
            "source": 114,
            "target": 181
        },
        {
            "source": 114,
            "target": 38
        },
        {
            "source": 114,
            "target": 156
        },
        {
            "source": 114,
            "target": 26
        },
        {
            "source": 114,
            "target": 219
        },
        {
            "source": 114,
            "target": 268
        },
        {
            "source": 115,
            "target": 21
        },
        {
            "source": 115,
            "target": 6
        },
        {
            "source": 115,
            "target": 78
        },
        {
            "source": 115,
            "target": 44
        },
        {
            "source": 115,
            "target": 96
        },
        {
            "source": 115,
            "target": 45
        },
        {
            "source": 115,
            "target": 35
        },
        {
            "source": 115,
            "target": 46
        },
        {
            "source": 115,
            "target": 12
        },
        {
            "source": 115,
            "target": 4
        },
        {
            "source": 115,
            "target": 129
        },
        {
            "source": 115,
            "target": 47
        },
        {
            "source": 115,
            "target": 99
        },
        {
            "source": 115,
            "target": 123
        },
        {
            "source": 115,
            "target": 128
        },
        {
            "source": 115,
            "target": 0
        },
        {
            "source": 115,
            "target": 79
        },
        {
            "source": 115,
            "target": 43
        },
        {
            "source": 115,
            "target": 50
        },
        {
            "source": 115,
            "target": 69
        },
        {
            "source": 115,
            "target": 80
        },
        {
            "source": 115,
            "target": 94
        },
        {
            "source": 115,
            "target": 51
        },
        {
            "source": 115,
            "target": 10
        },
        {
            "source": 115,
            "target": 38
        },
        {
            "source": 115,
            "target": 5
        },
        {
            "source": 115,
            "target": 41
        },
        {
            "source": 115,
            "target": 136
        },
        {
            "source": 115,
            "target": 40
        },
        {
            "source": 115,
            "target": 127
        },
        {
            "source": 115,
            "target": 98
        },
        {
            "source": 115,
            "target": 48
        },
        {
            "source": 115,
            "target": 65
        },
        {
            "source": 115,
            "target": 76
        },
        {
            "source": 115,
            "target": 152
        },
        {
            "source": 115,
            "target": 11
        },
        {
            "source": 115,
            "target": 57
        },
        {
            "source": 115,
            "target": 31
        },
        {
            "source": 115,
            "target": 23
        },
        {
            "source": 115,
            "target": 150
        },
        {
            "source": 115,
            "target": 39
        },
        {
            "source": 115,
            "target": 60
        },
        {
            "source": 115,
            "target": 144
        },
        {
            "source": 115,
            "target": 68
        },
        {
            "source": 115,
            "target": 158
        },
        {
            "source": 115,
            "target": 59
        },
        {
            "source": 115,
            "target": 157
        },
        {
            "source": 115,
            "target": 28
        },
        {
            "source": 115,
            "target": 116
        },
        {
            "source": 115,
            "target": 118
        },
        {
            "source": 115,
            "target": 189
        },
        {
            "source": 115,
            "target": 149
        },
        {
            "source": 115,
            "target": 102
        },
        {
            "source": 115,
            "target": 201
        },
        {
            "source": 116,
            "target": 91
        },
        {
            "source": 116,
            "target": 21
        },
        {
            "source": 116,
            "target": 6
        },
        {
            "source": 116,
            "target": 78
        },
        {
            "source": 116,
            "target": 44
        },
        {
            "source": 116,
            "target": 96
        },
        {
            "source": 116,
            "target": 45
        },
        {
            "source": 116,
            "target": 35
        },
        {
            "source": 116,
            "target": 46
        },
        {
            "source": 116,
            "target": 12
        },
        {
            "source": 116,
            "target": 4
        },
        {
            "source": 116,
            "target": 129
        },
        {
            "source": 116,
            "target": 47
        },
        {
            "source": 116,
            "target": 99
        },
        {
            "source": 116,
            "target": 123
        },
        {
            "source": 116,
            "target": 128
        },
        {
            "source": 116,
            "target": 0
        },
        {
            "source": 116,
            "target": 140
        },
        {
            "source": 116,
            "target": 79
        },
        {
            "source": 116,
            "target": 43
        },
        {
            "source": 116,
            "target": 50
        },
        {
            "source": 116,
            "target": 69
        },
        {
            "source": 116,
            "target": 80
        },
        {
            "source": 116,
            "target": 94
        },
        {
            "source": 116,
            "target": 51
        },
        {
            "source": 116,
            "target": 10
        },
        {
            "source": 116,
            "target": 104
        },
        {
            "source": 116,
            "target": 38
        },
        {
            "source": 116,
            "target": 18
        },
        {
            "source": 116,
            "target": 5
        },
        {
            "source": 116,
            "target": 41
        },
        {
            "source": 116,
            "target": 136
        },
        {
            "source": 116,
            "target": 25
        },
        {
            "source": 116,
            "target": 40
        },
        {
            "source": 116,
            "target": 127
        },
        {
            "source": 116,
            "target": 98
        },
        {
            "source": 116,
            "target": 48
        },
        {
            "source": 116,
            "target": 115
        },
        {
            "source": 116,
            "target": 65
        },
        {
            "source": 116,
            "target": 76
        },
        {
            "source": 116,
            "target": 152
        },
        {
            "source": 116,
            "target": 11
        },
        {
            "source": 116,
            "target": 57
        },
        {
            "source": 116,
            "target": 90
        },
        {
            "source": 116,
            "target": 31
        },
        {
            "source": 116,
            "target": 23
        },
        {
            "source": 116,
            "target": 39
        },
        {
            "source": 116,
            "target": 60
        },
        {
            "source": 116,
            "target": 144
        },
        {
            "source": 116,
            "target": 68
        },
        {
            "source": 116,
            "target": 158
        },
        {
            "source": 116,
            "target": 59
        },
        {
            "source": 116,
            "target": 27
        },
        {
            "source": 116,
            "target": 83
        },
        {
            "source": 116,
            "target": 157
        },
        {
            "source": 116,
            "target": 30
        },
        {
            "source": 116,
            "target": 28
        },
        {
            "source": 116,
            "target": 103
        },
        {
            "source": 116,
            "target": 270
        },
        {
            "source": 117,
            "target": 27
        },
        {
            "source": 118,
            "target": 21
        },
        {
            "source": 118,
            "target": 6
        },
        {
            "source": 118,
            "target": 78
        },
        {
            "source": 118,
            "target": 44
        },
        {
            "source": 118,
            "target": 96
        },
        {
            "source": 118,
            "target": 45
        },
        {
            "source": 118,
            "target": 35
        },
        {
            "source": 118,
            "target": 46
        },
        {
            "source": 118,
            "target": 12
        },
        {
            "source": 118,
            "target": 4
        },
        {
            "source": 118,
            "target": 129
        },
        {
            "source": 118,
            "target": 47
        },
        {
            "source": 118,
            "target": 99
        },
        {
            "source": 118,
            "target": 123
        },
        {
            "source": 118,
            "target": 128
        },
        {
            "source": 118,
            "target": 0
        },
        {
            "source": 118,
            "target": 36
        },
        {
            "source": 118,
            "target": 79
        },
        {
            "source": 118,
            "target": 43
        },
        {
            "source": 118,
            "target": 50
        },
        {
            "source": 118,
            "target": 69
        },
        {
            "source": 118,
            "target": 80
        },
        {
            "source": 118,
            "target": 94
        },
        {
            "source": 118,
            "target": 51
        },
        {
            "source": 118,
            "target": 10
        },
        {
            "source": 118,
            "target": 104
        },
        {
            "source": 118,
            "target": 38
        },
        {
            "source": 118,
            "target": 5
        },
        {
            "source": 118,
            "target": 41
        },
        {
            "source": 118,
            "target": 136
        },
        {
            "source": 118,
            "target": 40
        },
        {
            "source": 118,
            "target": 127
        },
        {
            "source": 118,
            "target": 98
        },
        {
            "source": 118,
            "target": 48
        },
        {
            "source": 118,
            "target": 115
        },
        {
            "source": 118,
            "target": 65
        },
        {
            "source": 118,
            "target": 76
        },
        {
            "source": 118,
            "target": 152
        },
        {
            "source": 118,
            "target": 11
        },
        {
            "source": 118,
            "target": 57
        },
        {
            "source": 118,
            "target": 31
        },
        {
            "source": 118,
            "target": 23
        },
        {
            "source": 118,
            "target": 39
        },
        {
            "source": 118,
            "target": 60
        },
        {
            "source": 118,
            "target": 144
        },
        {
            "source": 118,
            "target": 68
        },
        {
            "source": 118,
            "target": 158
        },
        {
            "source": 118,
            "target": 59
        },
        {
            "source": 118,
            "target": 157
        },
        {
            "source": 118,
            "target": 28
        },
        {
            "source": 118,
            "target": 116
        },
        {
            "source": 118,
            "target": 189
        },
        {
            "source": 118,
            "target": 149
        },
        {
            "source": 118,
            "target": 102
        },
        {
            "source": 118,
            "target": 244
        },
        {
            "source": 119,
            "target": 167
        },
        {
            "source": 119,
            "target": 112
        },
        {
            "source": 119,
            "target": 248
        },
        {
            "source": 119,
            "target": 290
        },
        {
            "source": 120,
            "target": 88
        },
        {
            "source": 120,
            "target": 27
        },
        {
            "source": 120,
            "target": 291
        },
        {
            "source": 121,
            "target": 6
        },
        {
            "source": 121,
            "target": 25
        },
        {
            "source": 121,
            "target": 125
        },
        {
            "source": 121,
            "target": 27
        },
        {
            "source": 122,
            "target": 185
        },
        {
            "source": 122,
            "target": 104
        },
        {
            "source": 122,
            "target": 124
        },
        {
            "source": 122,
            "target": 27
        },
        {
            "source": 123,
            "target": 21
        },
        {
            "source": 123,
            "target": 6
        },
        {
            "source": 123,
            "target": 78
        },
        {
            "source": 123,
            "target": 44
        },
        {
            "source": 123,
            "target": 96
        },
        {
            "source": 123,
            "target": 45
        },
        {
            "source": 123,
            "target": 35
        },
        {
            "source": 123,
            "target": 46
        },
        {
            "source": 123,
            "target": 12
        },
        {
            "source": 123,
            "target": 4
        },
        {
            "source": 123,
            "target": 129
        },
        {
            "source": 123,
            "target": 47
        },
        {
            "source": 123,
            "target": 99
        },
        {
            "source": 123,
            "target": 128
        },
        {
            "source": 123,
            "target": 0
        },
        {
            "source": 123,
            "target": 79
        },
        {
            "source": 123,
            "target": 43
        },
        {
            "source": 123,
            "target": 50
        },
        {
            "source": 123,
            "target": 69
        },
        {
            "source": 123,
            "target": 80
        },
        {
            "source": 123,
            "target": 94
        },
        {
            "source": 123,
            "target": 51
        },
        {
            "source": 123,
            "target": 10
        },
        {
            "source": 123,
            "target": 38
        },
        {
            "source": 123,
            "target": 5
        },
        {
            "source": 123,
            "target": 41
        },
        {
            "source": 123,
            "target": 136
        },
        {
            "source": 123,
            "target": 25
        },
        {
            "source": 123,
            "target": 40
        },
        {
            "source": 123,
            "target": 127
        },
        {
            "source": 123,
            "target": 98
        },
        {
            "source": 123,
            "target": 48
        },
        {
            "source": 123,
            "target": 115
        },
        {
            "source": 123,
            "target": 65
        },
        {
            "source": 123,
            "target": 76
        },
        {
            "source": 123,
            "target": 152
        },
        {
            "source": 123,
            "target": 11
        },
        {
            "source": 123,
            "target": 57
        },
        {
            "source": 123,
            "target": 31
        },
        {
            "source": 123,
            "target": 23
        },
        {
            "source": 123,
            "target": 39
        },
        {
            "source": 123,
            "target": 60
        },
        {
            "source": 123,
            "target": 144
        },
        {
            "source": 123,
            "target": 68
        },
        {
            "source": 123,
            "target": 158
        },
        {
            "source": 123,
            "target": 59
        },
        {
            "source": 123,
            "target": 27
        },
        {
            "source": 123,
            "target": 157
        },
        {
            "source": 123,
            "target": 28
        },
        {
            "source": 123,
            "target": 116
        },
        {
            "source": 123,
            "target": 118
        },
        {
            "source": 123,
            "target": 189
        },
        {
            "source": 123,
            "target": 149
        },
        {
            "source": 123,
            "target": 102
        },
        {
            "source": 124,
            "target": 87
        },
        {
            "source": 124,
            "target": 25
        },
        {
            "source": 124,
            "target": 27
        },
        {
            "source": 125,
            "target": 6
        },
        {
            "source": 125,
            "target": 121
        },
        {
            "source": 125,
            "target": 284
        },
        {
            "source": 126,
            "target": 98
        },
        {
            "source": 126,
            "target": 195
        },
        {
            "source": 126,
            "target": 27
        },
        {
            "source": 126,
            "target": 102
        },
        {
            "source": 126,
            "target": 281
        },
        {
            "source": 127,
            "target": 92
        },
        {
            "source": 127,
            "target": 78
        },
        {
            "source": 127,
            "target": 45
        },
        {
            "source": 127,
            "target": 4
        },
        {
            "source": 127,
            "target": 128
        },
        {
            "source": 127,
            "target": 52
        },
        {
            "source": 127,
            "target": 0
        },
        {
            "source": 127,
            "target": 69
        },
        {
            "source": 127,
            "target": 80
        },
        {
            "source": 127,
            "target": 25
        },
        {
            "source": 127,
            "target": 19
        },
        {
            "source": 127,
            "target": 103
        },
        {
            "source": 127,
            "target": 189
        },
        {
            "source": 127,
            "target": 257
        },
        {
            "source": 128,
            "target": 8
        },
        {
            "source": 128,
            "target": 21
        },
        {
            "source": 128,
            "target": 6
        },
        {
            "source": 128,
            "target": 78
        },
        {
            "source": 128,
            "target": 44
        },
        {
            "source": 128,
            "target": 96
        },
        {
            "source": 128,
            "target": 45
        },
        {
            "source": 128,
            "target": 35
        },
        {
            "source": 128,
            "target": 15
        },
        {
            "source": 128,
            "target": 75
        },
        {
            "source": 128,
            "target": 46
        },
        {
            "source": 128,
            "target": 71
        },
        {
            "source": 128,
            "target": 12
        },
        {
            "source": 128,
            "target": 4
        },
        {
            "source": 128,
            "target": 129
        },
        {
            "source": 128,
            "target": 47
        },
        {
            "source": 128,
            "target": 99
        },
        {
            "source": 128,
            "target": 123
        },
        {
            "source": 128,
            "target": 52
        },
        {
            "source": 128,
            "target": 0
        },
        {
            "source": 128,
            "target": 36
        },
        {
            "source": 128,
            "target": 161
        },
        {
            "source": 128,
            "target": 79
        },
        {
            "source": 128,
            "target": 43
        },
        {
            "source": 128,
            "target": 50
        },
        {
            "source": 128,
            "target": 69
        },
        {
            "source": 128,
            "target": 80
        },
        {
            "source": 128,
            "target": 94
        },
        {
            "source": 128,
            "target": 51
        },
        {
            "source": 128,
            "target": 10
        },
        {
            "source": 128,
            "target": 38
        },
        {
            "source": 128,
            "target": 5
        },
        {
            "source": 128,
            "target": 41
        },
        {
            "source": 128,
            "target": 136
        },
        {
            "source": 128,
            "target": 62
        },
        {
            "source": 128,
            "target": 25
        },
        {
            "source": 128,
            "target": 40
        },
        {
            "source": 128,
            "target": 127
        },
        {
            "source": 128,
            "target": 98
        },
        {
            "source": 128,
            "target": 48
        },
        {
            "source": 128,
            "target": 115
        },
        {
            "source": 128,
            "target": 65
        },
        {
            "source": 128,
            "target": 76
        },
        {
            "source": 128,
            "target": 67
        },
        {
            "source": 128,
            "target": 77
        },
        {
            "source": 128,
            "target": 152
        },
        {
            "source": 128,
            "target": 11
        },
        {
            "source": 128,
            "target": 57
        },
        {
            "source": 128,
            "target": 19
        },
        {
            "source": 128,
            "target": 31
        },
        {
            "source": 128,
            "target": 23
        },
        {
            "source": 128,
            "target": 39
        },
        {
            "source": 128,
            "target": 60
        },
        {
            "source": 128,
            "target": 144
        },
        {
            "source": 128,
            "target": 68
        },
        {
            "source": 128,
            "target": 158
        },
        {
            "source": 128,
            "target": 59
        },
        {
            "source": 128,
            "target": 157
        },
        {
            "source": 128,
            "target": 28
        },
        {
            "source": 128,
            "target": 116
        },
        {
            "source": 128,
            "target": 118
        },
        {
            "source": 128,
            "target": 189
        },
        {
            "source": 128,
            "target": 149
        },
        {
            "source": 128,
            "target": 102
        },
        {
            "source": 128,
            "target": 288
        },
        {
            "source": 129,
            "target": 21
        },
        {
            "source": 129,
            "target": 6
        },
        {
            "source": 129,
            "target": 78
        },
        {
            "source": 129,
            "target": 44
        },
        {
            "source": 129,
            "target": 198
        },
        {
            "source": 129,
            "target": 96
        },
        {
            "source": 129,
            "target": 45
        },
        {
            "source": 129,
            "target": 35
        },
        {
            "source": 129,
            "target": 46
        },
        {
            "source": 129,
            "target": 12
        },
        {
            "source": 129,
            "target": 4
        },
        {
            "source": 129,
            "target": 47
        },
        {
            "source": 129,
            "target": 99
        },
        {
            "source": 129,
            "target": 123
        },
        {
            "source": 129,
            "target": 128
        },
        {
            "source": 129,
            "target": 0
        },
        {
            "source": 129,
            "target": 79
        },
        {
            "source": 129,
            "target": 43
        },
        {
            "source": 129,
            "target": 50
        },
        {
            "source": 129,
            "target": 69
        },
        {
            "source": 129,
            "target": 80
        },
        {
            "source": 129,
            "target": 94
        },
        {
            "source": 129,
            "target": 51
        },
        {
            "source": 129,
            "target": 10
        },
        {
            "source": 129,
            "target": 104
        },
        {
            "source": 129,
            "target": 114
        },
        {
            "source": 129,
            "target": 38
        },
        {
            "source": 129,
            "target": 5
        },
        {
            "source": 129,
            "target": 41
        },
        {
            "source": 129,
            "target": 136
        },
        {
            "source": 129,
            "target": 40
        },
        {
            "source": 129,
            "target": 127
        },
        {
            "source": 129,
            "target": 98
        },
        {
            "source": 129,
            "target": 48
        },
        {
            "source": 129,
            "target": 115
        },
        {
            "source": 129,
            "target": 65
        },
        {
            "source": 129,
            "target": 76
        },
        {
            "source": 129,
            "target": 152
        },
        {
            "source": 129,
            "target": 11
        },
        {
            "source": 129,
            "target": 57
        },
        {
            "source": 129,
            "target": 31
        },
        {
            "source": 129,
            "target": 23
        },
        {
            "source": 129,
            "target": 39
        },
        {
            "source": 129,
            "target": 60
        },
        {
            "source": 129,
            "target": 144
        },
        {
            "source": 129,
            "target": 68
        },
        {
            "source": 129,
            "target": 158
        },
        {
            "source": 129,
            "target": 59
        },
        {
            "source": 129,
            "target": 157
        },
        {
            "source": 129,
            "target": 28
        },
        {
            "source": 129,
            "target": 116
        },
        {
            "source": 129,
            "target": 118
        },
        {
            "source": 129,
            "target": 189
        },
        {
            "source": 129,
            "target": 149
        },
        {
            "source": 129,
            "target": 102
        },
        {
            "source": 130,
            "target": 27
        },
        {
            "source": 130,
            "target": 203
        },
        {
            "source": 131,
            "target": 25
        },
        {
            "source": 131,
            "target": 27
        },
        {
            "source": 132,
            "target": 25
        },
        {
            "source": 132,
            "target": 263
        },
        {
            "source": 134,
            "target": 27
        },
        {
            "source": 134,
            "target": 214
        },
        {
            "source": 134,
            "target": 272
        },
        {
            "source": 135,
            "target": 160
        },
        {
            "source": 135,
            "target": 90
        },
        {
            "source": 135,
            "target": 234
        },
        {
            "source": 136,
            "target": 21
        },
        {
            "source": 136,
            "target": 6
        },
        {
            "source": 136,
            "target": 78
        },
        {
            "source": 136,
            "target": 44
        },
        {
            "source": 136,
            "target": 96
        },
        {
            "source": 136,
            "target": 45
        },
        {
            "source": 136,
            "target": 35
        },
        {
            "source": 136,
            "target": 46
        },
        {
            "source": 136,
            "target": 12
        },
        {
            "source": 136,
            "target": 29
        },
        {
            "source": 136,
            "target": 4
        },
        {
            "source": 136,
            "target": 129
        },
        {
            "source": 136,
            "target": 47
        },
        {
            "source": 136,
            "target": 99
        },
        {
            "source": 136,
            "target": 123
        },
        {
            "source": 136,
            "target": 128
        },
        {
            "source": 136,
            "target": 0
        },
        {
            "source": 136,
            "target": 79
        },
        {
            "source": 136,
            "target": 43
        },
        {
            "source": 136,
            "target": 50
        },
        {
            "source": 136,
            "target": 69
        },
        {
            "source": 136,
            "target": 80
        },
        {
            "source": 136,
            "target": 94
        },
        {
            "source": 136,
            "target": 51
        },
        {
            "source": 136,
            "target": 10
        },
        {
            "source": 136,
            "target": 38
        },
        {
            "source": 136,
            "target": 5
        },
        {
            "source": 136,
            "target": 41
        },
        {
            "source": 136,
            "target": 40
        },
        {
            "source": 136,
            "target": 127
        },
        {
            "source": 136,
            "target": 98
        },
        {
            "source": 136,
            "target": 48
        },
        {
            "source": 136,
            "target": 115
        },
        {
            "source": 136,
            "target": 65
        },
        {
            "source": 136,
            "target": 76
        },
        {
            "source": 136,
            "target": 152
        },
        {
            "source": 136,
            "target": 11
        },
        {
            "source": 136,
            "target": 57
        },
        {
            "source": 136,
            "target": 14
        },
        {
            "source": 136,
            "target": 31
        },
        {
            "source": 136,
            "target": 23
        },
        {
            "source": 136,
            "target": 39
        },
        {
            "source": 136,
            "target": 60
        },
        {
            "source": 136,
            "target": 144
        },
        {
            "source": 136,
            "target": 68
        },
        {
            "source": 136,
            "target": 158
        },
        {
            "source": 136,
            "target": 59
        },
        {
            "source": 136,
            "target": 27
        },
        {
            "source": 136,
            "target": 83
        },
        {
            "source": 136,
            "target": 157
        },
        {
            "source": 136,
            "target": 28
        },
        {
            "source": 136,
            "target": 116
        },
        {
            "source": 136,
            "target": 118
        },
        {
            "source": 136,
            "target": 189
        },
        {
            "source": 136,
            "target": 138
        },
        {
            "source": 136,
            "target": 149
        },
        {
            "source": 136,
            "target": 102
        },
        {
            "source": 137,
            "target": 198
        },
        {
            "source": 137,
            "target": 153
        },
        {
            "source": 137,
            "target": 159
        },
        {
            "source": 137,
            "target": 129
        },
        {
            "source": 137,
            "target": 146
        },
        {
            "source": 137,
            "target": 148
        },
        {
            "source": 137,
            "target": 51
        },
        {
            "source": 137,
            "target": 179
        },
        {
            "source": 137,
            "target": 104
        },
        {
            "source": 137,
            "target": 181
        },
        {
            "source": 137,
            "target": 114
        },
        {
            "source": 137,
            "target": 38
        },
        {
            "source": 137,
            "target": 156
        },
        {
            "source": 137,
            "target": 26
        },
        {
            "source": 137,
            "target": 245
        },
        {
            "source": 137,
            "target": 251
        },
        {
            "source": 137,
            "target": 252
        },
        {
            "source": 137,
            "target": 278
        },
        {
            "source": 138,
            "target": 99
        },
        {
            "source": 138,
            "target": 0
        },
        {
            "source": 138,
            "target": 94
        },
        {
            "source": 138,
            "target": 10
        },
        {
            "source": 138,
            "target": 25
        },
        {
            "source": 138,
            "target": 152
        },
        {
            "source": 138,
            "target": 14
        },
        {
            "source": 138,
            "target": 32
        },
        {
            "source": 138,
            "target": 113
        },
        {
            "source": 138,
            "target": 54
        },
        {
            "source": 138,
            "target": 60
        },
        {
            "source": 138,
            "target": 144
        },
        {
            "source": 138,
            "target": 16
        },
        {
            "source": 138,
            "target": 68
        },
        {
            "source": 138,
            "target": 27
        },
        {
            "source": 138,
            "target": 83
        },
        {
            "source": 138,
            "target": 247
        },
        {
            "source": 139,
            "target": 44
        },
        {
            "source": 139,
            "target": 25
        },
        {
            "source": 139,
            "target": 131
        },
        {
            "source": 139,
            "target": 199
        },
        {
            "source": 139,
            "target": 286
        },
        {
            "source": 140,
            "target": 25
        },
        {
            "source": 140,
            "target": 27
        },
        {
            "source": 140,
            "target": 116
        },
        {
            "source": 140,
            "target": 149
        },
        {
            "source": 141,
            "target": 90
        },
        {
            "source": 141,
            "target": 135
        },
        {
            "source": 142,
            "target": 35
        },
        {
            "source": 144,
            "target": 21
        },
        {
            "source": 144,
            "target": 6
        },
        {
            "source": 144,
            "target": 78
        },
        {
            "source": 144,
            "target": 44
        },
        {
            "source": 144,
            "target": 96
        },
        {
            "source": 144,
            "target": 45
        },
        {
            "source": 144,
            "target": 35
        },
        {
            "source": 144,
            "target": 46
        },
        {
            "source": 144,
            "target": 12
        },
        {
            "source": 144,
            "target": 4
        },
        {
            "source": 144,
            "target": 129
        },
        {
            "source": 144,
            "target": 47
        },
        {
            "source": 144,
            "target": 99
        },
        {
            "source": 144,
            "target": 88
        },
        {
            "source": 144,
            "target": 123
        },
        {
            "source": 144,
            "target": 128
        },
        {
            "source": 144,
            "target": 0
        },
        {
            "source": 144,
            "target": 79
        },
        {
            "source": 144,
            "target": 43
        },
        {
            "source": 144,
            "target": 50
        },
        {
            "source": 144,
            "target": 69
        },
        {
            "source": 144,
            "target": 80
        },
        {
            "source": 144,
            "target": 94
        },
        {
            "source": 144,
            "target": 51
        },
        {
            "source": 144,
            "target": 10
        },
        {
            "source": 144,
            "target": 38
        },
        {
            "source": 144,
            "target": 18
        },
        {
            "source": 144,
            "target": 5
        },
        {
            "source": 144,
            "target": 41
        },
        {
            "source": 144,
            "target": 136
        },
        {
            "source": 144,
            "target": 25
        },
        {
            "source": 144,
            "target": 40
        },
        {
            "source": 144,
            "target": 127
        },
        {
            "source": 144,
            "target": 98
        },
        {
            "source": 144,
            "target": 48
        },
        {
            "source": 144,
            "target": 115
        },
        {
            "source": 144,
            "target": 65
        },
        {
            "source": 144,
            "target": 76
        },
        {
            "source": 144,
            "target": 152
        },
        {
            "source": 144,
            "target": 11
        },
        {
            "source": 144,
            "target": 57
        },
        {
            "source": 144,
            "target": 32
        },
        {
            "source": 144,
            "target": 31
        },
        {
            "source": 144,
            "target": 23
        },
        {
            "source": 144,
            "target": 150
        },
        {
            "source": 144,
            "target": 39
        },
        {
            "source": 144,
            "target": 113
        },
        {
            "source": 144,
            "target": 60
        },
        {
            "source": 144,
            "target": 16
        },
        {
            "source": 144,
            "target": 68
        },
        {
            "source": 144,
            "target": 158
        },
        {
            "source": 144,
            "target": 59
        },
        {
            "source": 144,
            "target": 27
        },
        {
            "source": 144,
            "target": 83
        },
        {
            "source": 144,
            "target": 157
        },
        {
            "source": 144,
            "target": 28
        },
        {
            "source": 144,
            "target": 116
        },
        {
            "source": 144,
            "target": 118
        },
        {
            "source": 144,
            "target": 189
        },
        {
            "source": 144,
            "target": 138
        },
        {
            "source": 144,
            "target": 149
        },
        {
            "source": 144,
            "target": 102
        },
        {
            "source": 144,
            "target": 292
        },
        {
            "source": 145,
            "target": 56
        },
        {
            "source": 145,
            "target": 0
        },
        {
            "source": 145,
            "target": 25
        },
        {
            "source": 145,
            "target": 27
        },
        {
            "source": 145,
            "target": 266
        },
        {
            "source": 146,
            "target": 179
        },
        {
            "source": 146,
            "target": 104
        },
        {
            "source": 147,
            "target": 44
        },
        {
            "source": 147,
            "target": 35
        },
        {
            "source": 147,
            "target": 57
        },
        {
            "source": 147,
            "target": 108
        },
        {
            "source": 147,
            "target": 243
        },
        {
            "source": 148,
            "target": 104
        },
        {
            "source": 148,
            "target": 212
        },
        {
            "source": 148,
            "target": 233
        },
        {
            "source": 148,
            "target": 293
        },
        {
            "source": 149,
            "target": 21
        },
        {
            "source": 149,
            "target": 6
        },
        {
            "source": 149,
            "target": 78
        },
        {
            "source": 149,
            "target": 44
        },
        {
            "source": 149,
            "target": 96
        },
        {
            "source": 149,
            "target": 45
        },
        {
            "source": 149,
            "target": 35
        },
        {
            "source": 149,
            "target": 46
        },
        {
            "source": 149,
            "target": 12
        },
        {
            "source": 149,
            "target": 4
        },
        {
            "source": 149,
            "target": 129
        },
        {
            "source": 149,
            "target": 47
        },
        {
            "source": 149,
            "target": 99
        },
        {
            "source": 149,
            "target": 123
        },
        {
            "source": 149,
            "target": 128
        },
        {
            "source": 149,
            "target": 0
        },
        {
            "source": 149,
            "target": 140
        },
        {
            "source": 149,
            "target": 79
        },
        {
            "source": 149,
            "target": 43
        },
        {
            "source": 149,
            "target": 50
        },
        {
            "source": 149,
            "target": 69
        },
        {
            "source": 149,
            "target": 80
        },
        {
            "source": 149,
            "target": 94
        },
        {
            "source": 149,
            "target": 51
        },
        {
            "source": 149,
            "target": 10
        },
        {
            "source": 149,
            "target": 104
        },
        {
            "source": 149,
            "target": 38
        },
        {
            "source": 149,
            "target": 5
        },
        {
            "source": 149,
            "target": 41
        },
        {
            "source": 149,
            "target": 136
        },
        {
            "source": 149,
            "target": 25
        },
        {
            "source": 149,
            "target": 40
        },
        {
            "source": 149,
            "target": 127
        },
        {
            "source": 149,
            "target": 98
        },
        {
            "source": 149,
            "target": 48
        },
        {
            "source": 149,
            "target": 115
        },
        {
            "source": 149,
            "target": 65
        },
        {
            "source": 149,
            "target": 76
        },
        {
            "source": 149,
            "target": 152
        },
        {
            "source": 149,
            "target": 11
        },
        {
            "source": 149,
            "target": 57
        },
        {
            "source": 149,
            "target": 32
        },
        {
            "source": 149,
            "target": 31
        },
        {
            "source": 149,
            "target": 23
        },
        {
            "source": 149,
            "target": 39
        },
        {
            "source": 149,
            "target": 113
        },
        {
            "source": 149,
            "target": 60
        },
        {
            "source": 149,
            "target": 144
        },
        {
            "source": 149,
            "target": 16
        },
        {
            "source": 149,
            "target": 68
        },
        {
            "source": 149,
            "target": 158
        },
        {
            "source": 149,
            "target": 59
        },
        {
            "source": 149,
            "target": 27
        },
        {
            "source": 149,
            "target": 157
        },
        {
            "source": 149,
            "target": 28
        },
        {
            "source": 149,
            "target": 116
        },
        {
            "source": 149,
            "target": 118
        },
        {
            "source": 149,
            "target": 189
        },
        {
            "source": 149,
            "target": 102
        },
        {
            "source": 150,
            "target": 99
        },
        {
            "source": 150,
            "target": 86
        },
        {
            "source": 150,
            "target": 0
        },
        {
            "source": 150,
            "target": 94
        },
        {
            "source": 150,
            "target": 10
        },
        {
            "source": 150,
            "target": 152
        },
        {
            "source": 150,
            "target": 32
        },
        {
            "source": 150,
            "target": 113
        },
        {
            "source": 150,
            "target": 144
        },
        {
            "source": 150,
            "target": 16
        },
        {
            "source": 150,
            "target": 200
        },
        {
            "source": 150,
            "target": 267
        },
        {
            "source": 151,
            "target": 25
        },
        {
            "source": 151,
            "target": 27
        },
        {
            "source": 151,
            "target": 221
        },
        {
            "source": 152,
            "target": 21
        },
        {
            "source": 152,
            "target": 6
        },
        {
            "source": 152,
            "target": 78
        },
        {
            "source": 152,
            "target": 44
        },
        {
            "source": 152,
            "target": 96
        },
        {
            "source": 152,
            "target": 45
        },
        {
            "source": 152,
            "target": 35
        },
        {
            "source": 152,
            "target": 46
        },
        {
            "source": 152,
            "target": 12
        },
        {
            "source": 152,
            "target": 4
        },
        {
            "source": 152,
            "target": 129
        },
        {
            "source": 152,
            "target": 47
        },
        {
            "source": 152,
            "target": 99
        },
        {
            "source": 152,
            "target": 123
        },
        {
            "source": 152,
            "target": 128
        },
        {
            "source": 152,
            "target": 0
        },
        {
            "source": 152,
            "target": 79
        },
        {
            "source": 152,
            "target": 43
        },
        {
            "source": 152,
            "target": 50
        },
        {
            "source": 152,
            "target": 69
        },
        {
            "source": 152,
            "target": 80
        },
        {
            "source": 152,
            "target": 94
        },
        {
            "source": 152,
            "target": 51
        },
        {
            "source": 152,
            "target": 10
        },
        {
            "source": 152,
            "target": 38
        },
        {
            "source": 152,
            "target": 5
        },
        {
            "source": 152,
            "target": 41
        },
        {
            "source": 152,
            "target": 136
        },
        {
            "source": 152,
            "target": 40
        },
        {
            "source": 152,
            "target": 127
        },
        {
            "source": 152,
            "target": 98
        },
        {
            "source": 152,
            "target": 48
        },
        {
            "source": 152,
            "target": 115
        },
        {
            "source": 152,
            "target": 65
        },
        {
            "source": 152,
            "target": 76
        },
        {
            "source": 152,
            "target": 11
        },
        {
            "source": 152,
            "target": 57
        },
        {
            "source": 152,
            "target": 32
        },
        {
            "source": 152,
            "target": 31
        },
        {
            "source": 152,
            "target": 23
        },
        {
            "source": 152,
            "target": 39
        },
        {
            "source": 152,
            "target": 113
        },
        {
            "source": 152,
            "target": 60
        },
        {
            "source": 152,
            "target": 144
        },
        {
            "source": 152,
            "target": 16
        },
        {
            "source": 152,
            "target": 68
        },
        {
            "source": 152,
            "target": 158
        },
        {
            "source": 152,
            "target": 59
        },
        {
            "source": 152,
            "target": 27
        },
        {
            "source": 152,
            "target": 157
        },
        {
            "source": 152,
            "target": 28
        },
        {
            "source": 152,
            "target": 116
        },
        {
            "source": 152,
            "target": 118
        },
        {
            "source": 152,
            "target": 189
        },
        {
            "source": 152,
            "target": 149
        },
        {
            "source": 152,
            "target": 102
        },
        {
            "source": 152,
            "target": 208
        },
        {
            "source": 153,
            "target": 51
        },
        {
            "source": 153,
            "target": 179
        },
        {
            "source": 153,
            "target": 104
        },
        {
            "source": 153,
            "target": 209
        },
        {
            "source": 154,
            "target": 104
        },
        {
            "source": 155,
            "target": 42
        },
        {
            "source": 156,
            "target": 198
        },
        {
            "source": 156,
            "target": 153
        },
        {
            "source": 156,
            "target": 159
        },
        {
            "source": 156,
            "target": 129
        },
        {
            "source": 156,
            "target": 146
        },
        {
            "source": 156,
            "target": 137
        },
        {
            "source": 156,
            "target": 148
        },
        {
            "source": 156,
            "target": 51
        },
        {
            "source": 156,
            "target": 179
        },
        {
            "source": 156,
            "target": 104
        },
        {
            "source": 156,
            "target": 181
        },
        {
            "source": 156,
            "target": 114
        },
        {
            "source": 156,
            "target": 38
        },
        {
            "source": 156,
            "target": 287
        },
        {
            "source": 157,
            "target": 35
        },
        {
            "source": 157,
            "target": 25
        },
        {
            "source": 157,
            "target": 19
        },
        {
            "source": 157,
            "target": 27
        },
        {
            "source": 157,
            "target": 226
        },
        {
            "source": 158,
            "target": 21
        },
        {
            "source": 158,
            "target": 6
        },
        {
            "source": 158,
            "target": 78
        },
        {
            "source": 158,
            "target": 44
        },
        {
            "source": 158,
            "target": 96
        },
        {
            "source": 158,
            "target": 45
        },
        {
            "source": 158,
            "target": 35
        },
        {
            "source": 158,
            "target": 46
        },
        {
            "source": 158,
            "target": 12
        },
        {
            "source": 158,
            "target": 4
        },
        {
            "source": 158,
            "target": 129
        },
        {
            "source": 158,
            "target": 47
        },
        {
            "source": 158,
            "target": 99
        },
        {
            "source": 158,
            "target": 123
        },
        {
            "source": 158,
            "target": 128
        },
        {
            "source": 158,
            "target": 0
        },
        {
            "source": 158,
            "target": 79
        },
        {
            "source": 158,
            "target": 43
        },
        {
            "source": 158,
            "target": 50
        },
        {
            "source": 158,
            "target": 69
        },
        {
            "source": 158,
            "target": 80
        },
        {
            "source": 158,
            "target": 94
        },
        {
            "source": 158,
            "target": 51
        },
        {
            "source": 158,
            "target": 10
        },
        {
            "source": 158,
            "target": 38
        },
        {
            "source": 158,
            "target": 5
        },
        {
            "source": 158,
            "target": 41
        },
        {
            "source": 158,
            "target": 136
        },
        {
            "source": 158,
            "target": 40
        },
        {
            "source": 158,
            "target": 127
        },
        {
            "source": 158,
            "target": 98
        },
        {
            "source": 158,
            "target": 48
        },
        {
            "source": 158,
            "target": 115
        },
        {
            "source": 158,
            "target": 65
        },
        {
            "source": 158,
            "target": 76
        },
        {
            "source": 158,
            "target": 152
        },
        {
            "source": 158,
            "target": 11
        },
        {
            "source": 158,
            "target": 57
        },
        {
            "source": 158,
            "target": 31
        },
        {
            "source": 158,
            "target": 23
        },
        {
            "source": 158,
            "target": 39
        },
        {
            "source": 158,
            "target": 60
        },
        {
            "source": 158,
            "target": 144
        },
        {
            "source": 158,
            "target": 68
        },
        {
            "source": 158,
            "target": 59
        },
        {
            "source": 158,
            "target": 27
        },
        {
            "source": 158,
            "target": 157
        },
        {
            "source": 158,
            "target": 28
        },
        {
            "source": 158,
            "target": 116
        },
        {
            "source": 158,
            "target": 118
        },
        {
            "source": 158,
            "target": 189
        },
        {
            "source": 158,
            "target": 149
        },
        {
            "source": 158,
            "target": 102
        },
        {
            "source": 159,
            "target": 198
        },
        {
            "source": 159,
            "target": 153
        },
        {
            "source": 159,
            "target": 129
        },
        {
            "source": 159,
            "target": 146
        },
        {
            "source": 159,
            "target": 137
        },
        {
            "source": 159,
            "target": 148
        },
        {
            "source": 159,
            "target": 51
        },
        {
            "source": 159,
            "target": 179
        },
        {
            "source": 159,
            "target": 104
        },
        {
            "source": 159,
            "target": 181
        },
        {
            "source": 159,
            "target": 114
        },
        {
            "source": 159,
            "target": 38
        },
        {
            "source": 159,
            "target": 156
        },
        {
            "source": 159,
            "target": 26
        },
        {
            "source": 159,
            "target": 209
        },
        {
            "source": 160,
            "target": 25
        },
        {
            "source": 160,
            "target": 228
        },
        {
            "source": 160,
            "target": 285
        },
        {
            "source": 161,
            "target": 112
        },
        {
            "source": 161,
            "target": 27
        },
        {
            "source": 162,
            "target": 12
        },
        {
            "source": 162,
            "target": 53
        },
        {
            "source": 162,
            "target": 25
        },
        {
            "source": 162,
            "target": 27
        },
        {
            "source": 162,
            "target": 204
        },
        {
            "source": 162,
            "target": 246
        },
        {
            "source": 162,
            "target": 283
        },
        {
            "source": 163,
            "target": 35
        },
        {
            "source": 163,
            "target": 215
        },
        {
            "source": 163,
            "target": 225
        },
        {
            "source": 163,
            "target": 254
        },
        {
            "source": 163,
            "target": 264
        },
        {
            "source": 164,
            "target": 232
        },
        {
            "source": 165,
            "target": 261
        },
        {
            "source": 166,
            "target": 6
        },
        {
            "source": 166,
            "target": 5
        },
        {
            "source": 166,
            "target": 25
        },
        {
            "source": 166,
            "target": 27
        },
        {
            "source": 166,
            "target": 275
        },
        {
            "source": 167,
            "target": 27
        },
        {
            "source": 167,
            "target": 256
        },
        {
            "source": 167,
            "target": 269
        },
        {
            "source": 168,
            "target": 34
        },
        {
            "source": 168,
            "target": 27
        },
        {
            "source": 169,
            "target": 197
        },
        {
            "source": 169,
            "target": 99
        },
        {
            "source": 169,
            "target": 105
        },
        {
            "source": 169,
            "target": 34
        },
        {
            "source": 170,
            "target": 98
        },
        {
            "source": 170,
            "target": 195
        },
        {
            "source": 170,
            "target": 126
        },
        {
            "source": 170,
            "target": 190
        },
        {
            "source": 170,
            "target": 231
        },
        {
            "source": 170,
            "target": 250
        },
        {
            "source": 171,
            "target": 160
        },
        {
            "source": 171,
            "target": 179
        },
        {
            "source": 171,
            "target": 104
        },
        {
            "source": 171,
            "target": 25
        },
        {
            "source": 171,
            "target": 27
        },
        {
            "source": 171,
            "target": 220
        },
        {
            "source": 171,
            "target": 259
        },
        {
            "source": 171,
            "target": 260
        },
        {
            "source": 172,
            "target": 25
        },
        {
            "source": 172,
            "target": 27
        },
        {
            "source": 172,
            "target": 22
        },
        {
            "source": 172,
            "target": 7
        },
        {
            "source": 172,
            "target": 289
        },
        {
            "source": 173,
            "target": 133
        },
        {
            "source": 173,
            "target": 25
        },
        {
            "source": 173,
            "target": 171
        },
        {
            "source": 173,
            "target": 265
        },
        {
            "source": 174,
            "target": 108
        },
        {
            "source": 174,
            "target": 223
        },
        {
            "source": 174,
            "target": 224
        },
        {
            "source": 175,
            "target": 87
        },
        {
            "source": 175,
            "target": 15
        },
        {
            "source": 175,
            "target": 160
        },
        {
            "source": 175,
            "target": 133
        },
        {
            "source": 175,
            "target": 196
        },
        {
            "source": 175,
            "target": 249
        },
        {
            "source": 175,
            "target": 273
        },
        {
            "source": 176,
            "target": 88
        },
        {
            "source": 176,
            "target": 25
        },
        {
            "source": 176,
            "target": 27
        },
        {
            "source": 177,
            "target": 87
        },
        {
            "source": 177,
            "target": 106
        },
        {
            "source": 179,
            "target": 153
        },
        {
            "source": 179,
            "target": 51
        },
        {
            "source": 179,
            "target": 104
        },
        {
            "source": 179,
            "target": 103
        },
        {
            "source": 180,
            "target": 210
        },
        {
            "source": 180,
            "target": 211
        },
        {
            "source": 181,
            "target": 198
        },
        {
            "source": 181,
            "target": 153
        },
        {
            "source": 181,
            "target": 159
        },
        {
            "source": 181,
            "target": 129
        },
        {
            "source": 181,
            "target": 146
        },
        {
            "source": 181,
            "target": 137
        },
        {
            "source": 181,
            "target": 148
        },
        {
            "source": 181,
            "target": 51
        },
        {
            "source": 181,
            "target": 179
        },
        {
            "source": 181,
            "target": 104
        },
        {
            "source": 181,
            "target": 114
        },
        {
            "source": 181,
            "target": 38
        },
        {
            "source": 181,
            "target": 156
        },
        {
            "source": 181,
            "target": 26
        },
        {
            "source": 181,
            "target": 230
        },
        {
            "source": 182,
            "target": 25
        },
        {
            "source": 182,
            "target": 27
        },
        {
            "source": 183,
            "target": 87
        },
        {
            "source": 183,
            "target": 25
        },
        {
            "source": 183,
            "target": 280
        },
        {
            "source": 183,
            "target": 294
        },
        {
            "source": 184,
            "target": 25
        },
        {
            "source": 184,
            "target": 34
        },
        {
            "source": 184,
            "target": 27
        },
        {
            "source": 185,
            "target": 258
        },
        {
            "source": 186,
            "target": 100
        },
        {
            "source": 186,
            "target": 49
        },
        {
            "source": 186,
            "target": 27
        },
        {
            "source": 186,
            "target": 227
        },
        {
            "source": 187,
            "target": 5
        },
        {
            "source": 187,
            "target": 39
        },
        {
            "source": 188,
            "target": 96
        },
        {
            "source": 188,
            "target": 35
        },
        {
            "source": 188,
            "target": 160
        },
        {
            "source": 188,
            "target": 25
        },
        {
            "source": 188,
            "target": 255
        },
        {
            "source": 188,
            "target": 276
        },
        {
            "source": 189,
            "target": 21
        },
        {
            "source": 189,
            "target": 6
        },
        {
            "source": 189,
            "target": 78
        },
        {
            "source": 189,
            "target": 44
        },
        {
            "source": 189,
            "target": 198
        },
        {
            "source": 189,
            "target": 96
        },
        {
            "source": 189,
            "target": 45
        },
        {
            "source": 189,
            "target": 35
        },
        {
            "source": 189,
            "target": 46
        },
        {
            "source": 189,
            "target": 12
        },
        {
            "source": 189,
            "target": 4
        },
        {
            "source": 189,
            "target": 129
        },
        {
            "source": 189,
            "target": 47
        },
        {
            "source": 189,
            "target": 99
        },
        {
            "source": 189,
            "target": 123
        },
        {
            "source": 189,
            "target": 128
        },
        {
            "source": 189,
            "target": 0
        },
        {
            "source": 189,
            "target": 79
        },
        {
            "source": 189,
            "target": 43
        },
        {
            "source": 189,
            "target": 50
        },
        {
            "source": 189,
            "target": 69
        },
        {
            "source": 189,
            "target": 80
        },
        {
            "source": 189,
            "target": 94
        },
        {
            "source": 189,
            "target": 51
        },
        {
            "source": 189,
            "target": 10
        },
        {
            "source": 189,
            "target": 104
        },
        {
            "source": 189,
            "target": 114
        },
        {
            "source": 189,
            "target": 38
        },
        {
            "source": 189,
            "target": 26
        },
        {
            "source": 189,
            "target": 5
        },
        {
            "source": 189,
            "target": 41
        },
        {
            "source": 189,
            "target": 136
        },
        {
            "source": 189,
            "target": 25
        },
        {
            "source": 189,
            "target": 40
        },
        {
            "source": 189,
            "target": 127
        },
        {
            "source": 189,
            "target": 98
        },
        {
            "source": 189,
            "target": 48
        },
        {
            "source": 189,
            "target": 115
        },
        {
            "source": 189,
            "target": 65
        },
        {
            "source": 189,
            "target": 76
        },
        {
            "source": 189,
            "target": 152
        },
        {
            "source": 189,
            "target": 11
        },
        {
            "source": 189,
            "target": 57
        },
        {
            "source": 189,
            "target": 32
        },
        {
            "source": 189,
            "target": 31
        },
        {
            "source": 189,
            "target": 23
        },
        {
            "source": 189,
            "target": 150
        },
        {
            "source": 189,
            "target": 39
        },
        {
            "source": 189,
            "target": 113
        },
        {
            "source": 189,
            "target": 54
        },
        {
            "source": 189,
            "target": 60
        },
        {
            "source": 189,
            "target": 144
        },
        {
            "source": 189,
            "target": 16
        },
        {
            "source": 189,
            "target": 68
        },
        {
            "source": 189,
            "target": 158
        },
        {
            "source": 189,
            "target": 59
        },
        {
            "source": 189,
            "target": 27
        },
        {
            "source": 189,
            "target": 83
        },
        {
            "source": 189,
            "target": 157
        },
        {
            "source": 189,
            "target": 28
        },
        {
            "source": 189,
            "target": 116
        },
        {
            "source": 189,
            "target": 118
        },
        {
            "source": 189,
            "target": 149
        },
        {
            "source": 189,
            "target": 102
        },
        {
            "source": 189,
            "target": 241
        },
        {
            "source": 189,
            "target": 271
        },
        {
            "source": 190,
            "target": 192
        },
        {
            "source": 190,
            "target": 218
        },
        {
            "source": 191,
            "target": 3
        },
        {
            "source": 192,
            "target": 87
        },
        {
            "source": 192,
            "target": 25
        },
        {
            "source": 192,
            "target": 207
        },
        {
            "source": 192,
            "target": 238
        },
        {
            "source": 192,
            "target": 242
        },
        {
            "source": 193,
            "target": 194
        },
        {
            "source": 193,
            "target": 2
        },
        {
            "source": 193,
            "target": 202
        },
        {
            "source": 193,
            "target": 205
        },
        {
            "source": 193,
            "target": 235
        },
        {
            "source": 194,
            "target": 2
        },
        {
            "source": 194,
            "target": 193
        },
        {
            "source": 194,
            "target": 217
        },
        {
            "source": 195,
            "target": 237
        },
        {
            "source": 195,
            "target": 239
        },
        {
            "source": 196,
            "target": 35
        },
        {
            "source": 196,
            "target": 58
        },
        {
            "source": 196,
            "target": 151
        },
        {
            "source": 196,
            "target": 49
        },
        {
            "source": 196,
            "target": 25
        },
        {
            "source": 196,
            "target": 113
        },
        {
            "source": 196,
            "target": 27
        },
        {
            "source": 196,
            "target": 229
        },
        {
            "source": 196,
            "target": 236
        },
        {
            "source": 197,
            "target": 99
        },
        {
            "source": 197,
            "target": 169
        },
        {
            "source": 197,
            "target": 105
        },
        {
            "source": 197,
            "target": 34
        },
        {
            "source": 197,
            "target": 206
        },
        {
            "source": 198,
            "target": 35
        },
        {
            "source": 198,
            "target": 129
        },
        {
            "source": 198,
            "target": 51
        },
        {
            "source": 198,
            "target": 104
        },
        {
            "source": 198,
            "target": 114
        },
        {
            "source": 198,
            "target": 38
        },
        {
            "source": 198,
            "target": 48
        },
        {
            "source": 198,
            "target": 19
        },
        {
            "source": 198,
            "target": 189
        },
        {
            "source": 199,
            "target": 286
        },
        {
            "source": 199,
            "target": 304
        },
        {
            "source": 199,
            "target": 322
        },
        {
            "source": 199,
            "target": 333
        },
        {
            "source": 200,
            "target": 267
        },
        {
            "source": 200,
            "target": 104
        },
        {
            "source": 200,
            "target": 25
        },
        {
            "source": 200,
            "target": 150
        },
        {
            "source": 200,
            "target": 312
        },
        {
            "source": 201,
            "target": 104
        },
        {
            "source": 201,
            "target": 25
        },
        {
            "source": 201,
            "target": 124
        },
        {
            "source": 201,
            "target": 34
        },
        {
            "source": 201,
            "target": 247
        },
        {
            "source": 201,
            "target": 116
        },
        {
            "source": 201,
            "target": 291
        },
        {
            "source": 201,
            "target": 325
        },
        {
            "source": 202,
            "target": 104
        },
        {
            "source": 202,
            "target": 194
        },
        {
            "source": 202,
            "target": 2
        },
        {
            "source": 202,
            "target": 193
        },
        {
            "source": 202,
            "target": 205
        },
        {
            "source": 202,
            "target": 235
        },
        {
            "source": 202,
            "target": 217
        },
        {
            "source": 202,
            "target": 25
        },
        {
            "source": 203,
            "target": 25
        },
        {
            "source": 203,
            "target": 130
        },
        {
            "source": 203,
            "target": 27
        },
        {
            "source": 203,
            "target": 291
        },
        {
            "source": 203,
            "target": 318
        },
        {
            "source": 204,
            "target": 99
        },
        {
            "source": 204,
            "target": 53
        },
        {
            "source": 204,
            "target": 25
        },
        {
            "source": 204,
            "target": 246
        },
        {
            "source": 204,
            "target": 27
        },
        {
            "source": 205,
            "target": 194
        },
        {
            "source": 205,
            "target": 2
        },
        {
            "source": 205,
            "target": 193
        },
        {
            "source": 205,
            "target": 202
        },
        {
            "source": 205,
            "target": 235
        },
        {
            "source": 205,
            "target": 217
        },
        {
            "source": 205,
            "target": 332
        },
        {
            "source": 206,
            "target": 197
        },
        {
            "source": 206,
            "target": 99
        },
        {
            "source": 206,
            "target": 169
        },
        {
            "source": 206,
            "target": 93
        },
        {
            "source": 206,
            "target": 25
        },
        {
            "source": 206,
            "target": 105
        },
        {
            "source": 206,
            "target": 34
        },
        {
            "source": 206,
            "target": 27
        },
        {
            "source": 206,
            "target": 348
        },
        {
            "source": 206,
            "target": 353
        },
        {
            "source": 207,
            "target": 124
        },
        {
            "source": 207,
            "target": 291
        },
        {
            "source": 208,
            "target": 35
        },
        {
            "source": 208,
            "target": 262
        },
        {
            "source": 208,
            "target": 0
        },
        {
            "source": 208,
            "target": 27
        },
        {
            "source": 208,
            "target": 157
        },
        {
            "source": 208,
            "target": 352
        },
        {
            "source": 209,
            "target": 287
        },
        {
            "source": 209,
            "target": 268
        },
        {
            "source": 209,
            "target": 222
        },
        {
            "source": 209,
            "target": 198
        },
        {
            "source": 209,
            "target": 277
        },
        {
            "source": 209,
            "target": 153
        },
        {
            "source": 209,
            "target": 159
        },
        {
            "source": 209,
            "target": 129
        },
        {
            "source": 209,
            "target": 252
        },
        {
            "source": 209,
            "target": 146
        },
        {
            "source": 209,
            "target": 137
        },
        {
            "source": 209,
            "target": 219
        },
        {
            "source": 209,
            "target": 148
        },
        {
            "source": 209,
            "target": 51
        },
        {
            "source": 209,
            "target": 179
        },
        {
            "source": 209,
            "target": 104
        },
        {
            "source": 209,
            "target": 245
        },
        {
            "source": 209,
            "target": 181
        },
        {
            "source": 209,
            "target": 114
        },
        {
            "source": 209,
            "target": 278
        },
        {
            "source": 209,
            "target": 38
        },
        {
            "source": 209,
            "target": 230
        },
        {
            "source": 209,
            "target": 156
        },
        {
            "source": 209,
            "target": 251
        },
        {
            "source": 209,
            "target": 26
        },
        {
            "source": 210,
            "target": 180
        },
        {
            "source": 210,
            "target": 25
        },
        {
            "source": 210,
            "target": 331
        },
        {
            "source": 210,
            "target": 350
        },
        {
            "source": 211,
            "target": 87
        },
        {
            "source": 211,
            "target": 180
        },
        {
            "source": 211,
            "target": 25
        },
        {
            "source": 211,
            "target": 321
        },
        {
            "source": 211,
            "target": 328
        },
        {
            "source": 212,
            "target": 287
        },
        {
            "source": 212,
            "target": 268
        },
        {
            "source": 212,
            "target": 222
        },
        {
            "source": 212,
            "target": 198
        },
        {
            "source": 212,
            "target": 87
        },
        {
            "source": 212,
            "target": 122
        },
        {
            "source": 212,
            "target": 277
        },
        {
            "source": 212,
            "target": 233
        },
        {
            "source": 212,
            "target": 35
        },
        {
            "source": 212,
            "target": 153
        },
        {
            "source": 212,
            "target": 159
        },
        {
            "source": 212,
            "target": 129
        },
        {
            "source": 212,
            "target": 252
        },
        {
            "source": 212,
            "target": 146
        },
        {
            "source": 212,
            "target": 137
        },
        {
            "source": 212,
            "target": 219
        },
        {
            "source": 212,
            "target": 148
        },
        {
            "source": 212,
            "target": 51
        },
        {
            "source": 212,
            "target": 106
        },
        {
            "source": 212,
            "target": 179
        },
        {
            "source": 212,
            "target": 104
        },
        {
            "source": 212,
            "target": 245
        },
        {
            "source": 212,
            "target": 181
        },
        {
            "source": 212,
            "target": 114
        },
        {
            "source": 212,
            "target": 278
        },
        {
            "source": 212,
            "target": 209
        },
        {
            "source": 212,
            "target": 38
        },
        {
            "source": 213,
            "target": 387
        },
        {
            "source": 214,
            "target": 272
        },
        {
            "source": 214,
            "target": 27
        },
        {
            "source": 214,
            "target": 357
        },
        {
            "source": 214,
            "target": 391
        },
        {
            "source": 216,
            "target": 27
        },
        {
            "source": 216,
            "target": 362
        },
        {
            "source": 216,
            "target": 388
        },
        {
            "source": 217,
            "target": 194
        },
        {
            "source": 217,
            "target": 2
        },
        {
            "source": 217,
            "target": 193
        },
        {
            "source": 217,
            "target": 202
        },
        {
            "source": 217,
            "target": 205
        },
        {
            "source": 217,
            "target": 235
        },
        {
            "source": 219,
            "target": 287
        },
        {
            "source": 219,
            "target": 268
        },
        {
            "source": 219,
            "target": 222
        },
        {
            "source": 219,
            "target": 198
        },
        {
            "source": 219,
            "target": 277
        },
        {
            "source": 219,
            "target": 153
        },
        {
            "source": 219,
            "target": 159
        },
        {
            "source": 219,
            "target": 129
        },
        {
            "source": 219,
            "target": 252
        },
        {
            "source": 219,
            "target": 146
        },
        {
            "source": 219,
            "target": 137
        },
        {
            "source": 219,
            "target": 148
        },
        {
            "source": 219,
            "target": 51
        },
        {
            "source": 219,
            "target": 179
        },
        {
            "source": 219,
            "target": 104
        },
        {
            "source": 219,
            "target": 245
        },
        {
            "source": 219,
            "target": 181
        },
        {
            "source": 219,
            "target": 114
        },
        {
            "source": 219,
            "target": 278
        },
        {
            "source": 219,
            "target": 209
        },
        {
            "source": 219,
            "target": 38
        },
        {
            "source": 219,
            "target": 230
        },
        {
            "source": 219,
            "target": 156
        },
        {
            "source": 219,
            "target": 251
        },
        {
            "source": 219,
            "target": 26
        },
        {
            "source": 219,
            "target": 335
        },
        {
            "source": 219,
            "target": 349
        },
        {
            "source": 220,
            "target": 171
        },
        {
            "source": 220,
            "target": 260
        },
        {
            "source": 220,
            "target": 259
        },
        {
            "source": 220,
            "target": 382
        },
        {
            "source": 221,
            "target": 151
        },
        {
            "source": 221,
            "target": 25
        },
        {
            "source": 221,
            "target": 27
        },
        {
            "source": 222,
            "target": 287
        },
        {
            "source": 222,
            "target": 268
        },
        {
            "source": 222,
            "target": 198
        },
        {
            "source": 222,
            "target": 277
        },
        {
            "source": 222,
            "target": 153
        },
        {
            "source": 222,
            "target": 159
        },
        {
            "source": 222,
            "target": 129
        },
        {
            "source": 222,
            "target": 252
        },
        {
            "source": 222,
            "target": 146
        },
        {
            "source": 222,
            "target": 137
        },
        {
            "source": 222,
            "target": 219
        },
        {
            "source": 222,
            "target": 148
        },
        {
            "source": 222,
            "target": 51
        },
        {
            "source": 222,
            "target": 179
        },
        {
            "source": 222,
            "target": 104
        },
        {
            "source": 222,
            "target": 245
        },
        {
            "source": 222,
            "target": 181
        },
        {
            "source": 222,
            "target": 114
        },
        {
            "source": 222,
            "target": 278
        },
        {
            "source": 222,
            "target": 209
        },
        {
            "source": 222,
            "target": 38
        },
        {
            "source": 222,
            "target": 230
        },
        {
            "source": 222,
            "target": 156
        },
        {
            "source": 222,
            "target": 251
        },
        {
            "source": 222,
            "target": 26
        },
        {
            "source": 222,
            "target": 309
        },
        {
            "source": 223,
            "target": 174
        },
        {
            "source": 223,
            "target": 359
        },
        {
            "source": 224,
            "target": 25
        },
        {
            "source": 225,
            "target": 371
        },
        {
            "source": 226,
            "target": 157
        },
        {
            "source": 227,
            "target": 27
        },
        {
            "source": 228,
            "target": 336
        },
        {
            "source": 228,
            "target": 360
        },
        {
            "source": 229,
            "target": 6
        },
        {
            "source": 229,
            "target": 197
        },
        {
            "source": 229,
            "target": 99
        },
        {
            "source": 229,
            "target": 196
        },
        {
            "source": 229,
            "target": 206
        },
        {
            "source": 229,
            "target": 169
        },
        {
            "source": 229,
            "target": 25
        },
        {
            "source": 229,
            "target": 201
        },
        {
            "source": 229,
            "target": 105
        },
        {
            "source": 229,
            "target": 34
        },
        {
            "source": 229,
            "target": 27
        },
        {
            "source": 229,
            "target": 297
        },
        {
            "source": 229,
            "target": 329
        },
        {
            "source": 229,
            "target": 379
        },
        {
            "source": 229,
            "target": 383
        },
        {
            "source": 230,
            "target": 287
        },
        {
            "source": 230,
            "target": 268
        },
        {
            "source": 230,
            "target": 222
        },
        {
            "source": 230,
            "target": 198
        },
        {
            "source": 230,
            "target": 122
        },
        {
            "source": 230,
            "target": 277
        },
        {
            "source": 230,
            "target": 153
        },
        {
            "source": 230,
            "target": 159
        },
        {
            "source": 230,
            "target": 129
        },
        {
            "source": 230,
            "target": 252
        },
        {
            "source": 230,
            "target": 146
        },
        {
            "source": 230,
            "target": 137
        },
        {
            "source": 230,
            "target": 219
        },
        {
            "source": 230,
            "target": 148
        },
        {
            "source": 230,
            "target": 51
        },
        {
            "source": 230,
            "target": 179
        },
        {
            "source": 230,
            "target": 104
        },
        {
            "source": 230,
            "target": 245
        },
        {
            "source": 230,
            "target": 181
        },
        {
            "source": 230,
            "target": 114
        },
        {
            "source": 230,
            "target": 278
        },
        {
            "source": 230,
            "target": 209
        },
        {
            "source": 230,
            "target": 38
        },
        {
            "source": 230,
            "target": 156
        },
        {
            "source": 230,
            "target": 251
        },
        {
            "source": 230,
            "target": 26
        },
        {
            "source": 231,
            "target": 44
        },
        {
            "source": 231,
            "target": 262
        },
        {
            "source": 231,
            "target": 301
        },
        {
            "source": 231,
            "target": 302
        },
        {
            "source": 231,
            "target": 343
        },
        {
            "source": 231,
            "target": 390
        },
        {
            "source": 232,
            "target": 164
        },
        {
            "source": 232,
            "target": 308
        },
        {
            "source": 233,
            "target": 287
        },
        {
            "source": 233,
            "target": 148
        },
        {
            "source": 233,
            "target": 104
        },
        {
            "source": 233,
            "target": 212
        },
        {
            "source": 233,
            "target": 293
        },
        {
            "source": 234,
            "target": 291
        },
        {
            "source": 235,
            "target": 194
        },
        {
            "source": 235,
            "target": 2
        },
        {
            "source": 235,
            "target": 193
        },
        {
            "source": 235,
            "target": 202
        },
        {
            "source": 235,
            "target": 205
        },
        {
            "source": 235,
            "target": 217
        },
        {
            "source": 235,
            "target": 295
        },
        {
            "source": 235,
            "target": 338
        },
        {
            "source": 236,
            "target": 64
        },
        {
            "source": 236,
            "target": 253
        },
        {
            "source": 236,
            "target": 381
        },
        {
            "source": 236,
            "target": 385
        },
        {
            "source": 237,
            "target": 195
        },
        {
            "source": 237,
            "target": 291
        },
        {
            "source": 237,
            "target": 307
        },
        {
            "source": 237,
            "target": 370
        },
        {
            "source": 237,
            "target": 380
        },
        {
            "source": 238,
            "target": 291
        },
        {
            "source": 238,
            "target": 389
        },
        {
            "source": 239,
            "target": 199
        },
        {
            "source": 239,
            "target": 195
        },
        {
            "source": 241,
            "target": 45
        },
        {
            "source": 241,
            "target": 35
        },
        {
            "source": 241,
            "target": 73
        },
        {
            "source": 241,
            "target": 99
        },
        {
            "source": 241,
            "target": 86
        },
        {
            "source": 241,
            "target": 147
        },
        {
            "source": 241,
            "target": 0
        },
        {
            "source": 241,
            "target": 43
        },
        {
            "source": 241,
            "target": 271
        },
        {
            "source": 241,
            "target": 94
        },
        {
            "source": 241,
            "target": 10
        },
        {
            "source": 241,
            "target": 41
        },
        {
            "source": 241,
            "target": 136
        },
        {
            "source": 241,
            "target": 127
        },
        {
            "source": 241,
            "target": 334
        },
        {
            "source": 241,
            "target": 346
        },
        {
            "source": 241,
            "target": 367
        },
        {
            "source": 241,
            "target": 375
        },
        {
            "source": 242,
            "target": 192
        },
        {
            "source": 242,
            "target": 386
        },
        {
            "source": 243,
            "target": 330
        },
        {
            "source": 244,
            "target": 21
        },
        {
            "source": 244,
            "target": 6
        },
        {
            "source": 244,
            "target": 78
        },
        {
            "source": 244,
            "target": 44
        },
        {
            "source": 244,
            "target": 96
        },
        {
            "source": 244,
            "target": 45
        },
        {
            "source": 244,
            "target": 35
        },
        {
            "source": 244,
            "target": 46
        },
        {
            "source": 244,
            "target": 12
        },
        {
            "source": 244,
            "target": 4
        },
        {
            "source": 244,
            "target": 129
        },
        {
            "source": 244,
            "target": 47
        },
        {
            "source": 244,
            "target": 99
        },
        {
            "source": 244,
            "target": 123
        },
        {
            "source": 244,
            "target": 128
        },
        {
            "source": 244,
            "target": 0
        },
        {
            "source": 244,
            "target": 79
        },
        {
            "source": 244,
            "target": 43
        },
        {
            "source": 244,
            "target": 271
        },
        {
            "source": 244,
            "target": 50
        },
        {
            "source": 244,
            "target": 208
        },
        {
            "source": 244,
            "target": 69
        },
        {
            "source": 244,
            "target": 80
        },
        {
            "source": 244,
            "target": 94
        },
        {
            "source": 244,
            "target": 51
        },
        {
            "source": 244,
            "target": 10
        },
        {
            "source": 244,
            "target": 104
        },
        {
            "source": 244,
            "target": 38
        },
        {
            "source": 244,
            "target": 5
        },
        {
            "source": 244,
            "target": 41
        },
        {
            "source": 244,
            "target": 136
        },
        {
            "source": 244,
            "target": 40
        },
        {
            "source": 244,
            "target": 127
        },
        {
            "source": 244,
            "target": 98
        },
        {
            "source": 244,
            "target": 48
        },
        {
            "source": 244,
            "target": 115
        },
        {
            "source": 244,
            "target": 65
        },
        {
            "source": 244,
            "target": 76
        },
        {
            "source": 244,
            "target": 152
        },
        {
            "source": 244,
            "target": 11
        },
        {
            "source": 244,
            "target": 57
        },
        {
            "source": 244,
            "target": 32
        },
        {
            "source": 244,
            "target": 241
        },
        {
            "source": 244,
            "target": 31
        },
        {
            "source": 244,
            "target": 34
        },
        {
            "source": 244,
            "target": 23
        },
        {
            "source": 244,
            "target": 39
        },
        {
            "source": 244,
            "target": 113
        },
        {
            "source": 244,
            "target": 60
        },
        {
            "source": 244,
            "target": 144
        },
        {
            "source": 244,
            "target": 247
        },
        {
            "source": 244,
            "target": 16
        },
        {
            "source": 244,
            "target": 68
        },
        {
            "source": 244,
            "target": 158
        },
        {
            "source": 244,
            "target": 59
        },
        {
            "source": 244,
            "target": 27
        },
        {
            "source": 244,
            "target": 157
        },
        {
            "source": 244,
            "target": 28
        },
        {
            "source": 244,
            "target": 116
        },
        {
            "source": 244,
            "target": 288
        },
        {
            "source": 244,
            "target": 118
        },
        {
            "source": 244,
            "target": 189
        },
        {
            "source": 244,
            "target": 149
        },
        {
            "source": 244,
            "target": 102
        },
        {
            "source": 245,
            "target": 287
        },
        {
            "source": 245,
            "target": 268
        },
        {
            "source": 245,
            "target": 222
        },
        {
            "source": 245,
            "target": 198
        },
        {
            "source": 245,
            "target": 277
        },
        {
            "source": 245,
            "target": 35
        },
        {
            "source": 245,
            "target": 153
        },
        {
            "source": 245,
            "target": 159
        },
        {
            "source": 245,
            "target": 160
        },
        {
            "source": 245,
            "target": 129
        },
        {
            "source": 245,
            "target": 252
        },
        {
            "source": 245,
            "target": 146
        },
        {
            "source": 245,
            "target": 137
        },
        {
            "source": 245,
            "target": 219
        },
        {
            "source": 245,
            "target": 148
        },
        {
            "source": 245,
            "target": 51
        },
        {
            "source": 245,
            "target": 179
        },
        {
            "source": 245,
            "target": 104
        },
        {
            "source": 245,
            "target": 181
        },
        {
            "source": 245,
            "target": 114
        },
        {
            "source": 245,
            "target": 278
        },
        {
            "source": 245,
            "target": 209
        },
        {
            "source": 245,
            "target": 38
        },
        {
            "source": 245,
            "target": 230
        },
        {
            "source": 245,
            "target": 156
        },
        {
            "source": 245,
            "target": 251
        },
        {
            "source": 245,
            "target": 26
        },
        {
            "source": 245,
            "target": 337
        },
        {
            "source": 246,
            "target": 53
        },
        {
            "source": 246,
            "target": 299
        },
        {
            "source": 247,
            "target": 21
        },
        {
            "source": 247,
            "target": 6
        },
        {
            "source": 247,
            "target": 78
        },
        {
            "source": 247,
            "target": 44
        },
        {
            "source": 247,
            "target": 96
        },
        {
            "source": 247,
            "target": 45
        },
        {
            "source": 247,
            "target": 35
        },
        {
            "source": 247,
            "target": 46
        },
        {
            "source": 247,
            "target": 71
        },
        {
            "source": 247,
            "target": 12
        },
        {
            "source": 247,
            "target": 4
        },
        {
            "source": 247,
            "target": 129
        },
        {
            "source": 247,
            "target": 47
        },
        {
            "source": 247,
            "target": 99
        },
        {
            "source": 247,
            "target": 196
        },
        {
            "source": 247,
            "target": 123
        },
        {
            "source": 247,
            "target": 128
        },
        {
            "source": 247,
            "target": 0
        },
        {
            "source": 247,
            "target": 79
        },
        {
            "source": 247,
            "target": 43
        },
        {
            "source": 247,
            "target": 271
        },
        {
            "source": 247,
            "target": 50
        },
        {
            "source": 247,
            "target": 208
        },
        {
            "source": 247,
            "target": 69
        },
        {
            "source": 247,
            "target": 80
        },
        {
            "source": 247,
            "target": 94
        },
        {
            "source": 247,
            "target": 51
        },
        {
            "source": 247,
            "target": 10
        },
        {
            "source": 247,
            "target": 38
        },
        {
            "source": 247,
            "target": 5
        },
        {
            "source": 247,
            "target": 41
        },
        {
            "source": 247,
            "target": 136
        },
        {
            "source": 247,
            "target": 25
        },
        {
            "source": 247,
            "target": 40
        },
        {
            "source": 247,
            "target": 127
        },
        {
            "source": 247,
            "target": 98
        },
        {
            "source": 247,
            "target": 48
        },
        {
            "source": 247,
            "target": 115
        },
        {
            "source": 247,
            "target": 65
        },
        {
            "source": 247,
            "target": 76
        },
        {
            "source": 247,
            "target": 152
        },
        {
            "source": 247,
            "target": 201
        },
        {
            "source": 247,
            "target": 229
        },
        {
            "source": 247,
            "target": 11
        },
        {
            "source": 247,
            "target": 57
        },
        {
            "source": 247,
            "target": 32
        },
        {
            "source": 247,
            "target": 241
        },
        {
            "source": 247,
            "target": 31
        },
        {
            "source": 247,
            "target": 23
        },
        {
            "source": 247,
            "target": 39
        },
        {
            "source": 247,
            "target": 113
        },
        {
            "source": 247,
            "target": 60
        },
        {
            "source": 247,
            "target": 144
        },
        {
            "source": 247,
            "target": 244
        },
        {
            "source": 247,
            "target": 16
        },
        {
            "source": 247,
            "target": 68
        },
        {
            "source": 247,
            "target": 158
        },
        {
            "source": 247,
            "target": 59
        },
        {
            "source": 247,
            "target": 27
        },
        {
            "source": 247,
            "target": 157
        },
        {
            "source": 247,
            "target": 28
        },
        {
            "source": 247,
            "target": 116
        },
        {
            "source": 247,
            "target": 288
        },
        {
            "source": 247,
            "target": 118
        },
        {
            "source": 247,
            "target": 327
        },
        {
            "source": 248,
            "target": 119
        },
        {
            "source": 248,
            "target": 282
        },
        {
            "source": 248,
            "target": 167
        },
        {
            "source": 248,
            "target": 112
        },
        {
            "source": 248,
            "target": 290
        },
        {
            "source": 248,
            "target": 339
        },
        {
            "source": 248,
            "target": 345
        },
        {
            "source": 249,
            "target": 27
        },
        {
            "source": 250,
            "target": 1
        },
        {
            "source": 250,
            "target": 25
        },
        {
            "source": 250,
            "target": 98
        },
        {
            "source": 250,
            "target": 19
        },
        {
            "source": 250,
            "target": 195
        },
        {
            "source": 250,
            "target": 126
        },
        {
            "source": 250,
            "target": 231
        },
        {
            "source": 250,
            "target": 316
        },
        {
            "source": 251,
            "target": 104
        },
        {
            "source": 252,
            "target": 287
        },
        {
            "source": 252,
            "target": 268
        },
        {
            "source": 252,
            "target": 222
        },
        {
            "source": 252,
            "target": 198
        },
        {
            "source": 252,
            "target": 277
        },
        {
            "source": 252,
            "target": 153
        },
        {
            "source": 252,
            "target": 159
        },
        {
            "source": 252,
            "target": 129
        },
        {
            "source": 252,
            "target": 146
        },
        {
            "source": 252,
            "target": 137
        },
        {
            "source": 252,
            "target": 219
        },
        {
            "source": 252,
            "target": 148
        },
        {
            "source": 252,
            "target": 51
        },
        {
            "source": 252,
            "target": 179
        },
        {
            "source": 252,
            "target": 104
        },
        {
            "source": 252,
            "target": 245
        },
        {
            "source": 252,
            "target": 181
        },
        {
            "source": 252,
            "target": 114
        },
        {
            "source": 252,
            "target": 278
        },
        {
            "source": 252,
            "target": 209
        },
        {
            "source": 252,
            "target": 38
        },
        {
            "source": 252,
            "target": 230
        },
        {
            "source": 252,
            "target": 156
        },
        {
            "source": 252,
            "target": 251
        },
        {
            "source": 252,
            "target": 26
        },
        {
            "source": 252,
            "target": 368
        },
        {
            "source": 252,
            "target": 374
        },
        {
            "source": 252,
            "target": 377
        },
        {
            "source": 252,
            "target": 384
        },
        {
            "source": 254,
            "target": 27
        },
        {
            "source": 254,
            "target": 340
        },
        {
            "source": 255,
            "target": 276
        },
        {
            "source": 255,
            "target": 291
        },
        {
            "source": 256,
            "target": 167
        },
        {
            "source": 256,
            "target": 269
        },
        {
            "source": 256,
            "target": 303
        },
        {
            "source": 256,
            "target": 315
        },
        {
            "source": 257,
            "target": 4
        },
        {
            "source": 257,
            "target": 47
        },
        {
            "source": 257,
            "target": 128
        },
        {
            "source": 257,
            "target": 52
        },
        {
            "source": 257,
            "target": 69
        },
        {
            "source": 257,
            "target": 80
        },
        {
            "source": 257,
            "target": 127
        },
        {
            "source": 257,
            "target": 189
        },
        {
            "source": 258,
            "target": 87
        },
        {
            "source": 258,
            "target": 185
        },
        {
            "source": 258,
            "target": 106
        },
        {
            "source": 258,
            "target": 27
        },
        {
            "source": 258,
            "target": 108
        },
        {
            "source": 259,
            "target": 25
        },
        {
            "source": 259,
            "target": 220
        },
        {
            "source": 259,
            "target": 171
        },
        {
            "source": 259,
            "target": 260
        },
        {
            "source": 260,
            "target": 220
        },
        {
            "source": 260,
            "target": 171
        },
        {
            "source": 260,
            "target": 296
        },
        {
            "source": 261,
            "target": 165
        },
        {
            "source": 262,
            "target": 133
        },
        {
            "source": 262,
            "target": 25
        },
        {
            "source": 262,
            "target": 351
        },
        {
            "source": 263,
            "target": 132
        },
        {
            "source": 264,
            "target": 163
        },
        {
            "source": 265,
            "target": 173
        },
        {
            "source": 267,
            "target": 104
        },
        {
            "source": 267,
            "target": 25
        },
        {
            "source": 267,
            "target": 27
        },
        {
            "source": 267,
            "target": 291
        },
        {
            "source": 267,
            "target": 358
        },
        {
            "source": 268,
            "target": 287
        },
        {
            "source": 268,
            "target": 222
        },
        {
            "source": 268,
            "target": 198
        },
        {
            "source": 268,
            "target": 277
        },
        {
            "source": 268,
            "target": 153
        },
        {
            "source": 268,
            "target": 159
        },
        {
            "source": 268,
            "target": 129
        },
        {
            "source": 268,
            "target": 252
        },
        {
            "source": 268,
            "target": 146
        },
        {
            "source": 268,
            "target": 137
        },
        {
            "source": 268,
            "target": 219
        },
        {
            "source": 268,
            "target": 148
        },
        {
            "source": 268,
            "target": 51
        },
        {
            "source": 268,
            "target": 179
        },
        {
            "source": 268,
            "target": 104
        },
        {
            "source": 268,
            "target": 245
        },
        {
            "source": 268,
            "target": 181
        },
        {
            "source": 268,
            "target": 114
        },
        {
            "source": 268,
            "target": 278
        },
        {
            "source": 268,
            "target": 209
        },
        {
            "source": 268,
            "target": 38
        },
        {
            "source": 268,
            "target": 230
        },
        {
            "source": 268,
            "target": 156
        },
        {
            "source": 268,
            "target": 251
        },
        {
            "source": 268,
            "target": 26
        },
        {
            "source": 268,
            "target": 298
        },
        {
            "source": 268,
            "target": 300
        },
        {
            "source": 268,
            "target": 305
        },
        {
            "source": 268,
            "target": 355
        },
        {
            "source": 268,
            "target": 366
        },
        {
            "source": 269,
            "target": 365
        },
        {
            "source": 270,
            "target": 27
        },
        {
            "source": 270,
            "target": 116
        },
        {
            "source": 271,
            "target": 99
        },
        {
            "source": 271,
            "target": 0
        },
        {
            "source": 271,
            "target": 94
        },
        {
            "source": 271,
            "target": 10
        },
        {
            "source": 271,
            "target": 25
        },
        {
            "source": 271,
            "target": 152
        },
        {
            "source": 271,
            "target": 32
        },
        {
            "source": 271,
            "target": 241
        },
        {
            "source": 271,
            "target": 113
        },
        {
            "source": 271,
            "target": 144
        },
        {
            "source": 271,
            "target": 247
        },
        {
            "source": 271,
            "target": 244
        },
        {
            "source": 271,
            "target": 16
        },
        {
            "source": 271,
            "target": 27
        },
        {
            "source": 271,
            "target": 310
        },
        {
            "source": 272,
            "target": 25
        },
        {
            "source": 272,
            "target": 19
        },
        {
            "source": 272,
            "target": 27
        },
        {
            "source": 272,
            "target": 291
        },
        {
            "source": 272,
            "target": 313
        },
        {
            "source": 272,
            "target": 326
        },
        {
            "source": 272,
            "target": 363
        },
        {
            "source": 273,
            "target": 291
        },
        {
            "source": 274,
            "target": 25
        },
        {
            "source": 274,
            "target": 27
        },
        {
            "source": 274,
            "target": 342
        },
        {
            "source": 274,
            "target": 373
        },
        {
            "source": 275,
            "target": 27
        },
        {
            "source": 275,
            "target": 291
        },
        {
            "source": 276,
            "target": 255
        },
        {
            "source": 276,
            "target": 291
        },
        {
            "source": 276,
            "target": 323
        },
        {
            "source": 277,
            "target": 153
        },
        {
            "source": 277,
            "target": 51
        },
        {
            "source": 277,
            "target": 179
        },
        {
            "source": 277,
            "target": 104
        },
        {
            "source": 277,
            "target": 209
        },
        {
            "source": 277,
            "target": 27
        },
        {
            "source": 278,
            "target": 287
        },
        {
            "source": 278,
            "target": 268
        },
        {
            "source": 278,
            "target": 222
        },
        {
            "source": 278,
            "target": 198
        },
        {
            "source": 278,
            "target": 277
        },
        {
            "source": 278,
            "target": 35
        },
        {
            "source": 278,
            "target": 153
        },
        {
            "source": 278,
            "target": 159
        },
        {
            "source": 278,
            "target": 129
        },
        {
            "source": 278,
            "target": 252
        },
        {
            "source": 278,
            "target": 146
        },
        {
            "source": 278,
            "target": 137
        },
        {
            "source": 278,
            "target": 219
        },
        {
            "source": 278,
            "target": 148
        },
        {
            "source": 278,
            "target": 51
        },
        {
            "source": 278,
            "target": 179
        },
        {
            "source": 278,
            "target": 104
        },
        {
            "source": 278,
            "target": 245
        },
        {
            "source": 278,
            "target": 181
        },
        {
            "source": 278,
            "target": 114
        },
        {
            "source": 278,
            "target": 209
        },
        {
            "source": 278,
            "target": 38
        },
        {
            "source": 278,
            "target": 230
        },
        {
            "source": 278,
            "target": 156
        },
        {
            "source": 278,
            "target": 251
        },
        {
            "source": 278,
            "target": 26
        },
        {
            "source": 278,
            "target": 356
        },
        {
            "source": 279,
            "target": 160
        },
        {
            "source": 279,
            "target": 319
        },
        {
            "source": 280,
            "target": 185
        },
        {
            "source": 280,
            "target": 306
        },
        {
            "source": 280,
            "target": 317
        },
        {
            "source": 280,
            "target": 361
        },
        {
            "source": 281,
            "target": 44
        },
        {
            "source": 281,
            "target": 25
        },
        {
            "source": 281,
            "target": 250
        },
        {
            "source": 281,
            "target": 364
        },
        {
            "source": 282,
            "target": 119
        },
        {
            "source": 282,
            "target": 248
        },
        {
            "source": 282,
            "target": 167
        },
        {
            "source": 282,
            "target": 112
        },
        {
            "source": 282,
            "target": 290
        },
        {
            "source": 282,
            "target": 320
        },
        {
            "source": 282,
            "target": 324
        },
        {
            "source": 283,
            "target": 168
        },
        {
            "source": 283,
            "target": 25
        },
        {
            "source": 283,
            "target": 34
        },
        {
            "source": 283,
            "target": 27
        },
        {
            "source": 283,
            "target": 311
        },
        {
            "source": 284,
            "target": 6
        },
        {
            "source": 284,
            "target": 35
        },
        {
            "source": 284,
            "target": 88
        },
        {
            "source": 284,
            "target": 25
        },
        {
            "source": 285,
            "target": 160
        },
        {
            "source": 285,
            "target": 234
        },
        {
            "source": 285,
            "target": 228
        },
        {
            "source": 286,
            "target": 199
        },
        {
            "source": 286,
            "target": 139
        },
        {
            "source": 287,
            "target": 233
        },
        {
            "source": 287,
            "target": 148
        },
        {
            "source": 287,
            "target": 104
        },
        {
            "source": 287,
            "target": 212
        },
        {
            "source": 287,
            "target": 293
        },
        {
            "source": 287,
            "target": 341
        },
        {
            "source": 287,
            "target": 344
        },
        {
            "source": 288,
            "target": 21
        },
        {
            "source": 288,
            "target": 6
        },
        {
            "source": 288,
            "target": 78
        },
        {
            "source": 288,
            "target": 44
        },
        {
            "source": 288,
            "target": 96
        },
        {
            "source": 288,
            "target": 45
        },
        {
            "source": 288,
            "target": 35
        },
        {
            "source": 288,
            "target": 46
        },
        {
            "source": 288,
            "target": 12
        },
        {
            "source": 288,
            "target": 4
        },
        {
            "source": 288,
            "target": 129
        },
        {
            "source": 288,
            "target": 47
        },
        {
            "source": 288,
            "target": 99
        },
        {
            "source": 288,
            "target": 123
        },
        {
            "source": 288,
            "target": 128
        },
        {
            "source": 288,
            "target": 0
        },
        {
            "source": 288,
            "target": 79
        },
        {
            "source": 288,
            "target": 43
        },
        {
            "source": 288,
            "target": 50
        },
        {
            "source": 288,
            "target": 208
        },
        {
            "source": 288,
            "target": 69
        },
        {
            "source": 288,
            "target": 80
        },
        {
            "source": 288,
            "target": 94
        },
        {
            "source": 288,
            "target": 51
        },
        {
            "source": 288,
            "target": 10
        },
        {
            "source": 288,
            "target": 38
        },
        {
            "source": 288,
            "target": 5
        },
        {
            "source": 288,
            "target": 41
        },
        {
            "source": 288,
            "target": 136
        },
        {
            "source": 288,
            "target": 40
        },
        {
            "source": 288,
            "target": 127
        },
        {
            "source": 288,
            "target": 98
        },
        {
            "source": 288,
            "target": 48
        },
        {
            "source": 288,
            "target": 115
        },
        {
            "source": 288,
            "target": 65
        },
        {
            "source": 288,
            "target": 76
        },
        {
            "source": 288,
            "target": 152
        },
        {
            "source": 288,
            "target": 11
        },
        {
            "source": 288,
            "target": 57
        },
        {
            "source": 288,
            "target": 31
        },
        {
            "source": 288,
            "target": 23
        },
        {
            "source": 288,
            "target": 39
        },
        {
            "source": 288,
            "target": 60
        },
        {
            "source": 288,
            "target": 144
        },
        {
            "source": 288,
            "target": 247
        },
        {
            "source": 288,
            "target": 244
        },
        {
            "source": 288,
            "target": 68
        },
        {
            "source": 288,
            "target": 158
        },
        {
            "source": 288,
            "target": 59
        },
        {
            "source": 288,
            "target": 157
        },
        {
            "source": 288,
            "target": 28
        },
        {
            "source": 288,
            "target": 116
        },
        {
            "source": 288,
            "target": 118
        },
        {
            "source": 288,
            "target": 189
        },
        {
            "source": 288,
            "target": 149
        },
        {
            "source": 288,
            "target": 102
        },
        {
            "source": 288,
            "target": 347
        },
        {
            "source": 288,
            "target": 376
        },
        {
            "source": 289,
            "target": 66
        },
        {
            "source": 289,
            "target": 378
        },
        {
            "source": 290,
            "target": 119
        },
        {
            "source": 290,
            "target": 248
        },
        {
            "source": 290,
            "target": 282
        },
        {
            "source": 290,
            "target": 167
        },
        {
            "source": 290,
            "target": 112
        },
        {
            "source": 290,
            "target": 354
        },
        {
            "source": 290,
            "target": 372
        },
        {
            "source": 291,
            "target": 25
        },
        {
            "source": 291,
            "target": 112
        },
        {
            "source": 291,
            "target": 171
        },
        {
            "source": 291,
            "target": 27
        },
        {
            "source": 291,
            "target": 369
        },
        {
            "source": 292,
            "target": 12
        },
        {
            "source": 292,
            "target": 208
        },
        {
            "source": 292,
            "target": 5
        },
        {
            "source": 292,
            "target": 25
        },
        {
            "source": 292,
            "target": 19
        },
        {
            "source": 292,
            "target": 111
        },
        {
            "source": 292,
            "target": 60
        },
        {
            "source": 292,
            "target": 27
        },
        {
            "source": 292,
            "target": 102
        },
        {
            "source": 293,
            "target": 287
        },
        {
            "source": 293,
            "target": 233
        },
        {
            "source": 293,
            "target": 148
        },
        {
            "source": 293,
            "target": 104
        },
        {
            "source": 293,
            "target": 183
        },
        {
            "source": 293,
            "target": 212
        },
        {
            "source": 294,
            "target": 25
        },
        {
            "source": 294,
            "target": 27
        },
        {
            "source": 294,
            "target": 314
        },
        {
            "source": 295,
            "target": 332
        },
        {
            "source": 295,
            "target": 194
        },
        {
            "source": 295,
            "target": 338
        },
        {
            "source": 295,
            "target": 2
        },
        {
            "source": 295,
            "target": 193
        },
        {
            "source": 295,
            "target": 202
        },
        {
            "source": 295,
            "target": 205
        },
        {
            "source": 295,
            "target": 235
        },
        {
            "source": 295,
            "target": 217
        },
        {
            "source": 296,
            "target": 260
        },
        {
            "source": 297,
            "target": 197
        },
        {
            "source": 297,
            "target": 99
        },
        {
            "source": 297,
            "target": 206
        },
        {
            "source": 297,
            "target": 169
        },
        {
            "source": 297,
            "target": 353
        },
        {
            "source": 297,
            "target": 352
        },
        {
            "source": 297,
            "target": 105
        },
        {
            "source": 297,
            "target": 34
        },
        {
            "source": 298,
            "target": 305
        },
        {
            "source": 298,
            "target": 160
        },
        {
            "source": 298,
            "target": 291
        },
        {
            "source": 299,
            "target": 88
        },
        {
            "source": 299,
            "target": 352
        },
        {
            "source": 299,
            "target": 25
        },
        {
            "source": 300,
            "target": 287
        },
        {
            "source": 300,
            "target": 268
        },
        {
            "source": 300,
            "target": 368
        },
        {
            "source": 300,
            "target": 222
        },
        {
            "source": 300,
            "target": 337
        },
        {
            "source": 300,
            "target": 198
        },
        {
            "source": 300,
            "target": 277
        },
        {
            "source": 300,
            "target": 153
        },
        {
            "source": 300,
            "target": 159
        },
        {
            "source": 300,
            "target": 160
        },
        {
            "source": 300,
            "target": 377
        },
        {
            "source": 300,
            "target": 312
        },
        {
            "source": 300,
            "target": 129
        },
        {
            "source": 300,
            "target": 252
        },
        {
            "source": 300,
            "target": 355
        },
        {
            "source": 300,
            "target": 146
        },
        {
            "source": 300,
            "target": 366
        },
        {
            "source": 300,
            "target": 137
        },
        {
            "source": 300,
            "target": 219
        },
        {
            "source": 300,
            "target": 148
        },
        {
            "source": 300,
            "target": 356
        },
        {
            "source": 300,
            "target": 51
        },
        {
            "source": 300,
            "target": 179
        },
        {
            "source": 300,
            "target": 104
        },
        {
            "source": 300,
            "target": 245
        },
        {
            "source": 300,
            "target": 181
        },
        {
            "source": 300,
            "target": 114
        },
        {
            "source": 300,
            "target": 278
        },
        {
            "source": 300,
            "target": 349
        },
        {
            "source": 300,
            "target": 209
        },
        {
            "source": 300,
            "target": 309
        },
        {
            "source": 300,
            "target": 38
        },
        {
            "source": 300,
            "target": 230
        },
        {
            "source": 300,
            "target": 156
        },
        {
            "source": 300,
            "target": 251
        },
        {
            "source": 300,
            "target": 26
        },
        {
            "source": 300,
            "target": 335
        },
        {
            "source": 301,
            "target": 352
        },
        {
            "source": 301,
            "target": 27
        },
        {
            "source": 301,
            "target": 291
        },
        {
            "source": 302,
            "target": 44
        },
        {
            "source": 302,
            "target": 364
        },
        {
            "source": 302,
            "target": 343
        },
        {
            "source": 302,
            "target": 301
        },
        {
            "source": 302,
            "target": 352
        },
        {
            "source": 302,
            "target": 390
        },
        {
            "source": 302,
            "target": 250
        },
        {
            "source": 302,
            "target": 281
        },
        {
            "source": 302,
            "target": 131
        },
        {
            "source": 303,
            "target": 167
        },
        {
            "source": 303,
            "target": 256
        },
        {
            "source": 303,
            "target": 315
        },
        {
            "source": 303,
            "target": 269
        },
        {
            "source": 304,
            "target": 199
        },
        {
            "source": 304,
            "target": 352
        },
        {
            "source": 304,
            "target": 25
        },
        {
            "source": 305,
            "target": 298
        },
        {
            "source": 305,
            "target": 352
        },
        {
            "source": 306,
            "target": 280
        },
        {
            "source": 307,
            "target": 27
        },
        {
            "source": 309,
            "target": 287
        },
        {
            "source": 309,
            "target": 268
        },
        {
            "source": 309,
            "target": 368
        },
        {
            "source": 309,
            "target": 222
        },
        {
            "source": 309,
            "target": 337
        },
        {
            "source": 309,
            "target": 198
        },
        {
            "source": 309,
            "target": 277
        },
        {
            "source": 309,
            "target": 153
        },
        {
            "source": 309,
            "target": 159
        },
        {
            "source": 309,
            "target": 377
        },
        {
            "source": 309,
            "target": 129
        },
        {
            "source": 309,
            "target": 252
        },
        {
            "source": 309,
            "target": 355
        },
        {
            "source": 309,
            "target": 146
        },
        {
            "source": 309,
            "target": 366
        },
        {
            "source": 309,
            "target": 137
        },
        {
            "source": 309,
            "target": 219
        },
        {
            "source": 309,
            "target": 148
        },
        {
            "source": 309,
            "target": 356
        },
        {
            "source": 309,
            "target": 300
        },
        {
            "source": 309,
            "target": 51
        },
        {
            "source": 309,
            "target": 179
        },
        {
            "source": 309,
            "target": 104
        },
        {
            "source": 309,
            "target": 245
        },
        {
            "source": 309,
            "target": 181
        },
        {
            "source": 309,
            "target": 114
        },
        {
            "source": 309,
            "target": 278
        },
        {
            "source": 309,
            "target": 349
        },
        {
            "source": 309,
            "target": 209
        },
        {
            "source": 309,
            "target": 38
        },
        {
            "source": 309,
            "target": 230
        },
        {
            "source": 309,
            "target": 156
        },
        {
            "source": 309,
            "target": 251
        },
        {
            "source": 309,
            "target": 26
        },
        {
            "source": 309,
            "target": 335
        },
        {
            "source": 310,
            "target": 99
        },
        {
            "source": 310,
            "target": 0
        },
        {
            "source": 310,
            "target": 271
        },
        {
            "source": 310,
            "target": 94
        },
        {
            "source": 310,
            "target": 10
        },
        {
            "source": 310,
            "target": 352
        },
        {
            "source": 310,
            "target": 25
        },
        {
            "source": 310,
            "target": 152
        },
        {
            "source": 310,
            "target": 32
        },
        {
            "source": 310,
            "target": 241
        },
        {
            "source": 310,
            "target": 113
        },
        {
            "source": 310,
            "target": 144
        },
        {
            "source": 310,
            "target": 247
        },
        {
            "source": 310,
            "target": 244
        },
        {
            "source": 310,
            "target": 16
        },
        {
            "source": 310,
            "target": 327
        },
        {
            "source": 311,
            "target": 352
        },
        {
            "source": 311,
            "target": 25
        },
        {
            "source": 311,
            "target": 162
        },
        {
            "source": 311,
            "target": 27
        },
        {
            "source": 311,
            "target": 291
        },
        {
            "source": 312,
            "target": 319
        },
        {
            "source": 312,
            "target": 322
        },
        {
            "source": 313,
            "target": 352
        },
        {
            "source": 313,
            "target": 291
        },
        {
            "source": 314,
            "target": 322
        },
        {
            "source": 314,
            "target": 185
        },
        {
            "source": 314,
            "target": 352
        },
        {
            "source": 315,
            "target": 167
        },
        {
            "source": 315,
            "target": 256
        },
        {
            "source": 315,
            "target": 27
        },
        {
            "source": 315,
            "target": 303
        },
        {
            "source": 315,
            "target": 269
        },
        {
            "source": 316,
            "target": 322
        },
        {
            "source": 316,
            "target": 12
        },
        {
            "source": 316,
            "target": 104
        },
        {
            "source": 316,
            "target": 352
        },
        {
            "source": 316,
            "target": 25
        },
        {
            "source": 316,
            "target": 250
        },
        {
            "source": 316,
            "target": 281
        },
        {
            "source": 317,
            "target": 280
        },
        {
            "source": 317,
            "target": 183
        },
        {
            "source": 317,
            "target": 352
        },
        {
            "source": 317,
            "target": 294
        },
        {
            "source": 317,
            "target": 361
        },
        {
            "source": 318,
            "target": 352
        },
        {
            "source": 318,
            "target": 203
        },
        {
            "source": 318,
            "target": 130
        },
        {
            "source": 318,
            "target": 291
        },
        {
            "source": 319,
            "target": 312
        },
        {
            "source": 319,
            "target": 352
        },
        {
            "source": 319,
            "target": 25
        },
        {
            "source": 319,
            "target": 27
        },
        {
            "source": 319,
            "target": 228
        },
        {
            "source": 319,
            "target": 291
        },
        {
            "source": 320,
            "target": 291
        },
        {
            "source": 321,
            "target": 352
        },
        {
            "source": 323,
            "target": 276
        },
        {
            "source": 323,
            "target": 255
        },
        {
            "source": 324,
            "target": 365
        },
        {
            "source": 324,
            "target": 119
        },
        {
            "source": 324,
            "target": 320
        },
        {
            "source": 324,
            "target": 248
        },
        {
            "source": 324,
            "target": 282
        },
        {
            "source": 324,
            "target": 354
        },
        {
            "source": 324,
            "target": 372
        },
        {
            "source": 324,
            "target": 339
        },
        {
            "source": 324,
            "target": 167
        },
        {
            "source": 324,
            "target": 112
        },
        {
            "source": 324,
            "target": 290
        },
        {
            "source": 324,
            "target": 345
        },
        {
            "source": 326,
            "target": 272
        },
        {
            "source": 326,
            "target": 391
        },
        {
            "source": 326,
            "target": 357
        },
        {
            "source": 326,
            "target": 352
        },
        {
            "source": 326,
            "target": 25
        },
        {
            "source": 326,
            "target": 214
        },
        {
            "source": 326,
            "target": 19
        },
        {
            "source": 326,
            "target": 27
        },
        {
            "source": 327,
            "target": 99
        },
        {
            "source": 327,
            "target": 0
        },
        {
            "source": 327,
            "target": 310
        },
        {
            "source": 327,
            "target": 43
        },
        {
            "source": 327,
            "target": 271
        },
        {
            "source": 327,
            "target": 94
        },
        {
            "source": 327,
            "target": 10
        },
        {
            "source": 327,
            "target": 352
        },
        {
            "source": 327,
            "target": 25
        },
        {
            "source": 327,
            "target": 152
        },
        {
            "source": 327,
            "target": 32
        },
        {
            "source": 327,
            "target": 241
        },
        {
            "source": 327,
            "target": 34
        },
        {
            "source": 327,
            "target": 150
        },
        {
            "source": 327,
            "target": 113
        },
        {
            "source": 327,
            "target": 144
        },
        {
            "source": 327,
            "target": 247
        },
        {
            "source": 327,
            "target": 244
        },
        {
            "source": 327,
            "target": 16
        },
        {
            "source": 327,
            "target": 116
        },
        {
            "source": 328,
            "target": 352
        },
        {
            "source": 328,
            "target": 25
        },
        {
            "source": 328,
            "target": 27
        },
        {
            "source": 328,
            "target": 291
        },
        {
            "source": 329,
            "target": 352
        },
        {
            "source": 329,
            "target": 25
        },
        {
            "source": 329,
            "target": 229
        },
        {
            "source": 329,
            "target": 27
        },
        {
            "source": 330,
            "target": 243
        },
        {
            "source": 330,
            "target": 25
        },
        {
            "source": 331,
            "target": 180
        },
        {
            "source": 331,
            "target": 210
        },
        {
            "source": 331,
            "target": 352
        },
        {
            "source": 331,
            "target": 25
        },
        {
            "source": 332,
            "target": 179
        },
        {
            "source": 332,
            "target": 194
        },
        {
            "source": 332,
            "target": 338
        },
        {
            "source": 332,
            "target": 2
        },
        {
            "source": 332,
            "target": 193
        },
        {
            "source": 332,
            "target": 202
        },
        {
            "source": 332,
            "target": 205
        },
        {
            "source": 332,
            "target": 235
        },
        {
            "source": 332,
            "target": 217
        },
        {
            "source": 332,
            "target": 295
        },
        {
            "source": 332,
            "target": 352
        },
        {
            "source": 333,
            "target": 199
        },
        {
            "source": 333,
            "target": 25
        },
        {
            "source": 334,
            "target": 5
        },
        {
            "source": 334,
            "target": 352
        },
        {
            "source": 334,
            "target": 25
        },
        {
            "source": 334,
            "target": 27
        },
        {
            "source": 334,
            "target": 291
        },
        {
            "source": 335,
            "target": 287
        },
        {
            "source": 335,
            "target": 268
        },
        {
            "source": 335,
            "target": 368
        },
        {
            "source": 335,
            "target": 222
        },
        {
            "source": 335,
            "target": 337
        },
        {
            "source": 335,
            "target": 198
        },
        {
            "source": 335,
            "target": 277
        },
        {
            "source": 335,
            "target": 153
        },
        {
            "source": 335,
            "target": 159
        },
        {
            "source": 335,
            "target": 377
        },
        {
            "source": 335,
            "target": 129
        },
        {
            "source": 335,
            "target": 252
        },
        {
            "source": 335,
            "target": 355
        },
        {
            "source": 335,
            "target": 146
        },
        {
            "source": 335,
            "target": 366
        },
        {
            "source": 335,
            "target": 137
        },
        {
            "source": 335,
            "target": 219
        },
        {
            "source": 335,
            "target": 148
        },
        {
            "source": 335,
            "target": 356
        },
        {
            "source": 335,
            "target": 300
        },
        {
            "source": 335,
            "target": 51
        },
        {
            "source": 335,
            "target": 179
        },
        {
            "source": 335,
            "target": 104
        },
        {
            "source": 335,
            "target": 245
        },
        {
            "source": 335,
            "target": 181
        },
        {
            "source": 335,
            "target": 114
        },
        {
            "source": 335,
            "target": 278
        },
        {
            "source": 335,
            "target": 349
        },
        {
            "source": 335,
            "target": 209
        },
        {
            "source": 335,
            "target": 309
        },
        {
            "source": 335,
            "target": 38
        },
        {
            "source": 335,
            "target": 230
        },
        {
            "source": 335,
            "target": 156
        },
        {
            "source": 335,
            "target": 251
        },
        {
            "source": 335,
            "target": 26
        },
        {
            "source": 336,
            "target": 319
        },
        {
            "source": 336,
            "target": 312
        },
        {
            "source": 337,
            "target": 287
        },
        {
            "source": 337,
            "target": 268
        },
        {
            "source": 337,
            "target": 368
        },
        {
            "source": 337,
            "target": 222
        },
        {
            "source": 337,
            "target": 198
        },
        {
            "source": 337,
            "target": 277
        },
        {
            "source": 337,
            "target": 153
        },
        {
            "source": 337,
            "target": 159
        },
        {
            "source": 337,
            "target": 377
        },
        {
            "source": 337,
            "target": 129
        },
        {
            "source": 337,
            "target": 252
        },
        {
            "source": 337,
            "target": 355
        },
        {
            "source": 337,
            "target": 146
        },
        {
            "source": 337,
            "target": 366
        },
        {
            "source": 337,
            "target": 137
        },
        {
            "source": 337,
            "target": 219
        },
        {
            "source": 337,
            "target": 148
        },
        {
            "source": 337,
            "target": 356
        },
        {
            "source": 337,
            "target": 300
        },
        {
            "source": 337,
            "target": 51
        },
        {
            "source": 337,
            "target": 179
        },
        {
            "source": 337,
            "target": 104
        },
        {
            "source": 337,
            "target": 245
        },
        {
            "source": 337,
            "target": 181
        },
        {
            "source": 337,
            "target": 114
        },
        {
            "source": 337,
            "target": 278
        },
        {
            "source": 337,
            "target": 349
        },
        {
            "source": 337,
            "target": 209
        },
        {
            "source": 337,
            "target": 309
        },
        {
            "source": 337,
            "target": 38
        },
        {
            "source": 337,
            "target": 230
        },
        {
            "source": 337,
            "target": 156
        },
        {
            "source": 337,
            "target": 251
        },
        {
            "source": 337,
            "target": 26
        },
        {
            "source": 337,
            "target": 335
        },
        {
            "source": 338,
            "target": 332
        },
        {
            "source": 338,
            "target": 194
        },
        {
            "source": 338,
            "target": 2
        },
        {
            "source": 338,
            "target": 193
        },
        {
            "source": 338,
            "target": 202
        },
        {
            "source": 338,
            "target": 205
        },
        {
            "source": 338,
            "target": 235
        },
        {
            "source": 338,
            "target": 217
        },
        {
            "source": 338,
            "target": 295
        },
        {
            "source": 339,
            "target": 365
        },
        {
            "source": 339,
            "target": 119
        },
        {
            "source": 339,
            "target": 320
        },
        {
            "source": 339,
            "target": 248
        },
        {
            "source": 339,
            "target": 282
        },
        {
            "source": 339,
            "target": 354
        },
        {
            "source": 339,
            "target": 372
        },
        {
            "source": 339,
            "target": 324
        },
        {
            "source": 339,
            "target": 167
        },
        {
            "source": 339,
            "target": 112
        },
        {
            "source": 339,
            "target": 290
        },
        {
            "source": 339,
            "target": 345
        },
        {
            "source": 339,
            "target": 291
        },
        {
            "source": 340,
            "target": 87
        },
        {
            "source": 340,
            "target": 146
        },
        {
            "source": 340,
            "target": 352
        },
        {
            "source": 341,
            "target": 287
        },
        {
            "source": 341,
            "target": 233
        },
        {
            "source": 341,
            "target": 148
        },
        {
            "source": 341,
            "target": 104
        },
        {
            "source": 341,
            "target": 212
        },
        {
            "source": 341,
            "target": 352
        },
        {
            "source": 341,
            "target": 293
        },
        {
            "source": 341,
            "target": 344
        },
        {
            "source": 342,
            "target": 352
        },
        {
            "source": 342,
            "target": 25
        },
        {
            "source": 343,
            "target": 25
        },
        {
            "source": 343,
            "target": 98
        },
        {
            "source": 343,
            "target": 27
        },
        {
            "source": 343,
            "target": 231
        },
        {
            "source": 345,
            "target": 365
        },
        {
            "source": 345,
            "target": 119
        },
        {
            "source": 345,
            "target": 320
        },
        {
            "source": 345,
            "target": 248
        },
        {
            "source": 345,
            "target": 282
        },
        {
            "source": 345,
            "target": 354
        },
        {
            "source": 345,
            "target": 372
        },
        {
            "source": 345,
            "target": 324
        },
        {
            "source": 345,
            "target": 339
        },
        {
            "source": 345,
            "target": 167
        },
        {
            "source": 345,
            "target": 112
        },
        {
            "source": 345,
            "target": 290
        },
        {
            "source": 346,
            "target": 352
        },
        {
            "source": 346,
            "target": 113
        },
        {
            "source": 346,
            "target": 27
        },
        {
            "source": 348,
            "target": 352
        },
        {
            "source": 348,
            "target": 229
        },
        {
            "source": 348,
            "target": 34
        },
        {
            "source": 348,
            "target": 27
        },
        {
            "source": 349,
            "target": 287
        },
        {
            "source": 349,
            "target": 268
        },
        {
            "source": 349,
            "target": 368
        },
        {
            "source": 349,
            "target": 222
        },
        {
            "source": 349,
            "target": 337
        },
        {
            "source": 349,
            "target": 198
        },
        {
            "source": 349,
            "target": 277
        },
        {
            "source": 349,
            "target": 153
        },
        {
            "source": 349,
            "target": 159
        },
        {
            "source": 349,
            "target": 377
        },
        {
            "source": 349,
            "target": 129
        },
        {
            "source": 349,
            "target": 252
        },
        {
            "source": 349,
            "target": 355
        },
        {
            "source": 349,
            "target": 146
        },
        {
            "source": 349,
            "target": 366
        },
        {
            "source": 349,
            "target": 137
        },
        {
            "source": 349,
            "target": 219
        },
        {
            "source": 349,
            "target": 148
        },
        {
            "source": 349,
            "target": 356
        },
        {
            "source": 349,
            "target": 300
        },
        {
            "source": 349,
            "target": 51
        },
        {
            "source": 349,
            "target": 179
        },
        {
            "source": 349,
            "target": 104
        },
        {
            "source": 349,
            "target": 245
        },
        {
            "source": 349,
            "target": 181
        },
        {
            "source": 349,
            "target": 114
        },
        {
            "source": 349,
            "target": 278
        },
        {
            "source": 349,
            "target": 209
        },
        {
            "source": 349,
            "target": 309
        },
        {
            "source": 349,
            "target": 38
        },
        {
            "source": 349,
            "target": 230
        },
        {
            "source": 349,
            "target": 156
        },
        {
            "source": 349,
            "target": 251
        },
        {
            "source": 349,
            "target": 26
        },
        {
            "source": 349,
            "target": 335
        },
        {
            "source": 350,
            "target": 210
        },
        {
            "source": 350,
            "target": 352
        },
        {
            "source": 350,
            "target": 25
        },
        {
            "source": 351,
            "target": 262
        },
        {
            "source": 352,
            "target": 365
        },
        {
            "source": 352,
            "target": 119
        },
        {
            "source": 352,
            "target": 320
        },
        {
            "source": 352,
            "target": 248
        },
        {
            "source": 352,
            "target": 282
        },
        {
            "source": 352,
            "target": 354
        },
        {
            "source": 352,
            "target": 372
        },
        {
            "source": 352,
            "target": 324
        },
        {
            "source": 352,
            "target": 339
        },
        {
            "source": 352,
            "target": 167
        },
        {
            "source": 353,
            "target": 352
        },
        {
            "source": 354,
            "target": 365
        },
        {
            "source": 354,
            "target": 119
        },
        {
            "source": 354,
            "target": 352
        },
        {
            "source": 354,
            "target": 320
        },
        {
            "source": 354,
            "target": 248
        },
        {
            "source": 354,
            "target": 282
        },
        {
            "source": 354,
            "target": 372
        },
        {
            "source": 354,
            "target": 324
        },
        {
            "source": 354,
            "target": 339
        },
        {
            "source": 354,
            "target": 167
        },
        {
            "source": 354,
            "target": 112
        },
        {
            "source": 354,
            "target": 290
        },
        {
            "source": 354,
            "target": 345
        },
        {
            "source": 355,
            "target": 287
        },
        {
            "source": 355,
            "target": 268
        },
        {
            "source": 355,
            "target": 368
        },
        {
            "source": 355,
            "target": 222
        },
        {
            "source": 355,
            "target": 337
        },
        {
            "source": 355,
            "target": 198
        },
        {
            "source": 355,
            "target": 277
        },
        {
            "source": 355,
            "target": 35
        },
        {
            "source": 355,
            "target": 322
        },
        {
            "source": 355,
            "target": 153
        },
        {
            "source": 355,
            "target": 159
        },
        {
            "source": 355,
            "target": 160
        },
        {
            "source": 355,
            "target": 377
        },
        {
            "source": 355,
            "target": 129
        },
        {
            "source": 355,
            "target": 252
        },
        {
            "source": 355,
            "target": 146
        },
        {
            "source": 355,
            "target": 366
        },
        {
            "source": 355,
            "target": 137
        },
        {
            "source": 355,
            "target": 219
        },
        {
            "source": 355,
            "target": 148
        },
        {
            "source": 355,
            "target": 356
        },
        {
            "source": 355,
            "target": 300
        },
        {
            "source": 355,
            "target": 51
        },
        {
            "source": 355,
            "target": 179
        },
        {
            "source": 355,
            "target": 104
        },
        {
            "source": 355,
            "target": 245
        },
        {
            "source": 355,
            "target": 181
        },
        {
            "source": 355,
            "target": 114
        },
        {
            "source": 355,
            "target": 278
        },
        {
            "source": 355,
            "target": 349
        },
        {
            "source": 355,
            "target": 209
        },
        {
            "source": 355,
            "target": 309
        },
        {
            "source": 355,
            "target": 38
        },
        {
            "source": 356,
            "target": 287
        },
        {
            "source": 356,
            "target": 268
        },
        {
            "source": 356,
            "target": 368
        },
        {
            "source": 356,
            "target": 222
        },
        {
            "source": 356,
            "target": 337
        },
        {
            "source": 356,
            "target": 198
        },
        {
            "source": 356,
            "target": 277
        },
        {
            "source": 356,
            "target": 153
        },
        {
            "source": 356,
            "target": 159
        },
        {
            "source": 356,
            "target": 377
        },
        {
            "source": 356,
            "target": 129
        },
        {
            "source": 356,
            "target": 252
        },
        {
            "source": 356,
            "target": 355
        },
        {
            "source": 356,
            "target": 146
        },
        {
            "source": 356,
            "target": 366
        },
        {
            "source": 356,
            "target": 137
        },
        {
            "source": 356,
            "target": 219
        },
        {
            "source": 356,
            "target": 148
        },
        {
            "source": 356,
            "target": 300
        },
        {
            "source": 356,
            "target": 51
        },
        {
            "source": 356,
            "target": 179
        },
        {
            "source": 356,
            "target": 104
        },
        {
            "source": 356,
            "target": 245
        },
        {
            "source": 356,
            "target": 181
        },
        {
            "source": 356,
            "target": 114
        },
        {
            "source": 356,
            "target": 278
        },
        {
            "source": 356,
            "target": 349
        },
        {
            "source": 356,
            "target": 209
        },
        {
            "source": 356,
            "target": 309
        },
        {
            "source": 356,
            "target": 38
        },
        {
            "source": 356,
            "target": 230
        },
        {
            "source": 356,
            "target": 156
        },
        {
            "source": 356,
            "target": 251
        },
        {
            "source": 356,
            "target": 26
        },
        {
            "source": 356,
            "target": 335
        },
        {
            "source": 357,
            "target": 322
        },
        {
            "source": 357,
            "target": 272
        },
        {
            "source": 357,
            "target": 326
        },
        {
            "source": 357,
            "target": 391
        },
        {
            "source": 357,
            "target": 352
        },
        {
            "source": 357,
            "target": 25
        },
        {
            "source": 357,
            "target": 19
        },
        {
            "source": 357,
            "target": 27
        },
        {
            "source": 358,
            "target": 87
        },
        {
            "source": 358,
            "target": 312
        },
        {
            "source": 359,
            "target": 223
        },
        {
            "source": 360,
            "target": 336
        },
        {
            "source": 361,
            "target": 314
        },
        {
            "source": 361,
            "target": 280
        },
        {
            "source": 361,
            "target": 352
        },
        {
            "source": 361,
            "target": 25
        },
        {
            "source": 361,
            "target": 317
        },
        {
            "source": 362,
            "target": 352
        },
        {
            "source": 362,
            "target": 25
        },
        {
            "source": 362,
            "target": 27
        },
        {
            "source": 362,
            "target": 291
        },
        {
            "source": 363,
            "target": 272
        },
        {
            "source": 363,
            "target": 352
        },
        {
            "source": 363,
            "target": 25
        },
        {
            "source": 363,
            "target": 27
        },
        {
            "source": 364,
            "target": 44
        },
        {
            "source": 364,
            "target": 197
        },
        {
            "source": 364,
            "target": 302
        },
        {
            "source": 364,
            "target": 99
        },
        {
            "source": 364,
            "target": 343
        },
        {
            "source": 364,
            "target": 297
        },
        {
            "source": 364,
            "target": 206
        },
        {
            "source": 364,
            "target": 301
        },
        {
            "source": 364,
            "target": 169
        },
        {
            "source": 364,
            "target": 353
        },
        {
            "source": 364,
            "target": 93
        },
        {
            "source": 364,
            "target": 352
        },
        {
            "source": 364,
            "target": 390
        },
        {
            "source": 364,
            "target": 250
        },
        {
            "source": 365,
            "target": 15
        },
        {
            "source": 365,
            "target": 196
        },
        {
            "source": 365,
            "target": 119
        },
        {
            "source": 365,
            "target": 352
        },
        {
            "source": 365,
            "target": 320
        },
        {
            "source": 365,
            "target": 248
        },
        {
            "source": 365,
            "target": 282
        },
        {
            "source": 365,
            "target": 354
        },
        {
            "source": 365,
            "target": 372
        },
        {
            "source": 365,
            "target": 324
        },
        {
            "source": 365,
            "target": 339
        },
        {
            "source": 365,
            "target": 167
        },
        {
            "source": 366,
            "target": 287
        },
        {
            "source": 366,
            "target": 268
        },
        {
            "source": 366,
            "target": 368
        },
        {
            "source": 366,
            "target": 222
        },
        {
            "source": 366,
            "target": 337
        },
        {
            "source": 366,
            "target": 198
        },
        {
            "source": 366,
            "target": 277
        },
        {
            "source": 366,
            "target": 153
        },
        {
            "source": 366,
            "target": 159
        },
        {
            "source": 366,
            "target": 377
        },
        {
            "source": 366,
            "target": 129
        },
        {
            "source": 366,
            "target": 252
        },
        {
            "source": 366,
            "target": 355
        },
        {
            "source": 366,
            "target": 146
        },
        {
            "source": 366,
            "target": 137
        },
        {
            "source": 366,
            "target": 219
        },
        {
            "source": 366,
            "target": 148
        },
        {
            "source": 366,
            "target": 356
        },
        {
            "source": 366,
            "target": 300
        },
        {
            "source": 366,
            "target": 51
        },
        {
            "source": 366,
            "target": 179
        },
        {
            "source": 366,
            "target": 104
        },
        {
            "source": 366,
            "target": 245
        },
        {
            "source": 366,
            "target": 181
        },
        {
            "source": 366,
            "target": 114
        },
        {
            "source": 366,
            "target": 278
        },
        {
            "source": 366,
            "target": 349
        },
        {
            "source": 366,
            "target": 209
        },
        {
            "source": 366,
            "target": 309
        },
        {
            "source": 366,
            "target": 38
        },
        {
            "source": 366,
            "target": 230
        },
        {
            "source": 366,
            "target": 156
        },
        {
            "source": 366,
            "target": 251
        },
        {
            "source": 366,
            "target": 26
        },
        {
            "source": 366,
            "target": 335
        },
        {
            "source": 367,
            "target": 35
        },
        {
            "source": 367,
            "target": 352
        },
        {
            "source": 367,
            "target": 25
        },
        {
            "source": 367,
            "target": 34
        },
        {
            "source": 367,
            "target": 144
        },
        {
            "source": 367,
            "target": 27
        },
        {
            "source": 367,
            "target": 116
        },
        {
            "source": 368,
            "target": 287
        },
        {
            "source": 368,
            "target": 268
        },
        {
            "source": 368,
            "target": 222
        },
        {
            "source": 368,
            "target": 337
        },
        {
            "source": 368,
            "target": 198
        },
        {
            "source": 368,
            "target": 277
        },
        {
            "source": 368,
            "target": 35
        },
        {
            "source": 368,
            "target": 153
        },
        {
            "source": 368,
            "target": 159
        },
        {
            "source": 368,
            "target": 377
        },
        {
            "source": 368,
            "target": 129
        },
        {
            "source": 368,
            "target": 252
        },
        {
            "source": 368,
            "target": 355
        },
        {
            "source": 368,
            "target": 146
        },
        {
            "source": 368,
            "target": 366
        },
        {
            "source": 368,
            "target": 137
        },
        {
            "source": 368,
            "target": 219
        },
        {
            "source": 368,
            "target": 148
        },
        {
            "source": 368,
            "target": 356
        },
        {
            "source": 368,
            "target": 300
        },
        {
            "source": 368,
            "target": 51
        },
        {
            "source": 368,
            "target": 179
        },
        {
            "source": 368,
            "target": 104
        },
        {
            "source": 368,
            "target": 245
        },
        {
            "source": 368,
            "target": 181
        },
        {
            "source": 368,
            "target": 114
        },
        {
            "source": 368,
            "target": 278
        },
        {
            "source": 368,
            "target": 349
        },
        {
            "source": 368,
            "target": 209
        },
        {
            "source": 368,
            "target": 309
        },
        {
            "source": 368,
            "target": 38
        },
        {
            "source": 368,
            "target": 230
        },
        {
            "source": 368,
            "target": 156
        },
        {
            "source": 368,
            "target": 251
        },
        {
            "source": 368,
            "target": 26
        },
        {
            "source": 368,
            "target": 335
        },
        {
            "source": 369,
            "target": 352
        },
        {
            "source": 369,
            "target": 25
        },
        {
            "source": 369,
            "target": 27
        },
        {
            "source": 370,
            "target": 352
        },
        {
            "source": 370,
            "target": 25
        },
        {
            "source": 370,
            "target": 237
        },
        {
            "source": 371,
            "target": 314
        },
        {
            "source": 371,
            "target": 199
        },
        {
            "source": 371,
            "target": 333
        },
        {
            "source": 371,
            "target": 106
        },
        {
            "source": 371,
            "target": 352
        },
        {
            "source": 371,
            "target": 25
        },
        {
            "source": 372,
            "target": 365
        },
        {
            "source": 372,
            "target": 119
        },
        {
            "source": 372,
            "target": 320
        },
        {
            "source": 372,
            "target": 248
        },
        {
            "source": 372,
            "target": 282
        },
        {
            "source": 372,
            "target": 354
        },
        {
            "source": 372,
            "target": 324
        },
        {
            "source": 372,
            "target": 339
        },
        {
            "source": 372,
            "target": 167
        },
        {
            "source": 372,
            "target": 112
        },
        {
            "source": 372,
            "target": 290
        },
        {
            "source": 372,
            "target": 345
        },
        {
            "source": 373,
            "target": 192
        },
        {
            "source": 373,
            "target": 242
        },
        {
            "source": 373,
            "target": 274
        },
        {
            "source": 373,
            "target": 352
        },
        {
            "source": 373,
            "target": 25
        },
        {
            "source": 373,
            "target": 386
        },
        {
            "source": 373,
            "target": 190
        },
        {
            "source": 373,
            "target": 291
        },
        {
            "source": 374,
            "target": 340
        },
        {
            "source": 374,
            "target": 104
        },
        {
            "source": 375,
            "target": 43
        },
        {
            "source": 375,
            "target": 201
        },
        {
            "source": 375,
            "target": 27
        },
        {
            "source": 376,
            "target": 322
        },
        {
            "source": 377,
            "target": 104
        },
        {
            "source": 378,
            "target": 352
        },
        {
            "source": 378,
            "target": 289
        },
        {
            "source": 379,
            "target": 352
        },
        {
            "source": 379,
            "target": 201
        },
        {
            "source": 379,
            "target": 229
        },
        {
            "source": 379,
            "target": 291
        },
        {
            "source": 380,
            "target": 352
        },
        {
            "source": 380,
            "target": 25
        },
        {
            "source": 380,
            "target": 27
        },
        {
            "source": 380,
            "target": 291
        },
        {
            "source": 381,
            "target": 236
        },
        {
            "source": 381,
            "target": 352
        },
        {
            "source": 381,
            "target": 25
        },
        {
            "source": 381,
            "target": 27
        },
        {
            "source": 383,
            "target": 352
        },
        {
            "source": 383,
            "target": 25
        },
        {
            "source": 383,
            "target": 27
        },
        {
            "source": 383,
            "target": 291
        },
        {
            "source": 384,
            "target": 352
        },
        {
            "source": 385,
            "target": 87
        },
        {
            "source": 385,
            "target": 352
        },
        {
            "source": 385,
            "target": 25
        },
        {
            "source": 385,
            "target": 19
        },
        {
            "source": 385,
            "target": 27
        },
        {
            "source": 385,
            "target": 291
        },
        {
            "source": 386,
            "target": 192
        },
        {
            "source": 386,
            "target": 242
        },
        {
            "source": 386,
            "target": 352
        },
        {
            "source": 386,
            "target": 373
        },
        {
            "source": 386,
            "target": 291
        },
        {
            "source": 388,
            "target": 291
        },
        {
            "source": 389,
            "target": 352
        },
        {
            "source": 389,
            "target": 25
        },
        {
            "source": 389,
            "target": 27
        },
        {
            "source": 390,
            "target": 44
        },
        {
            "source": 390,
            "target": 364
        },
        {
            "source": 390,
            "target": 302
        },
        {
            "source": 390,
            "target": 343
        },
        {
            "source": 390,
            "target": 301
        },
        {
            "source": 390,
            "target": 352
        },
        {
            "source": 390,
            "target": 250
        },
        {
            "source": 390,
            "target": 281
        },
        {
            "source": 390,
            "target": 131
        },
        {
            "source": 391,
            "target": 272
        },
        {
            "source": 391,
            "target": 326
        },
        {
            "source": 391,
            "target": 357
        },
        {
            "source": 391,
            "target": 352
        },
        {
            "source": 391,
            "target": 25
        },
        {
            "source": 391,
            "target": 214
        },
        {
            "source": 391,
            "target": 27
        }
    ]
}