Crawling layers:   0%|          | 0/5 [00:00<?, ?it/s]Crawling layers:  20%|██        | 1/5 [00:00<00:01,  2.43it/s]Crawling layers:  40%|████      | 2/5 [00:38<01:07, 22.38s/it]Crawling layers:  60%|██████    | 3/5 [01:19<01:02, 31.04s/it]Crawling layers:  80%|████████  | 4/5 [01:56<00:33, 33.32s/it]Crawling layers: 100%|██████████| 5/5 [02:34<00:00, 35.05s/it]Crawling layers: 100%|██████████| 5/5 [02:34<00:00, 30.89s/it]
Embedding nodes:   0%|          | 0/392 [00:00<?, ?it/s]Embedding nodes:   0%|          | 1/392 [00:00<01:40,  3.91it/s]Embedding nodes:   1%|          | 3/392 [00:00<01:56,  3.35it/s]Embedding nodes:   1%|          | 4/392 [00:01<01:31,  4.24it/s]Embedding nodes:   1%|▏         | 5/392 [00:01<01:32,  4.17it/s]Embedding nodes:   2%|▏         | 6/392 [00:01<01:32,  4.18it/s]Embedding nodes:   2%|▏         | 7/392 [00:01<01:41,  3.81it/s]Embedding nodes:   2%|▏         | 8/392 [00:02<01:49,  3.50it/s]Embedding nodes:   3%|▎         | 10/392 [00:02<01:16,  4.99it/s]Embedding nodes:   3%|▎         | 11/392 [00:02<01:12,  5.23it/s]Embedding nodes:   3%|▎         | 12/392 [00:02<01:09,  5.49it/s]Embedding nodes:   4%|▎         | 14/392 [00:02<01:04,  5.89it/s]Embedding nodes:   4%|▍         | 16/392 [00:03<00:56,  6.60it/s]Embedding nodes:   5%|▍         | 18/392 [00:03<00:51,  7.32it/s]Embedding nodes:   5%|▍         | 19/392 [00:03<00:48,  7.71it/s]Embedding nodes:   5%|▌         | 20/392 [00:03<01:04,  5.81it/s]Embedding nodes:   5%|▌         | 21/392 [00:04<01:04,  5.78it/s]Embedding nodes:   6%|▌         | 23/392 [00:04<01:04,  5.76it/s]Embedding nodes:   6%|▌         | 24/392 [00:04<01:00,  6.09it/s]Embedding nodes:   7%|▋         | 26/392 [00:04<00:52,  6.99it/s]Embedding nodes:   7%|▋         | 27/392 [00:04<00:55,  6.60it/s]Embedding nodes:   7%|▋         | 29/392 [00:05<00:48,  7.55it/s]Embedding nodes:   8%|▊         | 30/392 [00:05<00:46,  7.74it/s]Embedding nodes:   8%|▊         | 31/392 [00:05<01:01,  5.84it/s]Embedding nodes:   8%|▊         | 32/392 [00:05<00:56,  6.32it/s]Embedding nodes:   9%|▊         | 34/392 [00:05<00:48,  7.38it/s]Embedding nodes:   9%|▉         | 35/392 [00:05<00:46,  7.63it/s]Embedding nodes:   9%|▉         | 36/392 [00:06<01:04,  5.55it/s]Embedding nodes:   9%|▉         | 37/392 [00:06<01:02,  5.70it/s]Embedding nodes:  10%|▉         | 38/392 [00:06<01:16,  4.62it/s]Embedding nodes:  10%|▉         | 39/392 [00:07<01:20,  4.41it/s]Embedding nodes:  10%|█         | 40/392 [00:07<01:08,  5.13it/s]Embedding nodes:  11%|█         | 42/392 [00:07<00:50,  6.90it/s]Embedding nodes:  11%|█         | 43/392 [00:07<01:01,  5.68it/s]Embedding nodes:  11%|█         | 44/392 [00:07<01:07,  5.15it/s]Embedding nodes:  12%|█▏        | 46/392 [00:08<00:57,  6.03it/s]Embedding nodes:  12%|█▏        | 47/392 [00:08<00:57,  6.05it/s]Embedding nodes:  12%|█▎        | 49/392 [00:08<00:47,  7.23it/s]Embedding nodes:  13%|█▎        | 50/392 [00:08<01:02,  5.51it/s]Embedding nodes:  13%|█▎        | 52/392 [00:08<00:47,  7.22it/s]Embedding nodes:  14%|█▍        | 54/392 [00:09<00:40,  8.33it/s]Embedding nodes:  14%|█▍        | 55/392 [00:09<00:47,  7.15it/s]Embedding nodes:  14%|█▍        | 56/392 [00:09<01:00,  5.51it/s]Embedding nodes:  15%|█▍        | 57/392 [00:09<00:57,  5.86it/s]Embedding nodes:  15%|█▌        | 59/392 [00:09<00:44,  7.51it/s]Embedding nodes:  16%|█▌        | 61/392 [00:10<00:46,  7.18it/s]Embedding nodes:  16%|█▌        | 62/392 [00:10<00:59,  5.51it/s]Embedding nodes:  16%|█▌        | 63/392 [00:10<00:59,  5.52it/s]Embedding nodes:  16%|█▋        | 64/392 [00:10<00:56,  5.84it/s]Embedding nodes:  17%|█▋        | 65/392 [00:11<00:58,  5.58it/s]Embedding nodes:  17%|█▋        | 66/392 [00:11<00:55,  5.90it/s]Embedding nodes:  17%|█▋        | 67/392 [00:11<01:07,  4.80it/s]Embedding nodes:  17%|█▋        | 68/392 [00:11<00:58,  5.50it/s]Embedding nodes:  18%|█▊        | 69/392 [00:11<00:56,  5.71it/s]Embedding nodes:  18%|█▊        | 70/392 [00:12<00:58,  5.46it/s]Embedding nodes:  18%|█▊        | 71/392 [00:12<01:02,  5.14it/s]Embedding nodes:  18%|█▊        | 72/392 [00:12<00:54,  5.82it/s]Embedding nodes:  19%|█▉        | 74/392 [00:12<00:38,  8.31it/s]Embedding nodes:  19%|█▉        | 75/392 [00:12<00:53,  5.97it/s]Embedding nodes:  19%|█▉        | 76/392 [00:12<00:48,  6.50it/s]Embedding nodes:  20%|█▉        | 77/392 [00:13<01:06,  4.74it/s]Embedding nodes:  20%|█▉        | 78/392 [00:13<00:57,  5.48it/s]Embedding nodes:  20%|██        | 79/392 [00:13<00:54,  5.76it/s]Embedding nodes:  21%|██        | 81/392 [00:13<00:47,  6.58it/s]Embedding nodes:  21%|██        | 82/392 [00:13<00:44,  7.03it/s]Embedding nodes:  21%|██        | 83/392 [00:14<00:56,  5.43it/s]Embedding nodes:  21%|██▏       | 84/392 [00:14<00:53,  5.81it/s]Embedding nodes:  22%|██▏       | 85/392 [00:14<01:03,  4.82it/s]Embedding nodes:  22%|██▏       | 86/392 [00:14<00:58,  5.19it/s]Embedding nodes:  22%|██▏       | 88/392 [00:15<00:47,  6.42it/s]Embedding nodes:  23%|██▎       | 90/392 [00:15<00:43,  6.99it/s]Embedding nodes:  23%|██▎       | 91/392 [00:15<00:40,  7.37it/s]Embedding nodes:  24%|██▎       | 93/392 [00:15<00:38,  7.81it/s]Embedding nodes:  24%|██▍       | 94/392 [00:15<00:38,  7.78it/s]Embedding nodes:  24%|██▍       | 95/392 [00:15<00:36,  8.03it/s]Embedding nodes:  24%|██▍       | 96/392 [00:16<00:37,  7.87it/s]Embedding nodes:  25%|██▌       | 98/392 [00:16<00:38,  7.73it/s]Embedding nodes:  25%|██▌       | 99/392 [00:16<00:36,  7.97it/s]Embedding nodes:  26%|██▌       | 100/392 [00:16<00:49,  5.91it/s]Embedding nodes:  26%|██▌       | 101/392 [00:16<00:48,  6.01it/s]Embedding nodes:  26%|██▌       | 102/392 [00:16<00:45,  6.31it/s]Embedding nodes:  26%|██▋       | 103/392 [00:17<00:47,  6.07it/s]Embedding nodes:  27%|██▋       | 104/392 [00:17<00:57,  5.05it/s]Embedding nodes:  27%|██▋       | 105/392 [00:17<01:10,  4.04it/s]Embedding nodes:  27%|██▋       | 106/392 [00:17<01:00,  4.76it/s]Embedding nodes:  27%|██▋       | 107/392 [00:18<01:12,  3.94it/s]Embedding nodes:  28%|██▊       | 108/392 [00:18<01:01,  4.62it/s]Embedding nodes:  28%|██▊       | 109/392 [00:18<01:13,  3.86it/s]Embedding nodes:  28%|██▊       | 111/392 [00:19<00:58,  4.79it/s]Embedding nodes:  29%|██▉       | 113/392 [00:19<00:48,  5.81it/s]Embedding nodes:  29%|██▉       | 114/392 [00:19<00:47,  5.87it/s]Embedding nodes:  29%|██▉       | 115/392 [00:19<00:56,  4.93it/s]Embedding nodes:  30%|██▉       | 116/392 [00:19<00:48,  5.66it/s]Embedding nodes:  30%|██▉       | 117/392 [00:20<01:00,  4.53it/s]Embedding nodes:  30%|███       | 119/392 [00:20<00:44,  6.19it/s]Embedding nodes:  31%|███       | 120/392 [00:20<00:39,  6.80it/s]Embedding nodes:  31%|███       | 121/392 [00:20<00:39,  6.85it/s]Embedding nodes:  31%|███       | 122/392 [00:20<00:43,  6.17it/s]Embedding nodes:  31%|███▏      | 123/392 [00:21<00:50,  5.36it/s]Embedding nodes:  32%|███▏      | 124/392 [00:21<00:46,  5.73it/s]Embedding nodes:  32%|███▏      | 125/392 [00:21<00:51,  5.19it/s]Embedding nodes:  32%|███▏      | 126/392 [00:21<00:49,  5.39it/s]Embedding nodes:  32%|███▏      | 127/392 [00:21<00:47,  5.63it/s]Embedding nodes:  33%|███▎      | 128/392 [00:21<00:42,  6.21it/s]Embedding nodes:  33%|███▎      | 129/392 [00:22<00:39,  6.70it/s]Embedding nodes:  33%|███▎      | 131/392 [00:22<00:30,  8.48it/s]Embedding nodes:  34%|███▍      | 133/392 [00:22<00:39,  6.51it/s]Embedding nodes:  34%|███▍      | 134/392 [00:22<00:52,  4.95it/s]Embedding nodes:  34%|███▍      | 135/392 [00:23<00:50,  5.07it/s]Embedding nodes:  35%|███▍      | 136/392 [00:23<00:44,  5.74it/s]Embedding nodes:  35%|███▍      | 137/392 [00:23<00:43,  5.87it/s]Embedding nodes:  35%|███▌      | 138/392 [00:23<00:43,  5.78it/s]Embedding nodes:  35%|███▌      | 139/392 [00:23<00:49,  5.14it/s]Embedding nodes:  36%|███▌      | 141/392 [00:24<00:40,  6.26it/s]Embedding nodes:  36%|███▌      | 142/392 [00:24<00:41,  5.98it/s]Embedding nodes:  37%|███▋      | 144/392 [00:24<00:30,  8.02it/s]Embedding nodes:  37%|███▋      | 145/392 [00:24<00:32,  7.65it/s]Embedding nodes:  37%|███▋      | 146/392 [00:24<00:36,  6.78it/s]Embedding nodes:  38%|███▊      | 147/392 [00:24<00:36,  6.74it/s]Embedding nodes:  38%|███▊      | 149/392 [00:25<00:30,  7.97it/s]Embedding nodes:  38%|███▊      | 150/392 [00:25<00:30,  7.82it/s]Embedding nodes:  39%|███▊      | 151/392 [00:25<00:31,  7.58it/s]Embedding nodes:  39%|███▉      | 152/392 [00:25<00:41,  5.75it/s]Embedding nodes:  39%|███▉      | 154/392 [00:25<00:32,  7.30it/s]Embedding nodes:  40%|███▉      | 155/392 [00:25<00:30,  7.72it/s]Embedding nodes:  40%|███▉      | 156/392 [00:26<00:30,  7.68it/s]Embedding nodes:  40%|████      | 157/392 [00:26<00:37,  6.25it/s]Embedding nodes:  41%|████      | 159/392 [00:26<00:30,  7.54it/s]Embedding nodes:  41%|████      | 161/392 [00:26<00:25,  8.96it/s]Embedding nodes:  42%|████▏     | 163/392 [00:26<00:25,  8.88it/s]Embedding nodes:  42%|████▏     | 164/392 [00:27<00:26,  8.74it/s]Embedding nodes:  42%|████▏     | 165/392 [00:27<00:30,  7.34it/s]Embedding nodes:  42%|████▏     | 166/392 [00:27<00:29,  7.78it/s]Embedding nodes:  43%|████▎     | 167/392 [00:27<00:31,  7.25it/s]Embedding nodes:  43%|████▎     | 169/392 [00:27<00:28,  7.90it/s]Embedding nodes:  43%|████▎     | 170/392 [00:27<00:27,  8.04it/s]Embedding nodes:  44%|████▍     | 172/392 [00:28<00:36,  6.06it/s]Embedding nodes:  44%|████▍     | 173/392 [00:28<00:39,  5.53it/s]Embedding nodes:  44%|████▍     | 174/392 [00:28<00:43,  5.04it/s]Embedding nodes:  45%|████▍     | 175/392 [00:29<00:53,  4.05it/s]Embedding nodes:  45%|████▍     | 176/392 [00:29<01:00,  3.54it/s]Embedding nodes:  45%|████▌     | 177/392 [00:29<00:50,  4.25it/s]Embedding nodes:  45%|████▌     | 178/392 [00:29<00:50,  4.23it/s]Embedding nodes:  46%|████▌     | 179/392 [00:30<01:00,  3.53it/s]Embedding nodes:  46%|████▌     | 180/392 [00:30<00:53,  3.94it/s]Embedding nodes:  46%|████▌     | 181/392 [00:30<00:52,  4.04it/s]Embedding nodes:  46%|████▋     | 182/392 [00:30<00:48,  4.32it/s]Embedding nodes:  47%|████▋     | 183/392 [00:31<00:40,  5.19it/s]Embedding nodes:  47%|████▋     | 184/392 [00:31<00:58,  3.54it/s]Embedding nodes:  47%|████▋     | 185/392 [00:31<01:00,  3.44it/s]Embedding nodes:  47%|████▋     | 186/392 [00:31<00:51,  3.96it/s]Embedding nodes:  48%|████▊     | 187/392 [00:32<00:46,  4.41it/s]Embedding nodes:  48%|████▊     | 188/392 [00:32<01:15,  2.71it/s]Embedding nodes:  48%|████▊     | 189/392 [00:33<01:06,  3.05it/s]Embedding nodes:  48%|████▊     | 190/392 [00:33<01:00,  3.36it/s]Embedding nodes:  49%|████▊     | 191/392 [00:33<01:06,  3.04it/s]Embedding nodes:  49%|████▉     | 192/392 [00:33<00:55,  3.59it/s]Embedding nodes:  49%|████▉     | 193/392 [00:34<01:02,  3.20it/s]Embedding nodes:  50%|████▉     | 195/392 [00:34<00:43,  4.52it/s]Embedding nodes:  50%|█████     | 196/392 [00:34<00:43,  4.47it/s]Embedding nodes:  51%|█████     | 198/392 [00:34<00:34,  5.59it/s]Embedding nodes:  51%|█████     | 199/392 [00:35<00:35,  5.41it/s]Embedding nodes:  51%|█████     | 200/392 [00:35<00:41,  4.65it/s]Embedding nodes:  52%|█████▏    | 202/392 [00:35<00:33,  5.75it/s]Embedding nodes:  52%|█████▏    | 203/392 [00:35<00:30,  6.21it/s]Embedding nodes:  52%|█████▏    | 204/392 [00:35<00:28,  6.58it/s]Embedding nodes:  53%|█████▎    | 206/392 [00:36<00:22,  8.15it/s]Embedding nodes:  53%|█████▎    | 207/392 [00:36<00:30,  6.13it/s]Embedding nodes:  53%|█████▎    | 209/392 [00:36<00:23,  7.64it/s]Embedding nodes:  54%|█████▎    | 210/392 [00:36<00:22,  8.02it/s]Embedding nodes:  54%|█████▍    | 211/392 [00:36<00:21,  8.35it/s]Embedding nodes:  54%|█████▍    | 212/392 [00:36<00:21,  8.56it/s]Embedding nodes:  54%|█████▍    | 213/392 [00:37<00:30,  5.84it/s]Embedding nodes:  55%|█████▍    | 214/392 [00:37<00:33,  5.33it/s]Embedding nodes:  55%|█████▌    | 216/392 [00:37<00:26,  6.73it/s]Embedding nodes:  55%|█████▌    | 217/392 [00:37<00:24,  7.27it/s]Embedding nodes:  56%|█████▌    | 219/392 [00:37<00:19,  8.78it/s]Embedding nodes:  56%|█████▋    | 221/392 [00:38<00:17,  9.93it/s]Embedding nodes:  57%|█████▋    | 223/392 [00:38<00:23,  7.28it/s]Embedding nodes:  57%|█████▋    | 224/392 [00:38<00:27,  6.09it/s]Embedding nodes:  57%|█████▋    | 225/392 [00:38<00:26,  6.19it/s]Embedding nodes:  58%|█████▊    | 227/392 [00:39<00:22,  7.31it/s]Embedding nodes:  58%|█████▊    | 228/392 [00:39<00:22,  7.26it/s]Embedding nodes:  58%|█████▊    | 229/392 [00:39<00:32,  5.01it/s]Embedding nodes:  59%|█████▊    | 230/392 [00:39<00:33,  4.90it/s]Embedding nodes:  59%|█████▉    | 231/392 [00:39<00:28,  5.65it/s]Embedding nodes:  59%|█████▉    | 232/392 [00:40<00:30,  5.21it/s]Embedding nodes:  59%|█████▉    | 233/392 [00:40<00:29,  5.40it/s]Embedding nodes:  60%|█████▉    | 235/392 [00:40<00:24,  6.52it/s]Embedding nodes:  60%|██████    | 237/392 [00:41<00:27,  5.62it/s]Embedding nodes:  61%|██████    | 238/392 [00:41<00:29,  5.30it/s]Embedding nodes:  61%|██████    | 239/392 [00:41<00:26,  5.71it/s]Embedding nodes:  61%|██████▏   | 241/392 [00:41<00:21,  6.92it/s]Embedding nodes:  62%|██████▏   | 243/392 [00:41<00:18,  7.85it/s]Embedding nodes:  62%|██████▏   | 244/392 [00:41<00:18,  7.94it/s]Embedding nodes:  62%|██████▎   | 245/392 [00:42<00:27,  5.27it/s]Embedding nodes:  63%|██████▎   | 246/392 [00:42<00:29,  4.91it/s]Embedding nodes:  63%|██████▎   | 247/392 [00:42<00:31,  4.67it/s]Embedding nodes:  63%|██████▎   | 248/392 [00:43<00:31,  4.62it/s]Embedding nodes:  64%|██████▍   | 250/392 [00:43<00:23,  6.12it/s]Embedding nodes:  64%|██████▍   | 251/392 [00:43<00:26,  5.27it/s]Embedding nodes:  64%|██████▍   | 252/392 [00:43<00:25,  5.44it/s]Embedding nodes:  65%|██████▍   | 254/392 [00:44<00:26,  5.23it/s]Embedding nodes:  65%|██████▌   | 255/392 [00:44<00:24,  5.64it/s]Embedding nodes:  65%|██████▌   | 256/392 [00:44<00:21,  6.28it/s]Embedding nodes:  66%|██████▌   | 258/392 [00:44<00:19,  6.77it/s]Embedding nodes:  66%|██████▌   | 259/392 [00:44<00:21,  6.12it/s]Embedding nodes:  67%|██████▋   | 261/392 [00:44<00:17,  7.33it/s]Embedding nodes:  67%|██████▋   | 262/392 [00:45<00:18,  6.97it/s]Embedding nodes:  67%|██████▋   | 263/392 [00:45<00:25,  5.03it/s]Embedding nodes:  67%|██████▋   | 264/392 [00:45<00:25,  4.99it/s]Embedding nodes:  68%|██████▊   | 265/392 [00:46<00:31,  4.00it/s]Embedding nodes:  68%|██████▊   | 267/392 [00:46<00:21,  5.72it/s]Embedding nodes:  68%|██████▊   | 268/392 [00:46<00:23,  5.17it/s]Embedding nodes:  69%|██████▊   | 269/392 [00:46<00:21,  5.67it/s]Embedding nodes:  69%|██████▉   | 270/392 [00:46<00:26,  4.59it/s]Embedding nodes:  69%|██████▉   | 271/392 [00:47<00:24,  4.87it/s]Embedding nodes:  69%|██████▉   | 272/392 [00:47<00:21,  5.60it/s]Embedding nodes:  70%|██████▉   | 273/392 [00:47<00:20,  5.88it/s]Embedding nodes:  70%|██████▉   | 274/392 [00:47<00:26,  4.45it/s]Embedding nodes:  70%|███████   | 275/392 [00:47<00:25,  4.61it/s]Embedding nodes:  70%|███████   | 276/392 [00:48<00:23,  4.99it/s]Embedding nodes:  71%|███████   | 277/392 [00:48<00:23,  4.99it/s]Embedding nodes:  71%|███████   | 279/392 [00:48<00:18,  6.06it/s]Embedding nodes:  71%|███████▏  | 280/392 [00:48<00:17,  6.28it/s]Embedding nodes:  72%|███████▏  | 281/392 [00:48<00:16,  6.70it/s]Embedding nodes:  72%|███████▏  | 282/392 [00:49<00:18,  5.85it/s]Embedding nodes:  72%|███████▏  | 283/392 [00:49<00:16,  6.59it/s]Embedding nodes:  72%|███████▏  | 284/392 [00:49<00:15,  7.18it/s]Embedding nodes:  73%|███████▎  | 285/392 [00:49<00:21,  5.04it/s]Embedding nodes:  73%|███████▎  | 286/392 [00:49<00:19,  5.35it/s]Embedding nodes:  73%|███████▎  | 288/392 [00:49<00:15,  6.84it/s]Embedding nodes:  74%|███████▎  | 289/392 [00:50<00:13,  7.39it/s]Embedding nodes:  74%|███████▍  | 290/392 [00:50<00:18,  5.58it/s]Embedding nodes:  74%|███████▍  | 291/392 [00:50<00:23,  4.25it/s]Embedding nodes:  74%|███████▍  | 292/392 [00:50<00:22,  4.47it/s]Embedding nodes:  75%|███████▍  | 293/392 [00:51<00:28,  3.43it/s]Embedding nodes:  75%|███████▌  | 294/392 [00:51<00:25,  3.81it/s]Embedding nodes:  75%|███████▌  | 295/392 [00:51<00:20,  4.64it/s]Embedding nodes:  76%|███████▌  | 297/392 [00:51<00:15,  6.29it/s]Embedding nodes:  76%|███████▌  | 298/392 [00:52<00:16,  5.67it/s]Embedding nodes:  76%|███████▋  | 299/392 [00:52<00:19,  4.70it/s]Embedding nodes:  77%|███████▋  | 300/392 [00:52<00:23,  3.84it/s]Embedding nodes:  77%|███████▋  | 301/392 [00:52<00:20,  4.49it/s]Embedding nodes:  77%|███████▋  | 302/392 [00:53<00:20,  4.39it/s]Embedding nodes:  77%|███████▋  | 303/392 [00:53<00:18,  4.69it/s]Embedding nodes:  78%|███████▊  | 304/392 [00:53<00:16,  5.44it/s]Embedding nodes:  78%|███████▊  | 306/392 [00:53<00:14,  5.88it/s]Embedding nodes:  79%|███████▊  | 308/392 [00:54<00:15,  5.29it/s]Embedding nodes:  79%|███████▉  | 309/392 [00:54<00:14,  5.78it/s]Embedding nodes:  79%|███████▉  | 310/392 [00:54<00:13,  5.96it/s]Embedding nodes:  79%|███████▉  | 311/392 [00:54<00:12,  6.43it/s]Embedding nodes:  80%|███████▉  | 312/392 [00:54<00:16,  4.91it/s]Embedding nodes:  80%|███████▉  | 313/392 [00:55<00:24,  3.22it/s]Embedding nodes:  80%|████████  | 314/392 [00:55<00:23,  3.28it/s]Embedding nodes:  80%|████████  | 315/392 [00:56<00:21,  3.59it/s]Embedding nodes:  81%|████████  | 316/392 [00:56<00:17,  4.38it/s]Embedding nodes:  81%|████████  | 317/392 [00:56<00:17,  4.26it/s]Embedding nodes:  81%|████████  | 318/392 [00:56<00:15,  4.82it/s]Embedding nodes:  81%|████████▏ | 319/392 [00:56<00:13,  5.45it/s]Embedding nodes:  82%|████████▏ | 320/392 [00:56<00:11,  6.03it/s]Embedding nodes:  82%|████████▏ | 321/392 [00:56<00:12,  5.91it/s]Embedding nodes:  82%|████████▏ | 323/392 [00:57<00:12,  5.48it/s]Embedding nodes:  83%|████████▎ | 324/392 [00:57<00:11,  5.99it/s]Embedding nodes:  83%|████████▎ | 326/392 [00:57<00:08,  7.62it/s]Embedding nodes:  83%|████████▎ | 327/392 [00:57<00:08,  7.24it/s]Embedding nodes:  84%|████████▍ | 329/392 [00:58<00:11,  5.59it/s]Embedding nodes:  84%|████████▍ | 330/392 [00:58<00:10,  5.92it/s]Embedding nodes:  85%|████████▍ | 332/392 [00:58<00:10,  5.82it/s]Embedding nodes:  85%|████████▍ | 333/392 [00:59<00:14,  3.97it/s]Embedding nodes:  85%|████████▌ | 334/392 [00:59<00:20,  2.90it/s]Embedding nodes:  85%|████████▌ | 335/392 [01:00<00:18,  3.15it/s]Embedding nodes:  86%|████████▌ | 336/392 [01:00<00:16,  3.35it/s]Embedding nodes:  86%|████████▌ | 337/392 [01:01<00:23,  2.34it/s]Embedding nodes:  86%|████████▌ | 338/392 [01:01<00:18,  2.88it/s]Embedding nodes:  86%|████████▋ | 339/392 [01:01<00:15,  3.50it/s]Embedding nodes:  87%|████████▋ | 341/392 [01:01<00:11,  4.34it/s]Embedding nodes:  88%|████████▊ | 343/392 [01:01<00:08,  5.59it/s]Embedding nodes:  88%|████████▊ | 345/392 [01:02<00:07,  6.58it/s]Embedding nodes:  89%|████████▊ | 347/392 [01:02<00:05,  8.24it/s]Embedding nodes:  89%|████████▉ | 349/392 [01:02<00:05,  8.06it/s]Embedding nodes:  89%|████████▉ | 350/392 [01:02<00:05,  7.45it/s]Embedding nodes:  90%|████████▉ | 351/392 [01:03<00:07,  5.25it/s]Embedding nodes:  90%|████████▉ | 352/392 [01:03<00:06,  5.78it/s]Embedding nodes:  90%|█████████ | 353/392 [01:03<00:07,  5.29it/s]Embedding nodes:  91%|█████████ | 355/392 [01:03<00:06,  5.83it/s]Embedding nodes:  91%|█████████ | 356/392 [01:04<00:06,  5.59it/s]Embedding nodes:  91%|█████████ | 357/392 [01:04<00:05,  5.95it/s]Embedding nodes:  91%|█████████▏| 358/392 [01:04<00:07,  4.42it/s]Embedding nodes:  92%|█████████▏| 359/392 [01:04<00:09,  3.65it/s]Embedding nodes:  92%|█████████▏| 361/392 [01:05<00:06,  5.12it/s]Embedding nodes:  92%|█████████▏| 362/392 [01:05<00:07,  4.07it/s]Embedding nodes:  93%|█████████▎| 363/392 [01:05<00:06,  4.33it/s]Embedding nodes:  93%|█████████▎| 365/392 [01:05<00:04,  5.55it/s]Embedding nodes:  93%|█████████▎| 366/392 [01:06<00:04,  5.40it/s]Embedding nodes:  94%|█████████▍| 368/392 [01:06<00:04,  4.89it/s]Embedding nodes:  94%|█████████▍| 369/392 [01:06<00:04,  5.42it/s]Embedding nodes:  94%|█████████▍| 370/392 [01:06<00:03,  5.66it/s]Embedding nodes:  95%|█████████▍| 371/392 [01:06<00:03,  6.28it/s]Embedding nodes:  95%|█████████▍| 372/392 [01:07<00:03,  5.88it/s]Embedding nodes:  95%|█████████▌| 374/392 [01:07<00:02,  6.62it/s]Embedding nodes:  96%|█████████▌| 375/392 [01:07<00:02,  6.09it/s]Embedding nodes:  96%|█████████▌| 376/392 [01:07<00:02,  6.27it/s]Embedding nodes:  96%|█████████▌| 377/392 [01:07<00:02,  6.80it/s]Embedding nodes:  96%|█████████▋| 378/392 [01:08<00:01,  7.37it/s]Embedding nodes:  97%|█████████▋| 379/392 [01:08<00:01,  7.89it/s]Embedding nodes:  97%|█████████▋| 380/392 [01:08<00:01,  6.23it/s]Embedding nodes:  97%|█████████▋| 381/392 [01:08<00:01,  5.54it/s]Embedding nodes:  97%|█████████▋| 382/392 [01:08<00:01,  5.88it/s]Embedding nodes:  98%|█████████▊| 384/392 [01:08<00:01,  6.80it/s]Embedding nodes:  98%|█████████▊| 385/392 [01:09<00:01,  6.18it/s]Embedding nodes:  98%|█████████▊| 386/392 [01:09<00:01,  4.50it/s]Embedding nodes:  99%|█████████▉| 388/392 [01:09<00:00,  6.41it/s]Embedding nodes:  99%|█████████▉| 389/392 [01:09<00:00,  5.39it/s]Embedding nodes: 100%|█████████▉| 391/392 [01:10<00:00,  6.71it/s]Embedding nodes: 100%|██████████| 392/392 [01:10<00:00,  5.58it/s]
/home/maxl/dev/wiki-connect/.venv/lib/python3.12/site-packages/torch_geometric/utils/convert.py:278: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)
  data_dict[key] = torch.as_tensor(value)
Data saved to data/deep_learning_graph.pt



Training with hidden_channels=32, out_channels=32, lr=0.01
Epoch: 10, Loss: 0.6067, Val AUC: 0.8495, Val AP: 0.8732, Val P: 0.6144
Epoch: 20, Loss: 0.4746, Val AUC: 0.8843, Val AP: 0.9026, Val P: 0.8340
Epoch: 30, Loss: 0.3970, Val AUC: 0.9142, Val AP: 0.9240, Val P: 0.8808
Epoch: 40, Loss: 0.3261, Val AUC: 0.9404, Val AP: 0.9440, Val P: 0.8801
Epoch: 50, Loss: 0.2866, Val AUC: 0.9535, Val AP: 0.9600, Val P: 0.9465
Epoch: 60, Loss: 0.2658, Val AUC: 0.9544, Val AP: 0.9602, Val P: 0.9468
Epoch: 70, Loss: 0.2575, Val AUC: 0.9542, Val AP: 0.9549, Val P: 0.9010
Epoch: 80, Loss: 0.2422, Val AUC: 0.9515, Val AP: 0.9576, Val P: 0.9320
Epoch: 90, Loss: 0.2625, Val AUC: 0.9523, Val AP: 0.9543, Val P: 0.8688
Epoch: 100, Loss: 0.2463, Val AUC: 0.9558, Val AP: 0.9617, Val P: 0.8876
Epoch: 110, Loss: 0.2355, Val AUC: 0.9574, Val AP: 0.9639, Val P: 0.9476
Epoch: 120, Loss: 0.2216, Val AUC: 0.9626, Val AP: 0.9662, Val P: 0.8969
Epoch: 130, Loss: 0.2304, Val AUC: 0.9610, Val AP: 0.9666, Val P: 0.9343
Epoch: 140, Loss: 0.2347, Val AUC: 0.9630, Val AP: 0.9676, Val P: 0.9331
Epoch: 150, Loss: 0.2160, Val AUC: 0.9628, Val AP: 0.9670, Val P: 0.9278
Epoch: 160, Loss: 0.2106, Val AUC: 0.9621, Val AP: 0.9666, Val P: 0.9248
Epoch: 170, Loss: 0.2192, Val AUC: 0.9644, Val AP: 0.9693, Val P: 0.9320
Epoch: 180, Loss: 0.2156, Val AUC: 0.9611, Val AP: 0.9667, Val P: 0.9048
Epoch: 190, Loss: 0.2192, Val AUC: 0.9630, Val AP: 0.9682, Val P: 0.9314
Epoch: 200, Loss: 0.2156, Val AUC: 0.9637, Val AP: 0.9686, Val P: 0.8805
Test AUC: 0.9644, Test AP: 0.9715, Test P: 0.8736
Finished training with hidden_channels=32, out_channels=32, lr=0.01



Training with hidden_channels=32, out_channels=32, lr=0.001
Epoch: 10, Loss: 0.6680, Val AUC: 0.8592, Val AP: 0.8673, Val P: 0.5000
Epoch: 20, Loss: 0.6233, Val AUC: 0.8596, Val AP: 0.8856, Val P: 0.6097
Epoch: 30, Loss: 0.5444, Val AUC: 0.8273, Val AP: 0.8689, Val P: 0.7653
Epoch: 40, Loss: 0.5171, Val AUC: 0.8511, Val AP: 0.8867, Val P: 0.7561
Epoch: 50, Loss: 0.4666, Val AUC: 0.8730, Val AP: 0.8976, Val P: 0.8256
Epoch: 60, Loss: 0.4210, Val AUC: 0.8981, Val AP: 0.9125, Val P: 0.8644
Epoch: 70, Loss: 0.3797, Val AUC: 0.9077, Val AP: 0.9164, Val P: 0.8979
Epoch: 80, Loss: 0.3783, Val AUC: 0.9052, Val AP: 0.9184, Val P: 0.9016
Epoch: 90, Loss: 0.3588, Val AUC: 0.9132, Val AP: 0.9205, Val P: 0.8864
Epoch: 100, Loss: 0.3442, Val AUC: 0.9201, Val AP: 0.9240, Val P: 0.8845
Epoch: 110, Loss: 0.3414, Val AUC: 0.9219, Val AP: 0.9264, Val P: 0.8601
Epoch: 120, Loss: 0.3226, Val AUC: 0.9281, Val AP: 0.9315, Val P: 0.8574
Epoch: 130, Loss: 0.3031, Val AUC: 0.9314, Val AP: 0.9361, Val P: 0.8580
Epoch: 140, Loss: 0.2924, Val AUC: 0.9381, Val AP: 0.9436, Val P: 0.9127
Epoch: 150, Loss: 0.2647, Val AUC: 0.9483, Val AP: 0.9511, Val P: 0.8957
Epoch: 160, Loss: 0.2522, Val AUC: 0.9531, Val AP: 0.9583, Val P: 0.9251
Epoch: 170, Loss: 0.2328, Val AUC: 0.9565, Val AP: 0.9591, Val P: 0.9138
Epoch: 180, Loss: 0.2412, Val AUC: 0.9569, Val AP: 0.9591, Val P: 0.9016
Epoch: 190, Loss: 0.2275, Val AUC: 0.9577, Val AP: 0.9599, Val P: 0.9100
Epoch: 200, Loss: 0.2179, Val AUC: 0.9580, Val AP: 0.9622, Val P: 0.9239
Test AUC: 0.9495, Test AP: 0.9494, Test P: 0.9214
Finished training with hidden_channels=32, out_channels=32, lr=0.001



Training with hidden_channels=32, out_channels=64, lr=0.01
Epoch: 10, Loss: 0.5757, Val AUC: 0.8054, Val AP: 0.8557, Val P: 0.8115
Epoch: 20, Loss: 0.4162, Val AUC: 0.8926, Val AP: 0.9092, Val P: 0.9213
Epoch: 30, Loss: 0.3678, Val AUC: 0.9145, Val AP: 0.9219, Val P: 0.8916
Epoch: 40, Loss: 0.3512, Val AUC: 0.9211, Val AP: 0.9278, Val P: 0.8586
Epoch: 50, Loss: 0.3298, Val AUC: 0.9241, Val AP: 0.9314, Val P: 0.9122
Epoch: 60, Loss: 0.3140, Val AUC: 0.9280, Val AP: 0.9396, Val P: 0.9508
Epoch: 70, Loss: 0.3040, Val AUC: 0.9367, Val AP: 0.9473, Val P: 0.9693
Epoch: 80, Loss: 0.2869, Val AUC: 0.9467, Val AP: 0.9552, Val P: 0.9593
Epoch: 90, Loss: 0.2717, Val AUC: 0.9560, Val AP: 0.9624, Val P: 0.9549
Epoch: 100, Loss: 0.2814, Val AUC: 0.9585, Val AP: 0.9641, Val P: 0.9263
Epoch: 110, Loss: 0.2632, Val AUC: 0.9604, Val AP: 0.9653, Val P: 0.9117
Epoch: 120, Loss: 0.2739, Val AUC: 0.9608, Val AP: 0.9642, Val P: 0.9264
Epoch: 130, Loss: 0.2615, Val AUC: 0.9667, Val AP: 0.9710, Val P: 0.9596
Epoch: 140, Loss: 0.2477, Val AUC: 0.9671, Val AP: 0.9713, Val P: 0.9487
Epoch: 150, Loss: 0.2512, Val AUC: 0.9672, Val AP: 0.9701, Val P: 0.9343
Epoch: 160, Loss: 0.2410, Val AUC: 0.9675, Val AP: 0.9717, Val P: 0.9599
Epoch: 170, Loss: 0.2480, Val AUC: 0.9674, Val AP: 0.9709, Val P: 0.9539
Epoch: 180, Loss: 0.2314, Val AUC: 0.9695, Val AP: 0.9715, Val P: 0.9547
Epoch: 190, Loss: 0.2415, Val AUC: 0.9672, Val AP: 0.9703, Val P: 0.9262
Epoch: 200, Loss: 0.2326, Val AUC: 0.9674, Val AP: 0.9706, Val P: 0.9500
Test AUC: 0.9601, Test AP: 0.9658, Test P: 0.9214
Finished training with hidden_channels=32, out_channels=64, lr=0.01



Training with hidden_channels=32, out_channels=64, lr=0.001
Epoch: 10, Loss: 0.6645, Val AUC: 0.8718, Val AP: 0.8873, Val P: 0.5025
Epoch: 20, Loss: 0.5934, Val AUC: 0.8690, Val AP: 0.8991, Val P: 0.6802
Epoch: 30, Loss: 0.5485, Val AUC: 0.8664, Val AP: 0.9019, Val P: 0.7478
Epoch: 40, Loss: 0.5097, Val AUC: 0.8749, Val AP: 0.9063, Val P: 0.7866
Epoch: 50, Loss: 0.4712, Val AUC: 0.8859, Val AP: 0.9121, Val P: 0.8940
Epoch: 60, Loss: 0.4429, Val AUC: 0.8998, Val AP: 0.9229, Val P: 0.8913
Epoch: 70, Loss: 0.4044, Val AUC: 0.9046, Val AP: 0.9267, Val P: 0.9240
Epoch: 80, Loss: 0.3842, Val AUC: 0.9110, Val AP: 0.9305, Val P: 0.9184
Epoch: 90, Loss: 0.3773, Val AUC: 0.9155, Val AP: 0.9308, Val P: 0.9113
Epoch: 100, Loss: 0.3662, Val AUC: 0.9201, Val AP: 0.9320, Val P: 0.8961
Epoch: 110, Loss: 0.3539, Val AUC: 0.9234, Val AP: 0.9343, Val P: 0.9006
Epoch: 120, Loss: 0.3350, Val AUC: 0.9280, Val AP: 0.9384, Val P: 0.9178
Epoch: 130, Loss: 0.3246, Val AUC: 0.9350, Val AP: 0.9438, Val P: 0.9056
Epoch: 140, Loss: 0.2962, Val AUC: 0.9416, Val AP: 0.9499, Val P: 0.9062
Epoch: 150, Loss: 0.2871, Val AUC: 0.9461, Val AP: 0.9543, Val P: 0.9376
Epoch: 160, Loss: 0.2715, Val AUC: 0.9516, Val AP: 0.9609, Val P: 0.9284
Epoch: 170, Loss: 0.2714, Val AUC: 0.9530, Val AP: 0.9630, Val P: 0.9267
Epoch: 180, Loss: 0.2358, Val AUC: 0.9545, Val AP: 0.9643, Val P: 0.9106
Epoch: 190, Loss: 0.2255, Val AUC: 0.9549, Val AP: 0.9644, Val P: 0.9267
Epoch: 200, Loss: 0.2147, Val AUC: 0.9545, Val AP: 0.9643, Val P: 0.9418
Test AUC: 0.9525, Test AP: 0.9577, Test P: 0.9277
Finished training with hidden_channels=32, out_channels=64, lr=0.001



Training with hidden_channels=64, out_channels=32, lr=0.01
Epoch: 10, Loss: 0.5817, Val AUC: 0.8346, Val AP: 0.8791, Val P: 0.7393
Epoch: 20, Loss: 0.4998, Val AUC: 0.8912, Val AP: 0.9113, Val P: 0.9048
Epoch: 30, Loss: 0.3853, Val AUC: 0.9286, Val AP: 0.9374, Val P: 0.9007
Epoch: 40, Loss: 0.3388, Val AUC: 0.9375, Val AP: 0.9440, Val P: 0.9136
Epoch: 50, Loss: 0.3247, Val AUC: 0.9440, Val AP: 0.9499, Val P: 0.9017
Epoch: 60, Loss: 0.2993, Val AUC: 0.9511, Val AP: 0.9563, Val P: 0.9172
Epoch: 70, Loss: 0.2906, Val AUC: 0.9588, Val AP: 0.9636, Val P: 0.9552
Epoch: 80, Loss: 0.2667, Val AUC: 0.9652, Val AP: 0.9694, Val P: 0.9205
Epoch: 90, Loss: 0.2472, Val AUC: 0.9727, Val AP: 0.9766, Val P: 0.9343
Epoch: 100, Loss: 0.2322, Val AUC: 0.9736, Val AP: 0.9777, Val P: 0.9554
Epoch: 110, Loss: 0.2130, Val AUC: 0.9747, Val AP: 0.9784, Val P: 0.9143
Epoch: 120, Loss: 0.2114, Val AUC: 0.9759, Val AP: 0.9793, Val P: 0.9354
Epoch: 130, Loss: 0.2035, Val AUC: 0.9768, Val AP: 0.9797, Val P: 0.9686
Epoch: 140, Loss: 0.2229, Val AUC: 0.9770, Val AP: 0.9801, Val P: 0.9531
Epoch: 150, Loss: 0.1931, Val AUC: 0.9775, Val AP: 0.9799, Val P: 0.9269
Epoch: 160, Loss: 0.2037, Val AUC: 0.9776, Val AP: 0.9809, Val P: 0.9731
Epoch: 170, Loss: 0.1879, Val AUC: 0.9789, Val AP: 0.9815, Val P: 0.9451
Epoch: 180, Loss: 0.1841, Val AUC: 0.9782, Val AP: 0.9810, Val P: 0.9447
Epoch: 190, Loss: 0.1811, Val AUC: 0.9787, Val AP: 0.9812, Val P: 0.9512
Epoch: 200, Loss: 0.1829, Val AUC: 0.9765, Val AP: 0.9796, Val P: 0.9711
Test AUC: 0.9535, Test AP: 0.9641, Test P: 0.9469
Finished training with hidden_channels=64, out_channels=32, lr=0.01



Training with hidden_channels=64, out_channels=32, lr=0.001
Epoch: 10, Loss: 0.6690, Val AUC: 0.8412, Val AP: 0.8694, Val P: 0.5000
Epoch: 20, Loss: 0.5954, Val AUC: 0.8417, Val AP: 0.8784, Val P: 0.6528
Epoch: 30, Loss: 0.5401, Val AUC: 0.8380, Val AP: 0.8828, Val P: 0.7948
Epoch: 40, Loss: 0.4860, Val AUC: 0.8697, Val AP: 0.8998, Val P: 0.8419
Epoch: 50, Loss: 0.4334, Val AUC: 0.8962, Val AP: 0.9126, Val P: 0.8806
Epoch: 60, Loss: 0.3952, Val AUC: 0.9102, Val AP: 0.9191, Val P: 0.8869
Epoch: 70, Loss: 0.3755, Val AUC: 0.9158, Val AP: 0.9211, Val P: 0.8715
Epoch: 80, Loss: 0.3717, Val AUC: 0.9173, Val AP: 0.9216, Val P: 0.8852
Epoch: 90, Loss: 0.3474, Val AUC: 0.9202, Val AP: 0.9240, Val P: 0.8802
Epoch: 100, Loss: 0.3448, Val AUC: 0.9249, Val AP: 0.9292, Val P: 0.8763
Epoch: 110, Loss: 0.3298, Val AUC: 0.9285, Val AP: 0.9342, Val P: 0.8750
Epoch: 120, Loss: 0.3250, Val AUC: 0.9322, Val AP: 0.9360, Val P: 0.9038
Epoch: 130, Loss: 0.3046, Val AUC: 0.9404, Val AP: 0.9479, Val P: 0.8941
Epoch: 140, Loss: 0.2657, Val AUC: 0.9463, Val AP: 0.9512, Val P: 0.8765
Epoch: 150, Loss: 0.2478, Val AUC: 0.9529, Val AP: 0.9573, Val P: 0.8988
Epoch: 160, Loss: 0.2286, Val AUC: 0.9553, Val AP: 0.9600, Val P: 0.9078
Epoch: 170, Loss: 0.2201, Val AUC: 0.9548, Val AP: 0.9607, Val P: 0.8858
Epoch: 180, Loss: 0.2147, Val AUC: 0.9563, Val AP: 0.9642, Val P: 0.9129
Epoch: 190, Loss: 0.2093, Val AUC: 0.9543, Val AP: 0.9603, Val P: 0.9089
Epoch: 200, Loss: 0.2006, Val AUC: 0.9553, Val AP: 0.9633, Val P: 0.9065
Test AUC: 0.9616, Test AP: 0.9680, Test P: 0.9292
Finished training with hidden_channels=64, out_channels=32, lr=0.001



Training with hidden_channels=64, out_channels=64, lr=0.01
Epoch: 10, Loss: 0.6542, Val AUC: 0.8123, Val AP: 0.8218, Val P: 0.7644
Epoch: 20, Loss: 0.5821, Val AUC: 0.8519, Val AP: 0.8835, Val P: 0.7550
Epoch: 30, Loss: 0.4456, Val AUC: 0.9037, Val AP: 0.9180, Val P: 0.9104
Epoch: 40, Loss: 0.3817, Val AUC: 0.9170, Val AP: 0.9213, Val P: 0.9361
Epoch: 50, Loss: 0.3423, Val AUC: 0.9305, Val AP: 0.9357, Val P: 0.9195
Epoch: 60, Loss: 0.3269, Val AUC: 0.9380, Val AP: 0.9395, Val P: 0.9281
Epoch: 70, Loss: 0.2946, Val AUC: 0.9580, Val AP: 0.9582, Val P: 0.8566
Epoch: 80, Loss: 0.2787, Val AUC: 0.9612, Val AP: 0.9629, Val P: 0.9353
Epoch: 90, Loss: 0.2769, Val AUC: 0.9625, Val AP: 0.9646, Val P: 0.8967
Epoch: 100, Loss: 0.2405, Val AUC: 0.9634, Val AP: 0.9647, Val P: 0.9311
Epoch: 110, Loss: 0.2320, Val AUC: 0.9618, Val AP: 0.9625, Val P: 0.9305
Epoch: 120, Loss: 0.2415, Val AUC: 0.9652, Val AP: 0.9653, Val P: 0.8734
Epoch: 130, Loss: 0.2451, Val AUC: 0.9650, Val AP: 0.9667, Val P: 0.9465
Epoch: 140, Loss: 0.2387, Val AUC: 0.9666, Val AP: 0.9644, Val P: 0.8790
Epoch: 150, Loss: 0.2222, Val AUC: 0.9660, Val AP: 0.9624, Val P: 0.8984
Epoch: 160, Loss: 0.2188, Val AUC: 0.9660, Val AP: 0.9608, Val P: 0.9474
Epoch: 170, Loss: 0.2159, Val AUC: 0.9649, Val AP: 0.9595, Val P: 0.9287
Epoch: 180, Loss: 0.2089, Val AUC: 0.9653, Val AP: 0.9602, Val P: 0.9482
Epoch: 190, Loss: 0.2112, Val AUC: 0.9645, Val AP: 0.9598, Val P: 0.9002
Epoch: 200, Loss: 0.2112, Val AUC: 0.9666, Val AP: 0.9607, Val P: 0.8755
Test AUC: 0.9626, Test AP: 0.9687, Test P: 0.8931
Finished training with hidden_channels=64, out_channels=64, lr=0.01



Training with hidden_channels=64, out_channels=64, lr=0.001
Epoch: 10, Loss: 0.6612, Val AUC: 0.8416, Val AP: 0.8484, Val P: 0.5000
Epoch: 20, Loss: 0.5967, Val AUC: 0.8319, Val AP: 0.8614, Val P: 0.7203
Epoch: 30, Loss: 0.5544, Val AUC: 0.8406, Val AP: 0.8808, Val P: 0.7361
Epoch: 40, Loss: 0.5068, Val AUC: 0.8546, Val AP: 0.8934, Val P: 0.8036
Epoch: 50, Loss: 0.4506, Val AUC: 0.8769, Val AP: 0.9047, Val P: 0.8837
Epoch: 60, Loss: 0.3962, Val AUC: 0.8992, Val AP: 0.9187, Val P: 0.9163
Epoch: 70, Loss: 0.3710, Val AUC: 0.9061, Val AP: 0.9207, Val P: 0.9252
Epoch: 80, Loss: 0.3546, Val AUC: 0.9098, Val AP: 0.9221, Val P: 0.9289
Epoch: 90, Loss: 0.3441, Val AUC: 0.9170, Val AP: 0.9233, Val P: 0.9097
Epoch: 100, Loss: 0.3236, Val AUC: 0.9201, Val AP: 0.9266, Val P: 0.9178
Epoch: 110, Loss: 0.3173, Val AUC: 0.9274, Val AP: 0.9314, Val P: 0.9187
Epoch: 120, Loss: 0.3047, Val AUC: 0.9370, Val AP: 0.9465, Val P: 0.9226
Epoch: 130, Loss: 0.2707, Val AUC: 0.9477, Val AP: 0.9568, Val P: 0.9131
Epoch: 140, Loss: 0.2627, Val AUC: 0.9553, Val AP: 0.9633, Val P: 0.9039
Epoch: 150, Loss: 0.2375, Val AUC: 0.9614, Val AP: 0.9684, Val P: 0.9150
Epoch: 160, Loss: 0.2306, Val AUC: 0.9622, Val AP: 0.9689, Val P: 0.9095
Epoch: 170, Loss: 0.2118, Val AUC: 0.9633, Val AP: 0.9696, Val P: 0.9162
Epoch: 180, Loss: 0.2142, Val AUC: 0.9626, Val AP: 0.9692, Val P: 0.9268
Epoch: 190, Loss: 0.2024, Val AUC: 0.9617, Val AP: 0.9686, Val P: 0.9493
Epoch: 200, Loss: 0.1986, Val AUC: 0.9631, Val AP: 0.9697, Val P: 0.9252
Test AUC: 0.9632, Test AP: 0.9601, Test P: 0.9306
Finished training with hidden_channels=64, out_channels=64, lr=0.001



Training with hidden_channels=128, out_channels=32, lr=0.01
Epoch: 10, Loss: 0.6583, Val AUC: 0.8440, Val AP: 0.8602, Val P: 0.7491
Epoch: 20, Loss: 0.5452, Val AUC: 0.8645, Val AP: 0.8914, Val P: 0.7921
Epoch: 30, Loss: 0.4311, Val AUC: 0.9165, Val AP: 0.9251, Val P: 0.8811
Epoch: 40, Loss: 0.3757, Val AUC: 0.9238, Val AP: 0.9293, Val P: 0.8967
Epoch: 50, Loss: 0.3585, Val AUC: 0.9296, Val AP: 0.9375, Val P: 0.9002
Epoch: 60, Loss: 0.3386, Val AUC: 0.9323, Val AP: 0.9402, Val P: 0.9067
Epoch: 70, Loss: 0.3262, Val AUC: 0.9357, Val AP: 0.9414, Val P: 0.9019
Epoch: 80, Loss: 0.3202, Val AUC: 0.9382, Val AP: 0.9430, Val P: 0.9114
Epoch: 90, Loss: 0.3093, Val AUC: 0.9401, Val AP: 0.9451, Val P: 0.9029
Epoch: 100, Loss: 0.2916, Val AUC: 0.9401, Val AP: 0.9455, Val P: 0.8984
Epoch: 110, Loss: 0.2632, Val AUC: 0.9427, Val AP: 0.9496, Val P: 0.8968
Epoch: 120, Loss: 0.2778, Val AUC: 0.9442, Val AP: 0.9545, Val P: 0.8947
Epoch: 130, Loss: 0.2598, Val AUC: 0.9452, Val AP: 0.9535, Val P: 0.8982
Epoch: 140, Loss: 0.2369, Val AUC: 0.9464, Val AP: 0.9548, Val P: 0.9201
Epoch: 150, Loss: 0.2471, Val AUC: 0.9533, Val AP: 0.9609, Val P: 0.9346
Epoch: 160, Loss: 0.2454, Val AUC: 0.9541, Val AP: 0.9610, Val P: 0.9165
Epoch: 170, Loss: 0.2336, Val AUC: 0.9559, Val AP: 0.9623, Val P: 0.9289
Epoch: 180, Loss: 0.1996, Val AUC: 0.9578, Val AP: 0.9646, Val P: 0.9358
Epoch: 190, Loss: 0.1977, Val AUC: 0.9585, Val AP: 0.9666, Val P: 0.9387
Epoch: 200, Loss: 0.1885, Val AUC: 0.9554, Val AP: 0.9604, Val P: 0.8959
Test AUC: 0.9535, Test AP: 0.9613, Test P: 0.9250
Finished training with hidden_channels=128, out_channels=32, lr=0.01



Training with hidden_channels=128, out_channels=32, lr=0.001
Epoch: 10, Loss: 0.6572, Val AUC: 0.8597, Val AP: 0.8917, Val P: 0.5785
Epoch: 20, Loss: 0.5668, Val AUC: 0.8285, Val AP: 0.8688, Val P: 0.7604
Epoch: 30, Loss: 0.5061, Val AUC: 0.8418, Val AP: 0.8761, Val P: 0.8348
Epoch: 40, Loss: 0.4525, Val AUC: 0.8669, Val AP: 0.8909, Val P: 0.8842
Epoch: 50, Loss: 0.4120, Val AUC: 0.8851, Val AP: 0.9032, Val P: 0.8847
Epoch: 60, Loss: 0.3913, Val AUC: 0.8914, Val AP: 0.9082, Val P: 0.8830
Epoch: 70, Loss: 0.3664, Val AUC: 0.8931, Val AP: 0.9097, Val P: 0.8957
Epoch: 80, Loss: 0.3649, Val AUC: 0.9001, Val AP: 0.9152, Val P: 0.8846
Epoch: 90, Loss: 0.3418, Val AUC: 0.9043, Val AP: 0.9189, Val P: 0.8833
Epoch: 100, Loss: 0.3411, Val AUC: 0.9087, Val AP: 0.9258, Val P: 0.8726
Epoch: 110, Loss: 0.3293, Val AUC: 0.9136, Val AP: 0.9315, Val P: 0.8834
Epoch: 120, Loss: 0.3070, Val AUC: 0.9214, Val AP: 0.9394, Val P: 0.9212
Epoch: 130, Loss: 0.2789, Val AUC: 0.9329, Val AP: 0.9490, Val P: 0.9580
Epoch: 140, Loss: 0.2544, Val AUC: 0.9443, Val AP: 0.9573, Val P: 0.9357
Epoch: 150, Loss: 0.2433, Val AUC: 0.9496, Val AP: 0.9612, Val P: 0.9262
Epoch: 160, Loss: 0.2254, Val AUC: 0.9496, Val AP: 0.9612, Val P: 0.9367
Epoch: 170, Loss: 0.2183, Val AUC: 0.9511, Val AP: 0.9621, Val P: 0.9309
Epoch: 180, Loss: 0.2108, Val AUC: 0.9555, Val AP: 0.9657, Val P: 0.9082
Epoch: 190, Loss: 0.2118, Val AUC: 0.9549, Val AP: 0.9651, Val P: 0.9389
Epoch: 200, Loss: 0.1994, Val AUC: 0.9533, Val AP: 0.9641, Val P: 0.9536
Test AUC: 0.9559, Test AP: 0.9672, Test P: 0.9248
Finished training with hidden_channels=128, out_channels=32, lr=0.001



Training with hidden_channels=128, out_channels=64, lr=0.01
Epoch: 10, Loss: 0.6327, Val AUC: 0.8213, Val AP: 0.8643, Val P: 0.5956
Epoch: 20, Loss: 0.5698, Val AUC: 0.8279, Val AP: 0.8746, Val P: 0.7480
Epoch: 30, Loss: 0.4324, Val AUC: 0.9089, Val AP: 0.9254, Val P: 0.9407
Epoch: 40, Loss: 0.3739, Val AUC: 0.9220, Val AP: 0.9335, Val P: 0.9178
Epoch: 50, Loss: 0.3226, Val AUC: 0.9285, Val AP: 0.9340, Val P: 0.9114
Epoch: 60, Loss: 0.2996, Val AUC: 0.9308, Val AP: 0.9265, Val P: 0.8522
Epoch: 70, Loss: 0.2874, Val AUC: 0.9418, Val AP: 0.9488, Val P: 0.9335
Epoch: 80, Loss: 0.2593, Val AUC: 0.9460, Val AP: 0.9543, Val P: 0.9667
Epoch: 90, Loss: 0.2465, Val AUC: 0.9450, Val AP: 0.9547, Val P: 0.9570
Epoch: 100, Loss: 0.2446, Val AUC: 0.9553, Val AP: 0.9629, Val P: 0.9485
Epoch: 110, Loss: 0.2349, Val AUC: 0.9570, Val AP: 0.9639, Val P: 0.9219
Epoch: 120, Loss: 0.2381, Val AUC: 0.9535, Val AP: 0.9613, Val P: 0.9249
Epoch: 130, Loss: 0.2121, Val AUC: 0.9535, Val AP: 0.9605, Val P: 0.9388
Epoch: 140, Loss: 0.2174, Val AUC: 0.9578, Val AP: 0.9643, Val P: 0.9465
Epoch: 150, Loss: 0.2038, Val AUC: 0.9592, Val AP: 0.9660, Val P: 0.9400
Epoch: 160, Loss: 0.2044, Val AUC: 0.9603, Val AP: 0.9661, Val P: 0.9022
Epoch: 170, Loss: 0.2106, Val AUC: 0.9595, Val AP: 0.9656, Val P: 0.9289
Epoch: 180, Loss: 0.2017, Val AUC: 0.9589, Val AP: 0.9644, Val P: 0.9400
Epoch: 190, Loss: 0.1963, Val AUC: 0.9606, Val AP: 0.9663, Val P: 0.8876
Epoch: 200, Loss: 0.2085, Val AUC: 0.9609, Val AP: 0.9667, Val P: 0.9429
Test AUC: 0.9495, Test AP: 0.9554, Test P: 0.9229
Finished training with hidden_channels=128, out_channels=64, lr=0.01



Training with hidden_channels=128, out_channels=64, lr=0.001
Epoch: 10, Loss: 0.6384, Val AUC: 0.8252, Val AP: 0.8477, Val P: 0.5822
Epoch: 20, Loss: 0.5384, Val AUC: 0.8056, Val AP: 0.8459, Val P: 0.7900
Epoch: 30, Loss: 0.5003, Val AUC: 0.8324, Val AP: 0.8650, Val P: 0.7903
Epoch: 40, Loss: 0.4633, Val AUC: 0.8423, Val AP: 0.8669, Val P: 0.8844
Epoch: 50, Loss: 0.4284, Val AUC: 0.8711, Val AP: 0.8921, Val P: 0.8584
Epoch: 60, Loss: 0.3982, Val AUC: 0.8763, Val AP: 0.8953, Val P: 0.8826
Epoch: 70, Loss: 0.3832, Val AUC: 0.8825, Val AP: 0.8978, Val P: 0.8650
Epoch: 80, Loss: 0.3744, Val AUC: 0.8865, Val AP: 0.9001, Val P: 0.8591
Epoch: 90, Loss: 0.3671, Val AUC: 0.8901, Val AP: 0.8971, Val P: 0.8688
Epoch: 100, Loss: 0.3541, Val AUC: 0.8942, Val AP: 0.9016, Val P: 0.8805
Epoch: 110, Loss: 0.3557, Val AUC: 0.8995, Val AP: 0.9056, Val P: 0.8789
Epoch: 120, Loss: 0.3398, Val AUC: 0.9043, Val AP: 0.9121, Val P: 0.8831
Epoch: 130, Loss: 0.3281, Val AUC: 0.9090, Val AP: 0.9171, Val P: 0.8896
Epoch: 140, Loss: 0.3062, Val AUC: 0.9188, Val AP: 0.9270, Val P: 0.8935
Epoch: 150, Loss: 0.2879, Val AUC: 0.9296, Val AP: 0.9363, Val P: 0.9148
Epoch: 160, Loss: 0.2592, Val AUC: 0.9372, Val AP: 0.9471, Val P: 0.9531
Epoch: 170, Loss: 0.2462, Val AUC: 0.9439, Val AP: 0.9525, Val P: 0.8990
Epoch: 180, Loss: 0.2355, Val AUC: 0.9467, Val AP: 0.9548, Val P: 0.8980
Epoch: 190, Loss: 0.2227, Val AUC: 0.9496, Val AP: 0.9582, Val P: 0.9022
Epoch: 200, Loss: 0.2121, Val AUC: 0.9509, Val AP: 0.9590, Val P: 0.8970
Test AUC: 0.9629, Test AP: 0.9647, Test P: 0.9135
Finished training with hidden_channels=128, out_channels=64, lr=0.001
/home/maxl/dev/wiki-connect/src/wiki_connect/model/inference.py:199: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  graph_data = torch.load(args.graph_path)
/home/maxl/dev/wiki-connect/src/wiki_connect/model/inference.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.encoder.load_state_dict(torch.load(
/home/maxl/dev/wiki-connect/src/wiki_connect/model/inference.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.predictor.load_state_dict(torch.load(
Data(edge_index=[2, 4164], title=[392], info_text=[392], categories=[392], x=[392, 768])
